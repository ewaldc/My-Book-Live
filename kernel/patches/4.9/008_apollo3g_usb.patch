diff -Naur a/drivers/usb/dwc_otg/Kconfig b/drivers/usb/dwc_otg/Kconfig
--- a/drivers/usb/dwc_otg/Kconfig	1970-01-01 00:00:00.000000000 +0000
+++ b/drivers/usb/dwc_otg/Kconfig	2017-06-20 08:22:21.977758278 +0000
@@ -0,0 +1,86 @@
+menuconfig USB_DWC_OTG
+	bool "Synopsys DWC OTG Controller"
+	depends on 405EZ || 405EX || 460EX || APM821xx
+	select USB_GADGET_DUALSPEED
+	select USB_GADGET_SELECTED
+	---help---
+		This driver provides USB Device Controller support for the
+		Synopsys DesignWare USB OTG Core used on the AMCC 405EZ/405EX/460EX/APM82181.
+		Note that on the 405EZ, this Core provides USB Device Controller function only.
+		It does not act as a true OTG device, and the OTG is slightly misleading.
+
+if USB_DWC_OTG
+
+config DWC_LEGACY_405EX
+	bool "Enable 405EX Legacy Support (lower performance)"
+	default n
+	depends on 405EX
+	select DWC_SLAVE
+	---help---
+		Enable Legacy 405EX Chip support (Rev 1.0) where DWC DMA is broken.
+		Selecting this option will cause lower performance.
+		Do not select this unless you want to support Rev 1.0 405EX chips (obsolete).
+
+menuconfig DWC_OTG_MODE
+	bool "DWC OTG Mode"
+	depends on 405EX || 460EX || APM821xx
+	---help---
+		Enable selection whether USB OTG should operate in Host or
+                Device mode only
+
+if DWC_OTG_MODE
+config DWC_HOST_ONLY
+	bool "DWC Host Only Mode"
+	depends on 405EX || 460EX || APM821xx
+	---help---
+		DWC Core in only host mode.
+
+config DWC_DEVICE_ONLY
+	bool "DWC Device Only Mode"
+	default y if 405EZ
+	---help---
+		DWC Core in only device mode.
+
+endif
+
+config DWC_SLAVE
+	bool "DWC Slave Mode" 
+	depends on 405EX || 460EX || APM821xx
+	default n
+	---help---
+		Slave mode uses the processor to tranfer data.
+		In Slave mode, processor DMA channels can be used if available.
+
+config DWC_USE_PLB_DMA
+	bool "Use PPC4xx PLB DMA (Only for Slave Mode)"
+	depends on DWC_SLAVE
+	depends on 405EX
+	default n
+	select OTG_PLB_DMA
+	select OTG_PLB_DMA_TASKLET
+	select PPC4xx_EDMA
+	---help---
+	 Enable use of PPC4xx DMA engines in Slave Mode.
+	 Please ensure PLB DMA channels not in use by any other block.
+
+if DWC_USE_PLB_DMA
+config OTG_PLB_DMA
+	bool
+	default n
+
+config OTG_PLB_DMA_TASKLET
+	bool
+	default n
+
+config PPC4xx_EDMA
+	bool
+	default n
+endif
+
+config DWC_DEBUG
+	bool "Enable DWC Debugging"
+	default n
+	---help---
+	 Enable DWC driver debugging 
+
+endif #USB_DWC_OTG
diff -Naur a/drivers/usb/dwc_otg/Makefile b/drivers/usb/dwc_otg/Makefile
--- a/drivers/usb/dwc_otg/Makefile	1970-01-01 00:00:00.000000000 +0000
+++ b/drivers/usb/dwc_otg/Makefile	2017-06-20 08:25:57.488758278 +0000
@@ -0,0 +1,12 @@
+#
+# Makefile for DWC_otg Highspeed USB controller driver
+#
+
+KBUILD_CPPFLAGS	+= -Dlinux 
+
+obj-$(CONFIG_USB_DWC_OTG)	+= dwc_otg.o
+
+dwc_otg-y := dwc_otg_driver.o dwc_otg_attr.o dwc_otg_cil.o \
+	    dwc_otg_cil_intr.o dwc_otg_pcd.o dwc_otg_pcd_intr.o \
+	    dwc_otg_hcd.o dwc_otg_hcd_intr.o dwc_otg_hcd_queue.o
+dwc_otg-$(CONFIG_DWC_USE_PLB_DMA) += ppc4xx_dma.o
diff -Naur a/drivers/usb/dwc_otg/built-in.mod.c b/drivers/usb/dwc_otg/built-in.mod.c
--- a/drivers/usb/dwc_otg/built-in.mod.c	1970-01-01 00:00:00.000000000 +0000
+++ b/drivers/usb/dwc_otg/built-in.mod.c	2016-02-19 19:08:08.000000000 +0000
@@ -0,0 +1,17 @@
+#include <linux/module.h>
+#include <linux/vermagic.h>
+#include <linux/compiler.h>
+
+MODULE_INFO(vermagic, VERMAGIC_STRING);
+
+struct module __this_module
+__attribute__((section(".gnu.linkonce.this_module"))) = {
+ .name = KBUILD_MODNAME,
+ .arch = MODULE_ARCH_INIT,
+};
+
+static const char __module_depends[]
+__used
+__attribute__((section(".modinfo"))) =
+"depends=";
+
diff -Naur a/drivers/usb/dwc_otg/dwc_otg.mod.c b/drivers/usb/dwc_otg/dwc_otg.mod.c
--- a/drivers/usb/dwc_otg/dwc_otg.mod.c	1970-01-01 00:00:00.000000000 +0000
+++ b/drivers/usb/dwc_otg/dwc_otg.mod.c	2016-02-19 19:08:08.000000000 +0000
@@ -0,0 +1,17 @@
+#include <linux/module.h>
+#include <linux/vermagic.h>
+#include <linux/compiler.h>
+
+MODULE_INFO(vermagic, VERMAGIC_STRING);
+
+struct module __this_module
+__attribute__((section(".gnu.linkonce.this_module"))) = {
+ .name = KBUILD_MODNAME,
+ .arch = MODULE_ARCH_INIT,
+};
+
+static const char __module_depends[]
+__used
+__attribute__((section(".modinfo"))) =
+"depends=";
+
diff -Naur a/drivers/usb/dwc_otg/dwc_otg_attr.c b/drivers/usb/dwc_otg/dwc_otg_attr.c
--- a/drivers/usb/dwc_otg/dwc_otg_attr.c	1970-01-01 00:00:00.000000000 +0000
+++ b/drivers/usb/dwc_otg/dwc_otg_attr.c	2017-06-22 08:40:09.540169352 +0000
@@ -0,0 +1,661 @@
+/* ==========================================================================
+ * $File: //dwh/usb_iip/dev/software/otg_ipmate/linux/drivers/dwc_otg_attr.c $
+ * $Revision: #5 $
+ * $Date: 2005/09/15 $
+ * $Change: 537387 $
+ *
+ * Synopsys HS OTG Linux Software Driver and documentation (hereinafter,
+ * "Software") is an Unsupported proprietary work of Synopsys, Inc. unless
+ * otherwise expressly agreed to in writing between Synopsys and you.
+ * 
+ * The Software IS NOT an item of Licensed Software or Licensed Product under
+ * any End User Software License Agreement or Agreement for Licensed Product
+ * with Synopsys or any supplement thereto. You are permitted to use and
+ * redistribute this Software in source and binary forms, with or without
+ * modification, provided that redistributions of source code must retain this
+ * notice. You may not view, use, disclose, copy or distribute this file or
+ * any information contained herein except pursuant to this license grant from
+ * Synopsys. If you do not agree with this notice, including the disclaimer
+ * below, then you are not authorized to use the Software.
+ * 
+ * THIS SOFTWARE IS BEING DISTRIBUTED BY SYNOPSYS SOLELY ON AN "AS IS" BASIS
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE HEREBY DISCLAIMED. IN NO EVENT SHALL SYNOPSYS BE LIABLE FOR ANY DIRECT,
+ * INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+ * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+ * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+ * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
+ * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
+ * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH
+ * DAMAGE.
+ * ========================================================================== */
+
+/** @file 
+ *
+ * The diagnostic interface will provide access to the controller for
+ * bringing up the hardware and testing.  The Linux driver attributes
+ * feature will be used to provide the Linux Diagnostic
+ * Interface. These attributes are accessed through sysfs.
+ */
+
+/** @page "Linux Module Attributes" 
+ *
+ * The Linux module attributes feature is used to provide the Linux
+ * Diagnostic Interface.  These attributes are accessed through sysfs.
+ * The diagnostic interface will provide access to the controller for
+ * bringing up the hardware and testing.
+
+
+ The following table shows the attributes.
+ <table>
+ <tr>
+ <td><b> Name</b></td>
+ <td><b> Description</b></td>
+ <td><b> Access</b></td>
+ </tr>
+ 
+ <tr>
+ <td> mode </td>
+ <td> Returns the current mode: 0 for device mode, 1 for host mode</td>
+ <td> Read</td>
+ </tr>
+ 
+ <tr>
+ <td> hnpcapable </td>
+ <td> Gets or sets the "HNP-capable" bit in the Core USB Configuraton Register.
+ Read returns the current value.</td>
+ <td> Read/Write</td>
+ </tr>
+ 
+ <tr>
+ <td> srpcapable </td>
+ <td> Gets or sets the "SRP-capable" bit in the Core USB Configuraton Register.
+ Read returns the current value.</td>
+ <td> Read/Write</td>
+ </tr>
+ 
+ <tr>
+ <td> hnp </td>
+ <td> Initiates the Host Negotiation Protocol.  Read returns the status.</td>
+ <td> Read/Write</td>
+ </tr>
+ 
+ <tr>
+ <td> srp </td>
+ <td> Initiates the Session Request Protocol.  Read returns the status.</td>
+ <td> Read/Write</td>
+ </tr>
+ 
+ <tr>
+ <td> buspower </td>
+ <td> Gets or sets the Power State of the bus (0 - Off or 1 - On)</td>
+ <td> Read/Write</td>
+ </tr>
+ 
+ <tr>
+ <td> bussuspend </td>
+ <td> Suspends the USB bus.</td>
+ <td> Read/Write</td>
+ </tr>
+ 
+ <tr>
+ <td> busconnected </td>
+ <td> Gets the connection status of the bus</td>
+ <td> Read</td>
+ </tr>
+ 
+ <tr>
+ <td> gotgctl </td>
+ <td> Gets or sets the Core Control Status Register.</td>
+ <td> Read/Write</td>
+ </tr>
+ 
+ <tr>
+ <td> gusbcfg </td>
+ <td> Gets or sets the Core USB Configuration Register</td>
+ <td> Read/Write</td>
+ </tr>
+ 
+ <tr>
+ <td> grxfsiz </td>
+ <td> Gets or sets the Receive FIFO Size Register</td>
+ <td> Read/Write</td>
+ </tr>
+ 
+ <tr>
+ <td> gnptxfsiz </td>
+ <td> Gets or sets the non-periodic Transmit Size Register</td>
+ <td> Read/Write</td>
+ </tr>
+ 
+ <tr>
+ <td> gpvndctl </td>
+ <td> Gets or sets the PHY Vendor Control Register</td>
+ <td> Read/Write</td>
+ </tr>
+ 
+ <tr>
+ <td> ggpio </td>
+ <td> Gets the value in the lower 16-bits of the General Purpose IO Register
+ or sets the upper 16 bits.</td>
+ <td> Read/Write</td>
+ </tr>
+ 
+ <tr>
+ <td> guid </td>
+ <td> Gets or sets the value of the User ID Register</td>
+ <td> Read/Write</td>
+ </tr>
+ 
+ <tr>
+ <td> gsnpsid </td>
+ <td> Gets the value of the Synopsys ID Regester</td>
+ <td> Read</td>
+ </tr>
+ 
+ <tr>
+ <td> devspeed </td>
+ <td> Gets or sets the device speed setting in the DCFG register</td>
+ <td> Read/Write</td>
+ </tr>
+ 
+ <tr>
+ <td> enumspeed </td>
+ <td> Gets the device enumeration Speed.</td>
+ <td> Read</td>
+ </tr>
+ 
+ <tr>
+ <td> hptxfsiz </td>
+ <td> Gets the value of the Host Periodic Transmit FIFO</td>
+ <td> Read</td>
+ </tr>
+ 
+ <tr>
+ <td> hprt0 </td>
+ <td> Gets or sets the value in the Host Port Control and Status Register</td>
+ <td> Read/Write</td>
+ </tr>
+ 
+ <tr>
+ <td> regoffset </td>
+ <td> Sets the register offset for the next Register Access</td>
+ <td> Read/Write</td>
+ </tr>
+ 
+ <tr>
+ <td> regvalue </td>
+ <td> Gets or sets the value of the register at the offset in the regoffset attribute.</td>
+ <td> Read/Write</td>
+ </tr>
+ 
+ <tr>
+ <td> remote_wakeup </td>
+ <td> On read, shows the status of Remote Wakeup. On write, initiates a remote
+ wakeup of the host. When bit 0 is 1 and Remote Wakeup is enabled, the Remote
+ Wakeup signalling bit in the Device Control Register is set for 1
+ milli-second.</td>
+ <td> Read/Write</td>
+ </tr>
+ 
+ <tr>
+ <td> regdump </td>
+ <td> Dumps the contents of core registers.</td>
+ <td> Read</td>
+ </tr>
+ 
+ <tr>
+ <td> hcddump </td>
+ <td> Dumps the current HCD state.</td>
+ <td> Read</td>
+ </tr>
+ 
+ <tr>
+ <td> hcd_frrem </td>
+ <td> Shows the average value of the Frame Remaining
+ field in the Host Frame Number/Frame Remaining register when an SOF interrupt
+ occurs. This can be used to determine the average interrupt latency. Also
+ shows the average Frame Remaining value for start_transfer and the "a" and
+ "b" sample points. The "a" and "b" sample points may be used during debugging
+ bto determine how long it takes to execute a section of the HCD code.</td>
+ <td> Read</td>
+ </tr>
+ 
+ <tr>
+ <td> rd_reg_test </td>
+ <td> Displays the time required to read the GNPTXFSIZ register many times
+ (the output shows the number of times the register is read).
+ <td> Read</td>
+ </tr>
+ 
+ <tr>
+ <td> wr_reg_test </td>
+ <td> Displays the time required to write the GNPTXFSIZ register many times
+ (the output shows the number of times the register is written).
+ <td> Read</td>
+ </tr>
+ 
+ </table>
+ 
+ Example usage:
+ To get the current mode:
+ cat /sys/devices/lm0/mode
+ 
+ To power down the USB:
+ echo 0 > /sys/devices/lm0/buspower
+ */
+
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/moduleparam.h>
+#include <linux/init.h>
+#include <linux/device.h>
+#include <linux/errno.h>
+#include <linux/types.h>
+#include <linux/stat.h>  /* permission constants */
+#include <asm/io.h>
+
+#include "dwc_otg_plat.h"
+#include "dwc_otg_attr.h"
+#include "dwc_otg_driver.h"
+#include "dwc_otg_pcd.h"
+#include "dwc_otg_hcd.h"
+
+/* MACROs for defining sysfs attribute */
+#define DWC_OTG_DEVICE_ATTR_BITFIELD_SHOW(_otg_attr_name_,_addr_,_mask_,_shift_,_string_) \
+static ssize_t _otg_attr_name_##_show (struct device *_dev, struct device_attribute *attr, char *buf) \
+{ \
+	dwc_otg_device_t *otg_dev = dev_get_drvdata(_dev);\
+	uint32_t val; \
+	val = dwc_read_reg32 (_addr_); \
+	val = (val & (_mask_)) >> _shift_; \
+	return sprintf (buf, "%s = 0x%x\n", _string_, val); \
+}
+#define DWC_OTG_DEVICE_ATTR_BITFIELD_STORE(_otg_attr_name_,_addr_,_mask_,_shift_,_string_) \
+static ssize_t _otg_attr_name_##_store (struct device *_dev, struct device_attribute *attr, \
+				const char *buf, size_t count) \
+{ \
+	dwc_otg_device_t *otg_dev = dev_get_drvdata(_dev);\
+	uint32_t set = simple_strtoul(buf, NULL, 16); \
+	uint32_t clear = set; \
+	clear = ((~clear) << _shift_) & _mask_; \
+	set = (set << _shift_) & _mask_; \
+	dev_dbg(_dev, "Storing Address=0x%08x Set=0x%08x Clear=0x%08x\n", (uint32_t)_addr_, set, clear); \
+	dwc_modify_reg32(_addr_, clear, set); \
+	return count; \
+}
+
+#define DWC_OTG_DEVICE_ATTR_BITFIELD_RW(_otg_attr_name_,_addr_,_mask_,_shift_,_string_) \
+DWC_OTG_DEVICE_ATTR_BITFIELD_SHOW(_otg_attr_name_,_addr_,_mask_,_shift_,_string_) \
+DWC_OTG_DEVICE_ATTR_BITFIELD_STORE(_otg_attr_name_,_addr_,_mask_,_shift_,_string_) \
+DEVICE_ATTR(_otg_attr_name_,0644,_otg_attr_name_##_show,_otg_attr_name_##_store);
+
+#define DWC_OTG_DEVICE_ATTR_BITFIELD_RO(_otg_attr_name_,_addr_,_mask_,_shift_,_string_) \
+DWC_OTG_DEVICE_ATTR_BITFIELD_SHOW(_otg_attr_name_,_addr_,_mask_,_shift_,_string_) \
+DEVICE_ATTR(_otg_attr_name_,0444,_otg_attr_name_##_show,NULL);
+
+/* MACROs for defining sysfs attribute for 32-bit registers */
+#define DWC_OTG_DEVICE_ATTR_REG_SHOW(_otg_attr_name_,_addr_,_string_) \
+static ssize_t _otg_attr_name_##_show (struct device *_dev, \
+				struct device_attribute *attr, char *buf) {\
+	dwc_otg_device_t *otg_dev = dev_get_drvdata(_dev);\
+	uint32_t val; \
+	val = dwc_read_reg32 (_addr_); \
+	return sprintf (buf, "%s = 0x%08x\n", _string_, val); \
+}
+#define DWC_OTG_DEVICE_ATTR_REG_STORE(_otg_attr_name_,_addr_,_string_) \
+static ssize_t _otg_attr_name_##_store (struct device *_dev, \
+				struct device_attribute *attr, const char *buf, size_t count) {\
+	dwc_otg_device_t *otg_dev = dev_get_drvdata(_dev);\
+	uint32_t val = simple_strtoul(buf, NULL, 16); \
+	dev_dbg(_dev, "Storing Address=0x%08x Val=0x%08x\n", (uint32_t)_addr_, val); \
+	dwc_write_reg32(_addr_, val); \
+	return count; \
+}
+
+#define DWC_OTG_DEVICE_ATTR_REG32_RW(_otg_attr_name_,_addr_,_string_) \
+DWC_OTG_DEVICE_ATTR_REG_SHOW(_otg_attr_name_,_addr_,_string_) \
+DWC_OTG_DEVICE_ATTR_REG_STORE(_otg_attr_name_,_addr_,_string_) \
+DEVICE_ATTR(_otg_attr_name_,0644,_otg_attr_name_##_show,_otg_attr_name_##_store);
+
+#define DWC_OTG_DEVICE_ATTR_REG32_RO(_otg_attr_name_,_addr_,_string_) \
+DWC_OTG_DEVICE_ATTR_REG_SHOW(_otg_attr_name_,_addr_,_string_) \
+DEVICE_ATTR(_otg_attr_name_,0444,_otg_attr_name_##_show,NULL);
+
+
+/** @name Functions for Show/Store of Attributes */
+/* Show the register offset of the Register Access. */
+static ssize_t regoffset_show(struct device *_dev,	struct device_attribute *attr, char *buf){
+	dwc_otg_device_t *otg_dev = dev_get_drvdata(_dev);
+	return snprintf(buf, sizeof("0xFFFFFFFF\n")+1,"0x%08x\n", otg_dev->reg_offset);
+}
+
+/* Set the register offset for the next Register Access	Read/Write */
+static ssize_t regoffset_store( struct device *_dev, struct device_attribute *attr, const char *buf, 
+                                size_t count ) {
+	dwc_otg_device_t *otg_dev = dev_get_drvdata(_dev);
+	uint32_t offset = simple_strtoul(buf, NULL, 16);
+	//dev_dbg(_dev, "Offset=0x%08x\n", offset);
+	if (offset < SZ_256K ) otg_dev->reg_offset = offset;
+	else dev_err( _dev, "invalid offset\n" );
+	return count;
+}
+DEVICE_ATTR(regoffset, S_IRUGO|S_IWUSR, regoffset_show, regoffset_store);
+
+/* Show the value of the register at the offset in the reg_offset attribute */
+static ssize_t regvalue_show(struct device *dev, struct device_attribute *attr, char *buf) {
+	dwc_otg_device_t *otg_dev = dev_get_drvdata(dev);
+	uint32_t val;
+	volatile uint32_t *addr;
+        
+	if (otg_dev->reg_offset != 0xFFFFFFFF &&  0 != otg_dev->base) {
+		/* Calculate the address */
+		addr = (uint32_t*)(otg_dev->reg_offset + (uint8_t*)otg_dev->base);
+		//dev_dbg(_dev, "@0x%08x\n", (unsigned)addr); 
+		val = dwc_read_reg32(addr);             
+		return snprintf(buf, 4+10+3+10+1, "Reg@0x%06x = 0x%08x\n", otg_dev->reg_offset, val);
+	} else {
+		dev_err(dev, "Invalid offset (0x%0x)\n", otg_dev->reg_offset);
+		return sprintf(buf, "invalid offset\n" );
+	}
+}
+
+/* Store the value in the register at the offset in the reg_offset attribute */
+static ssize_t regvalue_store(struct device *_dev, struct device_attribute *attr,
+	const char *buf, size_t count) {
+	dwc_otg_device_t *otg_dev = dev_get_drvdata(_dev);
+	uint32_t val = simple_strtoul(buf, NULL, 16);
+	//dev_dbg(_dev, "Offset=0x%08x Val=0x%08x\n", otg_dev->reg_offset, val);
+	if (otg_dev->reg_offset != 0xFFFFFFFF && 0 != otg_dev->base)
+		/* Calculate the address */
+		dwc_write_reg32((uint32_t*)(otg_dev->reg_offset + (uint8_t*)otg_dev->base), val );
+	else dev_err(_dev, "Invalid Register Offset (0x%08x)\n", otg_dev->reg_offset);
+	return count;
+}
+DEVICE_ATTR(regvalue,  S_IRUGO|S_IWUSR, regvalue_show, regvalue_store);
+
+/* Attributes */
+DWC_OTG_DEVICE_ATTR_BITFIELD_RO(mode,&(otg_dev->core_if->core_global_regs->gotgctl),(1<<20),20,"Mode");
+DWC_OTG_DEVICE_ATTR_BITFIELD_RW(hnpcapable,&(otg_dev->core_if->core_global_regs->gusbcfg),(1<<9),9,"Mode");
+DWC_OTG_DEVICE_ATTR_BITFIELD_RW(srpcapable,&(otg_dev->core_if->core_global_regs->gusbcfg),(1<<8),8,"Mode");
+
+//DWC_OTG_DEVICE_ATTR_BITFIELD_RW(buspower,&(otg_dev->core_if->core_global_regs->gotgctl),(1<<8),8,"Mode");
+//DWC_OTG_DEVICE_ATTR_BITFIELD_RW(bussuspend,&(otg_dev->core_if->core_global_regs->gotgctl),(1<<8),8,"Mode");
+DWC_OTG_DEVICE_ATTR_BITFIELD_RO(busconnected,otg_dev->core_if->host_if->hprt0,0x01,0,"Bus Connected");
+
+DWC_OTG_DEVICE_ATTR_REG32_RW(gotgctl,&(otg_dev->core_if->core_global_regs->gotgctl),"GOTGCTL");
+DWC_OTG_DEVICE_ATTR_REG32_RW(gusbcfg,&(otg_dev->core_if->core_global_regs->gusbcfg),"GUSBCFG");
+DWC_OTG_DEVICE_ATTR_REG32_RW(grxfsiz,&(otg_dev->core_if->core_global_regs->grxfsiz),"GRXFSIZ");
+DWC_OTG_DEVICE_ATTR_REG32_RW(gnptxfsiz,&(otg_dev->core_if->core_global_regs->gnptxfsiz),"GNPTXFSIZ");
+DWC_OTG_DEVICE_ATTR_REG32_RW(gpvndctl,&(otg_dev->core_if->core_global_regs->gpvndctl),"GPVNDCTL");
+DWC_OTG_DEVICE_ATTR_REG32_RW(ggpio,&(otg_dev->core_if->core_global_regs->ggpio),"GGPIO");
+DWC_OTG_DEVICE_ATTR_REG32_RW(guid,&(otg_dev->core_if->core_global_regs->guid),"GUID");
+DWC_OTG_DEVICE_ATTR_REG32_RO(gsnpsid,&(otg_dev->core_if->core_global_regs->gsnpsid),"GSNPSID");
+DWC_OTG_DEVICE_ATTR_BITFIELD_RW(devspeed,&(otg_dev->core_if->dev_if->dev_global_regs->dcfg),0x3,0,"Device Speed");
+DWC_OTG_DEVICE_ATTR_BITFIELD_RO(enumspeed,&(otg_dev->core_if->dev_if->dev_global_regs->dsts),0x6,1,"Device Enumeration Speed");
+
+DWC_OTG_DEVICE_ATTR_REG32_RO(hptxfsiz,&(otg_dev->core_if->core_global_regs->hptxfsiz),"HPTXFSIZ");
+DWC_OTG_DEVICE_ATTR_REG32_RW(hprt0,otg_dev->core_if->host_if->hprt0,"HPRT0");
+
+
+/* Add code to initiate the HNP */
+/* Show the HNP status bit */
+static ssize_t hnp_show( struct device *_dev, struct device_attribute *attr, char *buf) {
+	dwc_otg_device_t *otg_dev = dev_get_drvdata(_dev);
+	gotgctl_data_t val;
+	val.d32 = dwc_read_reg32 (&(otg_dev->core_if->core_global_regs->gotgctl));
+	return sprintf (buf, "HstNegScs = 0x%x\n", val.b.hstnegscs);
+}
+
+/* Set the HNP Request bit */
+static ssize_t hnp_store(struct device *_dev, struct device_attribute *attr, const char *buf, 
+			  size_t count) {
+	dwc_otg_device_t *otg_dev = dev_get_drvdata(_dev);
+	uint32_t in = simple_strtoul(buf, NULL, 16);
+	uint32_t *addr = (uint32_t *)&(otg_dev->core_if->core_global_regs->gotgctl);
+	gotgctl_data_t mem;
+	mem.d32 = dwc_read_reg32(addr);
+	mem.b.hnpreq = in;
+	dev_dbg(_dev, "Storing Address=0x%08x Data=0x%08x\n", (uint32_t)addr, mem.d32);
+	dwc_write_reg32(addr, mem.d32);
+	return count;
+}
+DEVICE_ATTR(hnp, 0644, hnp_show, hnp_store);
+
+/* Add code to initiate the SRP */
+/* Show the SRP status bit */
+static ssize_t srp_show( struct device *_dev, struct device_attribute *attr, char *buf) {
+#ifndef CONFIG_DWC_HOST_ONLY
+	dwc_otg_device_t *otg_dev = dev_get_drvdata(_dev);
+	gotgctl_data_t val;
+	val.d32 = dwc_read_reg32 (&(otg_dev->core_if->core_global_regs->gotgctl));
+	return sprintf (buf, "SesReqScs = 0x%x\n", val.b.sesreqscs);
+#else
+	return sprintf(buf, "Host Only Mode!\n");
+#endif
+}
+
+/* Set the SRP Request bit */
+static ssize_t srp_store(struct device *_dev, struct device_attribute *attr, const char *buf, 
+			  size_t count) {
+#ifndef CONFIG_DWC_HOST_ONLY
+	dwc_otg_device_t *otg_dev = dev_get_drvdata(_dev);
+	dwc_otg_pcd_initiate_srp(otg_dev->pcd);
+#endif
+	return count;
+}
+DEVICE_ATTR(srp, 0644, srp_show, srp_store);
+
+/* Need to do more for power on/off? */
+/* Show the Bus Power status */
+static ssize_t buspower_show( struct device *_dev, struct device_attribute *attr, char *buf) {
+	dwc_otg_device_t *otg_dev = dev_get_drvdata(_dev);
+	hprt0_data_t val;
+	val.d32 = dwc_read_reg32 (otg_dev->core_if->host_if->hprt0);
+	return sprintf (buf, "Bus Power = 0x%x\n", val.b.prtpwr);
+}
+
+
+/* Set the Bus Power status */
+static ssize_t buspower_store(struct device *_dev, struct device_attribute *attr, const char *buf, 
+    size_t count) {
+	dwc_otg_device_t *otg_dev = dev_get_drvdata(_dev);
+	uint32_t on = simple_strtoul(buf, NULL, 16);
+	uint32_t *addr = (uint32_t *)otg_dev->core_if->host_if->hprt0;
+	hprt0_data_t mem;
+
+	mem.d32 = dwc_read_reg32(addr);
+	mem.b.prtpwr = on;
+
+	//dev_dbg(_dev, "Storing Address=0x%08x Data=0x%08x\n", (uint32_t)addr, mem.d32);
+	dwc_write_reg32(addr, mem.d32);
+
+	return count;
+}
+DEVICE_ATTR(buspower, 0644, buspower_show, buspower_store);
+
+/* Need to do more for suspend? */
+/* Show the Bus Suspend status */
+static ssize_t bussuspend_show( struct device *_dev, struct device_attribute *attr, char *buf) {
+	dwc_otg_device_t *otg_dev = dev_get_drvdata(_dev);
+	hprt0_data_t val;
+	val.d32 = dwc_read_reg32 (otg_dev->core_if->host_if->hprt0);
+	return sprintf (buf, "Bus Suspend = 0x%x\n", val.b.prtsusp);
+}
+
+/* Set the Bus Suspend status */
+static ssize_t bussuspend_store(struct device *_dev, struct device_attribute *attr, const char *buf, 
+    size_t count) {
+	dwc_otg_device_t *otg_dev = dev_get_drvdata(_dev);
+	uint32_t in = simple_strtoul(buf, NULL, 16);
+	uint32_t *addr = (uint32_t *)otg_dev->core_if->host_if->hprt0;
+	hprt0_data_t mem;
+	mem.d32 = dwc_read_reg32(addr);
+	mem.b.prtsusp = in;
+	dev_dbg(_dev, "Storing Address=0x%08x Data=0x%08x\n", (uint32_t)addr, mem.d32);
+	dwc_write_reg32(addr, mem.d32);
+	return count;
+}
+DEVICE_ATTR(bussuspend, 0644, bussuspend_show, bussuspend_store);
+
+/* Show the status of Remote Wakeup */
+static ssize_t remote_wakeup_show(struct device *_dev, struct device_attribute *attr, char *buf) {
+#ifndef CONFIG_DWC_HOST_ONLY
+	dwc_otg_device_t *otg_dev = dev_get_drvdata(_dev);
+	dctl_data_t val;
+	val.d32 = dwc_read_reg32( &otg_dev->core_if->dev_if->dev_global_regs->dctl);
+	return sprintf(buf, "Remote Wakeup = %d Enabled = %d\n", 
+					val.b.rmtwkupsig, otg_dev->pcd->remote_wakeup_enable);
+#else
+	return sprintf(buf, "Host Only Mode!\n");
+#endif
+}
+
+/* Initiate a remote wakeup of the host.  The Device control register
+ * Remote Wakeup Signal bit is written if the PCD Remote wakeup enable flag is set */
+static ssize_t remote_wakeup_store( struct device *_dev, struct device_attribute *attr, 
+	const char *buf, size_t count) {
+#ifndef CONFIG_DWC_HOST_ONLY
+	uint32_t val = simple_strtoul(buf, NULL, 16);        
+	dwc_otg_device_t *otg_dev = dev_get_drvdata(_dev);
+	if (val&1) dwc_otg_pcd_remote_wakeup(otg_dev->pcd, 1);
+	else dwc_otg_pcd_remote_wakeup(otg_dev->pcd, 0);
+#endif
+	return count;
+}
+DEVICE_ATTR(remote_wakeup,  S_IRUGO|S_IWUSR, remote_wakeup_show, remote_wakeup_store);
+
+/* Dump global registers + host or device registers based on the current mode of the core */
+static ssize_t regdump_show(struct device *_dev, struct device_attribute *attr, char *buf){
+	dwc_otg_device_t *otg_dev = dev_get_drvdata(_dev);
+	printk("%s otg_dev=0x%p\n", __FUNCTION__, otg_dev);
+	dwc_otg_dump_global_registers( otg_dev->core_if);
+	if (dwc_otg_is_host_mode(otg_dev->core_if)) dwc_otg_dump_host_registers( otg_dev->core_if);
+	else dwc_otg_dump_dev_registers( otg_dev->core_if);
+   	return sprintf( buf, "Register Dump\n" );
+}
+DEVICE_ATTR(regdump, S_IRUGO|S_IWUSR, regdump_show, 0);
+
+/* Dump the current hcd state */
+static ssize_t hcddump_show(struct device *_dev, struct device_attribute *attr, char *buf) {
+#ifndef CONFIG_DWC_DEVICE_ONLY
+	dwc_otg_device_t *otg_dev = dev_get_drvdata(_dev);
+	dwc_otg_hcd_dump_state(otg_dev->hcd);
+#endif
+   	return sprintf( buf, "HCD Dump\n" );
+}
+DEVICE_ATTR(hcddump, S_IRUGO|S_IWUSR, hcddump_show, 0);
+
+/* Dump the average frame remaining at SOF. This can be used to determine average interrupt
+ * latency. Frame remaining is also shown forstart transfer and two additional sample points */
+static ssize_t hcd_frrem_show(struct device *_dev, struct device_attribute *attr, char *buf){
+#ifndef CONFIG_DWC_DEVICE_ONLY
+	dwc_otg_device_t *otg_dev = dev_get_drvdata(_dev);
+	dwc_otg_hcd_dump_frrem(otg_dev->hcd);
+#endif
+   	return sprintf( buf, "HCD Dump Frame Remaining\n" );
+}
+
+DEVICE_ATTR(hcd_frrem, S_IRUGO|S_IWUSR, hcd_frrem_show, 0);
+
+/* Displays the time required to read the GNPTXFSIZ register many times (the
+ * output shows the number of times the register is read) */
+#define RW_REG_COUNT 10000000
+#define MSEC_PER_JIFFIE 1000/HZ	
+static ssize_t rd_reg_test_show( struct device *_dev, struct device_attribute *attr, char *buf){
+	int i, time, start_jiffies;
+	dwc_otg_device_t *otg_dev = dev_get_drvdata(_dev);
+	printk("HZ %d, MSEC_PER_JIFFIE %d, loops_per_jiffy %lu\n", HZ, MSEC_PER_JIFFIE, loops_per_jiffy);
+	start_jiffies = jiffies;
+	for (i = 0; i < RW_REG_COUNT; i++)
+		dwc_read_reg32(&otg_dev->core_if->core_global_regs->gnptxfsiz);
+	time = jiffies - start_jiffies;
+   	return sprintf( buf, "Time to read GNPTXFSIZ reg %d times: %d msecs (%d jiffies)\n",
+			RW_REG_COUNT, time * MSEC_PER_JIFFIE, time );
+}
+
+DEVICE_ATTR(rd_reg_test, S_IRUGO|S_IWUSR, rd_reg_test_show, 0);
+
+/* Displays the time required to write the GNPTXFSIZ register many times (the
+ * output shows the number of times the register is written) */
+static ssize_t wr_reg_test_show( struct device *_dev, struct device_attribute *attr, char *buf) {
+	int i, time, start_jiffies;
+	dwc_otg_device_t *otg_dev = dev_get_drvdata(_dev);
+	uint32_t reg_val;
+
+	printk("HZ %d, MSEC_PER_JIFFIE %d, loops_per_jiffy %lu\n", HZ, MSEC_PER_JIFFIE, loops_per_jiffy);
+	reg_val = dwc_read_reg32(&otg_dev->core_if->core_global_regs->gnptxfsiz);
+	start_jiffies = jiffies;
+	for (i = 0; i < RW_REG_COUNT; i++)
+		dwc_write_reg32(&otg_dev->core_if->core_global_regs->gnptxfsiz, reg_val);
+	time = jiffies - start_jiffies;
+   	return sprintf( buf, "Time to write GNPTXFSIZ reg %d times: %d msecs (%d jiffies)\n",
+			RW_REG_COUNT, time * MSEC_PER_JIFFIE, time);
+}
+DEVICE_ATTR(wr_reg_test, S_IRUGO|S_IWUSR, wr_reg_test_show, 0);
+
+/* Create the device files */
+void dwc_otg_attr_create (struct device *dev) {
+	int ret_val = 0;
+	ret_val = device_create_file(dev, &dev_attr_regoffset);
+	ret_val = device_create_file(dev, &dev_attr_regvalue);
+	ret_val = device_create_file(dev, &dev_attr_mode);
+	ret_val = device_create_file(dev, &dev_attr_hnpcapable);
+	ret_val = device_create_file(dev, &dev_attr_srpcapable);
+	ret_val = device_create_file(dev, &dev_attr_hnp);
+	ret_val = device_create_file(dev, &dev_attr_srp);
+	ret_val = device_create_file(dev, &dev_attr_buspower);
+	ret_val = device_create_file(dev, &dev_attr_bussuspend);
+	ret_val = device_create_file(dev, &dev_attr_busconnected);
+	ret_val = device_create_file(dev, &dev_attr_gotgctl);
+	ret_val = device_create_file(dev, &dev_attr_gusbcfg);
+	ret_val = device_create_file(dev, &dev_attr_grxfsiz);
+	ret_val = device_create_file(dev, &dev_attr_gnptxfsiz);
+	ret_val = device_create_file(dev, &dev_attr_gpvndctl);
+	ret_val = device_create_file(dev, &dev_attr_ggpio);
+	ret_val = device_create_file(dev, &dev_attr_guid);
+	ret_val = device_create_file(dev, &dev_attr_gsnpsid);
+	ret_val = device_create_file(dev, &dev_attr_devspeed);
+	ret_val = device_create_file(dev, &dev_attr_enumspeed);
+	ret_val = device_create_file(dev, &dev_attr_hptxfsiz);
+	ret_val = device_create_file(dev, &dev_attr_hprt0);
+	ret_val = device_create_file(dev, &dev_attr_remote_wakeup);
+	ret_val = device_create_file(dev, &dev_attr_regdump);
+	ret_val = device_create_file(dev, &dev_attr_hcddump);
+	ret_val = device_create_file(dev, &dev_attr_hcd_frrem);
+	ret_val = device_create_file(dev, &dev_attr_rd_reg_test);
+	ret_val = device_create_file(dev, &dev_attr_wr_reg_test);
+}
+
+/* Remove the device files */
+void dwc_otg_attr_remove (struct device *dev) {
+	device_remove_file(dev, &dev_attr_regoffset);
+	device_remove_file(dev, &dev_attr_regvalue);
+	device_remove_file(dev, &dev_attr_mode);
+	device_remove_file(dev, &dev_attr_hnpcapable);
+	device_remove_file(dev, &dev_attr_srpcapable);
+	device_remove_file(dev, &dev_attr_hnp);
+	device_remove_file(dev, &dev_attr_srp);
+	device_remove_file(dev, &dev_attr_buspower);
+	device_remove_file(dev, &dev_attr_bussuspend);
+	device_remove_file(dev, &dev_attr_busconnected);
+	device_remove_file(dev, &dev_attr_gotgctl);
+	device_remove_file(dev, &dev_attr_gusbcfg);
+	device_remove_file(dev, &dev_attr_grxfsiz);
+	device_remove_file(dev, &dev_attr_gnptxfsiz);
+	device_remove_file(dev, &dev_attr_gpvndctl);
+	device_remove_file(dev, &dev_attr_ggpio);
+	device_remove_file(dev, &dev_attr_guid);
+	device_remove_file(dev, &dev_attr_gsnpsid);
+	device_remove_file(dev, &dev_attr_devspeed);
+	device_remove_file(dev, &dev_attr_enumspeed);
+	device_remove_file(dev, &dev_attr_hptxfsiz);
+	device_remove_file(dev, &dev_attr_hprt0);      
+	device_remove_file(dev, &dev_attr_remote_wakeup);      
+	device_remove_file(dev, &dev_attr_regdump);
+	device_remove_file(dev, &dev_attr_hcddump);
+	device_remove_file(dev, &dev_attr_hcd_frrem);
+	device_remove_file(dev, &dev_attr_rd_reg_test);
+	device_remove_file(dev, &dev_attr_wr_reg_test);
+}
diff -Naur a/drivers/usb/dwc_otg/dwc_otg_attr.h b/drivers/usb/dwc_otg/dwc_otg_attr.h
--- a/drivers/usb/dwc_otg/dwc_otg_attr.h	1970-01-01 00:00:00.000000000 +0000
+++ b/drivers/usb/dwc_otg/dwc_otg_attr.h	2017-06-21 17:15:32.266557439 +0000
@@ -0,0 +1,67 @@
+/* ==========================================================================
+ * $File: //dwh/usb_iip/dev/software/otg_ipmate/linux/drivers/dwc_otg_attr.h $
+ * $Revision: #1 $
+ * $Date: 2005/07/07 $
+ * $Change: 510275 $
+ *
+ * Synopsys HS OTG Linux Software Driver and documentation (hereinafter,
+ * "Software") is an Unsupported proprietary work of Synopsys, Inc. unless
+ * otherwise expressly agreed to in writing between Synopsys and you.
+ * 
+ * The Software IS NOT an item of Licensed Software or Licensed Product under
+ * any End User Software License Agreement or Agreement for Licensed Product
+ * with Synopsys or any supplement thereto. You are permitted to use and
+ * redistribute this Software in source and binary forms, with or without
+ * modification, provided that redistributions of source code must retain this
+ * notice. You may not view, use, disclose, copy or distribute this file or
+ * any information contained herein except pursuant to this license grant from
+ * Synopsys. If you do not agree with this notice, including the disclaimer
+ * below, then you are not authorized to use the Software.
+ * 
+ * THIS SOFTWARE IS BEING DISTRIBUTED BY SYNOPSYS SOLELY ON AN "AS IS" BASIS
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE HEREBY DISCLAIMED. IN NO EVENT SHALL SYNOPSYS BE LIABLE FOR ANY DIRECT,
+ * INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+ * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+ * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+ * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
+ * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
+ * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH
+ * DAMAGE.
+ * ========================================================================== */
+
+#if !defined(__DWC_OTG_ATTR_H__)
+#define __DWC_OTG_ATTR_H__
+
+/** @file
+ * This file contains the interface to the Linux device attributes.
+ */
+extern struct device_attribute dev_attr_regoffset;
+extern struct device_attribute dev_attr_regvalue;
+
+extern struct device_attribute dev_attr_mode;
+extern struct device_attribute dev_attr_hnpcapable;
+extern struct device_attribute dev_attr_srpcapable;
+extern struct device_attribute dev_attr_hnp;
+extern struct device_attribute dev_attr_srp;
+extern struct device_attribute dev_attr_buspower;
+extern struct device_attribute dev_attr_bussuspend;
+extern struct device_attribute dev_attr_busconnected;
+extern struct device_attribute dev_attr_gotgctl;
+extern struct device_attribute dev_attr_gusbcfg;
+extern struct device_attribute dev_attr_grxfsiz;
+extern struct device_attribute dev_attr_gnptxfsiz;
+extern struct device_attribute dev_attr_gpvndctl;
+extern struct device_attribute dev_attr_ggpio;
+extern struct device_attribute dev_attr_guid;
+extern struct device_attribute dev_attr_gsnpsid;
+extern struct device_attribute dev_attr_devspeed;
+extern struct device_attribute dev_attr_enumspeed;
+extern struct device_attribute dev_attr_hptxfsiz;
+extern struct device_attribute dev_attr_hprt0;
+
+void dwc_otg_attr_create (struct device *dev);
+void dwc_otg_attr_remove (struct device *dev);
+
+#endif
diff -Naur a/drivers/usb/dwc_otg/dwc_otg_cil.c b/drivers/usb/dwc_otg/dwc_otg_cil.c
--- a/drivers/usb/dwc_otg/dwc_otg_cil.c	1970-01-01 00:00:00.000000000 +0000
+++ b/drivers/usb/dwc_otg/dwc_otg_cil.c	2017-06-22 08:13:15.302658031 +0000
@@ -0,0 +1,3236 @@
+/* ==========================================================================
+ * $File: //dwh/usb_iip/dev/software/otg_ipmate/linux/drivers/dwc_otg_cil.c $
+ * $Revision: #24 $
+ * $Date: 2007/02/07 $
+ * $Change: 791271 $
+ *
+ * Synopsys HS OTG Linux Software Driver and documentation (hereinafter,
+ * "Software") is an Unsupported proprietary work of Synopsys, Inc. unless
+ * otherwise expressly agreed to in writing between Synopsys and you.
+ *
+ * The Software IS NOT an item of Licensed Software or Licensed Product under
+ * any End User Software License Agreement or Agreement for Licensed Product
+ * with Synopsys or any supplement thereto. You are permitted to use and
+ * redistribute this Software in source and binary forms, with or without
+ * modification, provided that redistributions of source code must retain this
+ * notice. You may not view, use, disclose, copy or distribute this file or
+ * any information contained herein except pursuant to this license grant from
+ * Synopsys. If you do not agree with this notice, including the disclaimer
+ * below, then you are not authorized to use the Software.
+ *
+ * THIS SOFTWARE IS BEING DISTRIBUTED BY SYNOPSYS SOLELY ON AN "AS IS" BASIS
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE HEREBY DISCLAIMED. IN NO EVENT SHALL SYNOPSYS BE LIABLE FOR ANY DIRECT,
+ * INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+ * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+ * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+ * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
+ * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
+ * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH
+ * DAMAGE.
+ * ========================================================================== */
+
+
+/** @file
+ *
+ * The Core Interface Layer provides basic services for accessing and
+ * managing the DWC_otg hardware. These services are used by both the
+ * Host Controller Driver and the Peripheral Controller Driver.
+ *
+ * The CIL manages the memory map for the core so that the HCD and PCD
+ * don't have to do this separately. It also handles basic tasks like
+ * reading/writing the registers and data FIFOs in the controller.
+ * Some of the data access functions provide encapsulation of several
+ * operations required to perform a task, such as writing multiple
+ * registers to start a transfer. Finally, the CIL performs basic
+ * services that are not specific to either the host or device modes
+ * of operation. These services include management of the OTG Host
+ * Negotiation Protocol (HNP) and Session Request Protocol (SRP). A
+ * Diagnostic API is also provided to allow testing of the controller
+ * hardware.
+ *
+ * The Core Interface Layer has the following requirements:
+ * - Provides basic controller operations.
+ * - Minimal use of OS services.
+ * - The OS services used will be abstracted by using inline functions
+ *	 or macros.
+ *
+ */
+#include <asm/unaligned.h>
+#ifdef CONFIG_DWC_DEBUG
+#include <linux/jiffies.h>
+#endif	/*  */
+
+#include <asm/dcr.h>
+#include "dwc_otg_plat.h"
+#include "dwc_otg_regs.h"
+#include "dwc_otg_cil.h"
+
+#ifdef CONFIG_OTG_PLB_DMA_TASKLET
+atomic_t release_later = ATOMIC_INIT(0);
+#endif
+/**
+ * This function is called to initialize the DWC_otg CSR data
+ * structures.	The register addresses in the device and host
+ * structures are initialized from the base address supplied by the
+ * caller.	The calling function must make the OS calls to get the
+ * base address of the DWC_otg controller registers.  The core_params
+ * argument holds the parameters that specify how the core should be
+ * configured.
+ *
+ * @param[in] _reg_base_addr Base address of DWC_otg core registers
+ * @param[in] _core_params Pointer to the core configuration parameters
+ *
+ */
+dwc_otg_core_if_t * dwc_otg_cil_init(const uint32_t * _reg_base_addr,
+	dwc_otg_core_params_t *_core_params)
+{
+	dwc_otg_core_if_t * core_if = 0;
+	dwc_otg_dev_if_t * dev_if = 0;
+	dwc_otg_host_if_t * host_if = 0;
+	uint8_t * reg_base = (uint8_t *) _reg_base_addr;
+	int i = 0;
+	DWC_DEBUGPL(DBG_CILV, "%s(%p,%p)\n", __func__, _reg_base_addr,
+		      _core_params);
+	core_if = kmalloc(sizeof(dwc_otg_core_if_t), GFP_KERNEL);
+	if (core_if == 0) {
+		DWC_DEBUGPL(DBG_CIL,"Allocation of dwc_otg_core_if_t failed\n");
+		return 0;
+	}
+	memset(core_if, 0, sizeof(dwc_otg_core_if_t));
+	core_if->core_params = _core_params;
+	core_if->core_global_regs = (dwc_otg_core_global_regs_t *) reg_base;
+
+    /*
+     * Allocate the Device Mode structures.
+     */
+	dev_if = kmalloc(sizeof(dwc_otg_dev_if_t), GFP_KERNEL);
+	if (dev_if == 0) {
+		DWC_DEBUGPL(DBG_CIL,"Allocation of dwc_otg_dev_if_t failed\n");
+		kfree(core_if);
+		return 0;
+	}
+	dev_if->dev_global_regs = (dwc_otg_device_global_regs_t *)(reg_base +
+					      DWC_DEV_GLOBAL_REG_OFFSET);
+	for (i = 0; i < MAX_EPS_CHANNELS; i++) {
+		dev_if->in_ep_regs[i] = (dwc_otg_dev_in_ep_regs_t *)
+		    (reg_base + DWC_DEV_IN_EP_REG_OFFSET + (i * DWC_EP_REG_OFFSET));
+		dev_if->out_ep_regs[i] = (dwc_otg_dev_out_ep_regs_t *)
+		    (reg_base + DWC_DEV_OUT_EP_REG_OFFSET + (i * DWC_EP_REG_OFFSET));
+		DWC_DEBUGPL(DBG_CILV, "in_ep_regs[%d]->diepctl=%p\n", i,
+			     &dev_if->in_ep_regs[i]->diepctl);
+		DWC_DEBUGPL(DBG_CILV, "out_ep_regs[%d]->doepctl=%p\n", i,
+			     &dev_if->out_ep_regs[i]->doepctl);
+	}
+	dev_if->speed = 0;	// unknown
+	core_if->dev_if = dev_if;
+
+    /*
+     * Allocate the Host Mode structures.
+     */
+	host_if = kmalloc(sizeof(dwc_otg_host_if_t), GFP_KERNEL);
+	if (host_if == 0) {
+		DWC_DEBUGPL(DBG_CIL,"Allocation of dwc_otg_host_if_t failed\n");
+		kfree(dev_if);
+		kfree(core_if);
+		return 0;
+	}
+	host_if->host_global_regs = (dwc_otg_host_global_regs_t *)
+	    (reg_base + DWC_OTG_HOST_GLOBAL_REG_OFFSET);
+	host_if->hprt0 = (uint32_t *) (reg_base + DWC_OTG_HOST_PORT_REGS_OFFSET);
+
+	for (i = 0; i < MAX_EPS_CHANNELS; i++) {
+		host_if->hc_regs[i] = (dwc_otg_hc_regs_t *)
+		    (reg_base + DWC_OTG_HOST_CHAN_REGS_OFFSET + (i * DWC_OTG_CHAN_REGS_OFFSET));
+		DWC_DEBUGPL(DBG_CILV, "hc_reg[%d]->hcchar=%p\n", i,&host_if->hc_regs[i]->hcchar);
+	}
+
+	host_if->num_host_channels = MAX_EPS_CHANNELS;
+	core_if->host_if = host_if;
+	for (i = 0; i < MAX_EPS_CHANNELS; i++) {
+		core_if->data_fifo[i] =
+		    (uint32_t *) (reg_base + DWC_OTG_DATA_FIFO_OFFSET +
+				  (i * DWC_OTG_DATA_FIFO_SIZE));
+		DWC_DEBUGPL(DBG_CILV, "data_fifo[%d]=0x%08x\n", i,
+			     (unsigned)core_if->data_fifo[i]);
+	}
+	core_if->pcgcctl = (uint32_t *) (reg_base + DWC_OTG_PCGCCTL_OFFSET);
+
+    /*
+     * Store the contents of the hardware configuration registers here for
+     * easy access later.
+     */
+	core_if->hwcfg1.d32 = dwc_read_reg32(&core_if->core_global_regs->ghwcfg1);
+	core_if->hwcfg2.d32 = dwc_read_reg32(&core_if->core_global_regs->ghwcfg2);
+#ifdef CONFIG_DWC_SLAVE
+	core_if->hwcfg2.b.architecture =  DWC_SLAVE_ONLY_ARCH;
+#endif
+	core_if->hwcfg3.d32 = dwc_read_reg32(&core_if->core_global_regs->ghwcfg3);
+	core_if->hwcfg4.d32 = dwc_read_reg32(&core_if->core_global_regs->ghwcfg4);
+	DWC_DEBUGPL(DBG_CILV, "hwcfg1=%08x\n", core_if->hwcfg1.d32);
+	DWC_DEBUGPL(DBG_CILV, "hwcfg2=%08x\n", core_if->hwcfg2.d32);
+	DWC_DEBUGPL(DBG_CILV, "hwcfg3=%08x\n", core_if->hwcfg3.d32);
+	DWC_DEBUGPL(DBG_CILV, "hwcfg4=%08x\n", core_if->hwcfg4.d32);
+	DWC_DEBUGPL(DBG_CILV, "op_mode=%0x\n", core_if->hwcfg2.b.op_mode);
+	DWC_DEBUGPL(DBG_CILV, "arch=%0x\n", core_if->hwcfg2.b.architecture);
+	DWC_DEBUGPL(DBG_CILV, "num_dev_ep=%d\n",core_if->hwcfg2.b.num_dev_ep + 1);
+	DWC_DEBUGPL(DBG_CILV, "num_host_chan=%d\n",core_if->hwcfg2.b.num_host_chan);
+	DWC_DEBUGPL(DBG_CILV, "nonperio_tx_q_depth=0x%0x\n",
+		     core_if->hwcfg2.b.nonperio_tx_q_depth);
+	DWC_DEBUGPL(DBG_CILV, "host_perio_tx_q_depth=0x%0x\n",
+		     core_if->hwcfg2.b.host_perio_tx_q_depth);
+	DWC_DEBUGPL(DBG_CILV, "dev_token_q_depth=0x%0x\n",
+		     core_if->hwcfg2.b.dev_token_q_depth);
+	DWC_DEBUGPL(DBG_CILV, "Total FIFO SZ=%d\n",
+		      core_if->hwcfg3.b.dfifo_depth);
+	DWC_DEBUGPL(DBG_CILV, "xfer_size_cntr_width=%0x\n",
+		     core_if->hwcfg3.b.xfer_size_cntr_width);
+
+    /*
+     * Set the SRP sucess bit for FS-I2c
+     */
+	core_if->srp_success = 0;
+	core_if->srp_timer_started = 0;
+	return core_if;
+}
+
+
+/**
+ * This function frees the structures allocated by dwc_otg_cil_init().
+ *
+ * @param[in] _core_if The core interface pointer returned from
+ * dwc_otg_cil_init().
+ *
+ */
+void dwc_otg_cil_remove(dwc_otg_core_if_t * _core_if)
+{
+    /* Disable all interrupts */
+	dwc_modify_reg32(&_core_if->core_global_regs->gahbcfg, 1, 0);
+	dwc_write_reg32(&_core_if->core_global_regs->gintmsk, 0);
+	if (_core_if->dev_if) {
+		kfree(_core_if->dev_if);
+	}
+	if (_core_if->host_if) {
+		kfree(_core_if->host_if);
+	}
+	kfree(_core_if);
+}
+
+
+/**
+ * This function enables the controller's Global Interrupt in the AHB Config
+ * register.
+ *
+ * @param[in] _core_if Programming view of DWC_otg controller.
+ */
+extern void dwc_otg_enable_global_interrupts(dwc_otg_core_if_t * _core_if)
+{
+	gahbcfg_data_t ahbcfg = {.d32 = 0};
+	ahbcfg.b.glblintrmsk = 1;	/* Enable interrupts */
+	dwc_modify_reg32(&_core_if->core_global_regs->gahbcfg, 0, ahbcfg.d32);
+}
+
+/**
+ * This function disables the controller's Global Interrupt in the AHB Config
+ * register.
+ *
+ * @param[in] _core_if Programming view of DWC_otg controller.
+ */
+extern void dwc_otg_disable_global_interrupts(dwc_otg_core_if_t * _core_if)
+{
+	gahbcfg_data_t ahbcfg = {.d32 = 0};
+	ahbcfg.b.glblintrmsk = 1;	/* Enable interrupts */
+	dwc_modify_reg32(&_core_if->core_global_regs->gahbcfg, ahbcfg.d32, 0);
+}
+
+/**
+ * This function initializes the commmon interrupts, used in both
+ * device and host modes.
+ *
+ * @param[in] _core_if Programming view of the DWC_otg controller
+ *
+ */
+static void dwc_otg_enable_common_interrupts(dwc_otg_core_if_t * _core_if)
+{
+	dwc_otg_core_global_regs_t * global_regs = _core_if->core_global_regs;
+	gintmsk_data_t intr_mask = {.d32 = 0};
+
+    /* Clear any pending OTG Interrupts */
+	dwc_write_reg32(&global_regs->gotgint, 0xFFFFFFFF);
+
+	/* Clear any pending interrupts */
+	dwc_write_reg32(&global_regs->gintsts, 0xFFFFFFFF);
+
+	/*
+	 * Enable the interrupts in the GINTMSK.
+	 */
+	intr_mask.b.modemismatch = 1;
+	intr_mask.b.otgintr = 1;
+	if (!_core_if->dma_enable) {
+		intr_mask.b.rxstsqlvl = 1;
+	}
+	intr_mask.b.conidstschng = 1;
+	intr_mask.b.wkupintr = 1;
+	intr_mask.b.disconnect = 1;
+	intr_mask.b.usbsuspend = 1;
+	intr_mask.b.sessreqintr = 1;
+	dwc_write_reg32(&global_regs->gintmsk, intr_mask.d32);
+}
+
+
+/**
+ * Initializes the FSLSPClkSel field of the HCFG register depending on the PHY
+ * type.
+ */
+static void init_fslspclksel(dwc_otg_core_if_t * _core_if)
+{
+	uint32_t val;
+	hcfg_data_t hcfg;
+	if (((_core_if->hwcfg2.b.hs_phy_type == 2) &&
+		(_core_if->hwcfg2.b.fs_phy_type == 1) &&
+		(_core_if->core_params->ulpi_fs_ls)) ||
+		(_core_if->core_params->phy_type == DWC_PHY_TYPE_PARAM_FS)) {
+		    /* Full speed PHY */
+		    val = DWC_HCFG_48_MHZ;
+	} else {
+		/* High speed PHY running at full speed or high speed */
+		val = DWC_HCFG_30_60_MHZ;
+	}
+	DWC_DEBUGPL(DBG_CIL, "Initializing HCFG.FSLSPClkSel to 0x%1x\n", val);
+	hcfg.d32 = dwc_read_reg32(&_core_if->host_if->host_global_regs->hcfg);
+	hcfg.b.fslspclksel = val;
+	dwc_write_reg32(&_core_if->host_if->host_global_regs->hcfg, hcfg.d32);
+}
+
+
+/**
+ * Initializes the DevSpd field of the DCFG register depending on the PHY type
+ * and the enumeration speed of the device.
+ */
+static void init_devspd(dwc_otg_core_if_t * _core_if)
+{
+	uint32_t val;
+	dcfg_data_t dcfg;
+	if (((_core_if->hwcfg2.b.hs_phy_type == 2) &&
+		(_core_if->hwcfg2.b.fs_phy_type == 1) &&
+		(_core_if->core_params->ulpi_fs_ls)) ||
+		(_core_if->core_params->phy_type == DWC_PHY_TYPE_PARAM_FS)) {
+		    /* Full speed PHY */
+			val = 0x3;
+	} else if (_core_if->core_params->speed == DWC_SPEED_PARAM_FULL) {
+    /* High speed PHY running at full speed */
+		val = 0x1;
+	} else {
+	    /* High speed PHY running at high speed */
+		val = 0x0;
+	}
+	DWC_DEBUGPL(DBG_CIL, "Initializing DCFG.DevSpd to 0x%1x\n", val);
+	dcfg.d32 = dwc_read_reg32(&_core_if->dev_if->dev_global_regs->dcfg);
+	dcfg.b.devspd = val;
+	dwc_write_reg32(&_core_if->dev_if->dev_global_regs->dcfg, dcfg.d32);
+}
+
+
+/**
+ * This function calculates the number of IN EPS
+ * using GHWCFG1 and GHWCFG2 registers values
+ *
+ * @param _pcd the pcd structure.
+ */
+static uint32_t calc_num_in_eps(dwc_otg_core_if_t * _core_if)
+{
+	uint32_t num_in_eps = 0;
+	uint32_t num_eps = _core_if->hwcfg2.b.num_dev_ep;
+	uint32_t hwcfg1 = _core_if->hwcfg1.d32 >> 2;
+	uint32_t num_tx_fifos = _core_if->hwcfg4.b.num_in_eps;
+	int i;
+	for (i = 0; i < num_eps; ++i) {
+		if (!(hwcfg1 & 0x1))
+			num_in_eps++;
+		hwcfg1 >>= 2;
+	}
+	if (_core_if->hwcfg4.b.ded_fifo_en) {
+		num_in_eps = (num_in_eps > num_tx_fifos) ? num_tx_fifos : num_in_eps;
+	}
+	return num_in_eps;
+}
+
+
+/**
+ * This function calculates the number of OUT EPS
+ * using GHWCFG1 and GHWCFG2 registers values
+ *
+ * @param _pcd the pcd structure.
+ */
+static uint32_t calc_num_out_eps(dwc_otg_core_if_t * _core_if)
+{
+	uint32_t num_out_eps = 0;
+	uint32_t num_eps = _core_if->hwcfg2.b.num_dev_ep;
+	uint32_t hwcfg1 = _core_if->hwcfg1.d32 >> 2;
+	int i;
+	for (i = 0; i < num_eps; ++i) {
+		if (!(hwcfg1 & 0x2))
+			num_out_eps++;
+		hwcfg1 >>= 2;
+	}
+	return num_out_eps;
+}
+
+
+/**
+ * This function initializes the DWC_otg controller registers and
+ * prepares the core for device mode or host mode operation.
+ *
+ * @param _core_if Programming view of the DWC_otg controller
+ *
+ */
+void dwc_otg_core_init(dwc_otg_core_if_t * _core_if)
+{
+	int i = 0;
+	dwc_otg_core_global_regs_t * global_regs = _core_if->core_global_regs;
+	dwc_otg_dev_if_t * dev_if = _core_if->dev_if;
+	gahbcfg_data_t ahbcfg = {.d32 = 0};
+	gusbcfg_data_t usbcfg = {.d32 = 0};
+	gi2cctl_data_t i2cctl = {.d32 = 0};
+	DWC_DEBUGPL(DBG_CILV, "dwc_otg_core_init(%p)\n", _core_if);
+
+    /* Common Initialization */
+	usbcfg.d32 = dwc_read_reg32(&global_regs->gusbcfg);
+	DWC_DEBUGPL(DBG_CIL, "USB config register: 0x%08x\n", usbcfg.d32);
+
+	/* Program the ULPI External VBUS bit if needed */
+#if defined(OTG_EXT_CHG_PUMP) || defined(CONFIG_460EX) || defined(CONFIG_APM82181)
+    usbcfg.b.ulpi_ext_vbus_drv = 1;
+#else
+    //usbcfg.b.ulpi_ext_vbus_drv = 0;
+	usbcfg.b.ulpi_ext_vbus_drv =
+	(_core_if->core_params->phy_ulpi_ext_vbus ==
+		DWC_PHY_ULPI_EXTERNAL_VBUS) ? 1 : 0;
+#endif
+
+	/* Set external TS Dline pulsing */
+	usbcfg.b.term_sel_dl_pulse = (_core_if->core_params->ts_dline == 1) ? 1 : 0;
+	dwc_write_reg32(&global_regs->gusbcfg, usbcfg.d32);
+
+	/* Reset the Controller */
+	dwc_otg_core_reset(_core_if);
+
+	/* Initialize parameters from Hardware configuration registers. */
+	dev_if->num_in_eps = calc_num_in_eps(_core_if);
+	dev_if->num_out_eps = calc_num_out_eps(_core_if);
+	DWC_DEBUGPL(DBG_CIL, "num_dev_perio_in_ep=%d\n",
+		       _core_if->hwcfg4.b.num_dev_perio_in_ep);
+	DWC_DEBUGPL(DBG_CIL, "Is power optimization enabled?  %s\n",
+		     _core_if->hwcfg4.b.power_optimiz ? "Yes" : "No");
+	DWC_DEBUGPL(DBG_CIL, "vbus_valid filter enabled?  %s\n",
+		     _core_if->hwcfg4.b.vbus_valid_filt_en ? "Yes" : "No");
+	DWC_DEBUGPL(DBG_CIL, "iddig filter enabled?  %s\n",
+		     _core_if->hwcfg4.b.iddig_filt_en ? "Yes" : "No");
+
+	for (i = 0; i < _core_if->hwcfg4.b.num_dev_perio_in_ep; i++) {
+		dev_if->perio_tx_fifo_size[i] =
+		    dwc_read_reg32(&global_regs->dptxfsiz_dieptxf[i]) >> 16;
+		DWC_DEBUGPL(DBG_CIL, "Periodic Tx FIFO SZ #%d=0x%0x\n", i,
+			     dev_if->perio_tx_fifo_size[i]);
+	}
+	for (i = 0; i < _core_if->hwcfg4.b.num_in_eps; i++) {
+		dev_if->tx_fifo_size[i] =
+		    dwc_read_reg32(&global_regs->dptxfsiz_dieptxf[i]) >> 16;
+		DWC_DEBUGPL(DBG_CIL, "Tx FIFO SZ #%d=0x%0x\n", i,
+			     dev_if->perio_tx_fifo_size[i]);
+	}
+	_core_if->total_fifo_size = _core_if->hwcfg3.b.dfifo_depth;
+	_core_if->rx_fifo_size = dwc_read_reg32(&global_regs->grxfsiz);
+	_core_if->nperio_tx_fifo_size = dwc_read_reg32(&global_regs->gnptxfsiz) >> 16;
+	DWC_DEBUGPL(DBG_CIL, "Total FIFO SZ=%d\n", _core_if->total_fifo_size);
+	DWC_DEBUGPL(DBG_CIL, "Rx FIFO SZ=%d\n", _core_if->rx_fifo_size);
+	DWC_DEBUGPL(DBG_CIL, "NP Tx FIFO SZ=%d\n",_core_if->nperio_tx_fifo_size);
+
+    /* This programming sequence needs to happen in FS mode before any other
+     * programming occurs */
+	if ((_core_if->core_params->speed == DWC_SPEED_PARAM_FULL) &&
+		(_core_if->core_params->phy_type == DWC_PHY_TYPE_PARAM_FS)) {
+
+	    /* If FS mode with FS PHY */
+
+	    /* core_init() is now called on every switch so only call the
+	     * following for the first time through.
+		 */
+		if (!_core_if->phy_init_done) {
+			_core_if->phy_init_done = 1;
+			DWC_DEBUGPL(DBG_CIL, "FS_PHY detected\n");
+			usbcfg.d32 = dwc_read_reg32(&global_regs->gusbcfg);
+			usbcfg.b.physel = 1;
+			dwc_write_reg32(&global_regs->gusbcfg, usbcfg.d32);
+
+		    /* Reset after a PHY select */
+		    dwc_otg_core_reset(_core_if);
+		}
+
+		/* Program DCFG.DevSpd or HCFG.FSLSPclkSel to 48Mhz in FS.      Also
+		 * do this on HNP Dev/Host mode switches (done in dev_init and
+		 * host_init).
+		 */
+		if (dwc_otg_is_host_mode(_core_if)) {
+			DWC_DEBUGPL(DBG_CIL, "host mode\n");
+			init_fslspclksel(_core_if);
+		} else {
+			DWC_DEBUGPL(DBG_CIL, "device mode\n");
+			init_devspd(_core_if);
+		}
+
+		if (_core_if->core_params->i2c_enable) {
+			DWC_DEBUGPL(DBG_CIL, "FS_PHY Enabling I2c\n");
+
+		    /* Program GUSBCFG.OtgUtmifsSel to I2C */
+		    usbcfg.d32 = dwc_read_reg32(&global_regs->gusbcfg);
+			usbcfg.b.otgutmifssel = 1;
+			dwc_write_reg32(&global_regs->gusbcfg, usbcfg.d32);
+
+		    /* Program GI2CCTL.I2CEn */
+		    i2cctl.d32 = dwc_read_reg32(&global_regs->gi2cctl);
+			i2cctl.b.i2cdevaddr = 1;
+			i2cctl.b.i2cen = 0;
+			dwc_write_reg32(&global_regs->gi2cctl, i2cctl.d32);
+			i2cctl.b.i2cen = 1;
+			dwc_write_reg32(&global_regs->gi2cctl, i2cctl.d32);
+		}
+	}	/* endif speed == DWC_SPEED_PARAM_FULL */
+	else {
+		/* High speed PHY. */
+		if (!_core_if->phy_init_done) {
+			_core_if->phy_init_done = 1;
+			DWC_DEBUGPL(DBG_CIL, "High spped PHY\n");
+		    /* HS PHY parameters.  These parameters are preserved
+		     * during soft reset so only program the first time.  Do
+		     * a soft reset immediately after setting phyif.
+			 */
+			// test-only: in AMCC 460EX code not used!!!???
+			usbcfg.b.ulpi_utmi_sel = _core_if->core_params->phy_type;
+			if (usbcfg.b.ulpi_utmi_sel == 1) {
+				DWC_DEBUGPL(DBG_CIL, "ULPI\n");
+			    /* ULPI interface */
+			    usbcfg.b.phyif = 0;
+				usbcfg.b.ddrsel = _core_if->core_params->phy_ulpi_ddr;
+			} else {
+			    /* UTMI+ interface */
+			    if (_core_if->core_params->phy_utmi_width == 16) {
+					usbcfg.b.phyif = 1;
+					DWC_DEBUGPL(DBG_CIL, "UTMI+ 16\n");
+				} else {
+					DWC_DEBUGPL(DBG_CIL, "UTMI+ 8\n");
+					usbcfg.b.phyif = 0;
+				}
+			}
+			dwc_write_reg32(&global_regs->gusbcfg, usbcfg.d32);
+		    /* Reset after setting the PHY parameters */
+		    dwc_otg_core_reset(_core_if);
+		}
+	}
+	if ((_core_if->hwcfg2.b.hs_phy_type == 2) &&
+		(_core_if->hwcfg2.b.fs_phy_type == 1) &&
+		(_core_if->core_params->ulpi_fs_ls)) {
+		DWC_DEBUGPL(DBG_CIL, "Setting ULPI FSLS\n");
+		usbcfg.d32 = dwc_read_reg32(&global_regs->gusbcfg);
+		usbcfg.b.ulpi_fsls = 1;
+		usbcfg.b.ulpi_clk_sus_m = 1;
+		dwc_write_reg32(&global_regs->gusbcfg, usbcfg.d32);
+	} else {
+		DWC_DEBUGPL(DBG_CIL, "Setting ULPI FSLS=0\n");
+		usbcfg.d32 = dwc_read_reg32(&global_regs->gusbcfg);
+		usbcfg.b.ulpi_fsls = 0;
+		usbcfg.b.ulpi_clk_sus_m = 0;
+		dwc_write_reg32(&global_regs->gusbcfg, usbcfg.d32);
+	}
+
+    /* Program the GAHBCFG Register. */
+    switch (_core_if->hwcfg2.b.architecture) {
+		case DWC_SLAVE_ONLY_ARCH:
+			DWC_DEBUGPL(DBG_CIL, "Slave Only Mode\n");
+			ahbcfg.b.nptxfemplvl_txfemplvl = DWC_GAHBCFG_TXFEMPTYLVL_HALFEMPTY;
+			ahbcfg.b.ptxfemplvl = DWC_GAHBCFG_TXFEMPTYLVL_HALFEMPTY;
+			_core_if->dma_enable = 0;
+			break;
+		case DWC_EXT_DMA_ARCH:
+			DWC_DEBUGPL(DBG_CIL, "External DMA Mode\n");
+			ahbcfg.b.hburstlen = _core_if->core_params->dma_burst_size;
+			_core_if->dma_enable = (_core_if->core_params->dma_enable != 0);
+			break;
+		case DWC_INT_DMA_ARCH:
+			DWC_DEBUGPL(DBG_CIL, "Internal DMA Mode\n");
+			#if defined(CONFIG_APM82181)
+				/* Avoid system hang during concurrently using USB and SATA */
+				ahbcfg.b.hburstlen = DWC_GAHBCFG_INT_DMA_BURST_INCR16;
+			#else
+				ahbcfg.b.hburstlen = DWC_GAHBCFG_INT_DMA_BURST_INCR;
+			#endif
+			_core_if->dma_enable = (_core_if->core_params->dma_enable != 0);
+			break;
+	}
+	ahbcfg.b.dmaenable = _core_if->dma_enable;
+	dwc_write_reg32(&global_regs->gahbcfg, ahbcfg.d32);
+	_core_if->en_multiple_tx_fifo = _core_if->hwcfg4.b.ded_fifo_en;
+
+    /*
+     * Program the GUSBCFG register.
+     */
+    usbcfg.d32 = dwc_read_reg32(&global_regs->gusbcfg);
+	switch (_core_if->hwcfg2.b.op_mode) {
+	case DWC_MODE_HNP_SRP_CAPABLE:
+		usbcfg.b.hnpcap = (_core_if->core_params->otg_cap ==
+			DWC_OTG_CAP_PARAM_HNP_SRP_CAPABLE);
+		usbcfg.b.srpcap = (_core_if->core_params->otg_cap !=
+			DWC_OTG_CAP_PARAM_NO_HNP_SRP_CAPABLE);
+		break;
+	case DWC_MODE_SRP_ONLY_CAPABLE:
+		usbcfg.b.hnpcap = 0;
+		usbcfg.b.srpcap = (_core_if->core_params->otg_cap !=
+			DWC_OTG_CAP_PARAM_NO_HNP_SRP_CAPABLE);
+		break;
+	case DWC_MODE_NO_HNP_SRP_CAPABLE:
+		usbcfg.b.hnpcap = 0;
+		usbcfg.b.srpcap = 0;
+		break;
+	case DWC_MODE_SRP_CAPABLE_DEVICE:
+		usbcfg.b.hnpcap = 0;
+		usbcfg.b.srpcap = (_core_if->core_params->otg_cap !=
+			DWC_OTG_CAP_PARAM_NO_HNP_SRP_CAPABLE);
+		break;
+	case DWC_MODE_NO_SRP_CAPABLE_DEVICE:
+		usbcfg.b.hnpcap = 0;
+		usbcfg.b.srpcap = 0;
+		break;
+	case DWC_MODE_SRP_CAPABLE_HOST:
+		usbcfg.b.hnpcap = 0;
+		usbcfg.b.srpcap = (_core_if->core_params->otg_cap !=
+			DWC_OTG_CAP_PARAM_NO_HNP_SRP_CAPABLE);
+		break;
+	case DWC_MODE_NO_SRP_CAPABLE_HOST:
+		usbcfg.b.hnpcap = 0;
+		usbcfg.b.srpcap = 0;
+		break;
+	}
+	dwc_write_reg32(&global_regs->gusbcfg, usbcfg.d32);
+
+    /* Enable common interrupts */
+    dwc_otg_enable_common_interrupts(_core_if);
+
+    /* Do device or host intialization based on mode during PCD
+     * and HCD initialization
+	 */
+    if (dwc_otg_is_host_mode(_core_if)) {
+		DWC_DEBUGPL(DBG_ANY, "Host Mode\n");
+		_core_if->op_state = A_HOST;
+	} else {
+		DWC_DEBUGPL(DBG_ANY, "Device Mode\n");
+		_core_if->op_state = B_PERIPHERAL;
+#ifdef CONFIG_DWC_DEVICE_ONLY
+	    dwc_otg_core_dev_init(_core_if);
+#endif	/*  */
+	}
+}
+
+
+/**
+ * This function enables the Device mode interrupts.
+ *
+ * @param _core_if Programming view of DWC_otg controller
+ */
+void dwc_otg_enable_device_interrupts(dwc_otg_core_if_t * _core_if)
+{
+	gintmsk_data_t intr_mask = {.d32 = 0};
+	dwc_otg_core_global_regs_t * global_regs = _core_if->core_global_regs;
+	DWC_DEBUGPL(DBG_CIL, "%s()\n", __func__);
+
+    /* Disable all interrupts. */
+	dwc_write_reg32(&global_regs->gintmsk, 0);
+
+	/* Clear any pending interrupts */
+	dwc_write_reg32(&global_regs->gintsts, 0xFFFFFFFF);
+
+	/* Enable the common interrupts */
+	dwc_otg_enable_common_interrupts(_core_if);
+
+	/* Enable interrupts */
+	intr_mask.b.usbreset = 1;
+	intr_mask.b.enumdone = 1;
+	intr_mask.b.inepintr = 1;
+	intr_mask.b.outepintr = 1;
+	intr_mask.b.erlysuspend = 1;
+	if (_core_if->en_multiple_tx_fifo == 0) {
+		intr_mask.b.epmismatch = 1;
+	}
+
+	/** @todo NGS: Should this be a module parameter? */
+#ifdef USE_PERIODIC_EP
+	intr_mask.b.isooutdrop = 1;
+	intr_mask.b.eopframe = 1;
+	intr_mask.b.incomplisoin = 1;
+	intr_mask.b.incomplisoout = 1;
+#endif	/*  */
+	dwc_modify_reg32(&global_regs->gintmsk, intr_mask.d32,
+			      intr_mask.d32);
+
+	DWC_DEBUGPL(DBG_CIL, "%s() gintmsk=%0x\n", __func__,
+		      dwc_read_reg32(&global_regs->gintmsk));
+}
+
+
+/**
+ * This function initializes the DWC_otg controller registers for
+ * device mode.
+ *
+ * @param _core_if Programming view of DWC_otg controller
+ *
+ */
+void dwc_otg_core_dev_init(dwc_otg_core_if_t * _core_if)
+{
+	int i;
+	dwc_otg_core_global_regs_t * global_regs = _core_if->core_global_regs;
+	dwc_otg_dev_if_t * dev_if = _core_if->dev_if;
+	dwc_otg_core_params_t * params = _core_if->core_params;
+	dcfg_data_t dcfg = {.d32 = 0};
+	grstctl_t resetctl = {.d32 = 0};
+	uint32_t rx_fifo_size;
+	fifosize_data_t nptxfifosize;
+	fifosize_data_t txfifosize;
+	dthrctl_data_t dthrctl;
+	fifosize_data_t ptxfifosize;
+
+	/* Restart the Phy Clock */
+	dwc_write_reg32(_core_if->pcgcctl, 0);
+
+	/* Device configuration register */
+	init_devspd(_core_if);
+	dcfg.d32 = dwc_read_reg32(&dev_if->dev_global_regs->dcfg);
+	dcfg.b.perfrint = DWC_DCFG_FRAME_INTERVAL_80;
+	dwc_write_reg32(&dev_if->dev_global_regs->dcfg, dcfg.d32);
+
+	/* Configure data FIFO sizes */
+	if (_core_if->hwcfg2.b.dynamic_fifo && params->enable_dynamic_fifo) {
+		DWC_DEBUGPL(DBG_CIL, "Total FIFO Size=%d\n",
+			     _core_if->total_fifo_size);
+		DWC_DEBUGPL(DBG_CIL, "Rx FIFO Size=%d\n",
+			     params->dev_rx_fifo_size);
+		DWC_DEBUGPL(DBG_CIL, "NP Tx FIFO Size=%d\n",
+			     params->dev_nperio_tx_fifo_size);
+
+		 /* Rx FIFO */
+		 DWC_DEBUGPL(DBG_CIL, "initial grxfsiz=%08x\n",
+				dwc_read_reg32(&global_regs->grxfsiz));
+		rx_fifo_size = params->dev_rx_fifo_size;
+		dwc_write_reg32(&global_regs->grxfsiz, rx_fifo_size);
+		DWC_DEBUGPL(DBG_CIL, "new grxfsiz=%08x\n",
+			      dwc_read_reg32(&global_regs->grxfsiz));
+
+		/** Set Periodic Tx FIFO Mask all bits 0 */
+	    _core_if->p_tx_msk = 0;
+
+		/** Set Tx FIFO Mask all bits 0 */
+	    _core_if->tx_msk = 0;
+		if (_core_if->en_multiple_tx_fifo == 0) {
+		    /* Non-periodic Tx FIFO */
+		    DWC_DEBUGPL(DBG_CIL, "initial gnptxfsiz=%08x\n",
+				dwc_read_reg32(&global_regs->gnptxfsiz));
+			nptxfifosize.b.depth = params->dev_nperio_tx_fifo_size;
+			nptxfifosize.b.startaddr = params->dev_rx_fifo_size;
+			dwc_write_reg32(&global_regs->gnptxfsiz,nptxfifosize.d32);
+			DWC_DEBUGPL(DBG_CIL, "new gnptxfsiz=%08x\n",
+				      dwc_read_reg32(&global_regs->gnptxfsiz));
+
+			/**@todo NGS: Fix Periodic FIFO Sizing! */
+		    /*
+		     * Periodic Tx FIFOs These FIFOs are numbered from 1 to 15.
+		     * Indexes of the FIFO size module parameters in the
+		     * dev_perio_tx_fifo_size array and the FIFO size registers in
+		     * the dptxfsiz array run from 0 to 14.
+		     */
+			/** @todo Finish debug of this */
+		    ptxfifosize.b.startaddr =
+		    nptxfifosize.b.startaddr + nptxfifosize.b.depth;
+			for (i = 0; i < _core_if->hwcfg4.b.num_dev_perio_in_ep;i++) {
+				ptxfifosize.b.depth = params->dev_perio_tx_fifo_size[i];
+				DWC_DEBUGPL(DBG_CIL,"initial dptxfsiz_dieptxf[%d]=%08x\n",
+				     i,dwc_read_reg32(&global_regs->dptxfsiz_dieptxf[i]));
+				dwc_write_reg32(&global_regs->dptxfsiz_dieptxf[i],ptxfifosize.d32);
+				DWC_DEBUGPL(DBG_CIL,"new dptxfsiz_dieptxf[%d]=%08x\n",
+				     i,dwc_read_reg32(&global_regs->dptxfsiz_dieptxf[i]));
+				ptxfifosize.b.startaddr += ptxfifosize.b.depth;
+			}
+		} else {
+
+		    /*
+		     * Tx FIFOs These FIFOs are numbered from 1 to 15.
+		     * Indexes of the FIFO size module parameters in the
+		     * dev_tx_fifo_size array and the FIFO size registers in
+		     * the dptxfsiz_dieptxf array run from 0 to 14.
+		     */
+
+		    /* Non-periodic Tx FIFO */
+		    DWC_DEBUGPL(DBG_CIL, "initial gnptxfsiz=%08x\n",
+				dwc_read_reg32(&global_regs->gnptxfsiz));
+			nptxfifosize.b.depth = params->dev_nperio_tx_fifo_size;
+			nptxfifosize.b.startaddr = params->dev_rx_fifo_size;
+			dwc_write_reg32(&global_regs->gnptxfsiz, nptxfifosize.d32);
+			DWC_DEBUGPL(DBG_CIL, "new gnptxfsiz=%08x\n",
+				      dwc_read_reg32(&global_regs->gnptxfsiz));
+			txfifosize.b.startaddr = nptxfifosize.b.startaddr + nptxfifosize.b.depth;
+			for (i = 1;i < _core_if->hwcfg4.b.num_dev_perio_in_ep;i++) {
+				txfifosize.b.depth = params->dev_tx_fifo_size[i];
+				DWC_DEBUGPL(DBG_CIL,"initial dptxfsiz_dieptxf[%d]=%08x\n",
+				      i,dwc_read_reg32(&global_regs->dptxfsiz_dieptxf[i]));
+				dwc_write_reg32(&global_regs->dptxfsiz_dieptxf[i - 1],txfifosize.d32);
+				DWC_DEBUGPL(DBG_CIL,"new dptxfsiz_dieptxf[%d]=%08x\n",
+				      i,dwc_read_reg32(&global_regs->dptxfsiz_dieptxf[i-1]));
+				txfifosize.b.startaddr += txfifosize.b.depth;
+			}
+		}
+	}
+
+	/* Flush the FIFOs */
+	dwc_otg_flush_tx_fifo(_core_if, 0x10);	/* all Tx FIFOs */
+	dwc_otg_flush_rx_fifo(_core_if);
+
+	/* Flush the Learning Queue. */
+	resetctl.b.intknqflsh = 1;
+	dwc_write_reg32(&_core_if->core_global_regs->grstctl, resetctl.d32);
+
+	/* Clear all pending Device Interrupts */
+	dwc_write_reg32(&dev_if->dev_global_regs->diepmsk, 0);
+	dwc_write_reg32(&dev_if->dev_global_regs->doepmsk, 0);
+	dwc_write_reg32(&dev_if->dev_global_regs->daint, 0xFFFFFFFF);
+	dwc_write_reg32(&dev_if->dev_global_regs->daintmsk, 0);
+	for (i = 0; i <= dev_if->num_in_eps; i++) {
+		depctl_data_t depctl;
+		depctl.d32 = dwc_read_reg32(&dev_if->in_ep_regs[i]->diepctl);
+		if (depctl.b.epena) {
+			depctl.d32 = 0;
+			depctl.b.epdis = 1;
+			depctl.b.snak = 1;
+		} else {
+			depctl.d32 = 0;
+		}
+		dwc_write_reg32(&dev_if->in_ep_regs[i]->diepctl, depctl.d32);
+		dwc_write_reg32(&dev_if->in_ep_regs[i]->dieptsiz, 0);
+		dwc_write_reg32(&dev_if->in_ep_regs[i]->diepdma, 0);
+		dwc_write_reg32(&dev_if->in_ep_regs[i]->diepint, 0xFF);
+	}
+	for (i = 0; i <= dev_if->num_out_eps; i++) {
+		depctl_data_t depctl;
+		depctl.d32 = dwc_read_reg32(&dev_if->out_ep_regs[i]->doepctl);
+		if (depctl.b.epena) {
+			depctl.d32 = 0;
+			depctl.b.epdis = 1;
+			depctl.b.snak = 1;
+		} else {
+			depctl.d32 = 0;
+		}
+		dwc_write_reg32(&dev_if->out_ep_regs[i]->doepctl, depctl.d32);
+		dwc_write_reg32(&dev_if->out_ep_regs[i]->doeptsiz, 0);
+		dwc_write_reg32(&dev_if->out_ep_regs[i]->doepdma, 0);
+		dwc_write_reg32(&dev_if->out_ep_regs[i]->doepint, 0xFF);
+	}
+	if (_core_if->en_multiple_tx_fifo && _core_if->dma_enable) {
+		dev_if->non_iso_tx_thr_en = _core_if->core_params->thr_ctl & 0x1;
+		dev_if->iso_tx_thr_en = (_core_if->core_params->thr_ctl >> 1) & 0x1;
+		dev_if->rx_thr_en = (_core_if->core_params->thr_ctl >> 2) & 0x1;
+		dev_if->rx_thr_length = _core_if->core_params->rx_thr_length;
+		dev_if->tx_thr_length = _core_if->core_params->tx_thr_length;
+		dthrctl.d32 = 0;
+		dthrctl.b.non_iso_thr_en = dev_if->non_iso_tx_thr_en;
+		dthrctl.b.iso_thr_en = dev_if->iso_tx_thr_en;
+		dthrctl.b.tx_thr_len = dev_if->tx_thr_length;
+		dthrctl.b.rx_thr_en = dev_if->rx_thr_en;
+		dthrctl.b.rx_thr_len = dev_if->rx_thr_length;
+		dwc_write_reg32(&dev_if->dev_global_regs->dtknqr3_dthrctl,dthrctl.d32);
+		DWC_DEBUGPL(DBG_CIL, "Non ISO Tx Thr - %d\nISO Tx Thr - %d\n"
+					"Rx Thr - %d\nTx Thr Len - %d\nRx Thr Len - %d\n",
+					dthrctl.b.non_iso_thr_en, dthrctl.b.iso_thr_en,
+					dthrctl.b.rx_thr_en, dthrctl.b.tx_thr_len,
+					dthrctl.b.rx_thr_len);
+	}
+	dwc_otg_enable_device_interrupts(_core_if);
+	{
+		diepmsk_data_t msk = {.d32 = 0};
+		msk.b.txfifoundrn = 1;
+		dwc_modify_reg32(&dev_if->dev_global_regs->diepmsk, msk.d32,msk.d32);
+	}
+}
+
+
+/**
+ * This function enables the Host mode interrupts.
+ *
+ * @param _core_if Programming view of DWC_otg controller
+ */
+void dwc_otg_enable_host_interrupts(dwc_otg_core_if_t * _core_if)
+{
+	dwc_otg_core_global_regs_t * global_regs = _core_if->core_global_regs;
+	gintmsk_data_t intr_mask = {.d32 = 0};
+	DWC_DEBUGPL(DBG_CIL, "%s()\n", __func__);
+
+    /* Disable all interrupts. */
+    dwc_write_reg32(&global_regs->gintmsk, 0);
+
+    /* Clear any pending interrupts. */
+    dwc_write_reg32(&global_regs->gintsts, 0xFFFFFFFF);
+
+    /* Enable the common interrupts */
+    dwc_otg_enable_common_interrupts(_core_if);
+
+    /*
+     * Enable host mode interrupts without disturbing common
+     * interrupts.
+     */
+    intr_mask.b.sofintr = 1;
+	intr_mask.b.portintr = 1;
+	intr_mask.b.hcintr = 1;
+	dwc_modify_reg32(&global_regs->gintmsk, intr_mask.d32, intr_mask.d32);
+}
+
+/**
+ * This function disables the Host Mode interrupts.
+ *
+ * @param _core_if Programming view of DWC_otg controller
+ */
+void dwc_otg_disable_host_interrupts(dwc_otg_core_if_t * _core_if)
+{
+	dwc_otg_core_global_regs_t * global_regs = _core_if->core_global_regs;
+	gintmsk_data_t intr_mask = {.d32 = 0};
+	DWC_DEBUGPL(DBG_CILV, "%s()\n", __func__);
+
+    /*
+     * Disable host mode interrupts without disturbing common
+     * interrupts.
+     */
+    intr_mask.b.sofintr = 1;
+	intr_mask.b.portintr = 1;
+	intr_mask.b.hcintr = 1;
+	intr_mask.b.ptxfempty = 1;
+	intr_mask.b.nptxfempty = 1;
+	dwc_modify_reg32(&global_regs->gintmsk, intr_mask.d32, 0);
+}
+
+#if 0
+/* currently not used, keep it here as if needed later */
+static int phy_read(dwc_otg_core_if_t * _core_if, int addr)
+{
+	u32 val;
+	int timeout = 10;
+
+	dwc_write_reg32(&_core_if->core_global_regs->gpvndctl,
+			0x02000000 | (addr << 16));
+	val = dwc_read_reg32(&_core_if->core_global_regs->gpvndctl);
+	while (((val & 0x08000000) == 0) && (timeout--)) {
+		udelay(1000);
+		val = dwc_read_reg32(&_core_if->core_global_regs->gpvndctl);
+	}
+	val = dwc_read_reg32(&_core_if->core_global_regs->gpvndctl);
+	printk("%s: addr=%02x regval=%02x\n", __func__, addr, val & 0x000000ff);
+
+	return 0;
+}
+#endif
+
+#ifdef CONFIG_405EX
+static int phy_write(dwc_otg_core_if_t * _core_if, int addr, int val8)
+{
+	u32 val;
+	int timeout = 10;
+
+	dwc_write_reg32(&_core_if->core_global_regs->gpvndctl,
+			0x02000000 | 0x00400000 | (addr << 16) | (val8 & 0x000000ff));
+	val = dwc_read_reg32(&_core_if->core_global_regs->gpvndctl);
+	while (((val & 0x08000000) == 0) && (timeout--)) {
+		udelay(1000);
+		val = dwc_read_reg32(&_core_if->core_global_regs->gpvndctl);
+	}
+	val = dwc_read_reg32(&_core_if->core_global_regs->gpvndctl);
+
+	return 0;
+}
+#endif
+
+/**
+ * This function initializes the DWC_otg controller registers for
+ * host mode.
+ *
+ * This function flushes the Tx and Rx FIFOs and it flushes any entries in the
+ * request queues. Host channels are reset to ensure that they are ready for
+ * performing transfers.
+ *
+ * @param _core_if Programming view of DWC_otg controller
+ *
+ */
+void dwc_otg_core_host_init(dwc_otg_core_if_t * _core_if)
+{
+	dwc_otg_core_global_regs_t * global_regs = _core_if->core_global_regs;
+	dwc_otg_host_if_t * host_if = _core_if->host_if;
+	dwc_otg_core_params_t * params = _core_if->core_params;
+	hprt0_data_t hprt0 = {.d32 = 0};
+	fifosize_data_t nptxfifosize;
+	fifosize_data_t ptxfifosize;
+	int i;
+	hcchar_data_t hcchar;
+	hcfg_data_t hcfg;
+	dwc_otg_hc_regs_t * hc_regs;
+	int num_channels;
+	gotgctl_data_t gotgctl = {.d32 = 0};
+	DWC_DEBUGPL(DBG_CILV, "%s(%p)\n", __func__, _core_if);
+
+    /* Restart the Phy Clock */
+    dwc_write_reg32(_core_if->pcgcctl, 0);
+
+    /* Initialize Host Configuration Register */
+    init_fslspclksel(_core_if);
+	if (_core_if->core_params->speed == DWC_SPEED_PARAM_FULL) {
+		hcfg.d32 = dwc_read_reg32(&host_if->host_global_regs->hcfg);
+		hcfg.b.fslssupp = 1;
+		dwc_write_reg32(&host_if->host_global_regs->hcfg, hcfg.d32);
+	}
+
+    /* Configure data FIFO sizes */
+    if (_core_if->hwcfg2.b.dynamic_fifo && params->enable_dynamic_fifo) {
+		DWC_DEBUGPL(DBG_CIL, "Total FIFO Size=%d\n", _core_if->total_fifo_size);
+		DWC_DEBUGPL(DBG_CIL, "Rx FIFO Size=%d\n", params->host_rx_fifo_size);
+		DWC_DEBUGPL(DBG_CIL, "NP Tx FIFO Size=%d\n",params->host_nperio_tx_fifo_size);
+		DWC_DEBUGPL(DBG_CIL, "P Tx FIFO Size=%d\n", params->host_perio_tx_fifo_size);
+
+	    /* Rx FIFO */
+	    DWC_DEBUGPL(DBG_CIL, "initial grxfsiz=%08x\n",dwc_read_reg32(&global_regs->grxfsiz));
+		dwc_write_reg32(&global_regs->grxfsiz,params->host_rx_fifo_size);
+		DWC_DEBUGPL(DBG_CIL, "new grxfsiz=%08x\n",dwc_read_reg32(&global_regs->grxfsiz));
+
+	    /* Non-periodic Tx FIFO */
+	    DWC_DEBUGPL(DBG_CIL, "initial gnptxfsiz=%08x\n",dwc_read_reg32(&global_regs->gnptxfsiz));
+		nptxfifosize.b.depth = params->host_nperio_tx_fifo_size;
+		nptxfifosize.b.startaddr = params->host_rx_fifo_size;
+		dwc_write_reg32(&global_regs->gnptxfsiz, nptxfifosize.d32);
+		DWC_DEBUGPL(DBG_CIL, "new gnptxfsiz=%08x\n", dwc_read_reg32(&global_regs->gnptxfsiz));
+
+	    /* Periodic Tx FIFO */
+	    DWC_DEBUGPL(DBG_CIL, "initial hptxfsiz=%08x\n",dwc_read_reg32(&global_regs->hptxfsiz));
+		ptxfifosize.b.depth = params->host_perio_tx_fifo_size;
+		ptxfifosize.b.startaddr = nptxfifosize.b.startaddr + nptxfifosize.b.depth;
+		dwc_write_reg32(&global_regs->hptxfsiz, ptxfifosize.d32);
+		DWC_DEBUGPL(DBG_CIL, "new hptxfsiz=%08x\n", dwc_read_reg32(&global_regs->hptxfsiz));
+	}
+
+    /* Clear Host Set HNP Enable in the OTG Control Register */
+    gotgctl.b.hstsethnpen = 1;
+	dwc_modify_reg32(&global_regs->gotgctl, gotgctl.d32, 0);
+
+    /* Make sure the FIFOs are flushed. */
+    dwc_otg_flush_tx_fifo(_core_if, 0x10 /* all Tx FIFOs */ );
+	dwc_otg_flush_rx_fifo(_core_if);
+
+    /* Flush out any leftover queued requests. */
+    num_channels = _core_if->core_params->host_channels;
+	for (i = 0; i < num_channels; i++) {
+		hc_regs = _core_if->host_if->hc_regs[i];
+		hcchar.d32 = dwc_read_reg32(&hc_regs->hcchar);
+		hcchar.b.chen = 0;
+		hcchar.b.chdis = 1;
+		hcchar.b.epdir = 0;
+		dwc_write_reg32(&hc_regs->hcchar, hcchar.d32);
+	}
+
+    /* Halt all channels to put them into a known state. */
+    for (i = 0; i < num_channels; i++) {
+		int count = 0;
+		hc_regs = _core_if->host_if->hc_regs[i];
+		hcchar.d32 = dwc_read_reg32(&hc_regs->hcchar);
+		hcchar.b.chen = 1;
+		hcchar.b.chdis = 1;
+		hcchar.b.epdir = 0;
+		dwc_write_reg32(&hc_regs->hcchar, hcchar.d32);
+		DWC_DEBUGPL(DBG_HCDV, "%s: Halt channel %d\n", __func__, i);
+
+		do {
+			hcchar.d32 = dwc_read_reg32(&hc_regs->hcchar);
+			if (++count > 200) {
+				DWC_ERROR
+				    ("%s: Unable to clear halt on channel %d\n",
+				     __func__, i);
+				break;
+			}
+			udelay(100);
+		} while (hcchar.b.chen);
+	}
+
+    /* Turn on the vbus power. */
+    DWC_PRINT("Init: Port Power? op_state=%d\n", _core_if->op_state);
+	if (_core_if->op_state == A_HOST) {
+		hprt0.d32 = dwc_otg_read_hprt0(_core_if);
+		DWC_PRINT("Init: Power Port (%d)\n", hprt0.b.prtpwr);
+		if (hprt0.b.prtpwr == 0) {
+			hprt0.b.prtpwr = 1;
+			dwc_write_reg32(host_if->hprt0, hprt0.d32);
+		}
+	}
+
+#ifdef CONFIG_405EX
+	/* Write 0x60 to USB PHY register 7:
+	 * Modify "Indicator Complement" and "Indicator Pass Thru" of
+	 * Interface control register to disable the internal Vbus
+	 * comparator, as suggested by RichTek FAE.
+	 * This produced better results recognizing and mounting USB
+	 * memory sticks on the Makalu 405EX platform. I couldn't see
+	 * any difference on Kilauea, but since it seems to be better
+	 * on Makalu, let's keep it in here too.
+	 */
+	phy_write(_core_if, 7, 0x60);
+#endif
+
+	dwc_otg_enable_host_interrupts(_core_if);
+}
+
+
+/**
+ * Prepares a host channel for transferring packets to/from a specific
+ * endpoint. The HCCHARn register is set up with the characteristics specified
+ * in _hc. Host channel interrupts that may need to be serviced while this
+ * transfer is in progress are enabled.
+ *
+ * @param _core_if Programming view of DWC_otg controller
+ * @param _hc Information needed to initialize the host channel
+ */
+void dwc_otg_hc_init(dwc_otg_core_if_t * _core_if, dwc_hc_t * _hc)
+{
+	uint32_t intr_enable;
+	hcintmsk_data_t hc_intr_mask;
+	gintmsk_data_t gintmsk = {.d32 = 0};
+	hcchar_data_t hcchar;
+	hcsplt_data_t hcsplt;
+	uint8_t hc_num = _hc->hc_num;
+	dwc_otg_host_if_t * host_if = _core_if->host_if;
+	dwc_otg_hc_regs_t * hc_regs = host_if->hc_regs[hc_num];
+
+    /* Clear old interrupt conditions for this host channel. */
+    hc_intr_mask.d32 = 0xFFFFFFFF;
+	hc_intr_mask.b.reserved = 0;
+	dwc_write_reg32(&hc_regs->hcint, hc_intr_mask.d32);
+
+    /* Enable channel interrupts required for this transfer. */
+    hc_intr_mask.d32 = 0;
+	hc_intr_mask.b.chhltd = 1;
+	if (_core_if->dma_enable) {
+		hc_intr_mask.b.ahberr = 1;
+		if (_hc->error_state && !_hc->do_split &&
+			 _hc->ep_type != DWC_OTG_EP_TYPE_ISOC) {
+			hc_intr_mask.b.ack = 1;
+			if (_hc->ep_is_in) {
+				hc_intr_mask.b.datatglerr = 1;
+				if (_hc->ep_type != DWC_OTG_EP_TYPE_INTR) {
+					hc_intr_mask.b.nak = 1;
+				}
+			}
+		}
+	} else {
+		switch (_hc->ep_type) {
+		case DWC_OTG_EP_TYPE_CONTROL:
+		case DWC_OTG_EP_TYPE_BULK:
+			hc_intr_mask.b.xfercompl = 1;
+			hc_intr_mask.b.stall = 1;
+			hc_intr_mask.b.xacterr = 1;
+			hc_intr_mask.b.datatglerr = 1;
+			if (_hc->ep_is_in) {
+				hc_intr_mask.b.bblerr = 1;
+			} else {
+				hc_intr_mask.b.nak = 1;
+				hc_intr_mask.b.nyet = 1;
+				if (_hc->do_ping) {
+					hc_intr_mask.b.ack = 1;
+				}
+			}
+			if (_hc->do_split) {
+				hc_intr_mask.b.nak = 1;
+				if (_hc->complete_split) {
+					hc_intr_mask.b.nyet = 1;
+				} else {
+					hc_intr_mask.b.ack = 1;
+				}
+			}
+			if (_hc->error_state) {
+				hc_intr_mask.b.ack = 1;
+			}
+			break;
+		case DWC_OTG_EP_TYPE_INTR:
+			hc_intr_mask.b.xfercompl = 1;
+			hc_intr_mask.b.nak = 1;
+			hc_intr_mask.b.stall = 1;
+			hc_intr_mask.b.xacterr = 1;
+			hc_intr_mask.b.datatglerr = 1;
+			hc_intr_mask.b.frmovrun = 1;
+			if (_hc->ep_is_in) {
+				hc_intr_mask.b.bblerr = 1;
+			}
+			if (_hc->error_state) {
+				hc_intr_mask.b.ack = 1;
+			}
+			if (_hc->do_split) {
+				if (_hc->complete_split) {
+					hc_intr_mask.b.nyet = 1;
+				} else {
+					hc_intr_mask.b.ack = 1;
+				}
+			}
+			break;
+		case DWC_OTG_EP_TYPE_ISOC:
+			hc_intr_mask.b.xfercompl = 1;
+			hc_intr_mask.b.frmovrun = 1;
+			hc_intr_mask.b.ack = 1;
+			if (_hc->ep_is_in) {
+				hc_intr_mask.b.xacterr = 1;
+				hc_intr_mask.b.bblerr = 1;
+			}
+			break;
+		}
+	}
+	dwc_write_reg32(&hc_regs->hcintmsk, hc_intr_mask.d32);
+
+    /* Enable the top level host channel interrupt. */
+    intr_enable = (1 << hc_num);
+	dwc_modify_reg32(&host_if->host_global_regs->haintmsk, 0, intr_enable);
+
+    /* Make sure host channel interrupts are enabled. */
+    gintmsk.b.hcintr = 1;
+	dwc_modify_reg32(&_core_if->core_global_regs->gintmsk, 0, gintmsk.d32);
+
+    /*
+     * Program the HCCHARn register with the endpoint characteristics for
+     * the current transfer.
+     */
+    hcchar.d32 = 0;
+	hcchar.b.devaddr = _hc->dev_addr;
+	hcchar.b.epnum = _hc->ep_num;
+	hcchar.b.epdir = _hc->ep_is_in;
+	hcchar.b.lspddev = (_hc->speed == DWC_OTG_EP_SPEED_LOW);
+	hcchar.b.eptype = _hc->ep_type;
+	hcchar.b.mps = _hc->max_packet;
+	dwc_write_reg32(&host_if->hc_regs[hc_num]->hcchar, hcchar.d32);
+	DWC_DEBUGPL(DBG_HCDV, "%s: Channel %d\n", __func__, _hc->hc_num);
+	DWC_DEBUGPL(DBG_HCDV, "	 Dev Addr: %d\n", hcchar.b.devaddr);
+	DWC_DEBUGPL(DBG_HCDV, "	 Ep Num: %d\n", hcchar.b.epnum);
+	DWC_DEBUGPL(DBG_HCDV, "	 Is In: %d\n", hcchar.b.epdir);
+	DWC_DEBUGPL(DBG_HCDV, "	 Is Low Speed: %d\n", hcchar.b.lspddev);
+	DWC_DEBUGPL(DBG_HCDV, "	 Ep Type: %d\n", hcchar.b.eptype);
+	DWC_DEBUGPL(DBG_HCDV, "	 Max Pkt: %d\n", hcchar.b.mps);
+	DWC_DEBUGPL(DBG_HCDV, "	 Multi Cnt: %d\n", hcchar.b.multicnt);
+
+    /*
+     * Program the HCSPLIT register for SPLITs
+     */
+    hcsplt.d32 = 0;
+	if (_hc->do_split) {
+		DWC_DEBUGPL(DBG_HCDV, "Programming HC %d with split --> %s\n",
+			     _hc->hc_num,_hc->complete_split ? "CSPLIT" : "SSPLIT");
+		hcsplt.b.compsplt = _hc->complete_split;
+		hcsplt.b.xactpos = _hc->xact_pos;
+		hcsplt.b.hubaddr = _hc->hub_addr;
+		hcsplt.b.prtaddr = _hc->port_addr;
+		DWC_DEBUGPL(DBG_HCDV, "	  comp split %d\n", _hc->complete_split);
+		DWC_DEBUGPL(DBG_HCDV, "	  xact pos %d\n", _hc->xact_pos);
+		DWC_DEBUGPL(DBG_HCDV, "	  hub addr %d\n", _hc->hub_addr);
+		DWC_DEBUGPL(DBG_HCDV, "	  port addr %d\n", _hc->port_addr);
+		DWC_DEBUGPL(DBG_HCDV, "	  is_in %d\n", _hc->ep_is_in);
+		DWC_DEBUGPL(DBG_HCDV, "	  Max Pkt: %d\n", hcchar.b.mps);
+		DWC_DEBUGPL(DBG_HCDV, "	  xferlen: %d\n", _hc->xfer_len);
+	}
+	dwc_write_reg32(&host_if->hc_regs[hc_num]->hcsplt, hcsplt.d32);
+}
+
+
+/**
+ * Attempts to halt a host channel. This function should only be called in
+ * Slave mode or to abort a transfer in either Slave mode or DMA mode. Under
+ * normal circumstances in DMA mode, the controller halts the channel when the
+ * transfer is complete or a condition occurs that requires application
+ * intervention.
+ *
+ * In slave mode, checks for a free request queue entry, then sets the Channel
+ * Enable and Channel Disable bits of the Host Channel Characteristics
+ * register of the specified channel to intiate the halt. If there is no free
+ * request queue entry, sets only the Channel Disable bit of the HCCHARn
+ * register to flush requests for this channel. In the latter case, sets a
+ * flag to indicate that the host channel needs to be halted when a request
+ * queue slot is open.
+ *
+ * In DMA mode, always sets the Channel Enable and Channel Disable bits of the
+ * HCCHARn register. The controller ensures there is space in the request
+ * queue before submitting the halt request.
+ *
+ * Some time may elapse before the core flushes any posted requests for this
+ * host channel and halts. The Channel Halted interrupt handler completes the
+ * deactivation of the host channel.
+ *
+ * @param _core_if Controller register interface.
+ * @param _hc Host channel to halt.
+ * @param _halt_status Reason for halting the channel.
+ */
+void dwc_otg_hc_halt(dwc_otg_core_if_t * _core_if,
+		     dwc_hc_t * _hc,  dwc_otg_halt_status_e _halt_status)
+{
+	gnptxsts_data_t nptxsts;
+	hptxsts_data_t hptxsts;
+	hcchar_data_t hcchar;
+	dwc_otg_hc_regs_t * hc_regs;
+	dwc_otg_core_global_regs_t * global_regs;
+	dwc_otg_host_global_regs_t * host_global_regs;
+	hc_regs = _core_if->host_if->hc_regs[_hc->hc_num];
+	global_regs = _core_if->core_global_regs;
+	host_global_regs = _core_if->host_if->host_global_regs;
+	WARN_ON(_halt_status == DWC_OTG_HC_XFER_NO_HALT_STATUS);
+	if (_halt_status == DWC_OTG_HC_XFER_URB_DEQUEUE ||
+		 _halt_status == DWC_OTG_HC_XFER_AHB_ERR) {
+
+	    /*
+	     * Disable all channel interrupts except Ch Halted. The QTD
+	     * and QH state associated with this transfer has been cleared
+	     * (in the case of URB_DEQUEUE), so the channel needs to be
+	     * shut down carefully to prevent crashes.
+	     */
+	    hcintmsk_data_t hcintmsk;
+		hcintmsk.d32 = 0;
+		hcintmsk.b.chhltd = 1;
+		dwc_write_reg32(&hc_regs->hcintmsk, hcintmsk.d32);
+
+	    /*
+	     * Make sure no other interrupts besides halt are currently
+	     * pending. Handling another interrupt could cause a crash due
+	     * to the QTD and QH state.
+	     */
+	    dwc_write_reg32(&hc_regs->hcint, ~hcintmsk.d32);
+
+	    /*
+	     * Make sure the halt status is set to URB_DEQUEUE or AHB_ERR
+	     * even if the channel was already halted for some other
+	     * reason.
+	     */
+	    _hc->halt_status = _halt_status;
+		hcchar.d32 = dwc_read_reg32(&hc_regs->hcchar);
+		if (hcchar.b.chen == 0) {
+		    /*
+		     * The channel is either already halted or it hasn't
+		     * started yet. In DMA mode, the transfer may halt if
+		     * it finishes normally or a condition occurs that
+		     * requires driver intervention. Don't want to halt
+		     * the channel again. In either Slave or DMA mode,
+		     * it's possible that the transfer has been assigned
+		     * to a channel, but not started yet when an URB is
+		     * dequeued. Don't want to halt a channel that hasn't
+		     * started yet.
+		     */
+		    return;
+		}
+	}
+	if (_hc->halt_pending) {
+
+	    /*
+	     * A halt has already been issued for this channel. This might
+	     * happen when a transfer is aborted by a higher level in
+	     * the stack.
+	     */
+#ifdef CONFIG_DWC_DEBUG
+	    DWC_PRINT("*** %s: Channel %d, _hc->halt_pending already set ***\n",
+		     __func__, _hc->hc_num);
+/*		dwc_otg_dump_global_registers(_core_if); */
+/*		dwc_otg_dump_host_registers(_core_if); */
+#endif	/*  */
+	    return;
+	}
+	hcchar.d32 = dwc_read_reg32(&hc_regs->hcchar);
+	hcchar.b.chen = 1;
+	hcchar.b.chdis = 1;
+	if (!_core_if->dma_enable) {
+	    /* Check for space in the request queue to issue the halt. */
+	    if (_hc->ep_type == DWC_OTG_EP_TYPE_CONTROL
+			|| _hc->ep_type == DWC_OTG_EP_TYPE_BULK) {
+			nptxsts.d32 = dwc_read_reg32(&global_regs->gnptxsts);
+			if (nptxsts.b.nptxqspcavail == 0) {
+				hcchar.b.chen = 0;
+			}
+		} else {
+			hptxsts.d32 = dwc_read_reg32(&host_global_regs->hptxsts);
+			if ((hptxsts.b.ptxqspcavail == 0) ||
+				 (_core_if->queuing_high_bandwidth)) {
+				hcchar.b.chen = 0;
+			}
+		}
+	}
+	dwc_write_reg32(&hc_regs->hcchar, hcchar.d32);
+	_hc->halt_status = _halt_status;
+	if (hcchar.b.chen) {
+		_hc->halt_pending = 1;
+		_hc->halt_on_queue = 0;
+	} else {
+		_hc->halt_on_queue = 1;
+	}
+	DWC_DEBUGPL(DBG_HCDV, "%s: Channel %d\n", __func__, _hc->hc_num);
+	DWC_DEBUGPL(DBG_HCDV, "	 hcchar: 0x%08x\n", hcchar.d32);
+	DWC_DEBUGPL(DBG_HCDV, "	 halt_pending: %d\n", _hc->halt_pending);
+	DWC_DEBUGPL(DBG_HCDV, "	 halt_on_queue: %d\n", _hc->halt_on_queue);
+	DWC_DEBUGPL(DBG_HCDV, "	 halt_status: %d\n", _hc->halt_status);
+	return;
+}
+
+
+/**
+ * Clears the transfer state for a host channel. This function is normally
+ * called after a transfer is done and the host channel is being released.
+ *
+ * @param _core_if Programming view of DWC_otg controller.
+ * @param _hc Identifies the host channel to clean up.
+ */
+void dwc_otg_hc_cleanup(dwc_otg_core_if_t * _core_if, dwc_hc_t * _hc)
+{
+	dwc_otg_hc_regs_t * hc_regs;
+	_hc->xfer_started = 0;
+
+    /*
+     * Clear channel interrupt enables and any unhandled channel interrupt
+     * conditions.
+     */
+    hc_regs = _core_if->host_if->hc_regs[_hc->hc_num];
+	dwc_write_reg32(&hc_regs->hcintmsk, 0);
+	dwc_write_reg32(&hc_regs->hcint, 0xFFFFFFFF);
+
+#ifdef CONFIG_DWC_DEBUG
+    del_timer(&_core_if->hc_xfer_timer[_hc->hc_num]);
+	{
+		hcchar_data_t hcchar;
+		hcchar.d32 = dwc_read_reg32(&hc_regs->hcchar);
+		if (hcchar.b.chdis) {
+			DWC_WARN("%s: chdis set, channel %d, hcchar 0x%08x\n",
+				  __func__, _hc->hc_num, hcchar.d32);
+		}
+	}
+#endif	/*  */
+}
+
+
+/**
+ * Sets the channel property that indicates in which frame a periodic transfer
+ * should occur. This is always set to the _next_ frame. This function has no
+ * effect on non-periodic transfers.
+ *
+ * @param _core_if Programming view of DWC_otg controller.
+ * @param _hc Identifies the host channel to set up and its properties.
+ * @param _hcchar Current value of the HCCHAR register for the specified host
+ * channel.
+ */
+static inline void hc_set_even_odd_frame(dwc_otg_core_if_t * _core_if,
+					 dwc_hc_t * _hc, hcchar_data_t * _hcchar)
+{
+	if (_hc->ep_type == DWC_OTG_EP_TYPE_INTR ||
+		 _hc->ep_type == DWC_OTG_EP_TYPE_ISOC) {
+		hfnum_data_t hfnum;
+		hfnum.d32 = dwc_read_reg32(&_core_if->host_if->host_global_regs->hfnum);
+
+	    /* 1 if _next_ frame is odd, 0 if it's even */
+	    _hcchar->b.oddfrm = (hfnum.b.frnum & 0x1) ? 0 : 1;
+
+#ifdef CONFIG_DWC_DEBUG
+	    if (_hc->ep_type == DWC_OTG_EP_TYPE_INTR && _hc->do_split
+			&& !_hc->complete_split) {
+			switch (hfnum.b.frnum & 0x7) {
+			case 7:
+				_core_if->hfnum_7_samples++;
+				_core_if->hfnum_7_frrem_accum += hfnum.b.frrem;
+				break;
+			case 0:
+				_core_if->hfnum_0_samples++;
+				_core_if->hfnum_0_frrem_accum += hfnum.b.frrem;
+				break;
+			default:
+				_core_if->hfnum_other_samples++;
+				_core_if->hfnum_other_frrem_accum +=
+				    hfnum.b.frrem;
+				break;
+			}
+		}
+#endif	/*  */
+	}
+}
+
+#ifdef CONFIG_DWC_DEBUG
+static void hc_xfer_timeout(unsigned long _ptr)
+{
+	hc_xfer_info_t * xfer_info = (hc_xfer_info_t *) _ptr;
+	int hc_num = xfer_info->hc->hc_num;
+	DWC_WARN("%s: timeout on channel %d\n", __func__, hc_num);
+	DWC_WARN("	start_hcchar_val 0x%08x\n",
+		  xfer_info->core_if->start_hcchar_val[hc_num]);
+}
+#endif	/*  */
+
+/*
+ * This function does the setup for a data transfer for a host channel and
+ * starts the transfer. May be called in either Slave mode or DMA mode. In
+ * Slave mode, the caller must ensure that there is sufficient space in the
+ * request queue and Tx Data FIFO.
+ *
+ * For an OUT transfer in Slave mode, it loads a data packet into the
+ * appropriate FIFO. If necessary, additional data packets will be loaded in
+ * the Host ISR.
+ *
+ * For an IN transfer in Slave mode, a data packet is requested. The data
+ * packets are unloaded from the Rx FIFO in the Host ISR. If necessary,
+ * additional data packets are requested in the Host ISR.
+ *
+ * For a PING transfer in Slave mode, the Do Ping bit is set in the HCTSIZ
+ * register along with a packet count of 1 and the channel is enabled. This
+ * causes a single PING transaction to occur. Other fields in HCTSIZ are
+ * simply set to 0 since no data transfer occurs in this case.
+ *
+ * For a PING transfer in DMA mode, the HCTSIZ register is initialized with
+ * all the information required to perform the subsequent data transfer. In
+ * addition, the Do Ping bit is set in the HCTSIZ register. In this case, the
+ * controller performs the entire PING protocol, then starts the data
+ * transfer.
+ *
+ * @param _core_if Programming view of DWC_otg controller.
+ * @param _hc Information needed to initialize the host channel. The xfer_len
+ * value may be reduced to accommodate the max widths of the XferSize and
+ * PktCnt fields in the HCTSIZn register. The multi_count value may be changed
+ * to reflect the final xfer_len value.
+ */
+void dwc_otg_hc_start_transfer(dwc_otg_core_if_t * _core_if, dwc_hc_t * _hc)
+{
+	hcchar_data_t hcchar;
+	hctsiz_data_t hctsiz;
+	uint16_t num_packets;
+	uint32_t max_hc_xfer_size = _core_if->core_params->max_transfer_size;
+	uint16_t max_hc_pkt_count = _core_if->core_params->max_packet_count;
+	dwc_otg_hc_regs_t * hc_regs = _core_if->host_if->hc_regs[_hc->hc_num];
+	hctsiz.d32 = 0;
+	if (_hc->do_ping) {
+		if (!_core_if->dma_enable) {
+			dwc_otg_hc_do_ping(_core_if, _hc);
+			_hc->xfer_started = 1;
+			return;
+		} else {
+			hctsiz.b.dopng = 1;
+		}
+	}
+	if (_hc->do_split) {
+		num_packets = 1;
+		if (_hc->complete_split && !_hc->ep_is_in) {
+		    /* For CSPLIT OUT Transfer, set the size to 0 so the
+		     * core doesn't expect any data written to the FIFO */
+		    _hc->xfer_len = 0;
+		} else if (_hc->ep_is_in || (_hc->xfer_len > _hc->max_packet)) {
+			_hc->xfer_len = _hc->max_packet;
+		} else if (!_hc->ep_is_in && (_hc->xfer_len > 188)) {
+			_hc->xfer_len = 188;
+		}
+		hctsiz.b.xfersize = _hc->xfer_len;
+	} else {
+	    /*
+	     * Ensure that the transfer length and packet count will fit
+	     * in the widths allocated for them in the HCTSIZn register.
+	     */
+	    if (_hc->ep_type == DWC_OTG_EP_TYPE_INTR
+			|| _hc->ep_type == DWC_OTG_EP_TYPE_ISOC) {
+		    /*
+		     * Make sure the transfer size is no larger than one
+		     * (micro)frame's worth of data. (A check was done
+		     * when the periodic transfer was accepted to ensure
+		     * that a (micro)frame's worth of data can be
+		     * programmed into a channel.)
+		     */
+		    uint32_t max_periodic_len = _hc->multi_count * _hc->max_packet;
+			if (_hc->xfer_len > max_periodic_len) {
+				_hc->xfer_len = max_periodic_len;
+			} else {
+			}
+		} else if (_hc->xfer_len > max_hc_xfer_size) {
+			/* Make sure that xfer_len is a multiple of max packet size. */
+		    _hc->xfer_len = max_hc_xfer_size - _hc->max_packet + 1;
+		}
+		if (_hc->xfer_len > 0) {
+			num_packets = (_hc->xfer_len + _hc->max_packet - 1) / _hc->max_packet;
+			if (num_packets > max_hc_pkt_count) {
+				num_packets = max_hc_pkt_count;
+				_hc->xfer_len = num_packets * _hc->max_packet;
+			}
+		} else {
+		    /* Need 1 packet for transfer length of 0. */
+		    num_packets = 1;
+		}
+		if (_hc->ep_is_in) {
+		    /* Always program an integral # of max packets for IN transfers. */
+		    _hc->xfer_len = num_packets * _hc->max_packet;
+		}
+		if (_hc->ep_type == DWC_OTG_EP_TYPE_INTR
+		      || _hc->ep_type == DWC_OTG_EP_TYPE_ISOC) {
+		    /*
+		     * Make sure that the multi_count field matches the
+		     * actual transfer length.
+		     */
+		    _hc->multi_count = num_packets;
+		}
+		if (_hc->ep_type == DWC_OTG_EP_TYPE_ISOC) {
+		    /* Set up the initial PID for the transfer. */
+		    if (_hc->speed == DWC_OTG_EP_SPEED_HIGH) {
+				if (_hc->ep_is_in) {
+					if (_hc->multi_count == 1) {
+						_hc->data_pid_start =
+						    DWC_OTG_HC_PID_DATA0;
+					} else if (_hc->multi_count == 2) {
+						_hc->data_pid_start =
+						    DWC_OTG_HC_PID_DATA1;
+					} else {
+						_hc->data_pid_start =
+						    DWC_OTG_HC_PID_DATA2;
+					}
+				} else {
+					if (_hc->multi_count == 1) {
+						_hc->data_pid_start =
+						    DWC_OTG_HC_PID_DATA0;
+					} else {
+						_hc->data_pid_start =
+						    DWC_OTG_HC_PID_MDATA;
+					}
+				}
+			} else {
+				_hc->data_pid_start = DWC_OTG_HC_PID_DATA0;
+			}
+		}
+		hctsiz.b.xfersize = _hc->xfer_len;
+	}
+	_hc->start_pkt_count = num_packets;
+	hctsiz.b.pktcnt = num_packets;
+	hctsiz.b.pid = _hc->data_pid_start;
+	dwc_write_reg32(&hc_regs->hctsiz, hctsiz.d32);
+	DWC_DEBUGPL(DBG_HCDV, "%s: Channel %d\n", __func__, _hc->hc_num);
+	DWC_DEBUGPL(DBG_HCDV, "	 Xfer Size: %d\n", hctsiz.b.xfersize);
+	DWC_DEBUGPL(DBG_HCDV, "	 Num Pkts: %d\n", hctsiz.b.pktcnt);
+	DWC_DEBUGPL(DBG_HCDV, "	 Start PID: %d\n", hctsiz.b.pid);
+	if (_core_if->dma_enable) {
+		dwc_write_reg32(&hc_regs->hcdma, (uint32_t) _hc->xfer_buff);
+	}
+
+    /* Start the split */
+    if (_hc->do_split) {
+		hcsplt_data_t hcsplt;
+		hcsplt.d32 = dwc_read_reg32(&hc_regs->hcsplt);
+		hcsplt.b.spltena = 1;
+		dwc_write_reg32(&hc_regs->hcsplt, hcsplt.d32);
+	}
+	hcchar.d32 = dwc_read_reg32(&hc_regs->hcchar);
+	hcchar.b.multicnt = _hc->multi_count;
+	hc_set_even_odd_frame(_core_if, _hc, &hcchar);
+
+#ifdef CONFIG_DWC_DEBUG
+    _core_if->start_hcchar_val[_hc->hc_num] = hcchar.d32;
+	if (hcchar.b.chdis) {
+		DWC_WARN("%s: chdis set, channel %d, hcchar 0x%08x\n",
+			  __func__, _hc->hc_num, hcchar.d32);
+	}
+
+#endif	/*  */
+
+    /* Set host channel enable after all other setup is complete. */
+    hcchar.b.chen = 1;
+	hcchar.b.chdis = 0;
+	dwc_write_reg32(&hc_regs->hcchar, hcchar.d32);
+	_hc->xfer_started = 1;
+	_hc->requests++;
+	if (!_core_if->dma_enable && !_hc->ep_is_in && _hc->xfer_len > 0) {
+	    /* Load OUT packet into the appropriate Tx FIFO. */
+	    dwc_otg_hc_write_packet(_core_if, _hc);
+	}
+
+#ifdef CONFIG_DWC_DEBUG
+    /* Start a timer for this transfer. */
+    _core_if->hc_xfer_timer[_hc->hc_num].function = hc_xfer_timeout;
+	_core_if->hc_xfer_info[_hc->hc_num].core_if = _core_if;
+	_core_if->hc_xfer_info[_hc->hc_num].hc = _hc;
+	_core_if->hc_xfer_timer[_hc->hc_num].data =
+	    (unsigned long)(&_core_if->hc_xfer_info[_hc->hc_num]);
+	_core_if->hc_xfer_timer[_hc->hc_num].expires = jiffies + (HZ * 10);
+	add_timer(&_core_if->hc_xfer_timer[_hc->hc_num]);
+#endif	/*  */
+}
+
+/**
+ * This function continues a data transfer that was started by previous call
+ * to <code>dwc_otg_hc_start_transfer</code>. The caller must ensure there is
+ * sufficient space in the request queue and Tx Data FIFO. This function
+ * should only be called in Slave mode. In DMA mode, the controller acts
+ * autonomously to complete transfers programmed to a host channel.
+ *
+ * For an OUT transfer, a new data packet is loaded into the appropriate FIFO
+ * if there is any data remaining to be queued. For an IN transfer, another
+ * data packet is always requested. For the SETUP phase of a control transfer,
+ * this function does nothing.
+ *
+ * @return 1 if a new request is queued, 0 if no more requests are required
+ * for this transfer.
+ */
+int dwc_otg_hc_continue_transfer(dwc_otg_core_if_t * _core_if, dwc_hc_t * _hc)
+{
+	DWC_DEBUGPL(DBG_HCDV, "%s: Channel %d\n", __func__, _hc->hc_num);
+	if (_hc->do_split) {
+	    /* SPLITs always queue just once per channel */
+	    return 0;
+	} else if (_hc->data_pid_start == DWC_OTG_HC_PID_SETUP) {
+	    /* SETUPs are queued only once since they can't be NAKed. */
+	    return 0;
+	} else if (_hc->ep_is_in) {
+	    /*
+	     * Always queue another request for other IN transfers. If
+	     * back-to-back INs are issued and NAKs are received for both,
+	     * the driver may still be processing the first NAK when the
+	     * second NAK is received. When the interrupt handler clears
+	     * the NAK interrupt for the first NAK, the second NAK will
+	     * not be seen. So we can't depend on the NAK interrupt
+	     * handler to requeue a NAKed request. Instead, IN requests
+	     * are issued each time this function is called. When the
+	     * transfer completes, the extra requests for the channel will
+	     * be flushed.
+	     */
+	    hcchar_data_t hcchar;
+		dwc_otg_hc_regs_t * hc_regs = _core_if->host_if->hc_regs[_hc->hc_num];
+		hcchar.d32 = dwc_read_reg32(&hc_regs->hcchar);
+		hc_set_even_odd_frame(_core_if, _hc, &hcchar);
+		hcchar.b.chen = 1;
+		hcchar.b.chdis = 0;
+		DWC_DEBUGPL(DBG_HCDV, "	 IN xfer: hcchar = 0x%08x\n", hcchar.d32);
+		dwc_write_reg32(&hc_regs->hcchar, hcchar.d32);
+		_hc->requests++;
+		return 1;
+	} else {
+	    /* OUT transfers. */
+	    if (_hc->xfer_count < _hc->xfer_len) {
+			if (_hc->ep_type == DWC_OTG_EP_TYPE_INTR ||
+				 _hc->ep_type == DWC_OTG_EP_TYPE_ISOC) {
+				hcchar_data_t hcchar;
+				dwc_otg_hc_regs_t * hc_regs;
+				hc_regs = _core_if->host_if->hc_regs[_hc->hc_num];
+				hcchar.d32 = dwc_read_reg32(&hc_regs->hcchar);
+				hc_set_even_odd_frame(_core_if, _hc, &hcchar);
+			}
+
+		    /* Load OUT packet into the appropriate Tx FIFO. */
+		    dwc_otg_hc_write_packet(_core_if, _hc);
+			_hc->requests++;
+			return 1;
+		} else {
+			return 0;
+		}
+	}
+}
+
+/**
+ * Starts a PING transfer. This function should only be called in Slave mode.
+ * The Do Ping bit is set in the HCTSIZ register, then the channel is enabled.
+ */
+void dwc_otg_hc_do_ping(dwc_otg_core_if_t * _core_if, dwc_hc_t * _hc)
+{
+	hcchar_data_t hcchar;
+	hctsiz_data_t hctsiz;
+	dwc_otg_hc_regs_t * hc_regs = _core_if->host_if->hc_regs[_hc->hc_num];
+	DWC_DEBUGPL(DBG_HCDV, "%s: Channel %d\n", __func__, _hc->hc_num);
+	hctsiz.d32 = 0;
+	hctsiz.b.dopng = 1;
+	hctsiz.b.pktcnt = 1;
+	dwc_write_reg32(&hc_regs->hctsiz, hctsiz.d32);
+	hcchar.d32 = dwc_read_reg32(&hc_regs->hcchar);
+	hcchar.b.chen = 1;
+	hcchar.b.chdis = 0;
+	dwc_write_reg32(&hc_regs->hcchar, hcchar.d32);
+}
+
+
+#ifdef CONFIG_OTG_PLB_DMA      /* PPC_PLB_DMA mode */
+/*
+ * This will dump the status of the dma registers -
+ * Only used in debug mode
+ */
+void ppc4xx_dump_dma(unsigned int dmanr)
+{
+	int index;
+
+	printk("%32s:\n", __FUNCTION__);
+	for (index=0; index<=7; index++) {
+	    printk("%32s dmanr=%d , 0x%x=0x%x\n",__FUNCTION__, dmanr ,
+				DCRN_DMACR0 + dmanr*8+index, mfdcr(DCRN_DMACR0 + dmanr*8 + index));
+	}
+	printk("%32s DCRN_DMASR=0x%x\n", __FUNCTION__, mfdcr(DCRN_DMASR));
+}
+
+/*
+ * This function programs the PLB-DMA engine to perform MEM-MEM transfer
+ *      This is used to RD & WR from the DWC_FIFO by the PLB_DMA engine
+ */
+void ppc4xx_start_plb_dma(dwc_otg_core_if_t *_core_if, void *src, void *dst, unsigned int length,
+            unsigned int use_interrupt,  unsigned int dma_ch, unsigned int dma_dir)
+{
+	int res = 0;
+	unsigned int control;
+	ppc_dma_ch_t p_init;
+
+	memset((char *)&p_init, sizeof(p_init), 0);
+	p_init.polarity = 0;
+	p_init.pwidth = PW_32;
+	p_init.in_use = 0;
+	if ( dma_dir == OTG_TX_DMA) {
+	    p_init.sai = 1;
+	    p_init.dai = 0;
+	} else if (dma_dir == OTG_RX_DMA) {
+	    p_init.sai = 0;
+	    p_init.dai = 1;
+	}
+	res = ppc4xx_init_dma_channel(dma_ch, &p_init);
+	    if (res) {
+	    printk("%32s: nit_dma_channel return %d %d bytes dest %p\n",
+	        __FUNCTION__, res, length, dst);
+	}
+	res = ppc4xx_clr_dma_status(dma_ch);
+	if (res) {
+	    printk("%32s: ppc4xx_clr_dma_status %d\n", __FUNCTION__, res);
+	}
+
+	if (dma_dir == OTG_TX_DMA) {
+	    ppc4xx_set_src_addr(dma_ch, virt_to_bus (src));
+	    ppc4xx_set_dst_addr(dma_ch, (_core_if->phys_addr +
+			(dst - (void *)(_core_if->core_global_regs))) );
+	} else if (dma_dir == OTG_RX_DMA) {
+	    ppc4xx_set_src_addr(dma_ch, (_core_if->phys_addr +
+			(src - (void *)(_core_if->core_global_regs))) );
+	    ppc4xx_set_dst_addr(dma_ch, virt_to_bus (dst));
+	}
+
+	ppc4xx_set_dma_mode(dma_ch, DMA_MODE_MM);
+	ppc4xx_set_dma_count(dma_ch, length);
+
+	/* flush cache before enabling DMA transfer */
+	if (dma_dir == OTG_TX_DMA) {
+	    flush_dcache_range((unsigned long)src,
+	                   (unsigned long)(src + length));
+	} else if (dma_dir == OTG_RX_DMA) {
+	    flush_dcache_range((unsigned long)dst,
+	                       (unsigned long)(dst + length));
+	}
+
+	if (use_interrupt) {
+	    res = ppc4xx_enable_dma_interrupt(dma_ch);
+	} else {
+	    res = ppc4xx_disable_dma_interrupt(dma_ch);
+	}
+	if (res) {
+	    printk("%32s: en/disable_dma_interrupt %d return %d per %d\n",
+	    __FUNCTION__, use_interrupt, res,
+	    ppc4xx_get_peripheral_width(dma_ch));
+	}
+
+	control = mfdcr(DCRN_DMACR0 + (dma_ch * 8));
+
+	control &= ~(SET_DMA_BEN(1));
+	control &= ~(SET_DMA_PSC(3));
+	control &= ~(SET_DMA_PWC(0x3f));
+	control &= ~(SET_DMA_PHC(0x7));
+	control &= ~(SET_DMA_PL(1));
+
+	mtdcr(DCRN_DMACR0 + (dma_ch * 8), control);
+
+#ifdef CONFIG_OTG_PLB_DMA_DBG
+	ppc4xx_dump_dma(dma_ch);
+#endif
+	ppc4xx_enable_dma(dma_ch);
+}
+#endif
+
+/*
+ * This function writes a packet into the Tx FIFO associated with the Host
+ * Channel. For a channel associated with a non-periodic EP, the non-periodic
+ * Tx FIFO is written. For a channel associated with a periodic EP, the
+ * periodic Tx FIFO is written. This function should only be called in Slave
+ * mode.
+ *
+ * Upon return the xfer_buff and xfer_count fields in _hc are incremented by
+ * then number of bytes written to the Tx FIFO.
+ */
+void dwc_otg_hc_write_packet(dwc_otg_core_if_t * _core_if, dwc_hc_t * _hc)
+{
+#ifndef CONFIG_OTG_PLB_DMA
+	uint32_t i;
+#endif
+	uint32_t remaining_count;
+	uint32_t byte_count;
+	uint32_t dword_count;
+	uint32_t * data_buff = (uint32_t *) (_hc->xfer_buff);
+	uint32_t * data_fifo = _core_if->data_fifo[_hc->hc_num];
+#if !defined( CONFIG_OTG_PLB_DMA_TASKLET) &&  defined(CONFIG_OTG_PLB_DMA)
+	uint32_t dma_sts = 0;
+#endif
+	remaining_count = _hc->xfer_len - _hc->xfer_count;
+	if (remaining_count > _hc->max_packet) {
+		byte_count = _hc->max_packet;
+	} else {
+		byte_count = remaining_count;
+	}
+	dword_count = (byte_count + 3) / 4;
+
+#ifdef CONFIG_OTG_PLB_DMA
+#ifdef CONFIG_OTG_PLB_DMA_TASKLET
+
+	if ( _hc->xfer_len < USB_BUFSIZ) {
+		int i;
+		if ((((unsigned long)data_buff) & 0x3) == 0) {
+		    /* xfer_buff is DWORD aligned. */
+	    	for (i = 0; i < dword_count; i++, data_buff++) {
+				dwc_write_datafifo32(data_fifo, *data_buff);
+			}
+		} else {
+	    	/* xfer_buff is not DWORD aligned. */
+		    for (i = 0; i < dword_count; i++, data_buff++) {
+				dwc_write_datafifo32(data_fifo, get_unaligned(data_buff));
+			}
+		}
+	} else {
+	    DWC_DEBUGPL(DBG_SP, "%s set release_later %d\n",  __func__, dword_count);
+    	atomic_set(& release_later, 1);
+		//disable_irq_nosync(94);
+		dwc_otg_disable_global_interrupts(_core_if);
+
+	    _core_if->dma_xfer.dma_data_buff = data_buff;
+   		_core_if->dma_xfer.dma_data_fifo = (void *)data_fifo;
+	    _core_if->dma_xfer.dma_count = dword_count;
+		_core_if->dma_xfer.dma_dir = OTG_TX_DMA;
+		tasklet_schedule(_core_if->plbdma_tasklet);
+	}
+#else	/* !CONFIG_OTG_PLB_DMA_TASKLET */
+    if ((((unsigned long)data_buff) & 0x3) == 0) {
+        /* call tx_dma - src,dest,len,intr */
+        ppc4xx_start_plb_dma(_core_if, (void *)data_buff, data_fifo,
+        	(dword_count * 4), PLB_DMA_INT_DIS, PLB_DMA_CH, OTG_TX_DMA);
+    } else {
+        ppc4xx_start_plb_dma(_core_if, (void *)get_unaligned(data_buff),
+        	data_fifo, (dword_count * 4), PLB_DMA_INT_DIS, PLB_DMA_CH, OTG_TX_DMA);
+    }
+
+	while (mfdcr(DCRN_DMACR0 + (PLB_DMA_CH*8)) & DMA_CE_ENABLE) {
+	}
+	dma_sts = (uint32_t)ppc4xx_get_dma_status();
+#ifdef CONFIG_OTG_PLB_DMA_DBG
+	if (!(dma_sts & DMA_CS0)) {
+		printk("Status (Terminal Count not occured) 0x%08x\n", mfdcr(DCRN_DMASR));
+	}
+#endif
+	if (dma_sts & DMA_CH0_ERR) {
+	    printk("Status (Channel Error) 0x%08x\n", mfdcr(DCRN_DMASR));
+	}
+	ppc4xx_clr_dma_status(PLB_DMA_CH);
+#ifdef CONFIG_OTG_PLB_DMA_DBG
+	printk("%32s DMA Status =0x%08x\n", __FUNCTION__, mfdcr(DCRN_DMASR)); /* vj_dbg */
+#endif
+
+#endif	/* CONFIG_OTG_PLB_DMA_TASKLET */
+
+
+#else
+	if ((((unsigned long)data_buff) & 0x3) == 0) {
+	    /* xfer_buff is DWORD aligned. */
+	    for (i = 0; i < dword_count; i++, data_buff++) {
+			dwc_write_datafifo32(data_fifo, *data_buff);
+		}
+	} else {
+	    /* xfer_buff is not DWORD aligned. */
+	    for (i = 0; i < dword_count; i++, data_buff++) {
+			dwc_write_datafifo32(data_fifo, get_unaligned(data_buff));
+		}
+	}
+#endif
+	_hc->xfer_count += byte_count;
+	_hc->xfer_buff += byte_count;
+}
+
+/**
+ * Gets the current USB frame number. This is the frame number from the last
+ * SOF packet.
+ */
+uint32_t dwc_otg_get_frame_number(dwc_otg_core_if_t * _core_if)
+{
+	dsts_data_t dsts;
+	dsts.d32 = dwc_read_reg32(&_core_if->dev_if->dev_global_regs->dsts);
+    /* read current frame/microfreme number from DSTS register */
+    return dsts.b.soffn;
+}
+
+
+/**
+ * This function reads a setup packet from the Rx FIFO into the destination
+ * buffer.	This function is called from the Rx Status Queue Level (RxStsQLvl)
+ * Interrupt routine when a SETUP packet has been received in Slave mode.
+ *
+ * @param _core_if Programming view of DWC_otg controller.
+ * @param _dest Destination buffer for packet data.
+ */
+void dwc_otg_read_setup_packet(dwc_otg_core_if_t * _core_if, uint32_t * _dest)
+{
+    /* Get the 8 bytes of a setup transaction data */
+
+    /* Pop 2 DWORDS off the receive data FIFO into memory */
+    _dest[0] = dwc_read_datafifo32(_core_if->data_fifo[0]);
+	_dest[1] = dwc_read_datafifo32(_core_if->data_fifo[0]);
+}
+
+/**
+ * This function enables EP0 OUT to receive SETUP packets and configures EP0
+ * IN for transmitting packets.	 It is normally called when the
+ * "Enumeration Done" interrupt occurs.
+ *
+ * @param _core_if Programming view of DWC_otg controller.
+ * @param _ep The EP0 data.
+ */
+void dwc_otg_ep0_activate(dwc_otg_core_if_t * _core_if, dwc_ep_t * _ep)
+{
+	dwc_otg_dev_if_t * dev_if = _core_if->dev_if;
+	dsts_data_t dsts;
+	depctl_data_t diepctl;
+	depctl_data_t doepctl;
+	dctl_data_t dctl = {.d32 = 0};
+
+    /* Read the Device Status and Endpoint 0 Control registers */
+    dsts.d32 = dwc_read_reg32(&dev_if->dev_global_regs->dsts);
+	diepctl.d32 = dwc_read_reg32(&dev_if->in_ep_regs[0]->diepctl);
+	doepctl.d32 = dwc_read_reg32(&dev_if->out_ep_regs[0]->doepctl);
+
+    /* Set the MPS of the IN EP based on the enumeration speed */
+    switch (dsts.b.enumspd) {
+	case DWC_DSTS_ENUMSPD_HS_PHY_30MHZ_OR_60MHZ:
+	case DWC_DSTS_ENUMSPD_FS_PHY_30MHZ_OR_60MHZ:
+	case DWC_DSTS_ENUMSPD_FS_PHY_48MHZ:
+		diepctl.b.mps = DWC_DEP0CTL_MPS_64;
+		break;
+	case DWC_DSTS_ENUMSPD_LS_PHY_6MHZ:
+		diepctl.b.mps = DWC_DEP0CTL_MPS_8;
+		break;
+	}
+	dwc_write_reg32(&dev_if->in_ep_regs[0]->diepctl, diepctl.d32);
+
+    /* Enable OUT EP for receive */
+    doepctl.b.epena = 1;
+	dwc_write_reg32(&dev_if->out_ep_regs[0]->doepctl, doepctl.d32);
+
+#ifdef VERBOSE
+    DWC_DEBUGPL(DBG_PCDV, "doepctl0=%0x\n",
+			dwc_read_reg32(&dev_if->out_ep_regs[0]->doepctl));
+	DWC_DEBUGPL(DBG_PCDV, "diepctl0=%0x\n",
+		     dwc_read_reg32(&dev_if->in_ep_regs[0]->diepctl));
+
+#endif	/*  */
+    dctl.b.cgnpinnak = 1;
+	dwc_modify_reg32(&dev_if->dev_global_regs->dctl, dctl.d32, dctl.d32);
+	DWC_DEBUGPL(DBG_PCDV, "dctl=%0x\n",
+		     dwc_read_reg32(&dev_if->dev_global_regs->dctl));
+}
+
+
+/**
+ * This function activates an EP.  The Device EP control register for
+ * the EP is configured as defined in the ep structure.	 Note: This
+ * function is not used for EP0.
+ *
+ * @param _core_if Programming view of DWC_otg controller.
+ * @param _ep The EP to activate.
+ */
+void dwc_otg_ep_activate(dwc_otg_core_if_t * _core_if, dwc_ep_t * _ep)
+{
+	dwc_otg_dev_if_t * dev_if = _core_if->dev_if;
+	depctl_data_t depctl;
+	volatile uint32_t *addr;
+	daint_data_t daintmsk = {.d32 = 0};
+	DWC_DEBUGPL(DBG_PCDV, "%s() EP%d-%s\n", __func__, _ep->num,
+		      (_ep->is_in ? "IN" : "OUT"));
+
+    /* Read DEPCTLn register */
+    if (_ep->is_in == 1) {
+		addr = &dev_if->in_ep_regs[_ep->num]->diepctl;
+		daintmsk.ep.in = 1 << _ep->num;
+	} else {
+		addr = &dev_if->out_ep_regs[_ep->num]->doepctl;
+		daintmsk.ep.out = 1 << _ep->num;
+	}
+
+    /* If the EP is already active don't change the EP Control
+     * register.
+	 */
+    depctl.d32 = dwc_read_reg32(addr);
+	if (!depctl.b.usbactep) {
+		depctl.b.mps = _ep->maxpacket;
+		depctl.b.eptype = _ep->type;
+		depctl.b.txfnum = _ep->tx_fifo_num;
+		if (_ep->type == DWC_OTG_EP_TYPE_ISOC) {
+			depctl.b.setd0pid = 1;	// ???
+		} else {
+			depctl.b.setd0pid = 1;
+		}
+		depctl.b.usbactep = 1;
+		dwc_write_reg32(addr, depctl.d32);
+		DWC_DEBUGPL(DBG_PCDV, "DEPCTL=%08x\n", dwc_read_reg32(addr));
+	}
+
+    /* Enable the Interrupt for this EP */
+    dwc_modify_reg32(&dev_if->dev_global_regs->daintmsk, 0,
+			     daintmsk.d32);
+	DWC_DEBUGPL(DBG_PCDV, "DAINTMSK=%0x\n",
+		      dwc_read_reg32(&dev_if->dev_global_regs->daintmsk));
+	_ep->stall_clear_flag = 0;
+	return;
+}
+
+
+/**
+ * This function deactivates an EP.	 This is done by clearing the USB Active
+ * EP bit in the Device EP control register.  Note: This function is not used
+ * for EP0. EP0 cannot be deactivated.
+ *
+ * @param _core_if Programming view of DWC_otg controller.
+ * @param _ep The EP to deactivate.
+ */
+void dwc_otg_ep_deactivate(dwc_otg_core_if_t * _core_if, dwc_ep_t * _ep)
+{
+	depctl_data_t depctl = {.d32 = 0};
+	volatile uint32_t *addr;
+	daint_data_t daintmsk = {.d32 = 0};
+
+    /* Read DEPCTLn register */
+    if (_ep->is_in == 1) {
+		addr = &_core_if->dev_if->in_ep_regs[_ep->num]->diepctl;
+		daintmsk.ep.in = 1 << _ep->num;
+	} else {
+		addr = &_core_if->dev_if->out_ep_regs[_ep->num]->doepctl;
+		daintmsk.ep.out = 1 << _ep->num;
+	}
+	depctl.b.usbactep = 0;
+	dwc_write_reg32(addr, depctl.d32);
+
+    /* Disable the Interrupt for this EP */
+    dwc_modify_reg32(&_core_if->dev_if->dev_global_regs->daintmsk,
+			     daintmsk.d32, 0);
+	return;
+}
+
+
+/**
+ * This function does the setup for a data transfer for an EP and
+ * starts the transfer.	 For an IN transfer, the packets will be
+ * loaded into the appropriate Tx FIFO in the ISR. For OUT transfers,
+ * the packets are unloaded from the Rx FIFO in the ISR.  the ISR.
+ *
+ * @param _core_if Programming view of DWC_otg controller.
+ * @param _ep The EP to start the transfer on.
+ */
+void dwc_otg_ep_start_transfer(dwc_otg_core_if_t * _core_if, dwc_ep_t * _ep)
+{
+	/** @todo Refactor this funciton to check the transfer size
+	 * count value does not execed the number bits in the Transfer
+	 * count register. */
+    depctl_data_t depctl;
+	deptsiz_data_t deptsiz;
+	gintmsk_data_t intr_mask = {.d32 = 0};
+
+#ifdef CHECK_PACKET_COUNTER_WIDTH
+	const uint32_t MAX_XFER_SIZE = _core_if->core_params->max_transfer_size;
+	const uint32_t MAX_PKT_COUNT = _core_if->core_params->max_packet_count;
+	uint32_t num_packets;
+	uint32_t transfer_len;
+	dwc_otg_dev_out_ep_regs_t * out_regs = _core_if->dev_if->out_ep_regs[_ep->num];
+	dwc_otg_dev_in_ep_regs_t * in_regs = _core_if->dev_if->in_ep_regs[_ep->num];
+	gnptxsts_data_t txstatus;
+	int lvl = SET_DEBUG_LEVEL(DBG_PCD);
+	DWC_DEBUGPL(DBG_PCD, "ep%d-%s xfer_len=%d xfer_cnt=%d "
+		      "xfer_buff=%p start_xfer_buff=%p\n", _ep->num,
+		      (_ep->is_in ? "IN" : "OUT"), _ep->xfer_len,
+		      _ep->xfer_count, _ep->xfer_buff, _ep->start_xfer_buff);
+	transfer_len = _ep->xfer_len - _ep->xfer_count;
+	if (transfer_len > MAX_XFER_SIZE) {
+		transfer_len = MAX_XFER_SIZE;
+	}
+	if (transfer_len == 0) {
+		num_packets = 1;
+
+	    /* OUT EP to recieve Zero-length packet set transfer
+	     * size to maxpacket size. */
+	    if (!_ep->is_in) {
+			transfer_len = _ep->maxpacket;
+		}
+	} else {
+		num_packets = (transfer_len + _ep->maxpacket - 1) / _ep->maxpacket;
+		if (num_packets > MAX_PKT_COUNT) {
+			num_packets = MAX_PKT_COUNT;
+		}
+	}
+	DWC_DEBUGPL(DBG_PCD, "transfer_len=%d #pckt=%d\n", transfer_len,
+		     num_packets);
+	deptsiz.b.xfersize = transfer_len;
+	deptsiz.b.pktcnt = num_packets;
+
+    /* IN endpoint */
+    if (_ep->is_in == 1) {
+		depctl.d32 = dwc_read_reg32(&in_regs->diepctl);
+	}			/* OUT endpoint */
+	else {
+		depctl.d32 = dwc_read_reg32(&out_regs->doepctl);
+	}
+
+    /* EP enable, IN data in FIFO */
+    depctl.b.cnak = 1;
+	depctl.b.epena = 1;
+
+    /* IN endpoint */
+    if (_ep->is_in == 1) {
+		txstatus.d32 = dwc_read_reg32(&_core_if->core_global_regs->gnptxsts);
+		if (txstatus.b.nptxqspcavail == 0) {
+			DWC_DEBUGPL(DBG_ANY, "TX Queue Full (0x%0x)\n",
+				     txstatus.d32);
+			return;
+		}
+		dwc_write_reg32(&in_regs->dieptsiz, deptsiz.d32);
+		dwc_write_reg32(&in_regs->diepctl, depctl.d32);
+
+		/**
+		 * Enable the Non-Periodic Tx FIFO empty interrupt, the
+		 * data will be written into the fifo by the ISR.
+		 */
+	    if (_core_if->dma_enable) {
+			dwc_write_reg32(&in_regs->diepdma, (uint32_t) _ep->xfer_buff);
+		} else {
+			if (_core_if->en_multiple_tx_fifo == 0) {
+				intr_mask.b.nptxfempty = 1;
+				dwc_modify_reg32(&_core_if->core_global_regs->gintsts,
+							intr_mask.d32, 0);
+				dwc_modify_reg32(&_core_if->core_global_regs->gintmsk,
+							intr_mask.d32,intr_mask.d32);
+			} else {
+			    /* Enable the Tx FIFO Empty Interrupt for this EP */
+			    if (_ep->xfer_len > 0 &&
+					 _ep->type != DWC_OTG_EP_TYPE_ISOC) {
+					uint32_t fifoemptymsk = 0;
+					fifoemptymsk = (0x1 << _ep->num);
+					dwc_modify_reg32(&_core_if->dev_if->dev_global_regs->
+							dtknqr4_fifoemptymsk,0, fifoemptymsk);
+				}
+			}
+		}
+	} else {
+	    /* OUT endpoint */
+	    dwc_write_reg32(&out_regs->doeptsiz, deptsiz.d32);
+		dwc_write_reg32(&out_regs->doepctl, depctl.d32);
+		if (_core_if->dma_enable) {
+			dwc_write_reg32(&out_regs->doepdma,(uint32_t) _ep->xfer_buff);
+		}
+	}
+	DWC_DEBUGPL(DBG_PCD, "DOEPCTL=%08x DOEPTSIZ=%08x\n",
+		     dwc_read_reg32(&out_regs->doepctl),
+		     dwc_read_reg32(&out_regs->doeptsiz));
+	DWC_DEBUGPL(DBG_PCD, "DAINTMSK=%08x GINTMSK=%08x\n",
+		     dwc_read_reg32(&_core_if->dev_if->dev_global_regs->daintmsk),
+		     dwc_read_reg32(&_core_if->core_global_regs->gintmsk));
+	SET_DEBUG_LEVEL(lvl);
+
+#endif	/*  */
+    DWC_DEBUGPL((DBG_PCDV | DBG_CILV), "%s()\n", __func__);
+	DWC_DEBUGPL(DBG_PCD, "ep%d-%s xfer_len=%d xfer_cnt=%d "
+		      "xfer_buff=%p start_xfer_buff=%p\n", _ep->num,
+		      (_ep->is_in ? "IN" : "OUT"), _ep->xfer_len,
+		      _ep->xfer_count, _ep->xfer_buff, _ep->start_xfer_buff);
+
+    /* IN endpoint */
+    if (_ep->is_in == 1) {
+		dwc_otg_dev_in_ep_regs_t * in_regs = _core_if->dev_if->in_ep_regs[_ep->num];
+		gnptxsts_data_t gtxstatus;
+		gtxstatus.d32 = dwc_read_reg32(&_core_if->core_global_regs->gnptxsts);
+		if (_core_if->en_multiple_tx_fifo == 0 &&
+			gtxstatus.b.nptxqspcavail == 0) {
+#ifdef CONFIG_DWC_DEBUG
+			    DWC_PRINT("TX Queue Full (0x%0x)\n", gtxstatus.d32);
+#endif	/*  */
+		    return;
+		}
+		depctl.d32 = dwc_read_reg32(&(in_regs->diepctl));
+		deptsiz.d32 = dwc_read_reg32(&(in_regs->dieptsiz));
+
+		/* Zero Length Packet? */
+		if (_ep->xfer_len == 0) {
+			deptsiz.b.xfersize = 0;
+			deptsiz.b.pktcnt = 1;
+		} else {
+			/* Program the transfer size and packet count
+			 *      as follows: xfersize = N * maxpacket +
+			 *      short_packet pktcnt = N + (short_packet
+			 *      exist ? 1 : 0)
+			 */
+
+#ifdef CONFIG_405EZ
+			/*
+			 * Added-sr: 2007-07-26
+			 *
+			 * Since the 405EZ (Ultra) only support 2047 bytes as
+			 * max transfer size, we have to split up bigger transfers
+			 * into multiple transfers of 1024 bytes sized messages.
+			 * I happens often, that transfers of 4096 bytes are
+			 * required (zero-gadget, file_storage-gadget).
+			 */
+			if (_ep->xfer_len > MAX_XFER_LEN) {
+				_ep->bytes_pending = _ep->xfer_len - MAX_XFER_LEN;
+				_ep->xfer_len = MAX_XFER_LEN;
+			}
+#endif
+
+			deptsiz.b.xfersize = _ep->xfer_len;
+			deptsiz.b.pktcnt = (_ep->xfer_len - 1 + _ep->maxpacket) / _ep->maxpacket;
+		}
+		dwc_write_reg32(&in_regs->dieptsiz, deptsiz.d32);
+
+	    /* Write the DMA register */
+	    if (_core_if->dma_enable) {
+			dwc_write_reg32(&(in_regs->diepdma), (uint32_t) _ep->dma_addr);
+		} else {
+			if (_ep->type != DWC_OTG_EP_TYPE_ISOC) {
+				/**
+				 * Enable the Non-Periodic Tx FIFO empty interrupt,
+				 * or the Tx FIFO epmty interrupt in dedicated Tx FIFO mode,
+				 * the data will be written into the fifo by the ISR.
+				 */
+			    if (_core_if->en_multiple_tx_fifo == 0) {
+					intr_mask.b.nptxfempty = 1;
+					dwc_modify_reg32(&_core_if->core_global_regs->gintsts,
+							  intr_mask.d32, 0);
+					dwc_modify_reg32(&_core_if->core_global_regs->gintmsk,
+							  intr_mask.d32, intr_mask.d32);
+				} else {
+				    /* Enable the Tx FIFO Empty Interrupt for this EP */
+				    if (_ep->xfer_len > 0) {
+						uint32_t fifoemptymsk = 0;
+						fifoemptymsk = 1 << _ep->num;
+						dwc_modify_reg32(&_core_if->dev_if->dev_global_regs->
+								  dtknqr4_fifoemptymsk,0,fifoemptymsk);
+					}
+				}
+			}
+		}
+
+		/* EP enable, IN data in FIFO */
+		depctl.b.cnak = 1;
+		depctl.b.epena = 1;
+		dwc_write_reg32(&in_regs->diepctl, depctl.d32);
+		if (_core_if->dma_enable) {
+			depctl.d32 = dwc_read_reg32(&_core_if->dev_if->in_ep_regs[0]->diepctl);
+			depctl.b.nextep = _ep->num;
+			dwc_write_reg32(&_core_if->dev_if->in_ep_regs[0]->diepctl, depctl.d32);
+		}
+	} else {
+	    /* OUT endpoint */
+	    dwc_otg_dev_out_ep_regs_t * out_regs = _core_if->dev_if->out_ep_regs[_ep->num];
+		depctl.d32 = dwc_read_reg32(&(out_regs->doepctl));
+		deptsiz.d32 = dwc_read_reg32(&(out_regs->doeptsiz));
+
+	    /* Program the transfer size and packet count as follows:
+	     *
+	     *      pktcnt = N
+	     *      xfersize = N * maxpacket
+	     */
+	    if (_ep->xfer_len == 0) {
+		    /* Zero Length Packet */
+		    deptsiz.b.xfersize = _ep->maxpacket;
+			deptsiz.b.pktcnt = 1;
+		} else {
+			deptsiz.b.pktcnt = (_ep->xfer_len + (_ep->maxpacket - 1)) / _ep->maxpacket;
+			deptsiz.b.xfersize = deptsiz.b.pktcnt * _ep->maxpacket;
+		}
+		dwc_write_reg32(&out_regs->doeptsiz, deptsiz.d32);
+		DWC_DEBUGPL(DBG_PCDV, "ep%d xfersize=%d pktcnt=%d\n",
+			      _ep->num, deptsiz.b.xfersize, deptsiz.b.pktcnt);
+		if (_core_if->dma_enable) {
+			dwc_write_reg32(&(out_regs->doepdma),
+					 (uint32_t) _ep->dma_addr);
+		}
+		if (_ep->type == DWC_OTG_EP_TYPE_ISOC) {
+			/** @todo NGS: dpid is read-only. Use setd0pid
+			 * or setd1pid. */
+			if (_ep->even_odd_frame) {
+				depctl.b.setd1pid = 1;
+			} else {
+				depctl.b.setd0pid = 1;
+			}
+		}
+
+	    /* EP enable */
+	    depctl.b.cnak = 1;
+		depctl.b.epena = 1;
+		dwc_write_reg32(&out_regs->doepctl, depctl.d32);
+		DWC_DEBUGPL(DBG_PCD, "DOEPCTL=%08x DOEPTSIZ=%08x\n",
+			      dwc_read_reg32(&out_regs->doepctl),
+			      dwc_read_reg32(&out_regs->doeptsiz));
+		DWC_DEBUGPL(DBG_PCD, "DAINTMSK=%08x GINTMSK=%08x\n",
+			     dwc_read_reg32(&_core_if->dev_if->dev_global_regs->daintmsk),
+			     dwc_read_reg32(&_core_if->core_global_regs->gintmsk));
+	}
+}
+
+/**
+ * This function does the setup for a data transfer for EP0 and starts
+ * the transfer.  For an IN transfer, the packets will be loaded into
+ * the appropriate Tx FIFO in the ISR. For OUT transfers, the packets are
+ * unloaded from the Rx FIFO in the ISR.
+ *
+ * @param _core_if Programming view of DWC_otg controller.
+ * @param _ep The EP0 data.
+ */
+void dwc_otg_ep0_start_transfer(dwc_otg_core_if_t * _core_if, dwc_ep_t * _ep)
+{
+	volatile depctl_data_t depctl;
+	volatile deptsiz0_data_t deptsiz;
+	gintmsk_data_t intr_mask = {.d32 = 0};
+	DWC_DEBUGPL(DBG_PCD, "ep%d-%s xfer_len=%d xfer_cnt=%d "
+		      "xfer_buff=%p start_xfer_buff=%p total_len=%d\n",
+		      _ep->num, (_ep->is_in ? "IN" : "OUT"), _ep->xfer_len,
+		      _ep->xfer_count, _ep->xfer_buff, _ep->start_xfer_buff,
+		      _ep->total_len);
+	_ep->total_len = _ep->xfer_len;
+
+    /* IN endpoint */
+    if (_ep->is_in == 1) {
+		dwc_otg_dev_in_ep_regs_t * in_regs = _core_if->dev_if->in_ep_regs[0];
+		gnptxsts_data_t gtxstatus;
+		gtxstatus.d32 = dwc_read_reg32(&_core_if->core_global_regs->gnptxsts);
+		if (_core_if->en_multiple_tx_fifo == 0 &&
+			gtxstatus.b.nptxqspcavail == 0) {
+#ifdef CONFIG_DWC_DEBUG
+		    deptsiz.d32 = dwc_read_reg32(&in_regs->dieptsiz);
+			DWC_DEBUGPL(DBG_PCD, "DIEPCTL0=%0x\n",
+				     dwc_read_reg32(&in_regs->diepctl));
+			DWC_DEBUGPL(DBG_PCD, "DIEPTSIZ0=%0x (sz=%d, pcnt=%d)\n",
+				     deptsiz.d32, deptsiz.b.xfersize,deptsiz.b.pktcnt);
+			DWC_PRINT("TX Queue or FIFO Full (0x%0x)\n", gtxstatus.d32);
+#endif	/*  */
+			printk("TX Queue or FIFO Full!!!!\n"); // test-only
+		    return;
+		}
+		depctl.d32 = dwc_read_reg32(&in_regs->diepctl);
+		deptsiz.d32 = dwc_read_reg32(&in_regs->dieptsiz);
+
+	    /* Zero Length Packet? */
+	    if (_ep->xfer_len == 0) {
+			deptsiz.b.xfersize = 0;
+			deptsiz.b.pktcnt = 1;
+		} else {
+		    /* Program the transfer size and packet count
+		     *      as follows: xfersize = N * maxpacket +
+		     *      short_packet pktcnt = N + (short_packet
+		     *      exist ? 1 : 0)
+		     */
+		    if (_ep->xfer_len > _ep->maxpacket) {
+				_ep->xfer_len = _ep->maxpacket;
+				deptsiz.b.xfersize = _ep->maxpacket;
+			} else {
+				deptsiz.b.xfersize = _ep->xfer_len;
+			}
+			deptsiz.b.pktcnt = 1;
+		}
+		dwc_write_reg32(&in_regs->dieptsiz, deptsiz.d32);
+		DWC_DEBUGPL(DBG_PCDV,"IN len=%d  xfersize=%d pktcnt=%d [%08x]\n",
+			     _ep->xfer_len, deptsiz.b.xfersize,deptsiz.b.pktcnt, deptsiz.d32);
+
+	    /* Write the DMA register */
+	    if (_core_if->dma_enable) {
+			dwc_write_reg32(&(in_regs->diepdma), (uint32_t) _ep->dma_addr);
+		}
+
+	    /* EP enable, IN data in FIFO */
+	    depctl.b.cnak = 1;
+		depctl.b.epena = 1;
+		dwc_write_reg32(&in_regs->diepctl, depctl.d32);
+
+		/**
+		 * Enable the Non-Periodic Tx FIFO empty interrupt, the
+		 * data will be written into the fifo by the ISR.
+		 */
+	    if (!_core_if->dma_enable) {
+			if (_core_if->en_multiple_tx_fifo == 0) {
+				intr_mask.b.nptxfempty = 1;
+				dwc_modify_reg32(&_core_if->core_global_regs->gintsts, intr_mask.d32, 0);
+				dwc_modify_reg32(&_core_if->core_global_regs->gintmsk, intr_mask.d32,
+						  intr_mask.d32);
+			} else {
+			    /* Enable the Tx FIFO Empty Interrupt for this EP */
+			    if (_ep->xfer_len > 0) {
+					uint32_t fifoemptymsk = 0;
+					fifoemptymsk |= 1 << _ep->num;
+					dwc_modify_reg32(&_core_if->dev_if->dev_global_regs->dtknqr4_fifoemptymsk,
+						 0, fifoemptymsk);
+				}
+			}
+		}
+	} else {
+	    /* OUT endpoint */
+	    dwc_otg_dev_out_ep_regs_t * out_regs = _core_if->dev_if->out_ep_regs[_ep->num];
+		depctl.d32 = dwc_read_reg32(&out_regs->doepctl);
+		deptsiz.d32 = dwc_read_reg32(&out_regs->doeptsiz);
+
+	    /* Program the transfer size and packet count as follows:
+	     *      xfersize = N * (maxpacket + 4 - (maxpacket % 4))
+	     *      pktcnt = N                                                                                      */
+	    if (_ep->xfer_len == 0) {
+		    /* Zero Length Packet */
+		    deptsiz.b.xfersize = _ep->maxpacket;
+			deptsiz.b.pktcnt = 1;
+		} else {
+			deptsiz.b.pktcnt = (_ep->xfer_len + (_ep->maxpacket - 1)) / _ep->maxpacket;
+			deptsiz.b.xfersize = deptsiz.b.pktcnt * _ep->maxpacket;
+		}
+		dwc_write_reg32(&out_regs->doeptsiz, deptsiz.d32);
+		DWC_DEBUGPL(DBG_PCDV, "len=%d  xfersize=%d pktcnt=%d\n",
+			     _ep->xfer_len, deptsiz.b.xfersize,deptsiz.b.pktcnt);
+		if (_core_if->dma_enable) {
+			dwc_write_reg32(&(out_regs->doepdma), (uint32_t) _ep->dma_addr);
+		}
+
+	    /* EP enable */
+	    depctl.b.cnak = 1;
+		depctl.b.epena = 1;
+		dwc_write_reg32(&(out_regs->doepctl), depctl.d32);
+	}
+}
+
+
+/**
+ * This function continues control IN transfers started by
+ * dwc_otg_ep0_start_transfer, when the transfer does not fit in a
+ * single packet.  NOTE: The DIEPCTL0/DOEPCTL0 registers only have one
+ * bit for the packet count.
+ *
+ * @param _core_if Programming view of DWC_otg controller.
+ * @param _ep The EP0 data.
+ */
+void dwc_otg_ep0_continue_transfer(dwc_otg_core_if_t * _core_if,
+				   dwc_ep_t * _ep)
+{
+	depctl_data_t depctl;
+	deptsiz0_data_t deptsiz;
+	gintmsk_data_t intr_mask = {.d32 = 0};
+	if (_ep->is_in == 1) {
+		dwc_otg_dev_in_ep_regs_t * in_regs = _core_if->dev_if->in_ep_regs[0];
+		gnptxsts_data_t tx_status = {.d32 = 0};
+		tx_status.d32 = dwc_read_reg32(&_core_if->core_global_regs->gnptxsts);
+
+		/** @todo Should there be check for room in the Tx
+		 * Status Queue.  If not remove the code above this comment. */
+	    depctl.d32 = dwc_read_reg32(&in_regs->diepctl);
+		deptsiz.d32 = dwc_read_reg32(&in_regs->dieptsiz);
+
+	    /* Program the transfer size and packet count
+	     *      as follows: xfersize = N * maxpacket +
+	     *      short_packet pktcnt = N + (short_packet
+	     *      exist ? 1 : 0)
+	     */
+	    deptsiz.b.xfersize = (_ep->total_len - _ep->xfer_count) >
+		    _ep->maxpacket ? _ep->maxpacket : (_ep->total_len -
+							_ep->xfer_count);
+		deptsiz.b.pktcnt = 1;
+		_ep->xfer_len += deptsiz.b.xfersize;
+		dwc_write_reg32(&in_regs->dieptsiz, deptsiz.d32);
+		DWC_DEBUGPL(DBG_PCDV,"IN len=%d  xfersize=%d pktcnt=%d [%08x]\n",
+			     _ep->xfer_len, deptsiz.b.xfersize,deptsiz.b.pktcnt, deptsiz.d32);
+
+	    /* Write the DMA register */
+	    if (_core_if->hwcfg2.b.architecture == DWC_INT_DMA_ARCH) {
+			dwc_write_reg32(&(in_regs->diepdma),(uint32_t) _ep->dma_addr);
+		}
+
+	    /* EP enable, IN data in FIFO */
+	    depctl.b.cnak = 1;
+		depctl.b.epena = 1;
+		dwc_write_reg32(&in_regs->diepctl, depctl.d32);
+
+		/**
+		 * Enable the Non-Periodic Tx FIFO empty interrupt, the
+		 * data will be written into the fifo by the ISR.
+		 */
+	    if (!_core_if->dma_enable) {
+		    /* First clear it from GINTSTS */
+		    intr_mask.b.nptxfempty = 1;
+			dwc_write_reg32(&_core_if->core_global_regs->gintsts,
+					 intr_mask.d32);
+			dwc_modify_reg32(&_core_if->core_global_regs->gintmsk,
+					 intr_mask.d32, intr_mask.d32);
+		}
+	}
+}
+
+#ifdef CONFIG_DWC_DEBUG
+void dump_msg(const u8 * buf, unsigned int length)
+{
+	unsigned int start, num, i;
+	char line[52], *p;
+	if (length >= 512)
+		return;
+	start = 0;
+	while (length > 0) {
+		num = min(length, 16u);
+		p = line;
+		for (i = 0; i < num; ++i) {
+			if (i == 8)
+				*p++ = ' ';
+			sprintf(p, " %02x", buf[i]);
+			p += 3;
+		}
+		*p = 0;
+		DWC_PRINT("%6x: %s\n", start, line);
+		buf += num;
+		start += num;
+		length -= num;
+	}
+}
+
+
+#else	/*  */
+static inline void dump_msg(const u8 * buf, unsigned int length)
+{
+}
+#endif	/*  */
+
+/**
+ * This function writes a packet into the Tx FIFO associated with the
+ * EP.	For non-periodic EPs the non-periodic Tx FIFO is written.  For
+ * periodic EPs the periodic Tx FIFO associated with the EP is written
+ * with all packets for the next micro-frame.
+ *
+ * @param _core_if Programming view of DWC_otg controller.
+ * @param _ep The EP to write packet for.
+ * @param _dma Indicates if DMA is being used.
+ */
+void dwc_otg_ep_write_packet(dwc_otg_core_if_t * _core_if, dwc_ep_t * _ep,
+			     int _dma)
+{
+	/**
+	 * The buffer is padded to DWORD on a per packet basis in
+	 * slave/dma mode if the MPS is not DWORD aligned.	The last
+	 * packet, if short, is also padded to a multiple of DWORD.
+	 *
+	 * ep->xfer_buff always starts DWORD aligned in memory and is a
+	 * multiple of DWORD in length
+	 *
+	 * ep->xfer_len can be any number of bytes
+	 *
+	 * ep->xfer_count is a multiple of ep->maxpacket until the last
+	 *	packet
+	 *
+	 * FIFO access is DWORD */
+#ifndef CONFIG_OTG_PLB_DMA
+	uint32_t i;
+#endif
+	uint32_t byte_count;
+	uint32_t dword_count;
+	uint32_t * fifo;
+	uint32_t * data_buff = (uint32_t *) _ep->xfer_buff;
+#if !defined( CONFIG_OTG_PLB_DMA_TASKLET) && defined(CONFIG_OTG_PLB_DMA)
+	uint32_t dma_sts = 0;
+#endif
+	//DWC_DEBUGPL((DBG_PCDV | DBG_CILV), "%s(%p,%p)\n", __func__, _core_if, _ep);
+	if (_ep->xfer_count >= _ep->xfer_len) {
+		DWC_DEBUGPL((DBG_PCDV | DBG_CILV), "%s() No data for EP%d!!!\n", __func__, _ep->num);
+		return;
+	}
+
+	/* Find the byte length of the packet either short packet or MPS */
+	if ((_ep->xfer_len - _ep->xfer_count) < _ep->maxpacket) {
+		byte_count = _ep->xfer_len - _ep->xfer_count;
+	} else {
+		byte_count = _ep->maxpacket;
+	}
+
+	/* Find the DWORD length, padded by extra bytes as neccessary if MPS
+	 * is not a multiple of DWORD */
+	dword_count = (byte_count + 3) / 4;
+
+#ifdef VERBOSE
+	dump_msg(_ep->xfer_buff, byte_count);
+#endif	/*  */
+
+	/**@todo NGS Where are the Periodic Tx FIFO addresses
+	 * intialized?	What should this be? */
+	fifo = _core_if->data_fifo[_ep->num];
+	DWC_DEBUGPL((DBG_PCDV | DBG_CILV), "fifo=%p buff=%p *p=%08x bc=%d\n",
+		       fifo, data_buff, *data_buff, byte_count);
+	if (!_dma) {
+#ifdef CONFIG_OTG_PLB_DMA
+#ifdef CONFIG_OTG_PLB_DMA_TASKLET
+		if (byte_count < USB_BUFSIZ) {
+			int i;
+			for (i = 0; i < dword_count; i++, data_buff++) {
+				dwc_write_datafifo32(fifo, *data_buff);
+			}
+		}
+		else {
+    		DWC_DEBUGPL(DBG_SP, "%s set release_later %d\n",  __func__, dword_count);
+	        atomic_set(& release_later, 1);
+    	    //disable_irq_nosync(94);
+	        dwc_otg_disable_global_interrupts(_core_if);
+
+		    _core_if->dma_xfer.dma_data_buff = data_buff;
+    		_core_if->dma_xfer.dma_data_fifo = fifo;
+		    _core_if->dma_xfer.dma_count = dword_count;
+    		_core_if->dma_xfer.dma_dir = OTG_TX_DMA;
+		    tasklet_schedule(_core_if->plbdma_tasklet);
+		}
+#else  /* !CONFIG_OTG_PLB_DMA_TASKLET */
+		ppc4xx_start_plb_dma(_core_if, data_buff, fifo, (dword_count * 4),
+			PLB_DMA_INT_DIS	, PLB_DMA_CH, OTG_TX_DMA);
+		while (mfdcr(DCRN_DMACR0 + (DMA_CH0*8)) & DMA_CE_ENABLE) {
+		}
+		dma_sts = (uint32_t)ppc4xx_get_dma_status();
+#ifdef CONFIG_OTG_PLB_DMA_DBG
+		if (!(dma_sts & DMA_CS0)) {
+			printk("DMA Status (Terminal Count not occured) 0x%08x\n", mfdcr(DCRN_DMASR));
+	    }
+#endif
+	    if (dma_sts & DMA_CH0_ERR) {
+	    	printk("DMA Status (Channel 0 Error) 0x%08x\n", mfdcr(DCRN_DMASR));
+        }
+        ppc4xx_clr_dma_status(PLB_DMA_CH);
+#ifdef CONFIG_OTG_PLB_DMA_DBG
+        printk("%32s DMA Status =0x%08x\n", __FUNCTION__, mfdcr(DCRN_DMASR)); /* vj_dbg */
+#endif
+#endif	/* CONFIG_OTG_PLB_DMA_TASKLET */
+
+#else       /* DWC_SLAVE mode */
+		for (i = 0; i < dword_count; i++, data_buff++) {
+			dwc_write_datafifo32(fifo, *data_buff);
+		}
+#endif
+	}
+
+	_ep->xfer_count += byte_count;
+	_ep->xfer_buff += byte_count;
+	_ep->dma_addr += byte_count;
+}
+
+
+/**
+ * Set the EP STALL.
+ *
+ * @param _core_if Programming view of DWC_otg controller.
+ * @param _ep The EP to set the stall on.
+ */
+void dwc_otg_ep_set_stall(dwc_otg_core_if_t * _core_if, dwc_ep_t * _ep)
+{
+	depctl_data_t depctl;
+	volatile uint32_t *depctl_addr;
+	DWC_DEBUGPL(DBG_PCD, "%s ep%d-%s\n", __func__, _ep->num,
+		      (_ep->is_in ? "IN" : "OUT"));
+	if (_ep->is_in == 1) {
+		depctl_addr = &(_core_if->dev_if->in_ep_regs[_ep->num]->diepctl);
+		depctl.d32 = dwc_read_reg32(depctl_addr);
+
+	    /* set the disable and stall bits */
+	    if (depctl.b.epena) {
+			depctl.b.epdis = 1;
+		}
+		depctl.b.stall = 1;
+		dwc_write_reg32(depctl_addr, depctl.d32);
+	} else {
+		depctl_addr = &(_core_if->dev_if->out_ep_regs[_ep->num]->doepctl);
+		depctl.d32 = dwc_read_reg32(depctl_addr);
+
+	    /* set the stall bit */
+	    depctl.b.stall = 1;
+		dwc_write_reg32(depctl_addr, depctl.d32);
+	}
+	DWC_DEBUGPL(DBG_PCD, "DEPCTL=%0x\n", dwc_read_reg32(depctl_addr));
+	return;
+}
+
+
+/**
+ * Clear the EP STALL.
+ *
+ * @param _core_if Programming view of DWC_otg controller.
+ * @param _ep The EP to clear stall from.
+ */
+void dwc_otg_ep_clear_stall(dwc_otg_core_if_t * _core_if, dwc_ep_t * _ep)
+{
+	depctl_data_t depctl;
+	volatile uint32_t *depctl_addr;
+	DWC_DEBUGPL(DBG_PCD, "%s ep%d-%s\n", __func__, _ep->num,
+		      (_ep->is_in ? "IN" : "OUT"));
+	if (_ep->is_in == 1) {
+		depctl_addr = &(_core_if->dev_if->in_ep_regs[_ep->num]->diepctl);
+	} else {
+		depctl_addr = &(_core_if->dev_if->out_ep_regs[_ep->num]->doepctl);
+	}
+	depctl.d32 = dwc_read_reg32(depctl_addr);
+
+    /* clear the stall bits */
+    depctl.b.stall = 0;
+
+    /*
+     * USB Spec 9.4.5: For endpoints using data toggle, regardless
+     * of whether an endpoint has the Halt feature set, a
+     * ClearFeature(ENDPOINT_HALT) request always results in the
+     * data toggle being reinitialized to DATA0.
+     */
+    if (_ep->type == DWC_OTG_EP_TYPE_INTR ||
+		_ep->type == DWC_OTG_EP_TYPE_BULK) {
+		depctl.b.setd0pid = 1;	/* DATA0 */
+	}
+	dwc_write_reg32(depctl_addr, depctl.d32);
+	DWC_DEBUGPL(DBG_PCD, "DEPCTL=%0x\n", dwc_read_reg32(depctl_addr));
+	return;
+}
+
+
+/**
+ * This function reads a packet from the Rx FIFO into the destination
+ * buffer.	To read SETUP data use dwc_otg_read_setup_packet.
+ *
+ * @param _core_if Programming view of DWC_otg controller.
+ * @param _dest	  Destination buffer for the packet.
+ * @param _bytes  Number of bytes to copy to the destination.
+ */
+void dwc_otg_read_packet(dwc_otg_core_if_t * _core_if,
+			 uint8_t * _dest,  uint16_t _bytes)
+{
+#ifndef CONFIG_OTG_PLB_DMA
+	int i;
+#endif
+	int word_count = (_bytes + 3) / 4;
+	volatile uint32_t *fifo = _core_if->data_fifo[0];
+	uint32_t * data_buff = (uint32_t *) _dest;
+#if !defined( CONFIG_OTG_PLB_DMA_TASKLET) && defined(CONFIG_OTG_PLB_DMA)
+	uint32_t dma_sts = 0;
+#endif
+
+	/**
+	 * @todo Account for the case where _dest is not dword aligned. This
+	 * requires reading data from the FIFO into a uint32_t temp buffer,
+	 * then moving it into the data buffer.
+	 */
+    DWC_DEBUGPL((DBG_PCDV | DBG_CILV | DBG_SP), "%s(%p,%p,%d)\n", __func__,
+			 _core_if, _dest, _bytes);
+#ifdef CONFIG_OTG_PLB_DMA
+#ifdef CONFIG_OTG_PLB_DMA_TASKLET
+	if ( _bytes < USB_BUFSIZ) {
+		int i;
+		for (i = 0; i < word_count; i++, data_buff++) {
+			*data_buff = dwc_read_datafifo32(fifo);
+		}
+	} else {
+    	DWC_DEBUGPL(DBG_SP, "%s set release_later %d\n",  __func__, _bytes);
+	    atomic_set(& release_later, 1);
+		//disable_irq_nosync(94);
+	    dwc_otg_disable_global_interrupts(_core_if);
+
+		/* plbdma tasklet */
+	    _core_if->dma_xfer.dma_data_buff = data_buff;
+   		_core_if->dma_xfer.dma_data_fifo = (void *)fifo;
+	    _core_if->dma_xfer.dma_count = word_count;
+		_core_if->dma_xfer.dma_dir = OTG_RX_DMA;
+		tasklet_schedule(_core_if->plbdma_tasklet);
+	}
+#else /* !CONFIG_OTG_PLB_DMA_TASKLET */
+    ppc4xx_start_plb_dma(_core_if,(void *)fifo,data_buff, (word_count * 4),
+		 PLB_DMA_INT_DIS, PLB_DMA_CH, OTG_RX_DMA);
+	while (mfdcr(DCRN_DMACR0 + (DMA_CH0*8)) & DMA_CE_ENABLE) {
+	}
+	dma_sts = (uint32_t)ppc4xx_get_dma_status();
+#ifdef CONFIG_OTG_PLB_DMA_DBG
+	if (!(dma_sts & DMA_CS0)) {
+		printk("DMA Status (Terminal Count not occured) 0x%08x\n", mfdcr(DCRN_DMASR));
+    }
+#endif
+	if (dma_sts & DMA_CH0_ERR) {
+		printk("DMA Status (Channel 0 Error) 0x%08x\n", mfdcr(DCRN_DMASR));
+	}
+	ppc4xx_clr_dma_status(PLB_DMA_CH);
+#ifdef CONFIG_OTG_PLB_DMA_DBG
+	printk("%32s DMA Status =0x%08x\n", __FUNCTION__, mfdcr(DCRN_DMASR));
+	printk(" Rxed buffer \n");
+	for( i=0; i< _bytes; i++) {
+	    printk(" 0x%02x",*(_dest +i));
+	}
+	printk(" \n End of Rxed buffer \n");
+#endif
+#endif /* CONFIG_OTG_PLB_DMA_TASKLET */
+
+#else   /* DWC_SLAVE mode */
+	for (i = 0; i < word_count; i++, data_buff++) {
+		*data_buff = dwc_read_datafifo32(fifo);
+	}
+#endif
+	return;
+}
+
+
+/**
+ * This functions reads the device registers and prints them
+ *
+ * @param _core_if Programming view of DWC_otg controller.
+ */
+void dwc_otg_dump_dev_registers(dwc_otg_core_if_t * _core_if)
+{
+	int i;
+	volatile uint32_t *addr;
+	DWC_PRINT("Device Global Registers\n");
+	addr = &_core_if->dev_if->dev_global_regs->dcfg;
+	DWC_PRINT("DCFG		 @0x%08X : 0x%08X\n", (uint32_t) addr,
+		   dwc_read_reg32(addr));
+	addr = &_core_if->dev_if->dev_global_regs->dctl;
+	DWC_PRINT("DCTL		 @0x%08X : 0x%08X\n", (uint32_t) addr,
+		   dwc_read_reg32(addr));
+	addr = &_core_if->dev_if->dev_global_regs->dsts;
+	DWC_PRINT("DSTS		 @0x%08X : 0x%08X\n", (uint32_t) addr,
+		   dwc_read_reg32(addr));
+	addr = &_core_if->dev_if->dev_global_regs->diepmsk;
+	DWC_PRINT("DIEPMSK	 @0x%08X : 0x%08X\n", (uint32_t) addr,
+		   dwc_read_reg32(addr));
+	addr = &_core_if->dev_if->dev_global_regs->doepmsk;
+	DWC_PRINT("DOEPMSK	 @0x%08X : 0x%08X\n", (uint32_t) addr,
+		   dwc_read_reg32(addr));
+	addr = &_core_if->dev_if->dev_global_regs->daint;
+	DWC_PRINT("DAINT	 @0x%08X : 0x%08X\n", (uint32_t) addr,
+		   dwc_read_reg32(addr));
+	addr = &_core_if->dev_if->dev_global_regs->dtknqr1;
+	DWC_PRINT("DTKNQR1	 @0x%08X : 0x%08X\n", (uint32_t) addr,
+		   dwc_read_reg32(addr));
+	if (_core_if->hwcfg2.b.dev_token_q_depth > 6) {
+		addr = &_core_if->dev_if->dev_global_regs->dtknqr2;
+		DWC_PRINT("DTKNQR2	 @0x%08X : 0x%08X\n",
+			   (uint32_t) addr, dwc_read_reg32(addr));
+	}
+	addr = &_core_if->dev_if->dev_global_regs->dvbusdis;
+	DWC_PRINT("DVBUSID	 @0x%08X : 0x%08X\n", (uint32_t) addr,
+		   dwc_read_reg32(addr));
+	addr = &_core_if->dev_if->dev_global_regs->dvbuspulse;
+	DWC_PRINT("DVBUSPULSE	@0x%08X : 0x%08X\n",
+		   (uint32_t) addr, dwc_read_reg32(addr));
+	if (_core_if->hwcfg2.b.dev_token_q_depth > 14) {
+		addr = &_core_if->dev_if->dev_global_regs->dtknqr3_dthrctl;
+		DWC_PRINT("DTKNQR3	 @0x%08X : 0x%08X\n",
+			   (uint32_t) addr, dwc_read_reg32(addr));
+	}
+	if (_core_if->hwcfg2.b.dev_token_q_depth > 22) {
+		addr = &_core_if->dev_if->dev_global_regs->dtknqr4_fifoemptymsk;
+		DWC_PRINT("DTKNQR4	 @0x%08X : 0x%08X\n", (uint32_t) addr,
+			   dwc_read_reg32(addr));
+	}
+	for (i = 0; i <= _core_if->dev_if->num_in_eps; i++) {
+		DWC_PRINT("Device IN EP %d Registers\n", i);
+		addr = &_core_if->dev_if->in_ep_regs[i]->diepctl;
+		DWC_PRINT("DIEPCTL	 @0x%08X : 0x%08X\n", (uint32_t) addr,
+			   dwc_read_reg32(addr));
+		addr = &_core_if->dev_if->in_ep_regs[i]->diepint;
+		DWC_PRINT("DIEPINT	 @0x%08X : 0x%08X\n", (uint32_t) addr,
+			   dwc_read_reg32(addr));
+		addr = &_core_if->dev_if->in_ep_regs[i]->dieptsiz;
+		DWC_PRINT("DIETSIZ	 @0x%08X : 0x%08X\n", (uint32_t) addr,
+			   dwc_read_reg32(addr));
+		addr = &_core_if->dev_if->in_ep_regs[i]->diepdma;
+		DWC_PRINT("DIEPDMA	 @0x%08X : 0x%08X\n", (uint32_t) addr,
+			   dwc_read_reg32(addr));
+		addr = &_core_if->dev_if->in_ep_regs[i]->dtxfsts;
+		DWC_PRINT("DTXFSTS	 @0x%08X : 0x%08X\n", (uint32_t) addr,
+			   dwc_read_reg32(addr));
+	}
+	for (i = 0; i <= _core_if->dev_if->num_out_eps; i++) {
+		DWC_PRINT("Device OUT EP %d Registers\n", i);
+		addr = &_core_if->dev_if->out_ep_regs[i]->doepctl;
+		DWC_PRINT("DOEPCTL	 @0x%08X : 0x%08X\n", (uint32_t) addr,
+			   dwc_read_reg32(addr));
+		addr = &_core_if->dev_if->out_ep_regs[i]->doepfn;
+		DWC_PRINT("DOEPFN	 @0x%08X : 0x%08X\n", (uint32_t) addr,
+			   dwc_read_reg32(addr));
+		addr = &_core_if->dev_if->out_ep_regs[i]->doepint;
+		DWC_PRINT("DOEPINT	 @0x%08X : 0x%08X\n", (uint32_t) addr,
+			   dwc_read_reg32(addr));
+		addr = &_core_if->dev_if->out_ep_regs[i]->doeptsiz;
+		DWC_PRINT("DOETSIZ	 @0x%08X : 0x%08X\n", (uint32_t) addr,
+			   dwc_read_reg32(addr));
+		addr = &_core_if->dev_if->out_ep_regs[i]->doepdma;
+		DWC_PRINT("DOEPDMA	 @0x%08X : 0x%08X\n", (uint32_t) addr,
+			   dwc_read_reg32(addr));
+	}
+	return;
+}
+
+
+/**
+ * This function reads the host registers and prints them
+ *
+ * @param _core_if Programming view of DWC_otg controller.
+ */
+void dwc_otg_dump_host_registers(dwc_otg_core_if_t * _core_if)
+{
+	int i;
+	volatile uint32_t *addr;
+	DWC_PRINT("Host Global Registers\n");
+	addr = &_core_if->host_if->host_global_regs->hcfg;
+	DWC_PRINT("HCFG		 @0x%08X : 0x%08X\n", (uint32_t) addr,
+		   dwc_read_reg32(addr));
+	addr = &_core_if->host_if->host_global_regs->hfir;
+	DWC_PRINT("HFIR		 @0x%08X : 0x%08X\n", (uint32_t) addr,
+		   dwc_read_reg32(addr));
+	addr = &_core_if->host_if->host_global_regs->hfnum;
+	DWC_PRINT("HFNUM	 @0x%08X : 0x%08X\n", (uint32_t) addr,
+		   dwc_read_reg32(addr));
+	addr = &_core_if->host_if->host_global_regs->hptxsts;
+	DWC_PRINT("HPTXSTS	 @0x%08X : 0x%08X\n", (uint32_t) addr,
+		   dwc_read_reg32(addr));
+	addr = &_core_if->host_if->host_global_regs->haint;
+	DWC_PRINT("HAINT	 @0x%08X : 0x%08X\n", (uint32_t) addr,
+		   dwc_read_reg32(addr));
+	addr = &_core_if->host_if->host_global_regs->haintmsk;
+	DWC_PRINT("HAINTMSK	 @0x%08X : 0x%08X\n", (uint32_t) addr,
+		   dwc_read_reg32(addr));
+	addr = _core_if->host_if->hprt0;
+	DWC_PRINT("HPRT0	 @0x%08X : 0x%08X\n", (uint32_t) addr,
+		   dwc_read_reg32(addr));
+	for (i = 0; i < _core_if->core_params->host_channels; i++) {
+		DWC_PRINT("Host Channel %d Specific Registers\n", i);
+		addr = &_core_if->host_if->hc_regs[i]->hcchar;
+		DWC_PRINT("HCCHAR	 @0x%08X : 0x%08X\n", (uint32_t) addr,
+			   dwc_read_reg32(addr));
+		addr = &_core_if->host_if->hc_regs[i]->hcsplt;
+		DWC_PRINT("HCSPLT	 @0x%08X : 0x%08X\n", (uint32_t) addr,
+			   dwc_read_reg32(addr));
+		addr = &_core_if->host_if->hc_regs[i]->hcint;
+		DWC_PRINT("HCINT	 @0x%08X : 0x%08X\n", (uint32_t) addr,
+			   dwc_read_reg32(addr));
+		addr = &_core_if->host_if->hc_regs[i]->hcintmsk;
+		DWC_PRINT("HCINTMSK	 @0x%08X : 0x%08X\n", (uint32_t) addr,
+			   dwc_read_reg32(addr));
+		addr = &_core_if->host_if->hc_regs[i]->hctsiz;
+		DWC_PRINT("HCTSIZ	 @0x%08X : 0x%08X\n", (uint32_t) addr,
+			   dwc_read_reg32(addr));
+		addr = &_core_if->host_if->hc_regs[i]->hcdma;
+		DWC_PRINT("HCDMA	 @0x%08X : 0x%08X\n", (uint32_t) addr,
+			   dwc_read_reg32(addr));
+	}
+	return;
+}
+
+
+/**
+ * This function reads the core global registers and prints them
+ *
+ * @param _core_if Programming view of DWC_otg controller.
+ */
+void dwc_otg_dump_global_registers(dwc_otg_core_if_t * _core_if)
+{
+	int i;
+	volatile uint32_t *addr;
+	DWC_PRINT("Core Global Registers");
+	addr = &_core_if->core_global_regs->gotgctl;
+	DWC_PRINT("GOTGCTL	 @0x%08X : 0x%08X\n", (uint32_t) addr,
+		   dwc_read_reg32(addr));
+	addr = &_core_if->core_global_regs->gotgint;
+	DWC_PRINT("GOTGINT	 @0x%08X : 0x%08X\n", (uint32_t) addr,
+		   dwc_read_reg32(addr));
+	addr = &_core_if->core_global_regs->gahbcfg;
+	DWC_PRINT("GAHBCFG	 @0x%08X : 0x%08X\n", (uint32_t) addr,
+		   dwc_read_reg32(addr));
+	addr = &_core_if->core_global_regs->gusbcfg;
+	DWC_PRINT("GUSBCFG	 @0x%08X : 0x%08X\n", (uint32_t) addr,
+		   dwc_read_reg32(addr));
+	addr = &_core_if->core_global_regs->grstctl;
+	DWC_PRINT("GRSTCTL	 @0x%08X : 0x%08X\n", (uint32_t) addr,
+		   dwc_read_reg32(addr));
+	addr = &_core_if->core_global_regs->gintsts;
+	DWC_PRINT("GINTSTS	 @0x%08X : 0x%08X\n", (uint32_t) addr,
+		   dwc_read_reg32(addr));
+	addr = &_core_if->core_global_regs->gintmsk;
+	DWC_PRINT("GINTMSK	 @0x%08X : 0x%08X\n", (uint32_t) addr,
+		   dwc_read_reg32(addr));
+	addr = &_core_if->core_global_regs->grxstsr;
+	DWC_PRINT("GRXSTSR	 @0x%08X : 0x%08X\n", (uint32_t) addr,
+		   dwc_read_reg32(addr));
+
+    //addr=&_core_if->core_global_regs->grxstsp;
+    //DWC_PRINT("GRXSTSP   @0x%08X : 0x%08X\n",(uint32_t)addr,dwc_read_reg32(addr));
+    addr = &_core_if->core_global_regs->grxfsiz;
+	DWC_PRINT("GRXFSIZ	 @0x%08X : 0x%08X\n", (uint32_t) addr,
+		   dwc_read_reg32(addr));
+	addr = &_core_if->core_global_regs->gnptxfsiz;
+	DWC_PRINT("GNPTXFSIZ @0x%08X : 0x%08X\n", (uint32_t) addr,
+		   dwc_read_reg32(addr));
+	addr = &_core_if->core_global_regs->gnptxsts;
+	DWC_PRINT("GNPTXSTS	 @0x%08X : 0x%08X\n", (uint32_t) addr,
+		   dwc_read_reg32(addr));
+	addr = &_core_if->core_global_regs->gi2cctl;
+	DWC_PRINT("GI2CCTL	 @0x%08X : 0x%08X\n", (uint32_t) addr,
+		   dwc_read_reg32(addr));
+	addr = &_core_if->core_global_regs->gpvndctl;
+	DWC_PRINT("GPVNDCTL	 @0x%08X : 0x%08X\n", (uint32_t) addr,
+		   dwc_read_reg32(addr));
+	addr = &_core_if->core_global_regs->ggpio;
+	DWC_PRINT("GGPIO	 @0x%08X : 0x%08X\n", (uint32_t) addr,
+		   dwc_read_reg32(addr));
+	addr = &_core_if->core_global_regs->guid;
+	DWC_PRINT("GUID		 @0x%08X : 0x%08X\n", (uint32_t) addr,
+		   dwc_read_reg32(addr));
+	addr = &_core_if->core_global_regs->gsnpsid;
+	DWC_PRINT("GSNPSID	 @0x%08X : 0x%08X\n", (uint32_t) addr,
+		   dwc_read_reg32(addr));
+	addr = &_core_if->core_global_regs->ghwcfg1;
+	DWC_PRINT("GHWCFG1	 @0x%08X : 0x%08X\n", (uint32_t) addr,
+		   dwc_read_reg32(addr));
+	addr = &_core_if->core_global_regs->ghwcfg2;
+	DWC_PRINT("GHWCFG2	 @0x%08X : 0x%08X\n", (uint32_t) addr,
+		   dwc_read_reg32(addr));
+	addr = &_core_if->core_global_regs->ghwcfg3;
+	DWC_PRINT("GHWCFG3	 @0x%08X : 0x%08X\n", (uint32_t) addr,
+		   dwc_read_reg32(addr));
+	addr = &_core_if->core_global_regs->ghwcfg4;
+	DWC_PRINT("GHWCFG4	 @0x%08X : 0x%08X\n", (uint32_t) addr,
+		   dwc_read_reg32(addr));
+	addr = &_core_if->core_global_regs->hptxfsiz;
+	DWC_PRINT("HPTXFSIZ	 @0x%08X : 0x%08X\n", (uint32_t) addr,
+		   dwc_read_reg32(addr));
+	for (i = 0; i < _core_if->hwcfg4.b.num_dev_perio_in_ep; i++) {
+		addr = &_core_if->core_global_regs->dptxfsiz_dieptxf[i];
+		DWC_PRINT("DPTXFSIZ[%d] @0x%08X : 0x%08X\n", i,
+			   (uint32_t) addr, dwc_read_reg32(addr));
+	}
+}
+
+
+/**
+ * Flush a Tx FIFO.
+ *
+ * @param _core_if Programming view of DWC_otg controller.
+ * @param _num Tx FIFO to flush.
+ */
+extern void dwc_otg_flush_tx_fifo(dwc_otg_core_if_t * _core_if,
+				  const int _num)
+{
+	dwc_otg_core_global_regs_t * global_regs = _core_if->core_global_regs;
+	volatile grstctl_t greset = {.d32 = 0 };
+	int count = 0;
+	DWC_DEBUGPL((DBG_CIL | DBG_PCDV), "Flush Tx FIFO %d\n", _num);
+	greset.b.txfflsh = 1;
+	greset.b.txfnum = _num;
+	dwc_write_reg32(&global_regs->grstctl, greset.d32);
+
+	do {
+		greset.d32 = dwc_read_reg32(&global_regs->grstctl);
+		if (++count > 10000) {
+			DWC_WARN("%s() HANG! GRSTCTL=%0x GNPTXSTS=0x%08x\n",
+				  __func__, greset.d32, dwc_read_reg32(&global_regs->gnptxsts));
+			break;
+		}
+		udelay(1);
+	} while (greset.b.txfflsh == 1);
+    /* Wait for 3 PHY Clocks */
+    UDELAY(1);
+}
+
+
+/**
+ * Flush Rx FIFO.
+ *
+ * @param _core_if Programming view of DWC_otg controller.
+ */
+extern void dwc_otg_flush_rx_fifo(dwc_otg_core_if_t * _core_if)
+{
+	dwc_otg_core_global_regs_t * global_regs = _core_if->core_global_regs;
+	volatile grstctl_t greset = {.d32 = 0 };
+	int count = 0;
+	DWC_DEBUGPL((DBG_CIL | DBG_PCDV), "%s\n", __func__);
+
+    /*
+     *
+     */
+    greset.b.rxfflsh = 1;
+	dwc_write_reg32(&global_regs->grstctl, greset.d32);
+
+	do {
+		greset.d32 = dwc_read_reg32(&global_regs->grstctl);
+		if (++count > 10000) {
+			DWC_WARN("%s() HANG! GRSTCTL=%0x\n", __func__, greset.d32);
+			break;
+		}
+		udelay(1);
+	} while (greset.b.rxfflsh == 1);
+
+    /* Wait for 3 PHY Clocks */
+    UDELAY(1);
+}
+
+
+/**
+ * Do core a soft reset of the core.  Be careful with this because it
+ * resets all the internal state machines of the core.
+ */
+void dwc_otg_core_reset(dwc_otg_core_if_t * _core_if)
+{
+	dwc_otg_core_global_regs_t * global_regs = _core_if->core_global_regs;
+	volatile grstctl_t greset = {.d32 = 0 };
+	int count = 0;
+	DWC_DEBUGPL(DBG_CILV, "%s\n", __func__);
+
+    /* Wait for AHB master IDLE state. */
+    do {
+		UDELAY(10);
+		greset.d32 = dwc_read_reg32(&global_regs->grstctl);
+		if (++count > 100000) {
+			DWC_WARN("%s() HANG! AHB Idle GRSTCTL=%0x\n", __func__, greset.d32);
+			return;
+		}
+	} while (greset.b.ahbidle == 0);
+
+    /* Core Soft Reset */
+    count = 0;
+	greset.b.csftrst = 1;
+	dwc_write_reg32(&global_regs->grstctl, greset.d32);
+
+	do {
+		greset.d32 = dwc_read_reg32(&global_regs->grstctl);
+		if (++count > 10000) {
+			DWC_WARN("%s() HANG! Soft Reset GRSTCTL=%0x\n", __func__, greset.d32);
+			break;
+		}
+		udelay(1);
+	} while (greset.b.csftrst == 1);
+
+    /* Wait for 3 PHY Clocks */
+    //DWC_PRINT("100ms\n");
+    MDELAY(100);
+}
+
+
+/**
+ * Register HCD callbacks.	The callbacks are used to start and stop
+ * the HCD for interrupt processing.
+ *
+ * @param _core_if Programming view of DWC_otg controller.
+ * @param _cb the HCD callback structure.
+ * @param _p pointer to be passed to callback function (usb_hcd*).
+ */
+extern void dwc_otg_cil_register_hcd_callbacks(dwc_otg_core_if_t * _core_if,
+		       dwc_otg_cil_callbacks_t * _cb, void *_p)
+{
+	_core_if->hcd_cb = _cb;
+	_cb->p = _p;
+}
+
+/**
+ * Register PCD callbacks.	The callbacks are used to start and stop
+ * the PCD for interrupt processing.
+ *
+ * @param _core_if Programming view of DWC_otg controller.
+ * @param _cb the PCD callback structure.
+ * @param _p pointer to be passed to callback function (pcd*).
+ */
+extern void dwc_otg_cil_register_pcd_callbacks(dwc_otg_core_if_t * _core_if,
+		       dwc_otg_cil_callbacks_t * _cb, void *_p)
+{
+	_core_if->pcd_cb = _cb;
+	_cb->p = _p;
+}
+
diff -Naur a/drivers/usb/dwc_otg/dwc_otg_cil.h b/drivers/usb/dwc_otg/dwc_otg_cil.h
--- a/drivers/usb/dwc_otg/dwc_otg_cil.h	1970-01-01 00:00:00.000000000 +0000
+++ b/drivers/usb/dwc_otg/dwc_otg_cil.h	2017-06-22 08:12:48.816602641 +0000
@@ -0,0 +1,686 @@
+/* ==========================================================================
+ * $File: //dwh/usb_iip/dev/software/otg_ipmate/linux/drivers/dwc_otg_cil.h $
+ * $Revision: #12 $
+ * $Date: 2007/02/08 $
+ * $Change: 792294 $
+ *
+ * Synopsys HS OTG Linux Software Driver and documentation (hereinafter,
+ * "Software") is an Unsupported proprietary work of Synopsys, Inc. unless
+ * otherwise expressly agreed to in writing between Synopsys and you.
+ *
+ * The Software IS NOT an item of Licensed Software or Licensed Product under
+ * any End User Software License Agreement or Agreement for Licensed Product
+ * with Synopsys or any supplement thereto. You are permitted to use and
+ * redistribute this Software in source and binary forms, with or without
+ * modification, provided that redistributions of source code must retain this
+ * notice. You may not view, use, disclose, copy or distribute this file or
+ * any information contained herein except pursuant to this license grant from
+ * Synopsys. If you do not agree with this notice, including the disclaimer
+ * below, then you are not authorized to use the Software.
+ *
+ * THIS SOFTWARE IS BEING DISTRIBUTED BY SYNOPSYS SOLELY ON AN "AS IS" BASIS
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE HEREBY DISCLAIMED. IN NO EVENT SHALL SYNOPSYS BE LIABLE FOR ANY DIRECT,
+ * INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+ * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+ * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+ * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
+ * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
+ * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH
+ * DAMAGE.
+ * ========================================================================== */
+
+#if !defined(__DWC_CIL_H__)
+#define __DWC_CIL_H__
+
+#include "dwc_otg_plat.h"
+#include "dwc_otg_regs.h"
+#ifdef CONFIG_DWC_DEBUG
+#include "linux/timer.h"
+#endif
+
+#ifdef CONFIG_OTG_PLB_DMA
+#include "ppc4xx_dma.h"
+#include <asm/cacheflush.h>
+#include <linux/interrupt.h>
+#include <asm/time.h>
+#include <asm/unaligned.h>
+
+#undef OTG_PLB_DMA_DBG
+#define OTG_TX_DMA 0    /* TX DMA direction */
+#define OTG_RX_DMA 1    /* RX DMA direction */
+#define PLB_DMA_CH DMA_CH0	/* plb dma channel */
+#define PLB_DMA_CH_INT 12
+#define PLB_DMA_INT_ENA	1
+#define PLB_DMA_INT_DIS	0
+#define USB_BUFSIZ	512
+
+#ifdef CONFIG_OTG_PLB_DMA_TASKLET
+#ifndef CONFIG_OTG_PLB_DMA
+#define CONFIG_OTG_PLB_DMA
+#endif
+
+extern atomic_t release_later;
+#endif
+#endif
+
+/* This file contains the interface to the Core Interface Layer.*/
+#ifdef CONFIG_405EZ
+/* Since the 405EZ (Ultra) only support 2047 bytes as max transfer size, we have to split up bigger transfers
+ * into multiple transfers of 1024 bytes sized messages. It happens often, that transfers of 4096 bytes are
+ * required (zero-gadget, file_storage-gadget). MAX_XFER_LEN is set to 1024 right now, but could be 2047,
+ * since the xfer-size field in the 405EZ USB device controller implementation has 11 bits.
+ * Using 1024 seems to work for now. */
+#define MAX_XFER_LEN	1024
+#endif
+
+/* The <code>dwc_ep</code> structure represents the state of a single
+ * endpoint when acting in device mode. It contains the data items
+ * needed for an endpoint to be activated and transfer packets.*/
+typedef struct dwc_ep {
+	uint8_t	 num;					// EP number used for register address lookup
+	unsigned is_in : 1;				// EP direction 0 = OUT
+	unsigned active : 1;			// EP active
+	/** Periodic Tx FIFO # for IN EPs For INTR EP set to 0 to use non-periodic Tx FIFO
+		If dedicated Tx FIFOs are enabled for all IN Eps - Tx FIFO # FOR IN EPs*/
+	unsigned tx_fifo_num : 4;		
+#define DWC_OTG_EP_TYPE_CONTROL	   0
+#define DWC_OTG_EP_TYPE_ISOC	   1
+#define DWC_OTG_EP_TYPE_BULK	   2
+#define DWC_OTG_EP_TYPE_INTR	   3
+	unsigned type : DWC_OTG_EP_TYPE_BULK; // EP type: 0 - Control, 1 - ISOC,	 2 - BULK,	3 - INTR
+	unsigned data_pid_start : 1;	// DATA start PID for INTR and BULK EP
+	unsigned even_odd_frame : 1;	// Frame (even/odd) for ISOC EP
+	unsigned maxpacket : 11;		// Max Packet bytes
+	uint32_t dma_addr;				// Pointer to the beginning of the transfer buffer -- do not modify during transfer
+	uint8_t *start_xfer_buff;
+	uint8_t *xfer_buff;				// pointer to the transfer buffer
+	unsigned xfer_len : 19;			// Number of bytes to transfer
+	unsigned xfer_count : 19;		// Number of bytes transferred
+	unsigned sent_zlp : 1;			// Sent ZLP 
+	unsigned total_len : 19;		// Total len for control transfer
+	unsigned stall_clear_flag : 1;	// stall clear flag
+
+#ifdef CONFIG_405EZ
+	/* Since the 405EZ (Ultra) only support 2047 bytes as max transfer size, we have to split up bigger transfers
+	 * into multiple transfers of 1024 bytes sized messages. It happens often that transfers of 4096 bytes are
+	 * required (zero-gadget, file_storage-gadget). "bytes_pending" will hold the amount of bytes that are
+	 * still pending to be send in further messages to complete the bigger transfer. */
+	u32 bytes_pending;
+#endif
+} dwc_ep_t;
+
+/* Reasons for halting a host channel. */
+typedef enum dwc_otg_halt_status {
+	DWC_OTG_HC_XFER_NO_HALT_STATUS,
+	DWC_OTG_HC_XFER_COMPLETE,
+	DWC_OTG_HC_XFER_URB_COMPLETE,
+	DWC_OTG_HC_XFER_ACK,
+	DWC_OTG_HC_XFER_NAK,
+	DWC_OTG_HC_XFER_NYET,
+	DWC_OTG_HC_XFER_STALL,
+	DWC_OTG_HC_XFER_XACT_ERR,
+	DWC_OTG_HC_XFER_FRAME_OVERRUN,
+	DWC_OTG_HC_XFER_BABBLE_ERR,
+	DWC_OTG_HC_XFER_DATA_TOGGLE_ERR,
+	DWC_OTG_HC_XFER_AHB_ERR,
+	DWC_OTG_HC_XFER_PERIODIC_INCOMPLETE,
+	DWC_OTG_HC_XFER_URB_DEQUEUE
+} dwc_otg_halt_status_e;
+
+/* Host channel descriptor. This structure represents the state of a single host channel when acting
+ * in host mode. It contains the data items needed to transfer packets to an endpoint via a host channel. */
+typedef struct dwc_hc {
+	uint8_t	 hc_num;				// Host channel number used for register address lookup
+	unsigned dev_addr : 7;			// Device to access
+	unsigned ep_num : 4;			// EP to access
+	unsigned ep_is_in : 1;			// EP direction. 0: OUT, 1: IN
+#define DWC_OTG_EP_SPEED_LOW	0
+#define DWC_OTG_EP_SPEED_FULL	1
+#define DWC_OTG_EP_SPEED_HIGH	2
+	unsigned speed : DWC_OTG_EP_SPEED_HIGH;	// EP speed
+	unsigned ep_type : DWC_OTG_EP_TYPE_BULK;	// Endpoint type
+	unsigned max_packet : 11;		// Max packet size in bytes
+#define DWC_OTG_HC_PID_DATA0 0		// Data0
+#define DWC_OTG_HC_PID_DATA2 1		// Data2
+#define DWC_OTG_HC_PID_DATA1 2		// Data1
+#define DWC_OTG_HC_PID_MDATA 3		// (non-Control EP)
+#define DWC_OTG_HC_PID_SETUP 3		// SETUP (Control EP)
+	unsigned data_pid_start : 2;	// PID for initial transaction
+	unsigned multi_count: 2;		// Number of periodic transactions per (micro)frame
+	uint8_t *xfer_buff;				// pointer to the transfer buffer
+	uint32_t xfer_len;				// Number of bytes to transfer
+	uint32_t xfer_count : 19;		// Number of bytes transferred
+	uint16_t start_pkt_count;		// Packet count at start of transfe 
+	uint8_t xfer_started;			// Transfer started flag: started=1, not started=0
+	uint8_t do_ping;				// Issue PING request: yes=1, no=0 
+	uint8_t error_state;			// Error count: error=1, no error=0
+	uint8_t halt_on_queue;			// Halt channel at next queued request. This is necessary in
+		// slave mode if no request queue space is available when an attempt is made to halt the channel.
+	uint8_t halt_pending;			// 1=host channel halted, but the core is not finished flushing queued requests
+	dwc_otg_halt_status_e	halt_status;	// Reason for halting the host channel
+	uint8_t do_split;		   		// Enable split for the host channel
+	uint8_t complete_split;	   		// Enable complete split
+	uint8_t hub_addr;		   		// Address of high speed hub
+	uint8_t port_addr;		   		// Port of the low/full speed device
+	/** Split transaction position, one of the following values:
+	 *	  - DWC_HCSPLIT_XACTPOS_MID
+	 *	  - DWC_HCSPLIT_XACTPOS_BEGIN
+	 *	  - DWC_HCSPLIT_XACTPOS_END
+	 *	  - DWC_HCSPLIT_XACTPOS_ALL */
+	uint8_t xact_pos;
+	uint8_t short_read;				// Set when the host channel does a short read
+	uint8_t requests;				// # requests issued for this channel since it was assigned to the current transfer (not counting PINGs)
+	struct dwc_otg_qh *qh;			// Queue Head for the transfer being processed by this channel
+	struct list_head hc_list_entry;	// Entry in list of host channels. */
+} dwc_hc_t;
+
+/* The following parameters may be specified when starting the module. These parameters define how the DWC_otg
+ * controller should be configured. Parameter values are passed to the CIL initialization function dwc_otg_cil_init. */
+typedef struct dwc_otg_core_params {
+	int32_t opt;
+#define dwc_param_opt_default 1
+	/**
+	 * Specifies the OTG capabilities. The driver will automatically
+	 * detect the value for this parameter if none is specified.
+	 * 0 - HNP and SRP capable (default)
+	 * 1 - SRP Only capable
+	 * 2 - No HNP/SRP capable
+	 */
+	int32_t otg_cap;
+#define DWC_OTG_CAP_PARAM_HNP_SRP_CAPABLE 0
+#define DWC_OTG_CAP_PARAM_SRP_ONLY_CAPABLE 1
+#define DWC_OTG_CAP_PARAM_NO_HNP_SRP_CAPABLE 2
+#define dwc_param_otg_cap_default DWC_OTG_CAP_PARAM_HNP_SRP_CAPABLE
+
+	/**
+	 * Specifies whether to use slave or DMA mode for accessing the data
+	 * FIFOs. The driver will automatically detect the value for this
+	 * parameter if none is specified.
+	 * 0 - Slave
+	 * 1 - DMA (default, if available)
+	 */
+	int32_t dma_enable;
+#define dwc_param_dma_enable_default 1
+
+	/** The DMA Burst size (applicable only for External DMA
+	 * Mode). 1, 4, 8 16, 32, 64, 128, 256 (default 32)
+	 */
+	int32_t dma_burst_size;	 /* Translate this to GAHBCFG values */
+#define dwc_param_dma_burst_size_default 32
+
+	/**
+	 * Specifies the maximum speed of operation in host and device mode.
+	 * The actual speed depends on the speed of the attached device and
+	 * the value of phy_type. The actual speed depends on the speed of the
+	 * attached device.
+	 * 0 - High Speed (default)
+	 * 1 - Full Speed
+	 */
+	int32_t speed;
+#define dwc_param_speed_default 0
+#define DWC_SPEED_PARAM_HIGH 0
+#define DWC_SPEED_PARAM_FULL 1
+
+	/** Specifies whether low power mode is supported when attached
+	 *	to a Full Speed or Low Speed device in host mode.
+	 * 0 - Don't support low power mode (default)
+	 * 1 - Support low power mode
+	 */
+	int32_t host_support_fs_ls_low_power;
+#define dwc_param_host_support_fs_ls_low_power_default 0
+
+	/** Specifies the PHY clock rate in low power mode when connected to a
+	 * Low Speed device in host mode. This parameter is applicable only if
+	 * HOST_SUPPORT_FS_LS_LOW_POWER is enabled.	 If PHY_TYPE is set to FS
+	 * then defaults to 6 MHZ otherwise 48 MHZ.
+	 *
+	 * 0 - 48 MHz
+	 * 1 - 6 MHz
+	 */
+	int32_t host_ls_low_power_phy_clk;
+#define dwc_param_host_ls_low_power_phy_clk_default 0
+#define DWC_HOST_LS_LOW_POWER_PHY_CLK_PARAM_48MHZ 0
+#define DWC_HOST_LS_LOW_POWER_PHY_CLK_PARAM_6MHZ 1
+
+	/**
+	 * 0 - Use cC FIFO size parameters
+	 * 1 - Allow dynamic FIFO sizing (default)
+	 */
+	int32_t enable_dynamic_fifo;
+#define dwc_param_enable_dynamic_fifo_default 1
+
+	/** Total number of 4-byte words in the data FIFO memory. This
+	 * memory includes the Rx FIFO, non-periodic Tx FIFO, and periodic Tx FIFOs.
+	 * 32 to 32768 (default 8192) Note: The total FIFO memory depth in the FPGA configuration is 8192. */
+	int32_t data_fifo_size;
+#define dwc_param_data_fifo_size_default 8192
+
+	/** Number of 4-byte words in the Rx FIFO in device mode when dynamic
+	 * FIFO sizing is enabled.
+	 * 16 to 32768 (default 1064)
+	 */
+	int32_t dev_rx_fifo_size;
+#define dwc_param_dev_rx_fifo_size_default 1064
+
+	/** Number of 4-byte words in the non-periodic Tx FIFO in device mode
+	 * when dynamic FIFO sizing is enabled. 16 to 32768 (default 1024) */
+	int32_t dev_nperio_tx_fifo_size;
+#define dwc_param_dev_nperio_tx_fifo_size_default 1024
+
+	/** Number of 4-byte words in each of the periodic Tx FIFOs in device
+	 * mode when dynamic FIFO sizing is enabled.
+	 * 4 to 768 (default 256)
+	 */
+	uint32_t dev_perio_tx_fifo_size[MAX_PERIO_FIFOS];
+#define dwc_param_dev_perio_tx_fifo_size_default 256
+
+	/** Number of 4-byte words in the Rx FIFO in host mode when dynamic
+	 * FIFO sizing is enabled.
+	 * 16 to 32768 (default 1024)
+	 */
+	int32_t host_rx_fifo_size;
+#define dwc_param_host_rx_fifo_size_default 1024
+
+		/** Number of 4-byte words in the non-periodic Tx FIFO in host mode
+	 * when Dynamic FIFO sizing is enabled in the core.
+	 * 16 to 32768 (default 1024)
+	 */
+	int32_t host_nperio_tx_fifo_size;
+#define dwc_param_host_nperio_tx_fifo_size_default 1024
+
+	/** Number of 4-byte words in the host periodic Tx FIFO when dynamic
+	 * FIFO sizing is enabled.
+	 * 16 to 32768 (default 1024)
+	 */
+	int32_t host_perio_tx_fifo_size;
+#define dwc_param_host_perio_tx_fifo_size_default 1024
+
+	/** The maximum transfer size supported in bytes.
+	 * 2047 to 65,535  (default 65,535)
+	 */
+	int32_t max_transfer_size;
+#define dwc_param_max_transfer_size_default 65535
+
+	/** The maximum number of packets in a transfer.
+	 * 15 to 511  (default 511)
+	 */
+	int32_t max_packet_count;
+#define dwc_param_max_packet_count_default 511
+
+	/** The number of host channel registers to use.
+	 * 1 to 16 (default 12)
+	 * Note: The FPGA configuration supports a maximum of 12 host channels.
+	 */
+	int32_t host_channels;
+#define dwc_param_host_channels_default 12
+
+	/** The number of endpoints in addition to EP0 available for device
+	 * mode operations.
+	 * 1 to 15 (default 6 IN and OUT)
+	 * Note: The FPGA configuration supports a maximum of 6 IN and OUT
+	 * endpoints in addition to EP0.
+	 */
+	int32_t dev_endpoints;
+#define dwc_param_dev_endpoints_default 6
+
+		/**
+		 * Specifies the type of PHY interface to use. By default, the driver
+		 * will automatically detect the phy_type.
+		 *
+		 * 0 - Full Speed PHY
+		 * 1 - UTMI+ (default)
+		 * 2 - ULPI
+		 */
+	int32_t phy_type;
+#define DWC_PHY_TYPE_PARAM_FS 0
+#define DWC_PHY_TYPE_PARAM_UTMI 1
+#define DWC_PHY_TYPE_PARAM_ULPI 2
+#define dwc_param_phy_type_default DWC_PHY_TYPE_PARAM_UTMI
+
+	/**
+	 * Specifies the UTMI+ Data Width.	This parameter is
+	 * applicable for a PHY_TYPE of UTMI+ or ULPI. (For a ULPI
+	 * PHY_TYPE, this parameter indicates the data width between
+	 * the MAC and the ULPI Wrapper.) Also, this parameter is
+	 * applicable only if the OTG_HSPHY_WIDTH cC parameter was set
+	 * to "8 and 16 bits", meaning that the core has been
+	 * configured to work at either data path width.
+	 *
+	 * 8 or 16 bits (default 16)
+	 */
+	int32_t phy_utmi_width;
+#define dwc_param_phy_utmi_width_default 16
+
+	/**
+	 * Specifies whether the ULPI operates at double or single
+	 * data rate. This parameter is only applicable if PHY_TYPE is
+	 * ULPI.
+	 *
+	 * 0 - single data rate ULPI interface with 8 bit wide data
+	 * bus (default)
+	 * 1 - double data rate ULPI interface with 4 bit wide data
+	 * bus
+	 */
+	int32_t phy_ulpi_ddr;
+#define dwc_param_phy_ulpi_ddr_default 0
+
+	/**
+	 * Specifies whether to use the internal or external supply to
+	 * drive the vbus with a ULPI phy.
+	 */
+	int32_t phy_ulpi_ext_vbus;
+#define DWC_PHY_ULPI_INTERNAL_VBUS 0
+#define DWC_PHY_ULPI_EXTERNAL_VBUS 1
+#define dwc_param_phy_ulpi_ext_vbus_default DWC_PHY_ULPI_INTERNAL_VBUS
+
+	/**
+	 * Specifies whether to use the I2Cinterface for full speed PHY. This
+	 * parameter is only applicable if PHY_TYPE is FS.
+	 * 0 - No (default)
+	 * 1 - Yes
+	 */
+	int32_t i2c_enable;
+#define dwc_param_i2c_enable_default 0
+
+	int32_t ulpi_fs_ls;
+#define dwc_param_ulpi_fs_ls_default 0
+
+	int32_t ts_dline;
+#define dwc_param_ts_dline_default 0
+
+	/**
+	 * Specifies whether dedicated transmit FIFOs are
+	 * enabled for non periodic IN endpoints in device mode
+	 * 0 - No
+	 * 1 - Yes
+	 */
+	 int32_t en_multiple_tx_fifo;
+#define dwc_param_en_multiple_tx_fifo_default 1
+
+	/** Number of 4-byte words in each of the Tx FIFOs in device
+	 * mode when dynamic FIFO sizing is enabled.
+	 * 4 to 768 (default 256)
+	 */
+	uint32_t dev_tx_fifo_size[MAX_TX_FIFOS];
+#define dwc_param_dev_tx_fifo_size_default 256
+
+	/** Thresholding enable flag-
+	 * bit 0 - enable non-ISO Tx thresholding
+	 * bit 1 - enable ISO Tx thresholding
+	 * bit 2 - enable Rx thresholding
+	 */
+	uint32_t thr_ctl;
+#define dwc_param_thr_ctl_default 0
+
+	/** Thresholding length for Tx
+	 *	FIFOs in 32 bit DWORDs
+	 */
+	uint32_t tx_thr_length;
+#define dwc_param_tx_thr_length_default 64
+
+	/** Thresholding length for Rx
+	 *	FIFOs in 32 bit DWORDs
+	 */
+	uint32_t rx_thr_length;
+#define dwc_param_rx_thr_length_default 64
+
+} dwc_otg_core_params_t;
+
+#ifdef CONFIG_DWC_DEBUG
+struct dwc_otg_core_if;
+typedef struct hc_xfer_info
+{
+	struct dwc_otg_core_if	*core_if;
+	dwc_hc_t		*hc;
+} hc_xfer_info_t;
+#endif
+
+#ifdef CONFIG_OTG_PLB_DMA_TASKLET
+typedef struct dma_xfer_s {
+    uint32_t *dma_data_buff;
+    void 	*dma_data_fifo;
+    uint32_t dma_count;
+	uint32_t dma_dir;
+} dma_xfer_t;
+#endif
+
+/* The <code>dwc_otg_core_if</code> structure contains information needed to manage
+ * the DWC_otg controller acting in either host or device mode. It
+ * represents the programming view of the controller as a whole */
+typedef struct dwc_otg_core_if {
+	/** Parameters that define how the core should be configured.*/
+	dwc_otg_core_params_t	   *core_params;
+
+	/** Core Global registers starting at offset 000h. */
+	dwc_otg_core_global_regs_t *core_global_regs;
+
+	/** Device-specific information */
+	dwc_otg_dev_if_t		   *dev_if;
+	/** Host-specific information */
+	dwc_otg_host_if_t		   *host_if;
+
+	/* Set to 1 if the core PHY interface bits in USBCFG have been initialized */
+	uint8_t phy_init_done;
+
+	/*SRP Success flag, set by srp success interrupt in FS I2C mode */
+	uint8_t srp_success;
+	uint8_t srp_timer_started;
+
+	/* Common configuration information */
+	volatile uint32_t *pcgcctl;			// Power and Clock Gating Control Register
+
+#define DWC_OTG_PCGCCTL_OFFSET 0xE00
+
+	uint32_t *data_fifo[MAX_EPS_CHANNELS];	// Push/pop addresses for endpoints or host channels
+
+#define DWC_OTG_DATA_FIFO_OFFSET 0x1000
+#define DWC_OTG_DATA_FIFO_SIZE 0x1000
+
+	uint16_t total_fifo_size;		// Total RAM for FIFOs (Bytes)
+	uint16_t rx_fifo_size;			// Size of Rx FIFO (Bytes)
+	uint16_t nperio_tx_fifo_size;	// Size of Non-periodic Tx FIFO (Bytes)
+	uint8_t dma_enable;				// 1 if DMA is enabled, 0 otherwise
+	uint8_t en_multiple_tx_fifo;	// 1 if dedicated Tx FIFOs are enabled, 0 otherwise
+	uint8_t queuing_high_bandwidth;	// 1 if multiple packets of a high-bandwidth xfer are in process of being queued
+
+	/** Hardware Configuration -- stored here for convenience.*/
+	hwcfg1_data_t hwcfg1;
+	hwcfg2_data_t hwcfg2;
+	hwcfg3_data_t hwcfg3;
+	hwcfg4_data_t hwcfg4;
+
+	/* The operational State, during transations (a_host>>a_peripherial and b_device=>b_host) this may not
+	 * match the core but allows the software to determine transitions. */
+	uint8_t op_state;
+
+	/* Set to 1 if the HCD needs to be restarted on a session request interrupt. This is required if no connector 
+	 * ID status change has occurred since the HCD was last disconnected. */
+	uint8_t restart_hcd_on_session_req;
+
+	/** HCD callbacks */
+#define A_HOST			(1)		// A-Device is a_host
+#define A_SUSPEND		(2)		// A-Device is a_suspend
+#define A_PERIPHERAL	(3)		// A-Device is a_peripherial
+#define B_PERIPHERAL	(4)		// B-Device is operating as a Peripheral
+#define B_HOST			(5)		// B-Device is operating as a Host
+
+	struct dwc_otg_cil_callbacks *hcd_cb;	// HCD callbacks
+	struct dwc_otg_cil_callbacks *pcd_cb;	// PCD callbacks
+	uint32_t p_tx_msk;						// Device mode Periodic Tx FIFO Mask
+	uint32_t tx_msk;						// Device mode Periodic Tx FIFO Mask
+
+#ifdef CONFIG_DWC_DEBUG
+	uint32_t			start_hcchar_val[MAX_EPS_CHANNELS];
+
+	hc_xfer_info_t		hc_xfer_info[MAX_EPS_CHANNELS];
+	struct timer_list	hc_xfer_timer[MAX_EPS_CHANNELS];
+
+	uint32_t		hfnum_7_samples;
+	uint64_t		hfnum_7_frrem_accum;
+	uint32_t		hfnum_0_samples;
+	uint64_t		hfnum_0_frrem_accum;
+	uint32_t		hfnum_other_samples;
+	uint64_t		hfnum_other_frrem_accum;
+#endif
+	resource_size_t phys_addr;		/* Added to support PLB DMA : phys-virt mapping */
+#ifdef CONFIG_OTG_PLB_DMA_TASKLET
+    /* Tasket to do plbdma */
+    struct tasklet_struct   *plbdma_tasklet;
+#if 1
+	dma_xfer_t		dma_xfer;
+#else
+    uint32_t *dma_data_buff;
+    void 	*dma_data_fifo;
+    uint32_t dma_count;
+	uint32_t dma_dir;
+#endif
+#endif
+} dwc_otg_core_if_t;
+
+/* The following functions support initialization of the CIL driver component and the DWC_otg controller. */
+extern dwc_otg_core_if_t *dwc_otg_cil_init(const uint32_t *_reg_base_addr, dwc_otg_core_params_t *_core_params);
+extern void dwc_otg_cil_remove(dwc_otg_core_if_t *_core_if);
+extern void dwc_otg_core_init(dwc_otg_core_if_t *_core_if);
+extern void dwc_otg_core_host_init(dwc_otg_core_if_t *_core_if);
+extern void dwc_otg_core_dev_init(dwc_otg_core_if_t *_core_if);
+extern void dwc_otg_enable_global_interrupts( dwc_otg_core_if_t *_core_if );
+extern void dwc_otg_disable_global_interrupts( dwc_otg_core_if_t *_core_if );
+
+/* The following functions support managing the DWC_otg controller in device mode. */
+extern void dwc_otg_wakeup(dwc_otg_core_if_t *_core_if);
+extern void dwc_otg_read_setup_packet (dwc_otg_core_if_t *_core_if, uint32_t *_dest);
+extern uint32_t dwc_otg_get_frame_number(dwc_otg_core_if_t *_core_if);
+extern void dwc_otg_ep0_activate(dwc_otg_core_if_t *_core_if, dwc_ep_t *_ep);
+extern void dwc_otg_ep_activate(dwc_otg_core_if_t *_core_if, dwc_ep_t *_ep);
+extern void dwc_otg_ep_deactivate(dwc_otg_core_if_t *_core_if, dwc_ep_t *_ep);
+extern void dwc_otg_ep_start_transfer(dwc_otg_core_if_t *_core_if, dwc_ep_t *_ep);
+extern void dwc_otg_ep0_start_transfer(dwc_otg_core_if_t *_core_if, dwc_ep_t *_ep);
+extern void dwc_otg_ep0_continue_transfer(dwc_otg_core_if_t *_core_if, dwc_ep_t *_ep);
+extern void dwc_otg_ep_write_packet(dwc_otg_core_if_t *_core_if, dwc_ep_t *_ep, int _dma);
+extern void dwc_otg_ep_set_stall(dwc_otg_core_if_t *_core_if, dwc_ep_t *_ep);
+extern void dwc_otg_ep_clear_stall(dwc_otg_core_if_t *_core_if, dwc_ep_t *_ep);
+extern void dwc_otg_enable_device_interrupts(dwc_otg_core_if_t *_core_if);
+extern void dwc_otg_dump_dev_registers(dwc_otg_core_if_t *_core_if);
+
+/*The following functions support managing the DWC_otg controller in host mode.*/
+extern void dwc_otg_hc_init(dwc_otg_core_if_t *_core_if, dwc_hc_t *_hc);
+extern void dwc_otg_hc_halt(dwc_otg_core_if_t *_core_if, dwc_hc_t *_hc, dwc_otg_halt_status_e _halt_status);
+extern void dwc_otg_hc_cleanup(dwc_otg_core_if_t *_core_if, dwc_hc_t *_hc);
+extern void dwc_otg_hc_start_transfer(dwc_otg_core_if_t *_core_if, dwc_hc_t *_hc);
+extern int dwc_otg_hc_continue_transfer(dwc_otg_core_if_t *_core_if, dwc_hc_t *_hc);
+extern void dwc_otg_hc_do_ping(dwc_otg_core_if_t *_core_if, dwc_hc_t *_hc);
+extern void dwc_otg_hc_write_packet(dwc_otg_core_if_t *_core_if, dwc_hc_t *_hc);
+extern void dwc_otg_enable_host_interrupts(dwc_otg_core_if_t *_core_if);
+extern void dwc_otg_disable_host_interrupts(dwc_otg_core_if_t *_core_if);
+
+/* This function Reads HPRT0 in preparation to modify.	It keeps the WC bits 0 so that if they are 
+ * read as 1, they won't clear when you write it back */
+static inline uint32_t dwc_otg_read_hprt0(dwc_otg_core_if_t *_core_if) {
+	hprt0_data_t hprt0;
+	hprt0.d32 = dwc_read_reg32(_core_if->host_if->hprt0);
+	hprt0.b.prtena = 0;
+	hprt0.b.prtconndet = 0;
+	hprt0.b.prtenchng = 0;
+	hprt0.b.prtovrcurrchng = 0;
+	return hprt0.d32;
+}
+extern void dwc_otg_dump_host_registers(dwc_otg_core_if_t *_core_if);
+
+/* The following functions support managing the DWC_otg controller in either device or host mode.*/
+extern void dwc_otg_read_packet(dwc_otg_core_if_t *core_if, uint8_t *dest,	uint16_t bytes);
+extern void dwc_otg_dump_global_registers(dwc_otg_core_if_t *_core_if);
+extern void dwc_otg_flush_tx_fifo(dwc_otg_core_if_t *_core_if, const int _num);
+extern void dwc_otg_flush_rx_fifo(dwc_otg_core_if_t *_core_if);
+extern void dwc_otg_core_reset(dwc_otg_core_if_t *_core_if);
+
+#ifdef CONFIG_OTG_PLB_DMA
+extern void ppc4xx_start_plb_dma(dwc_otg_core_if_t *_core_if, void *src, void *dst,
+	unsigned int length, unsigned int use_interrupt, unsigned int dma_ch, unsigned int dma_dir);
+#endif
+
+#define NP_TXFIFO_EMPTY -1
+#define MAX_NP_TXREQUEST_Q_SLOTS 8
+/* Returns the endpoint number of the request at the top of non-periodic TX FIFO or -1 if the request FIFO is empty. */
+static inline int dwc_otg_top_nptxfifo_epnum(dwc_otg_core_if_t *cif) {
+	gnptxsts_data_t txstatus = {.d32 = 0};
+	txstatus.d32 = dwc_read_reg32(&cif->core_global_regs->gnptxsts);
+	return (txstatus.b.nptxqspcavail == MAX_NP_TXREQUEST_Q_SLOTS ? -1 : txstatus.b.nptxqtop_chnep);
+}
+
+/* This function returns the Core Interrupt register */
+static inline uint32_t dwc_otg_read_core_intr(dwc_otg_core_if_t *cif) {
+	return (dwc_read_reg32(&cif->core_global_regs->gintsts) & dwc_read_reg32(&cif->core_global_regs->gintmsk));
+}
+
+/* This function returns the OTG Interrupt register */
+static inline uint32_t dwc_otg_read_otg_intr (dwc_otg_core_if_t *cif) {
+	return (dwc_read_reg32(&cif->core_global_regs->gotgint));
+}
+
+/* This function reads the Device All Endpoints Interrupt register and returns the IN endpoint interrupt bits */
+static inline uint32_t dwc_otg_read_dev_all_in_ep_intr(dwc_otg_core_if_t *cif) {
+	return (dwc_read_reg32(&cif->dev_if->dev_global_regs->daint) &
+			dwc_read_reg32(&cif->dev_if->dev_global_regs->daintmsk)) & 0xffff;
+
+}
+
+/* This function reads the Device All Endpoints Interrupt register and returns the OUT endpoint interrupt bits */
+static inline uint32_t dwc_otg_read_dev_all_out_ep_intr(dwc_otg_core_if_t *cif) {
+	return ((dwc_read_reg32(&cif->dev_if->dev_global_regs->daint) &
+			dwc_read_reg32(&cif->dev_if->dev_global_regs->daintmsk)) & 0xffff0000) >> 16;
+}
+
+/* This function returns the Device IN EP Interrupt register */
+static inline uint32_t dwc_otg_read_dev_in_ep_intr(dwc_otg_core_if_t *cif, dwc_ep_t *_ep) {
+	dwc_otg_dev_if_t *dev_if = cif->dev_if;
+	uint32_t emp = dwc_read_reg32(&dev_if->dev_global_regs->dtknqr4_fifoemptymsk);
+	uint32_t msk = dwc_read_reg32(&dev_if->dev_global_regs->diepmsk) | ((emp >> _ep->num) & 0x1) << 7;
+	return dwc_read_reg32(&dev_if->in_ep_regs[_ep->num]->diepint) & msk;
+//	return dwc_read_reg32(&dev_if->in_ep_regs[_ep->num]->diepint) & dwc_read_reg32(&dev_if->dev_global_regs->diepmsk);
+}
+/* This function returns the Device OUT EP Interrupt register */
+static inline uint32_t dwc_otg_read_dev_out_ep_intr(dwc_otg_core_if_t *cif, dwc_ep_t *_ep) {
+	dwc_otg_dev_if_t *dev_if = cif->dev_if;
+	return dwc_read_reg32(&dev_if->out_ep_regs[_ep->num]->doepint) & dwc_read_reg32(&dev_if->dev_global_regs->doepmsk);
+}
+
+/* This function returns the Host All Channel Interrupt register */
+static inline uint32_t dwc_otg_read_host_all_channels_intr (dwc_otg_core_if_t *cif) {
+	return (dwc_read_reg32(&cif->host_if->host_global_regs->haint));
+}
+
+static inline uint32_t dwc_otg_read_host_channel_intr (dwc_otg_core_if_t *cif, dwc_hc_t *_hc) {
+	return (dwc_read_reg32(&cif->host_if->hc_regs[_hc->hc_num]->hcint));
+}
+
+/* This function returns the mode of the operation, host or device. @return 0 - Device Mode, 1 - Host Mode */
+static inline uint32_t dwc_otg_mode(dwc_otg_core_if_t *cif) {
+	return (dwc_read_reg32(&cif->core_global_regs->gintsts) & 0x1);
+}
+
+static inline uint8_t dwc_otg_is_device_mode(dwc_otg_core_if_t *cif) {
+	return (dwc_otg_mode(cif) != DWC_HOST_MODE);
+}
+static inline uint8_t dwc_otg_is_host_mode(dwc_otg_core_if_t *cif) {
+	return (dwc_otg_mode(cif) == DWC_HOST_MODE);
+}
+
+/* DWC_otg CIL callback structure.	This structure allows the HCD and PCD to register functions used for
+ * starting and stopping the PCD and HCD for role change on for a DRD. */
+typedef struct dwc_otg_cil_callbacks {
+	int (*start) (void *_p);			// Start function for role change
+	int (*stop) (void *_p);			// Stop Function for role change
+	int (*disconnect) (void *_p);		// Disconnect Function for role change
+	int (*resume_wakeup) (void *_p); 	// Resume/Remote wakeup Function
+	int (*suspend) (void *_p);			// Suspend function
+	int (*session_start) (void *_p);	// Session Start (SRP)
+	void *p;							// Pointer passed to start() and stop()
+} dwc_otg_cil_callbacks_t;
+
+extern int32_t dwc_otg_handle_common_intr(dwc_otg_core_if_t *_core_if);
+extern void dwc_otg_cil_register_pcd_callbacks(dwc_otg_core_if_t *_core_if, dwc_otg_cil_callbacks_t *_cb, void *_p);
+extern void dwc_otg_cil_register_hcd_callbacks(dwc_otg_core_if_t *_core_if, dwc_otg_cil_callbacks_t *_cb, void *_p);
+
+#endif
diff -Naur a/drivers/usb/dwc_otg/dwc_otg_cil.h.bak b/drivers/usb/dwc_otg/dwc_otg_cil.h.bak
--- a/drivers/usb/dwc_otg/dwc_otg_cil.h.bak	1970-01-01 00:00:00.000000000 +0000
+++ b/drivers/usb/dwc_otg/dwc_otg_cil.h.bak	2017-06-21 18:26:46.018675500 +0000
@@ -0,0 +1,705 @@
+/* ==========================================================================
+ * $File: //dwh/usb_iip/dev/software/otg_ipmate/linux/drivers/dwc_otg_cil.h $
+ * $Revision: #12 $
+ * $Date: 2007/02/08 $
+ * $Change: 792294 $
+ *
+ * Synopsys HS OTG Linux Software Driver and documentation (hereinafter,
+ * "Software") is an Unsupported proprietary work of Synopsys, Inc. unless
+ * otherwise expressly agreed to in writing between Synopsys and you.
+ *
+ * The Software IS NOT an item of Licensed Software or Licensed Product under
+ * any End User Software License Agreement or Agreement for Licensed Product
+ * with Synopsys or any supplement thereto. You are permitted to use and
+ * redistribute this Software in source and binary forms, with or without
+ * modification, provided that redistributions of source code must retain this
+ * notice. You may not view, use, disclose, copy or distribute this file or
+ * any information contained herein except pursuant to this license grant from
+ * Synopsys. If you do not agree with this notice, including the disclaimer
+ * below, then you are not authorized to use the Software.
+ *
+ * THIS SOFTWARE IS BEING DISTRIBUTED BY SYNOPSYS SOLELY ON AN "AS IS" BASIS
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE HEREBY DISCLAIMED. IN NO EVENT SHALL SYNOPSYS BE LIABLE FOR ANY DIRECT,
+ * INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+ * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+ * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+ * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
+ * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
+ * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH
+ * DAMAGE.
+ * ========================================================================== */
+
+#if !defined(__DWC_CIL_H__)
+#define __DWC_CIL_H__
+
+#include "linux/dwc_otg_plat.h"
+#include "dwc_otg_regs.h"
+#ifdef CONFIG_DWC_DEBUG
+#include "linux/timer.h"
+#endif
+
+#ifdef CONFIG_OTG_PLB_DMA
+#include "ppc4xx_dma.h"
+#include <asm/cacheflush.h>
+#include <linux/interrupt.h>
+#include <asm/time.h>
+#include <asm/unaligned.h>
+
+#undef OTG_PLB_DMA_DBG
+#define OTG_TX_DMA 0    /* TX DMA direction */
+#define OTG_RX_DMA 1    /* RX DMA direction */
+#define PLB_DMA_CH DMA_CH0	/* plb dma channel */
+#define PLB_DMA_CH_INT 12
+#define PLB_DMA_INT_ENA	1
+#define PLB_DMA_INT_DIS	0
+#define USB_BUFSIZ	512
+
+#ifdef CONFIG_OTG_PLB_DMA_TASKLET
+#ifndef CONFIG_OTG_PLB_DMA
+#define CONFIG_OTG_PLB_DMA
+#endif
+
+extern atomic_t release_later;
+#endif
+#endif
+
+/* This file contains the interface to the Core Interface Layer.*/
+#ifdef CONFIG_405EZ
+/* Since the 405EZ (Ultra) only support 2047 bytes as max transfer size, we have to split up bigger transfers
+ * into multiple transfers of 1024 bytes sized messages. It happens often, that transfers of 4096 bytes are
+ * required (zero-gadget, file_storage-gadget). MAX_XFER_LEN is set to 1024 right now, but could be 2047,
+ * since the xfer-size field in the 405EZ USB device controller implementation has 11 bits.
+ * Using 1024 seems to work for now. */
+#define MAX_XFER_LEN	1024
+#endif
+
+/* The <code>dwc_ep</code> structure represents the state of a single
+ * endpoint when acting in device mode. It contains the data items
+ * needed for an endpoint to be activated and transfer packets.*/
+typedef struct dwc_ep {
+	uint8_t	 num;					// EP number used for register address lookup
+	unsigned is_in : 1;				// EP direction 0 = OUT
+	unsigned active : 1;			// EP active
+	/** Periodic Tx FIFO # for IN EPs For INTR EP set to 0 to use non-periodic Tx FIFO
+		If dedicated Tx FIFOs are enabled for all IN Eps - Tx FIFO # FOR IN EPs*/
+	unsigned tx_fifo_num : 4;		
+#define DWC_OTG_EP_TYPE_CONTROL	   0
+#define DWC_OTG_EP_TYPE_ISOC	   1
+#define DWC_OTG_EP_TYPE_BULK	   2
+#define DWC_OTG_EP_TYPE_INTR	   3
+	unsigned type : DWC_OTG_EP_TYPE_BULK; // EP type: 0 - Control, 1 - ISOC,	 2 - BULK,	3 - INTR
+	unsigned data_pid_start : 1;	// DATA start PID for INTR and BULK EP
+	unsigned even_odd_frame : 1;	// Frame (even/odd) for ISOC EP
+	unsigned maxpacket : 11;		// Max Packet bytes
+	uint32_t dma_addr;				// Pointer to the beginning of the transfer buffer -- do not modify during transfer
+	uint8_t *start_xfer_buff;
+	uint8_t *xfer_buff;				// pointer to the transfer buffer
+	unsigned xfer_len : 19;			// Number of bytes to transfer
+	unsigned xfer_count : 19;		// Number of bytes transferred
+	unsigned sent_zlp : 1;			// Sent ZLP 
+	unsigned total_len : 19;		// Total len for control transfer
+	unsigned stall_clear_flag : 1;	// stall clear flag
+
+#ifdef CONFIG_405EZ
+	/* Since the 405EZ (Ultra) only support 2047 bytes as max transfer size, we have to split up bigger transfers
+	 * into multiple transfers of 1024 bytes sized messages. It happens often that transfers of 4096 bytes are
+	 * required (zero-gadget, file_storage-gadget). "bytes_pending" will hold the amount of bytes that are
+	 * still pending to be send in further messages to complete the bigger transfer. */
+	u32 bytes_pending;
+#endif
+} dwc_ep_t;
+
+/* Reasons for halting a host channel. */
+typedef enum dwc_otg_halt_status {
+	DWC_OTG_HC_XFER_NO_HALT_STATUS,
+	DWC_OTG_HC_XFER_COMPLETE,
+	DWC_OTG_HC_XFER_URB_COMPLETE,
+	DWC_OTG_HC_XFER_ACK,
+	DWC_OTG_HC_XFER_NAK,
+	DWC_OTG_HC_XFER_NYET,
+	DWC_OTG_HC_XFER_STALL,
+	DWC_OTG_HC_XFER_XACT_ERR,
+	DWC_OTG_HC_XFER_FRAME_OVERRUN,
+	DWC_OTG_HC_XFER_BABBLE_ERR,
+	DWC_OTG_HC_XFER_DATA_TOGGLE_ERR,
+	DWC_OTG_HC_XFER_AHB_ERR,
+	DWC_OTG_HC_XFER_PERIODIC_INCOMPLETE,
+	DWC_OTG_HC_XFER_URB_DEQUEUE
+} dwc_otg_halt_status_e;
+
+/* Host channel descriptor. This structure represents the state of a single host channel when acting
+ * in host mode. It contains the data items needed to transfer packets to an endpoint via a host channel. */
+typedef struct dwc_hc {
+	uint8_t	 hc_num;				// Host channel number used for register address lookup
+	unsigned dev_addr : 7;			// Device to access
+	unsigned ep_num : 4;			// EP to access
+	unsigned ep_is_in : 1;			// EP direction. 0: OUT, 1: IN
+#define DWC_OTG_EP_SPEED_LOW	0
+#define DWC_OTG_EP_SPEED_FULL	1
+#define DWC_OTG_EP_SPEED_HIGH	2
+	unsigned speed : DWC_OTG_EP_SPEED_HIGH;	// EP speed
+	unsigned ep_type : DWC_OTG_EP_TYPE_BULK;	// Endpoint type
+	unsigned max_packet : 11;		// Max packet size in bytes
+#define DWC_OTG_HC_PID_DATA0 0		// Data0
+#define DWC_OTG_HC_PID_DATA2 1		// Data2
+#define DWC_OTG_HC_PID_DATA1 2		// Data1
+#define DWC_OTG_HC_PID_MDATA 3		// (non-Control EP)
+#define DWC_OTG_HC_PID_SETUP 3		// SETUP (Control EP)
+	unsigned data_pid_start : 2;	// PID for initial transaction
+	unsigned multi_count: 2;		// Number of periodic transactions per (micro)frame
+	uint8_t *xfer_buff;				// pointer to the transfer buffer
+	uint32_t xfer_len;				// Number of bytes to transfer
+	uint32_t xfer_count : 19;		// Number of bytes transferred
+	uint16_t start_pkt_count;		// Packet count at start of transfe 
+	uint8_t xfer_started;			// Transfer started flag: started=1, not started=0
+	uint8_t do_ping;				// Issue PING request: yes=1, no=0 
+	uint8_t error_state;			// Error count: error=1, no error=0
+	uint8_t halt_on_queue;			// Halt channel at next queued request. This is necessary in
+		// slave mode if no request queue space is available when an attempt is made to halt the channel.
+	uint8_t halt_pending;			// 1=host channel halted, but the core is not finished flushing queued requests
+	dwc_otg_halt_status_e	halt_status;	// Reason for halting the host channel
+	uint8_t do_split;		   		// Enable split for the host channel
+	uint8_t complete_split;	   		// Enable complete split
+	uint8_t hub_addr;		   		// Address of high speed hub
+	uint8_t port_addr;		   		// Port of the low/full speed device
+	/** Split transaction position, one of the following values:
+	 *	  - DWC_HCSPLIT_XACTPOS_MID
+	 *	  - DWC_HCSPLIT_XACTPOS_BEGIN
+	 *	  - DWC_HCSPLIT_XACTPOS_END
+	 *	  - DWC_HCSPLIT_XACTPOS_ALL */
+	uint8_t xact_pos;
+	uint8_t short_read;				// Set when the host channel does a short read
+	uint8_t requests;				// # requests issued for this channel since it was assigned to the current transfer (not counting PINGs)
+	struct dwc_otg_qh *qh;			// Queue Head for the transfer being processed by this channel
+	struct list_head hc_list_entry;	// Entry in list of host channels. */
+} dwc_hc_t;
+
+/* The following parameters may be specified when starting the module. These parameters define how the DWC_otg
+ * controller should be configured. Parameter values are passed to the CIL initialization function dwc_otg_cil_init. */
+typedef struct dwc_otg_core_params {
+	int32_t opt;
+#define dwc_param_opt_default 1
+	/**
+	 * Specifies the OTG capabilities. The driver will automatically
+	 * detect the value for this parameter if none is specified.
+	 * 0 - HNP and SRP capable (default)
+	 * 1 - SRP Only capable
+	 * 2 - No HNP/SRP capable
+	 */
+	int32_t otg_cap;
+#define DWC_OTG_CAP_PARAM_HNP_SRP_CAPABLE 0
+#define DWC_OTG_CAP_PARAM_SRP_ONLY_CAPABLE 1
+#define DWC_OTG_CAP_PARAM_NO_HNP_SRP_CAPABLE 2
+#define dwc_param_otg_cap_default DWC_OTG_CAP_PARAM_HNP_SRP_CAPABLE
+
+	/**
+	 * Specifies whether to use slave or DMA mode for accessing the data
+	 * FIFOs. The driver will automatically detect the value for this
+	 * parameter if none is specified.
+	 * 0 - Slave
+	 * 1 - DMA (default, if available)
+	 */
+	int32_t dma_enable;
+#define dwc_param_dma_enable_default 1
+
+	/** The DMA Burst size (applicable only for External DMA
+	 * Mode). 1, 4, 8 16, 32, 64, 128, 256 (default 32)
+	 */
+	int32_t dma_burst_size;	 /* Translate this to GAHBCFG values */
+#define dwc_param_dma_burst_size_default 32
+
+	/**
+	 * Specifies the maximum speed of operation in host and device mode.
+	 * The actual speed depends on the speed of the attached device and
+	 * the value of phy_type. The actual speed depends on the speed of the
+	 * attached device.
+	 * 0 - High Speed (default)
+	 * 1 - Full Speed
+	 */
+	int32_t speed;
+#define dwc_param_speed_default 0
+#define DWC_SPEED_PARAM_HIGH 0
+#define DWC_SPEED_PARAM_FULL 1
+
+	/** Specifies whether low power mode is supported when attached
+	 *	to a Full Speed or Low Speed device in host mode.
+	 * 0 - Don't support low power mode (default)
+	 * 1 - Support low power mode
+	 */
+	int32_t host_support_fs_ls_low_power;
+#define dwc_param_host_support_fs_ls_low_power_default 0
+
+	/** Specifies the PHY clock rate in low power mode when connected to a
+	 * Low Speed device in host mode. This parameter is applicable only if
+	 * HOST_SUPPORT_FS_LS_LOW_POWER is enabled.	 If PHY_TYPE is set to FS
+	 * then defaults to 6 MHZ otherwise 48 MHZ.
+	 *
+	 * 0 - 48 MHz
+	 * 1 - 6 MHz
+	 */
+	int32_t host_ls_low_power_phy_clk;
+#define dwc_param_host_ls_low_power_phy_clk_default 0
+#define DWC_HOST_LS_LOW_POWER_PHY_CLK_PARAM_48MHZ 0
+#define DWC_HOST_LS_LOW_POWER_PHY_CLK_PARAM_6MHZ 1
+
+	/**
+	 * 0 - Use cC FIFO size parameters
+	 * 1 - Allow dynamic FIFO sizing (default)
+	 */
+	int32_t enable_dynamic_fifo;
+#define dwc_param_enable_dynamic_fifo_default 1
+
+	/** Total number of 4-byte words in the data FIFO memory. This
+	 * memory includes the Rx FIFO, non-periodic Tx FIFO, and periodic Tx FIFOs.
+	 * 32 to 32768 (default 8192) Note: The total FIFO memory depth in the FPGA configuration is 8192. */
+	int32_t data_fifo_size;
+#define dwc_param_data_fifo_size_default 8192
+
+	/** Number of 4-byte words in the Rx FIFO in device mode when dynamic
+	 * FIFO sizing is enabled.
+	 * 16 to 32768 (default 1064)
+	 */
+	int32_t dev_rx_fifo_size;
+#define dwc_param_dev_rx_fifo_size_default 1064
+
+	/** Number of 4-byte words in the non-periodic Tx FIFO in device mode
+	 * when dynamic FIFO sizing is enabled. 16 to 32768 (default 1024) */
+	int32_t dev_nperio_tx_fifo_size;
+#define dwc_param_dev_nperio_tx_fifo_size_default 1024
+
+	/** Number of 4-byte words in each of the periodic Tx FIFOs in device
+	 * mode when dynamic FIFO sizing is enabled.
+	 * 4 to 768 (default 256)
+	 */
+	uint32_t dev_perio_tx_fifo_size[MAX_PERIO_FIFOS];
+#define dwc_param_dev_perio_tx_fifo_size_default 256
+
+	/** Number of 4-byte words in the Rx FIFO in host mode when dynamic
+	 * FIFO sizing is enabled.
+	 * 16 to 32768 (default 1024)
+	 */
+	int32_t host_rx_fifo_size;
+#define dwc_param_host_rx_fifo_size_default 1024
+
+		/** Number of 4-byte words in the non-periodic Tx FIFO in host mode
+	 * when Dynamic FIFO sizing is enabled in the core.
+	 * 16 to 32768 (default 1024)
+	 */
+	int32_t host_nperio_tx_fifo_size;
+#define dwc_param_host_nperio_tx_fifo_size_default 1024
+
+	/** Number of 4-byte words in the host periodic Tx FIFO when dynamic
+	 * FIFO sizing is enabled.
+	 * 16 to 32768 (default 1024)
+	 */
+	int32_t host_perio_tx_fifo_size;
+#define dwc_param_host_perio_tx_fifo_size_default 1024
+
+	/** The maximum transfer size supported in bytes.
+	 * 2047 to 65,535  (default 65,535)
+	 */
+	int32_t max_transfer_size;
+#define dwc_param_max_transfer_size_default 65535
+
+	/** The maximum number of packets in a transfer.
+	 * 15 to 511  (default 511)
+	 */
+	int32_t max_packet_count;
+#define dwc_param_max_packet_count_default 511
+
+	/** The number of host channel registers to use.
+	 * 1 to 16 (default 12)
+	 * Note: The FPGA configuration supports a maximum of 12 host channels.
+	 */
+	int32_t host_channels;
+#define dwc_param_host_channels_default 12
+
+	/** The number of endpoints in addition to EP0 available for device
+	 * mode operations.
+	 * 1 to 15 (default 6 IN and OUT)
+	 * Note: The FPGA configuration supports a maximum of 6 IN and OUT
+	 * endpoints in addition to EP0.
+	 */
+	int32_t dev_endpoints;
+#define dwc_param_dev_endpoints_default 6
+
+		/**
+		 * Specifies the type of PHY interface to use. By default, the driver
+		 * will automatically detect the phy_type.
+		 *
+		 * 0 - Full Speed PHY
+		 * 1 - UTMI+ (default)
+		 * 2 - ULPI
+		 */
+	int32_t phy_type;
+#define DWC_PHY_TYPE_PARAM_FS 0
+#define DWC_PHY_TYPE_PARAM_UTMI 1
+#define DWC_PHY_TYPE_PARAM_ULPI 2
+#define dwc_param_phy_type_default DWC_PHY_TYPE_PARAM_UTMI
+
+	/**
+	 * Specifies the UTMI+ Data Width.	This parameter is
+	 * applicable for a PHY_TYPE of UTMI+ or ULPI. (For a ULPI
+	 * PHY_TYPE, this parameter indicates the data width between
+	 * the MAC and the ULPI Wrapper.) Also, this parameter is
+	 * applicable only if the OTG_HSPHY_WIDTH cC parameter was set
+	 * to "8 and 16 bits", meaning that the core has been
+	 * configured to work at either data path width.
+	 *
+	 * 8 or 16 bits (default 16)
+	 */
+	int32_t phy_utmi_width;
+#define dwc_param_phy_utmi_width_default 16
+
+	/**
+	 * Specifies whether the ULPI operates at double or single
+	 * data rate. This parameter is only applicable if PHY_TYPE is
+	 * ULPI.
+	 *
+	 * 0 - single data rate ULPI interface with 8 bit wide data
+	 * bus (default)
+	 * 1 - double data rate ULPI interface with 4 bit wide data
+	 * bus
+	 */
+	int32_t phy_ulpi_ddr;
+#define dwc_param_phy_ulpi_ddr_default 0
+
+	/**
+	 * Specifies whether to use the internal or external supply to
+	 * drive the vbus with a ULPI phy.
+	 */
+	int32_t phy_ulpi_ext_vbus;
+#define DWC_PHY_ULPI_INTERNAL_VBUS 0
+#define DWC_PHY_ULPI_EXTERNAL_VBUS 1
+#define dwc_param_phy_ulpi_ext_vbus_default DWC_PHY_ULPI_INTERNAL_VBUS
+
+	/**
+	 * Specifies whether to use the I2Cinterface for full speed PHY. This
+	 * parameter is only applicable if PHY_TYPE is FS.
+	 * 0 - No (default)
+	 * 1 - Yes
+	 */
+	int32_t i2c_enable;
+#define dwc_param_i2c_enable_default 0
+
+	int32_t ulpi_fs_ls;
+#define dwc_param_ulpi_fs_ls_default 0
+
+	int32_t ts_dline;
+#define dwc_param_ts_dline_default 0
+
+	/**
+	 * Specifies whether dedicated transmit FIFOs are
+	 * enabled for non periodic IN endpoints in device mode
+	 * 0 - No
+	 * 1 - Yes
+	 */
+	 int32_t en_multiple_tx_fifo;
+#define dwc_param_en_multiple_tx_fifo_default 1
+
+	/** Number of 4-byte words in each of the Tx FIFOs in device
+	 * mode when dynamic FIFO sizing is enabled.
+	 * 4 to 768 (default 256)
+	 */
+	uint32_t dev_tx_fifo_size[MAX_TX_FIFOS];
+#define dwc_param_dev_tx_fifo_size_default 256
+
+	/** Thresholding enable flag-
+	 * bit 0 - enable non-ISO Tx thresholding
+	 * bit 1 - enable ISO Tx thresholding
+	 * bit 2 - enable Rx thresholding
+	 */
+	uint32_t thr_ctl;
+#define dwc_param_thr_ctl_default 0
+
+	/** Thresholding length for Tx
+	 *	FIFOs in 32 bit DWORDs
+	 */
+	uint32_t tx_thr_length;
+#define dwc_param_tx_thr_length_default 64
+
+	/** Thresholding length for Rx
+	 *	FIFOs in 32 bit DWORDs
+	 */
+	uint32_t rx_thr_length;
+#define dwc_param_rx_thr_length_default 64
+
+} dwc_otg_core_params_t;
+
+#ifdef CONFIG_DWC_DEBUG
+struct dwc_otg_core_if;
+typedef struct hc_xfer_info
+{
+	struct dwc_otg_core_if	*core_if;
+	dwc_hc_t		*hc;
+} hc_xfer_info_t;
+#endif
+
+#ifdef CONFIG_OTG_PLB_DMA_TASKLET
+typedef struct dma_xfer_s {
+    uint32_t *dma_data_buff;
+    void 	*dma_data_fifo;
+    uint32_t dma_count;
+	uint32_t dma_dir;
+} dma_xfer_t;
+#endif
+
+/**
+ * The <code>dwc_otg_core_if</code> structure contains information needed to manage
+ * the DWC_otg controller acting in either host or device mode. It
+ * represents the programming view of the controller as a whole.
+ */
+typedef struct dwc_otg_core_if {
+	/** Parameters that define how the core should be configured.*/
+	dwc_otg_core_params_t	   *core_params;
+
+	/** Core Global registers starting at offset 000h. */
+	dwc_otg_core_global_regs_t *core_global_regs;
+
+	/** Device-specific information */
+	dwc_otg_dev_if_t		   *dev_if;
+	/** Host-specific information */
+	dwc_otg_host_if_t		   *host_if;
+
+	/* Set to 1 if the core PHY interface bits in USBCFG have been initialized */
+	uint8_t phy_init_done;
+
+	/*
+	 * SRP Success flag, set by srp success interrupt in FS I2C mode
+	 */
+	uint8_t srp_success;
+	uint8_t srp_timer_started;
+
+	/* Common configuration information */
+	/** Power and Clock Gating Control Register */
+	volatile uint32_t *pcgcctl;
+#define DWC_OTG_PCGCCTL_OFFSET 0xE00
+
+	/** Push/pop addresses for endpoints or host channels.*/
+	uint32_t *data_fifo[MAX_EPS_CHANNELS];
+#define DWC_OTG_DATA_FIFO_OFFSET 0x1000
+#define DWC_OTG_DATA_FIFO_SIZE 0x1000
+
+	/** Total RAM for FIFOs (Bytes) */
+	uint16_t total_fifo_size;
+	/** Size of Rx FIFO (Bytes) */
+	uint16_t rx_fifo_size;
+	/** Size of Non-periodic Tx FIFO (Bytes) */
+	uint16_t nperio_tx_fifo_size;
+	/** 1 if DMA is enabled, 0 otherwise. */
+	uint8_t dma_enable;
+	/** 1 if dedicated Tx FIFOs are enabled, 0 otherwise. */
+	uint8_t en_multiple_tx_fifo;
+	/* Set to 1 if multiple packets of a high-bandwidth transfer is in process of being queued */
+	uint8_t queuing_high_bandwidth;
+	/** Hardware Configuration -- stored here for convenience.*/
+	hwcfg1_data_t hwcfg1;
+	hwcfg2_data_t hwcfg2;
+	hwcfg3_data_t hwcfg3;
+	hwcfg4_data_t hwcfg4;
+
+	/* The operational State, during transations (a_host>>a_peripherial and b_device=>b_host) this may not
+	 * match the core but allows the software to determine transitions. */
+	uint8_t op_state;
+
+	/* Set to 1 if the HCD needs to be restarted on a session request interrupt. This is required if no connector 
+	 * ID status change has occurred since the HCD was last disconnected. */
+	uint8_t restart_hcd_on_session_req;
+
+	/** HCD callbacks */
+	/** A-Device is a_host */
+#define A_HOST		(1)
+	/** A-Device is a_suspend */
+#define A_SUSPEND	(2)
+	/** A-Device is a_peripherial */
+#define A_PERIPHERAL	(3)
+	/** B-Device is operating as a Peripheral. */
+#define B_PERIPHERAL	(4)
+	/** B-Device is operating as a Host. */
+#define B_HOST		(5)
+
+	/** HCD callbacks */
+	struct dwc_otg_cil_callbacks *hcd_cb;
+	/** PCD callbacks */
+	struct dwc_otg_cil_callbacks *pcd_cb;
+
+	/** Device mode Periodic Tx FIFO Mask */
+	uint32_t p_tx_msk;
+	/** Device mode Periodic Tx FIFO Mask */
+	uint32_t tx_msk;
+
+#ifdef CONFIG_DWC_DEBUG
+	uint32_t		start_hcchar_val[MAX_EPS_CHANNELS];
+
+	hc_xfer_info_t		hc_xfer_info[MAX_EPS_CHANNELS];
+	struct timer_list	hc_xfer_timer[MAX_EPS_CHANNELS];
+
+	uint32_t		hfnum_7_samples;
+	uint64_t		hfnum_7_frrem_accum;
+	uint32_t		hfnum_0_samples;
+	uint64_t		hfnum_0_frrem_accum;
+	uint32_t		hfnum_other_samples;
+	uint64_t		hfnum_other_frrem_accum;
+#endif
+	resource_size_t phys_addr;		/* Added to support PLB DMA : phys-virt mapping */
+#ifdef CONFIG_OTG_PLB_DMA_TASKLET
+    /* Tasket to do plbdma */
+    struct tasklet_struct   *plbdma_tasklet;
+#if 1
+	dma_xfer_t		dma_xfer;
+#else
+    uint32_t *dma_data_buff;
+    void 	*dma_data_fifo;
+    uint32_t dma_count;
+	uint32_t dma_dir;
+#endif
+#endif
+} dwc_otg_core_if_t;
+
+/* The following functions support initialization of the CIL driver component and the DWC_otg controller. */
+extern dwc_otg_core_if_t *dwc_otg_cil_init(const uint32_t *_reg_base_addr, dwc_otg_core_params_t *_core_params);
+extern void dwc_otg_cil_remove(dwc_otg_core_if_t *_core_if);
+extern void dwc_otg_core_init(dwc_otg_core_if_t *_core_if);
+extern void dwc_otg_core_host_init(dwc_otg_core_if_t *_core_if);
+extern void dwc_otg_core_dev_init(dwc_otg_core_if_t *_core_if);
+extern void dwc_otg_enable_global_interrupts( dwc_otg_core_if_t *_core_if );
+extern void dwc_otg_disable_global_interrupts( dwc_otg_core_if_t *_core_if );
+
+/* The following functions support managing the DWC_otg controller in device mode. */
+extern void dwc_otg_wakeup(dwc_otg_core_if_t *_core_if);
+extern void dwc_otg_read_setup_packet (dwc_otg_core_if_t *_core_if, uint32_t *_dest);
+extern uint32_t dwc_otg_get_frame_number(dwc_otg_core_if_t *_core_if);
+extern void dwc_otg_ep0_activate(dwc_otg_core_if_t *_core_if, dwc_ep_t *_ep);
+extern void dwc_otg_ep_activate(dwc_otg_core_if_t *_core_if, dwc_ep_t *_ep);
+extern void dwc_otg_ep_deactivate(dwc_otg_core_if_t *_core_if, dwc_ep_t *_ep);
+extern void dwc_otg_ep_start_transfer(dwc_otg_core_if_t *_core_if, dwc_ep_t *_ep);
+extern void dwc_otg_ep0_start_transfer(dwc_otg_core_if_t *_core_if, dwc_ep_t *_ep);
+extern void dwc_otg_ep0_continue_transfer(dwc_otg_core_if_t *_core_if, dwc_ep_t *_ep);
+extern void dwc_otg_ep_write_packet(dwc_otg_core_if_t *_core_if, dwc_ep_t *_ep, int _dma);
+extern void dwc_otg_ep_set_stall(dwc_otg_core_if_t *_core_if, dwc_ep_t *_ep);
+extern void dwc_otg_ep_clear_stall(dwc_otg_core_if_t *_core_if, dwc_ep_t *_ep);
+extern void dwc_otg_enable_device_interrupts(dwc_otg_core_if_t *_core_if);
+extern void dwc_otg_dump_dev_registers(dwc_otg_core_if_t *_core_if);
+
+/*The following functions support managing the DWC_otg controller in host mode.*/
+extern void dwc_otg_hc_init(dwc_otg_core_if_t *_core_if, dwc_hc_t *_hc);
+extern void dwc_otg_hc_halt(dwc_otg_core_if_t *_core_if, dwc_hc_t *_hc, dwc_otg_halt_status_e _halt_status);
+extern void dwc_otg_hc_cleanup(dwc_otg_core_if_t *_core_if, dwc_hc_t *_hc);
+extern void dwc_otg_hc_start_transfer(dwc_otg_core_if_t *_core_if, dwc_hc_t *_hc);
+extern int dwc_otg_hc_continue_transfer(dwc_otg_core_if_t *_core_if, dwc_hc_t *_hc);
+extern void dwc_otg_hc_do_ping(dwc_otg_core_if_t *_core_if, dwc_hc_t *_hc);
+extern void dwc_otg_hc_write_packet(dwc_otg_core_if_t *_core_if, dwc_hc_t *_hc);
+extern void dwc_otg_enable_host_interrupts(dwc_otg_core_if_t *_core_if);
+extern void dwc_otg_disable_host_interrupts(dwc_otg_core_if_t *_core_if);
+
+/* This function Reads HPRT0 in preparation to modify.	It keeps the WC bits 0 so that if they are 
+ * read as 1, they won't clear when you write it back */
+static inline uint32_t dwc_otg_read_hprt0(dwc_otg_core_if_t *_core_if) {
+	hprt0_data_t hprt0;
+	hprt0.d32 = dwc_read_reg32(_core_if->host_if->hprt0);
+	hprt0.b.prtena = 0;
+	hprt0.b.prtconndet = 0;
+	hprt0.b.prtenchng = 0;
+	hprt0.b.prtovrcurrchng = 0;
+	return hprt0.d32;
+}
+extern void dwc_otg_dump_host_registers(dwc_otg_core_if_t *_core_if);
+
+/* The following functions support managing the DWC_otg controller in either device or host mode.*/
+extern void dwc_otg_read_packet(dwc_otg_core_if_t *core_if, uint8_t *dest,	uint16_t bytes);
+extern void dwc_otg_dump_global_registers(dwc_otg_core_if_t *_core_if);
+extern void dwc_otg_flush_tx_fifo(dwc_otg_core_if_t *_core_if, const int _num);
+extern void dwc_otg_flush_rx_fifo(dwc_otg_core_if_t *_core_if);
+extern void dwc_otg_core_reset(dwc_otg_core_if_t *_core_if);
+
+#ifdef CONFIG_OTG_PLB_DMA
+extern void ppc4xx_start_plb_dma(dwc_otg_core_if_t *_core_if, void *src, void *dst,
+	unsigned int length, unsigned int use_interrupt, unsigned int dma_ch, unsigned int dma_dir);
+#endif
+
+#define NP_TXFIFO_EMPTY -1
+#define MAX_NP_TXREQUEST_Q_SLOTS 8
+/* Returns the endpoint number of the request at the top of non-periodic TX FIFO or -1 if the request FIFO is empty. */
+static inline int dwc_otg_top_nptxfifo_epnum(dwc_otg_core_if_t *cif) {
+	gnptxsts_data_t txstatus = {.d32 = 0};
+	txstatus.d32 = dwc_read_reg32(&cif->core_global_regs->gnptxsts);
+	return (txstatus.b.nptxqspcavail == MAX_NP_TXREQUEST_Q_SLOTS ? -1 : txstatus.b.nptxqtop_chnep);
+}
+
+/* This function returns the Core Interrupt register */
+static inline uint32_t dwc_otg_read_core_intr(dwc_otg_core_if_t *cif) {
+	return (dwc_read_reg32(&cif->core_global_regs->gintsts) & dwc_read_reg32(&cif->core_global_regs->gintmsk));
+}
+
+/* This function returns the OTG Interrupt register */
+static inline uint32_t dwc_otg_read_otg_intr (dwc_otg_core_if_t *cif) {
+	return (dwc_read_reg32(&cif->core_global_regs->gotgint));
+}
+
+/* This function reads the Device All Endpoints Interrupt register and returns the IN endpoint interrupt bits */
+static inline uint32_t dwc_otg_read_dev_all_in_ep_intr(dwc_otg_core_if_t *cif) {
+	return (dwc_read_reg32(&cif->dev_if->dev_global_regs->daint) &
+			dwc_read_reg32(&cif->dev_if->dev_global_regs->daintmsk)) & 0xffff;
+
+}
+
+/* This function reads the Device All Endpoints Interrupt register and returns the OUT endpoint interrupt bits */
+static inline uint32_t dwc_otg_read_dev_all_out_ep_intr(dwc_otg_core_if_t *cif) {
+	return ((dwc_read_reg32(&cif->dev_if->dev_global_regs->daint) &
+			dwc_read_reg32(&cif->dev_if->dev_global_regs->daintmsk)) & 0xffff0000) >> 16;
+}
+
+/* This function returns the Device IN EP Interrupt register */
+static inline uint32_t dwc_otg_read_dev_in_ep_intr(dwc_otg_core_if_t *cif, dwc_ep_t *_ep) {
+	dwc_otg_dev_if_t *dev_if = cif->dev_if;
+	uint32_t emp = dwc_read_reg32(&dev_if->dev_global_regs->dtknqr4_fifoemptymsk);
+	uint32_t msk = dwc_read_reg32(&dev_if->dev_global_regs->diepmsk) | ((emp >> _ep->num) & 0x1) << 7;
+	return dwc_read_reg32(&dev_if->in_ep_regs[_ep->num]->diepint) & msk;
+//	return dwc_read_reg32(&dev_if->in_ep_regs[_ep->num]->diepint) & dwc_read_reg32(&dev_if->dev_global_regs->diepmsk);
+}
+/* This function returns the Device OUT EP Interrupt register */
+static inline uint32_t dwc_otg_read_dev_out_ep_intr(dwc_otg_core_if_t *cif, dwc_ep_t *_ep) {
+	dwc_otg_dev_if_t *dev_if = cif->dev_if;
+	return dwc_read_reg32(&dev_if->out_ep_regs[_ep->num]->doepint) & dwc_read_reg32(&dev_if->dev_global_regs->doepmsk);
+}
+
+/* This function returns the Host All Channel Interrupt register */
+static inline uint32_t dwc_otg_read_host_all_channels_intr (dwc_otg_core_if_t *cif) {
+	return (dwc_read_reg32(&cif->host_if->host_global_regs->haint));
+}
+
+static inline uint32_t dwc_otg_read_host_channel_intr (dwc_otg_core_if_t *cif, dwc_hc_t *_hc) {
+	return (dwc_read_reg32(&cif->host_if->hc_regs[_hc->hc_num]->hcint));
+}
+
+/* This function returns the mode of the operation, host or device. @return 0 - Device Mode, 1 - Host Mode */
+static inline uint32_t dwc_otg_mode(dwc_otg_core_if_t *if) {
+	return (dwc_read_reg32(&if->core_global_regs->gintsts) & 0x1);
+}
+
+static inline uint8_t dwc_otg_is_device_mode(dwc_otg_core_if_t *if) {
+	return (dwc_otg_mode(if) != DWC_HOST_MODE);
+}
+static inline uint8_t dwc_otg_is_host_mode(dwc_otg_core_if_t *if) {
+	return (dwc_otg_mode(if) == DWC_HOST_MODE);
+}
+
+/* DWC_otg CIL callback structure.	This structure allows the HCD and PCD to register functions used for
+ * starting and stopping the PCD and HCD for role change on for a DRD. */
+typedef struct dwc_otg_cil_callbacks {
+	int (*start) (void *_p);			// Start function for role change
+	int (*stop) (void *_p);			// Stop Function for role change
+	int (*disconnect) (void *_p);		// Disconnect Function for role change
+	int (*resume_wakeup) (void *_p); 	// Resume/Remote wakeup Function
+	int (*suspend) (void *_p);			// Suspend function
+	int (*session_start) (void *_p);	// Session Start (SRP)
+	void *p;							// Pointer passed to start() and stop()
+} dwc_otg_cil_callbacks_t;
+
+extern int32_t dwc_otg_handle_common_intr(dwc_otg_core_if_t *_core_if);
+extern void dwc_otg_cil_register_pcd_callbacks(dwc_otg_core_if_t *_core_if, dwc_otg_cil_callbacks_t *_cb, void *_p);
+extern void dwc_otg_cil_register_hcd_callbacks(dwc_otg_core_if_t *_core_if, dwc_otg_cil_callbacks_t *_cb, void *_p);
+
+#endif
diff -Naur a/drivers/usb/dwc_otg/dwc_otg_cil_intr.c b/drivers/usb/dwc_otg/dwc_otg_cil_intr.c
--- a/drivers/usb/dwc_otg/dwc_otg_cil_intr.c	1970-01-01 00:00:00.000000000 +0000
+++ b/drivers/usb/dwc_otg/dwc_otg_cil_intr.c	2017-06-22 08:13:22.760754956 +0000
@@ -0,0 +1,701 @@
+/* ==========================================================================
+ * $File: //dwh/usb_iip/dev/software/otg_ipmate/linux/drivers/dwc_otg_cil_intr.c $
+ * $Revision: #7 $
+ * $Date: 2005/11/02 $
+ * $Change: 553126 $
+ *
+ * Synopsys HS OTG Linux Software Driver and documentation (hereinafter,
+ * "Software") is an Unsupported proprietary work of Synopsys, Inc. unless
+ * otherwise expressly agreed to in writing between Synopsys and you.
+ * 
+ * The Software IS NOT an item of Licensed Software or Licensed Product under
+ * any End User Software License Agreement or Agreement for Licensed Product
+ * with Synopsys or any supplement thereto. You are permitted to use and
+ * redistribute this Software in source and binary forms, with or without
+ * modification, provided that redistributions of source code must retain this
+ * notice. You may not view, use, disclose, copy or distribute this file or
+ * any information contained herein except pursuant to this license grant from
+ * Synopsys. If you do not agree with this notice, including the disclaimer
+ * below, then you are not authorized to use the Software.
+ * 
+ * THIS SOFTWARE IS BEING DISTRIBUTED BY SYNOPSYS SOLELY ON AN "AS IS" BASIS
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE HEREBY DISCLAIMED. IN NO EVENT SHALL SYNOPSYS BE LIABLE FOR ANY DIRECT,
+ * INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+ * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+ * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+ * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
+ * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
+ * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH
+ * DAMAGE.
+ * ========================================================================== */
+     
+    
+/** @file 
+ *
+ * The Core Interface Layer provides basic services for accessing and
+ * managing the DWC_otg hardware. These services are used by both the
+ * Host Controller Driver and the Peripheral Controller Driver.
+ *
+ * This file contains the Common Interrupt handlers.
+ */ 
+#include "dwc_otg_plat.h"
+#include "dwc_otg_regs.h"
+#include "dwc_otg_cil.h"
+    
+inline const char *op_state_str(dwc_otg_core_if_t * _core_if) 
+{
+	return (_core_if->op_state == A_HOST ? "a_host" : 
+		(_core_if->op_state == A_SUSPEND ? "a_suspend" : 
+		(_core_if->op_state == A_PERIPHERAL ? "a_peripheral" : 
+		(_core_if->op_state == B_PERIPHERAL ? "b_peripheral" : 
+		(_core_if->op_state == B_HOST ? "b_host" : "unknown")))));
+}
+    
+/** This function will log a debug message 
+ *
+ * @param _core_if Programming view of DWC_otg controller.
+ */ 
+int32_t dwc_otg_handle_mode_mismatch_intr(dwc_otg_core_if_t * _core_if) 
+{
+	gintsts_data_t gintsts;
+	DWC_WARN("Mode Mismatch Interrupt: currently in %s mode\n",
+		  dwc_otg_mode(_core_if) ? "Host" : "Device");
+	
+	/* Clear interrupt */ 
+	gintsts.d32 = 0;
+	gintsts.b.modemismatch = 1;
+	dwc_write_reg32(&_core_if->core_global_regs->gintsts, gintsts.d32);
+	return 1;
+}
+
+/** Start the HCD.  Helper function for using the HCD callbacks.
+ *
+ * @param _core_if Programming view of DWC_otg controller.
+ */ 
+static inline void hcd_start(dwc_otg_core_if_t * _core_if) 
+{
+	if (_core_if->hcd_cb && _core_if->hcd_cb->start) {
+		_core_if->hcd_cb->start(_core_if->hcd_cb->p);
+	}
+}
+
+/** Stop the HCD.  Helper function for using the HCD callbacks. 
+ *
+ * @param _core_if Programming view of DWC_otg controller.
+ */ 
+static inline void hcd_stop(dwc_otg_core_if_t * _core_if) 
+{
+	if (_core_if->hcd_cb && _core_if->hcd_cb->stop) {
+		_core_if->hcd_cb->stop(_core_if->hcd_cb->p);
+	}
+}
+
+/** Disconnect the HCD.  Helper function for using the HCD callbacks.
+ *
+ * @param _core_if Programming view of DWC_otg controller.
+ */ 
+static inline void hcd_disconnect(dwc_otg_core_if_t * _core_if) 
+{
+	if (_core_if->hcd_cb && _core_if->hcd_cb->disconnect) {
+		_core_if->hcd_cb->disconnect(_core_if->hcd_cb->p);
+	}
+}
+
+/** Inform the HCD the a New Session has begun.  Helper function for
+ * using the HCD callbacks.
+ *
+ * @param _core_if Programming view of DWC_otg controller.
+ */ 
+static inline void hcd_session_start(dwc_otg_core_if_t * _core_if) 
+{
+	if (_core_if->hcd_cb && _core_if->hcd_cb->session_start) {
+		_core_if->hcd_cb->session_start(_core_if->hcd_cb->p);
+	}
+}
+
+/** Start the PCD.  Helper function for using the PCD callbacks.
+ *
+ * @param _core_if Programming view of DWC_otg controller.
+ */ 
+static inline void pcd_start(dwc_otg_core_if_t * _core_if) 
+{
+	if (_core_if->pcd_cb && _core_if->pcd_cb->start) {
+		_core_if->pcd_cb->start(_core_if->pcd_cb->p);
+	}
+}
+
+/** Stop the PCD.  Helper function for using the PCD callbacks. 
+ *
+ * @param _core_if Programming view of DWC_otg controller.
+ */ 
+static inline void pcd_stop(dwc_otg_core_if_t * _core_if) 
+{
+	if (_core_if->pcd_cb && _core_if->pcd_cb->stop) {
+		_core_if->pcd_cb->stop(_core_if->pcd_cb->p);
+	}
+}
+
+/** Suspend the PCD.  Helper function for using the PCD callbacks. 
+ *
+ * @param _core_if Programming view of DWC_otg controller.
+ */ 
+static inline void pcd_suspend(dwc_otg_core_if_t * _core_if) 
+{
+	if (_core_if->pcd_cb && _core_if->pcd_cb->suspend) {
+		_core_if->pcd_cb->suspend(_core_if->pcd_cb->p);
+	}
+}
+
+/** Resume the PCD.  Helper function for using the PCD callbacks. 
+ *
+ * @param _core_if Programming view of DWC_otg controller.
+ */ 
+static inline void pcd_resume(dwc_otg_core_if_t * _core_if) 
+{
+	if (_core_if->pcd_cb && _core_if->pcd_cb->resume_wakeup) {
+		_core_if->pcd_cb->resume_wakeup(_core_if->pcd_cb->p);
+	}
+}
+
+/**
+ * This function handles the OTG Interrupts. It reads the OTG
+ * Interrupt Register (GOTGINT) to determine what interrupt has
+ * occurred.
+ *
+ * @param _core_if Programming view of DWC_otg controller.
+ */ 
+int32_t dwc_otg_handle_otg_intr(dwc_otg_core_if_t * _core_if) 
+{
+	dwc_otg_core_global_regs_t * global_regs = _core_if->core_global_regs;
+	gotgint_data_t gotgint;
+	gotgctl_data_t gotgctl;
+	gintmsk_data_t gintmsk;
+	gotgint.d32 = dwc_read_reg32(&global_regs->gotgint);
+	gotgctl.d32 = dwc_read_reg32(&global_regs->gotgctl);
+	DWC_DEBUGPL(DBG_CIL, "++OTG Interrupt gotgint=%0x [%s]\n", gotgint.d32,
+		     op_state_str(_core_if));
+	
+	//DWC_DEBUGPL(DBG_CIL, "gotgctl=%08x\n", gotgctl.d32 );
+	if (gotgint.b.sesenddet) {
+		DWC_DEBUGPL(DBG_ANY, " ++OTG Interrupt: " 
+			     "Session End Detected++ (%s)\n",
+			     op_state_str(_core_if));
+		gotgctl.d32 = dwc_read_reg32(&global_regs->gotgctl);
+		if (_core_if->op_state == B_HOST) {
+			pcd_start(_core_if);
+			_core_if->op_state = B_PERIPHERAL;
+		} else {
+			/* If not B_HOST and Device HNP still set. HNP
+			 * Did not succeed!*/ 
+			if (gotgctl.b.devhnpen) {
+				DWC_DEBUGPL(DBG_ANY, "Session End Detected\n");
+				DWC_ERROR("Device Not Connected/Responding!\n");
+			}
+			/* If Session End Detected the B-Cable has
+			 * been disconnected. */ 
+			/* Reset PCD and Gadget driver to a
+			 * clean state. */ 
+			pcd_stop(_core_if);
+		}
+		gotgctl.d32 = 0;
+		gotgctl.b.devhnpen = 1;
+		dwc_modify_reg32(&global_regs->gotgctl, gotgctl.d32, 0);
+	}
+	if (gotgint.b.sesreqsucstschng) {
+		DWC_DEBUGPL(DBG_ANY, " ++OTG Interrupt: " 
+			     "Session Reqeust Success Status Change++\n");
+		gotgctl.d32 = dwc_read_reg32(&global_regs->gotgctl);
+		if (gotgctl.b.sesreqscs) {
+			if ((_core_if->core_params->phy_type ==
+			      DWC_PHY_TYPE_PARAM_FS)
+			     && (_core_if->core_params->i2c_enable)) {
+				_core_if->srp_success = 1;
+			} else {
+				pcd_resume(_core_if);
+				
+				/* Clear Session Request */ 
+				gotgctl.d32 = 0;
+				gotgctl.b.sesreq = 1;
+				dwc_modify_reg32(&global_regs->gotgctl,
+						  gotgctl.d32, 0);
+			}
+		}
+	}
+	if (gotgint.b.hstnegsucstschng) {
+		/* Print statements during the HNP interrupt handling
+		 * can cause it to fail.*/ 
+		gotgctl.d32 = dwc_read_reg32(&global_regs->gotgctl);
+		if (gotgctl.b.hstnegscs) {
+			if (dwc_otg_is_host_mode(_core_if)) {
+				_core_if->op_state = B_HOST;
+				
+				/*
+				 * Need to disable SOF interrupt immediately.
+				 * When switching from device to host, the PCD
+				 * interrupt handler won't handle the
+				 * interrupt if host mode is already set. The
+				 * HCD interrupt handler won't get called if
+				 * the HCD state is HALT. This means that the
+				 * interrupt does not get handled and Linux
+				 * complains loudly.
+				 */ 
+				gintmsk.d32 = 0;
+				gintmsk.b.sofintr = 1;
+				dwc_modify_reg32(&global_regs->gintmsk, gintmsk.d32, 0);
+				pcd_stop(_core_if);
+				
+				/*
+				 * Initialize the Core for Host mode.
+				 */ 
+				hcd_start(_core_if);
+				_core_if->op_state = B_HOST;
+			}
+		} else {
+			gotgctl.d32 = 0;
+			gotgctl.b.hnpreq = 1;
+			gotgctl.b.devhnpen = 1;
+			dwc_modify_reg32(&global_regs->gotgctl, gotgctl.d32, 0);
+			DWC_DEBUGPL(DBG_ANY, "HNP Failed\n");
+			DWC_ERROR("Device Not Connected/Responding\n");
+		}
+	}
+	if (gotgint.b.hstnegdet) {
+		
+		/* The disconnect interrupt is set at the same time as
+		 * Host Negotiation Detected.  During the mode
+		 * switch all interrupts are cleared so the disconnect
+		 * interrupt handler will not get executed.
+		 */ 
+		DWC_DEBUGPL(DBG_ANY, " ++OTG Interrupt: " 
+				"Host Negotiation Detected++ (%s)\n", 
+				(dwc_otg_is_host_mode(_core_if) ? "Host" :
+				 "Device"));
+		if (dwc_otg_is_device_mode(_core_if)) {
+			DWC_DEBUGPL(DBG_ANY, "a_suspend->a_peripheral (%d)\n",
+				     _core_if->op_state);
+			hcd_disconnect(_core_if);
+			pcd_start(_core_if);
+			_core_if->op_state = A_PERIPHERAL;
+		} else {
+			
+			/*
+			 * Need to disable SOF interrupt immediately. When
+			 * switching from device to host, the PCD interrupt
+			 * handler won't handle the interrupt if host mode is
+			 * already set. The HCD interrupt handler won't get
+			 * called if the HCD state is HALT. This means that
+			 * the interrupt does not get handled and Linux
+			 * complains loudly.
+			 */ 
+			gintmsk.d32 = 0;
+			gintmsk.b.sofintr = 1;
+			dwc_modify_reg32(&global_regs->gintmsk, gintmsk.d32,
+					  0);
+			pcd_stop(_core_if);
+			hcd_start(_core_if);
+			_core_if->op_state = A_HOST;
+		}
+	}
+	if (gotgint.b.adevtoutchng) {
+		DWC_DEBUGPL(DBG_ANY, " ++OTG Interrupt: " 
+			     "A-Device Timeout Change++\n");
+	}
+	if (gotgint.b.debdone) {
+		DWC_DEBUGPL(DBG_ANY, " ++OTG Interrupt: " 
+			     "Debounce Done++\n");
+	}
+	
+	/* Clear GOTGINT */ 
+	dwc_write_reg32(&_core_if->core_global_regs->gotgint, gotgint.d32);
+	return 1;
+}
+
+/**
+ * This function handles the Connector ID Status Change Interrupt.  It
+ * reads the OTG Interrupt Register (GOTCTL) to determine whether this
+ * is a Device to Host Mode transition or a Host Mode to Device
+ * Transition.  
+ *
+ * This only occurs when the cable is connected/removed from the PHY
+ * connector.
+ *
+ * @param _core_if Programming view of DWC_otg controller.
+ */ 
+int32_t dwc_otg_handle_conn_id_status_change_intr(dwc_otg_core_if_t *
+						      _core_if) 
+{
+	uint32_t count = 0;
+	gintsts_data_t gintsts = {.d32 = 0};
+	gintmsk_data_t gintmsk = {.d32 = 0};
+	gotgctl_data_t gotgctl = {.d32 = 0};
+	
+	/*
+	 * Need to disable SOF interrupt immediately. If switching from device
+	 * to host, the PCD interrupt handler won't handle the interrupt if
+	 * host mode is already set. The HCD interrupt handler won't get
+	 * called if the HCD state is HALT. This means that the interrupt does
+	 * not get handled and Linux complains loudly.
+	 */ 
+	gintmsk.b.sofintr = 1;
+	dwc_modify_reg32(&_core_if->core_global_regs->gintmsk, gintmsk.d32, 0);
+	DWC_DEBUGPL(DBG_CIL,
+		      " ++Connector ID Status Change Interrupt++  (%s)\n",
+		      (dwc_otg_is_host_mode(_core_if) ? "Host" : "Device"));
+	gotgctl.d32 = dwc_read_reg32(&_core_if->core_global_regs->gotgctl);
+	DWC_DEBUGPL(DBG_CIL, "gotgctl=%0x\n", gotgctl.d32);
+	DWC_DEBUGPL(DBG_CIL, "gotgctl.b.conidsts=%d\n", gotgctl.b.conidsts);
+	
+	/* B-Device connector (Device Mode) */ 
+	if (gotgctl.b.conidsts) {
+		
+		/* Wait for switch to device mode. */ 
+		while (!dwc_otg_is_device_mode(_core_if)) {
+			DWC_PRINT("Waiting for Peripheral Mode, Mode=%s\n", 
+				   (dwc_otg_is_host_mode(_core_if) ? "Host" :
+				    "Peripheral"));
+			MDELAY(100);
+			if (++count > 10000)
+				*(uint32_t *) NULL = 0;
+		}
+		_core_if->op_state = B_PERIPHERAL;
+		dwc_otg_core_init(_core_if);
+		dwc_otg_enable_global_interrupts(_core_if);
+		pcd_start(_core_if);
+	} else {
+		
+		/* A-Device connector (Host Mode) */ 
+		while (!dwc_otg_is_host_mode(_core_if)) {
+			DWC_PRINT("Waiting for Host Mode, Mode=%s\n", 
+				   (dwc_otg_is_host_mode(_core_if) ? "Host" :
+				    "Peripheral"));
+			MDELAY(100);
+			if (++count > 10000)
+				*(uint32_t *) NULL = 0;
+		}
+		_core_if->op_state = A_HOST;
+		
+		/*
+		 * Initialize the Core for Host mode.
+		 */ 
+		dwc_otg_core_init(_core_if);
+		dwc_otg_enable_global_interrupts(_core_if);
+		hcd_start(_core_if);
+	}
+	
+	/* Set flag and clear interrupt */ 
+	gintsts.b.conidstschng = 1;
+	dwc_write_reg32(&_core_if->core_global_regs->gintsts, gintsts.d32);
+	return 1;
+}
+
+/** 
+ * This interrupt indicates that a device is initiating the Session
+ * Request Protocol to request the host to turn on bus power so a new
+ * session can begin. The handler responds by turning on bus power. If
+ * the DWC_otg controller is in low power mode, the handler brings the
+ * controller out of low power mode before turning on bus power. 
+ *
+ * @param _core_if Programming view of DWC_otg controller.
+ */ 
+int32_t dwc_otg_handle_session_req_intr(dwc_otg_core_if_t * _core_if) 
+{
+	gintsts_data_t gintsts;
+	
+#ifndef CONFIG_DWC_HOST_ONLY
+	hprt0_data_t hprt0;
+	DWC_DEBUGPL(DBG_ANY, "++Session Request Interrupt++\n");
+	if (dwc_otg_is_device_mode(_core_if)) {
+		DWC_PRINT("SRP: Device mode\n");
+	} else {
+		DWC_PRINT("SRP: Host mode\n");
+		
+		/* Turn on the port power bit. */ 
+		hprt0.d32 = dwc_otg_read_hprt0(_core_if);
+		hprt0.b.prtpwr = 1;
+		dwc_write_reg32(_core_if->host_if->hprt0, hprt0.d32);
+		
+		/* Start the Connection timer. So a message can be displayed
+		 * if connect does not occur within 10 seconds. */ 
+		hcd_session_start(_core_if);
+	}
+	
+#endif	/*  */
+	    
+	/* Clear interrupt */ 
+	gintsts.d32 = 0;
+	gintsts.b.sessreqintr = 1;
+	dwc_write_reg32(&_core_if->core_global_regs->gintsts, gintsts.d32);
+	return 1;
+}
+
+/** 
+ * This interrupt indicates that the DWC_otg controller has detected a
+ * resume or remote wakeup sequence. If the DWC_otg controller is in
+ * low power mode, the handler must brings the controller out of low
+ * power mode. The controller automatically begins resume
+ * signaling. The handler schedules a time to stop resume signaling.
+ */ 
+int32_t dwc_otg_handle_wakeup_detected_intr(dwc_otg_core_if_t * _core_if) 
+{
+	gintsts_data_t gintsts;
+	DWC_DEBUGPL(DBG_ANY,"++Resume and Remote Wakeup Detected Interrupt++\n");
+	if (dwc_otg_is_device_mode(_core_if)) {
+		dctl_data_t dctl = {.d32 = 0};
+		DWC_DEBUGPL(DBG_PCD, "DSTS=0x%0x\n",
+				dwc_read_reg32(&_core_if->dev_if->dev_global_regs->dsts));
+		
+#ifdef PARTIAL_POWER_DOWN
+		if (_core_if->hwcfg4.b.power_optimiz) {
+			pcgcctl_data_t power = {.d32 = 0};
+			power.d32 = dwc_read_reg32(_core_if->pcgcctl);
+			DWC_DEBUGPL(DBG_CIL, "PCGCCTL=%0x\n", power.d32);
+			power.b.stoppclk = 0;
+			dwc_write_reg32(_core_if->pcgcctl, power.d32);
+			power.b.pwrclmp = 0;
+			dwc_write_reg32(_core_if->pcgcctl, power.d32);
+			power.b.rstpdwnmodule = 0;
+			dwc_write_reg32(_core_if->pcgcctl, power.d32);
+		}
+		
+#endif	/*  */
+		/* Clear the Remote Wakeup Signalling */ 
+		dctl.b.rmtwkupsig = 1;
+		dwc_modify_reg32(&_core_if->dev_if->dev_global_regs->dctl,
+				  dctl.d32, 0);
+		if (_core_if->pcd_cb && _core_if->pcd_cb->resume_wakeup) {
+			_core_if->pcd_cb->resume_wakeup(_core_if->pcd_cb->p);
+		}
+	} else {
+		
+		/*
+		 * Clear the Resume after 70ms. (Need 20 ms minimum. Use 70 ms
+		 * so that OPT tests pass with all PHYs).
+		 */ 
+		hprt0_data_t hprt0 = {.d32 = 0};
+		pcgcctl_data_t pcgcctl = {.d32 = 0};
+		
+		/* Restart the Phy Clock */ 
+		pcgcctl.b.stoppclk = 1;
+		dwc_modify_reg32(_core_if->pcgcctl, pcgcctl.d32, 0);
+		UDELAY(10);
+		
+		/* Now wait for 70 ms. */ 
+		hprt0.d32 = dwc_otg_read_hprt0(_core_if);
+		DWC_DEBUGPL(DBG_ANY, "Resume: HPRT0=%0x\n", hprt0.d32);
+		MDELAY(70);
+		hprt0.b.prtres = 0;	/* Resume */
+		dwc_write_reg32(_core_if->host_if->hprt0, hprt0.d32);
+		DWC_DEBUGPL(DBG_ANY, "Clear Resume: HPRT0=%0x\n",
+			     dwc_read_reg32(_core_if->host_if->hprt0));
+	}
+	
+	/* Clear interrupt */ 
+	gintsts.d32 = 0;
+	gintsts.b.wkupintr = 1;
+	dwc_write_reg32(&_core_if->core_global_regs->gintsts, gintsts.d32);
+	return 1;
+}
+
+/** 
+ * This interrupt indicates that a device has been disconnected from
+ * the root port. 
+ */ 
+int32_t dwc_otg_handle_disconnect_intr(dwc_otg_core_if_t * _core_if) 
+{
+	gintsts_data_t gintsts;
+	printk(KERN_ERR "  Disconnect Detected Interrupt++ (%s) %s\n", 
+		 (dwc_otg_is_host_mode(_core_if) ? "Host" : "Device"),
+		 op_state_str(_core_if));
+	DWC_DEBUGPL(DBG_ANY, "++Disconnect Detected Interrupt++ (%s) %s\n",
+		     (dwc_otg_is_host_mode(_core_if) ? "Host" : "Device"),
+		     op_state_str(_core_if));
+	
+/** @todo Consolidate this if statement. */ 
+#ifndef CONFIG_DWC_HOST_ONLY
+	if (_core_if->op_state == B_HOST) {
+		
+		/* If in device mode Disconnect and stop the HCD, then
+		 * start the PCD. */ 
+		hcd_disconnect(_core_if);
+		pcd_start(_core_if);
+		_core_if->op_state = B_PERIPHERAL;
+	} else if (dwc_otg_is_device_mode(_core_if)) {
+		gotgctl_data_t gotgctl = {.d32 = 0};
+		gotgctl.d32 = dwc_read_reg32(&_core_if->core_global_regs->gotgctl);
+		if (gotgctl.b.hstsethnpen == 1) {
+			/* Do nothing, if HNP in process the OTG
+			 * interrupt "Host Negotiation Detected"
+			 * interrupt will do the mode switch.
+			 */ 
+		} else if (gotgctl.b.devhnpen == 0) {
+			/* If in device mode Disconnect and stop the HCD, then
+			 * start the PCD. */ 
+			hcd_disconnect(_core_if);
+			pcd_start(_core_if);
+			_core_if->op_state = B_PERIPHERAL;
+		} else {
+			DWC_DEBUGPL(DBG_ANY, "!a_peripheral && !devhnpen\n");
+		}
+	} else {
+		if (_core_if->op_state == A_HOST) {
+			/* A-Cable still connected but device disconnected. */ 
+			hcd_disconnect(_core_if);
+		}
+	}
+	
+#endif	/*  */
+	gintsts.d32 = 0;
+	gintsts.b.disconnect = 1;
+	dwc_write_reg32(&_core_if->core_global_regs->gintsts, gintsts.d32);
+	return 1;
+}
+
+/**
+ * This interrupt indicates that SUSPEND state has been detected on
+ * the USB.
+ * 
+ * For HNP the USB Suspend interrupt signals the change from
+ * "a_peripheral" to "a_host".
+ *
+ * When power management is enabled the core will be put in low power
+ * mode.
+ */ 
+int32_t dwc_otg_handle_usb_suspend_intr(dwc_otg_core_if_t * _core_if) 
+{
+	dsts_data_t dsts;
+	gintsts_data_t gintsts;
+	DWC_DEBUGPL(DBG_ANY, "USB SUSPEND\n");
+	if (dwc_otg_is_device_mode(_core_if)) {
+		
+		/* Check the Device status register to determine if the Suspend
+		 * state is active. */ 
+		dsts.d32 = dwc_read_reg32(&_core_if->dev_if->dev_global_regs->dsts);
+		DWC_DEBUGPL(DBG_PCD, "DSTS=0x%0x\n", dsts.d32);
+		DWC_DEBUGPL(DBG_PCD, "DSTS.Suspend Status=%d " 
+			     "HWCFG4.power Optimize=%d\n", dsts.b.suspsts,
+			     _core_if->hwcfg4.b.power_optimiz);
+		
+#ifdef PARTIAL_POWER_DOWN
+/** @todo Add a module parameter for power management. */ 
+		if (dsts.b.suspsts && _core_if->hwcfg4.b.power_optimiz) {
+			pcgcctl_data_t power = {.d32 = 0};
+			DWC_DEBUGPL(DBG_CIL, "suspend\n");
+			power.b.pwrclmp = 1;
+			dwc_write_reg32(_core_if->pcgcctl, power.d32);
+			power.b.rstpdwnmodule = 1;
+			dwc_modify_reg32(_core_if->pcgcctl, 0, power.d32);
+			power.b.stoppclk = 1;
+			dwc_modify_reg32(_core_if->pcgcctl, 0, power.d32);
+		} else {
+			DWC_DEBUGPL(DBG_ANY, "disconnect?\n");
+		}
+		
+#endif	/*  */
+		/* PCD callback for suspend. */ 
+		pcd_suspend(_core_if);
+	} else {
+		if (_core_if->op_state == A_PERIPHERAL) {
+			DWC_DEBUGPL(DBG_ANY, "a_peripheral->a_host\n");
+			
+			/* Clear the a_peripheral flag, back to a_host. */ 
+			pcd_stop(_core_if);
+			hcd_start(_core_if);
+			_core_if->op_state = A_HOST;
+		}
+	}
+	
+	/* Clear interrupt */ 
+	gintsts.d32 = 0;
+	gintsts.b.usbsuspend = 1;
+	dwc_write_reg32(&_core_if->core_global_regs->gintsts, gintsts.d32);
+	return 1;
+}
+
+/**
+ * This function returns the Core Interrupt register.
+ */ 
+static inline uint32_t dwc_otg_read_common_intr(dwc_otg_core_if_t * _core_if) 
+{
+	gintsts_data_t gintsts;
+	gintmsk_data_t gintmsk;
+	gintmsk_data_t gintmsk_common = {.d32 = 0};
+	gintmsk_common.b.wkupintr = 1;
+	gintmsk_common.b.sessreqintr = 1;
+	gintmsk_common.b.conidstschng = 1;
+	gintmsk_common.b.otgintr = 1;
+	gintmsk_common.b.modemismatch = 1;
+	gintmsk_common.b.disconnect = 1;
+	gintmsk_common.b.usbsuspend = 1;
+	
+	/** @todo: The port interrupt occurs while in device 
+     * mode. Added code to CIL to clear the interrupt for now! 
+     */ 
+	gintmsk_common.b.portintr = 1;
+	gintsts.d32 = dwc_read_reg32(&_core_if->core_global_regs->gintsts);
+	gintmsk.d32 = dwc_read_reg32(&_core_if->core_global_regs->gintmsk);
+	
+#ifdef CONFIG_DWC_DEBUG
+	/* if any common interrupts set */ 
+	if (gintsts.d32 & gintmsk_common.d32) {
+		DWC_DEBUGPL(DBG_ANY, "gintsts=%08x  gintmsk=%08x\n",
+			     gintsts.d32, gintmsk.d32);
+	}
+	
+#endif	/*  */
+	return ((gintsts.d32 & gintmsk.d32) & gintmsk_common.d32);
+}
+
+/**
+ * Common interrupt handler.
+ *
+ * The common interrupts are those that occur in both Host and Device mode. 
+ * This handler handles the following interrupts:
+ * - Mode Mismatch Interrupt
+ * - Disconnect Interrupt
+ * - OTG Interrupt
+ * - Connector ID Status Change Interrupt
+ * - Session Request Interrupt.
+ * - Resume / Remote Wakeup Detected Interrupt.
+ * 
+ */ 
+extern int32_t dwc_otg_handle_common_intr(dwc_otg_core_if_t * _core_if) 
+{
+	int retval = 0;
+	gintsts_data_t gintsts;
+	gintsts.d32 = dwc_otg_read_common_intr(_core_if);
+	if (gintsts.b.modemismatch) {
+		retval |= dwc_otg_handle_mode_mismatch_intr(_core_if);
+	}
+	if (gintsts.b.otgintr) {
+		retval |= dwc_otg_handle_otg_intr(_core_if);
+	}
+	if (gintsts.b.conidstschng) {
+		retval |= dwc_otg_handle_conn_id_status_change_intr(_core_if);
+	}
+	if (gintsts.b.disconnect) {
+		retval |= dwc_otg_handle_disconnect_intr(_core_if);
+	}
+	if (gintsts.b.sessreqintr) {
+		retval |= dwc_otg_handle_session_req_intr(_core_if);
+	}
+	if (gintsts.b.wkupintr) {
+		retval |= dwc_otg_handle_wakeup_detected_intr(_core_if);
+	}
+	if (gintsts.b.usbsuspend) {
+		retval |= dwc_otg_handle_usb_suspend_intr(_core_if);
+	}
+	if (gintsts.b.portintr && dwc_otg_is_device_mode(_core_if)) {
+		/* The port interrupt occurs while in device mode with HPRT0
+		 * Port Enable/Disable.
+		 */ 
+		gintsts.d32 = 0;
+		gintsts.b.portintr = 1;
+		dwc_write_reg32(&_core_if->core_global_regs->gintsts,
+				 gintsts.d32);
+		retval |= 1;
+	}
+	return retval;
+}
+
diff -Naur a/drivers/usb/dwc_otg/dwc_otg_driver.c b/drivers/usb/dwc_otg/dwc_otg_driver.c
--- a/drivers/usb/dwc_otg/dwc_otg_driver.c	1970-01-01 00:00:00.000000000 +0000
+++ b/drivers/usb/dwc_otg/dwc_otg_driver.c	2017-06-22 08:13:33.925816941 +0000
@@ -0,0 +1,1193 @@
+/* ==========================================================================
+ * $File: //dwh/usb_iip/dev/software/otg_ipmate/linux/drivers/dwc_otg_driver.c $
+ * $Revision: #12 $
+ * $Date: 2007/02/07 $
+ * $Change: 791271 $
+ *
+ * Synopsys HS OTG Linux Software Driver and documentation (hereinafter,
+ * "Software") is an Unsupported proprietary work of Synopsys, Inc. unless
+ * otherwise expressly agreed to in writing between Synopsys and you.
+ *
+ * The Software IS NOT an item of Licensed Software or Licensed Product under
+ * any End User Software License Agreement or Agreement for Licensed Product
+ * with Synopsys or any supplement thereto. You are permitted to use and
+ * redistribute this Software in source and binary forms, with or without
+ * modification, provided that redistributions of source code must retain this
+ * notice. You may not view, use, disclose, copy or distribute this file or
+ * any information contained herein except pursuant to this license grant from
+ * Synopsys. If you do not agree with this notice, including the disclaimer
+ * below, then you are not authorized to use the Software.
+ *
+ * THIS SOFTWARE IS BEING DISTRIBUTED BY SYNOPSYS SOLELY ON AN "AS IS" BASIS
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE HEREBY DISCLAIMED. IN NO EVENT SHALL SYNOPSYS BE LIABLE FOR ANY DIRECT,
+ * INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+ * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+ * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+ * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
+ * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
+ * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH
+ * DAMAGE.
+ * ========================================================================== */
+
+
+/** @file
+ * The dwc_otg_driver module provides the initialization and cleanup entry
+ * points for the DWC_otg driver. This module will be dynamically installed
+ * after Linux is booted using the insmod command. When the module is
+ * installed, the dwc_otg_driver_init function is called. When the module is
+ * removed (using rmmod), the dwc_otg_driver_cleanup function is called.
+ *
+ * This module also defines a data structure for the dwc_otg_driver, which is
+ * used in conjunction with the standard device structure. These
+ * structures allow the OTG driver to comply with the standard Linux driver
+ * model in which devices and drivers are registered with a bus driver. This
+ * has the benefit that Linux can expose attributes of the driver and device
+ * in its special sysfs file system. Users can then read or write files in
+ * this file system to perform diagnostics on the driver components or the
+ * device.
+ */
+
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/moduleparam.h>
+#include <linux/init.h>
+#include <linux/device.h>
+#include <linux/errno.h>
+#include <linux/types.h>
+#include <linux/stat.h>	 /* permission constants */
+#include <linux/platform_device.h>
+#include <linux/irq.h>
+#include <asm/io.h>
+
+#include "dwc_otg_plat.h"
+#include "dwc_otg_attr.h"
+#include "dwc_otg_driver.h"
+#include "dwc_otg_cil.h"
+#include "dwc_otg_pcd.h"
+#include "dwc_otg_hcd.h"
+
+#define DWC_DRIVER_VERSION	"2.60 22-May-2017"
+#define DWC_DRIVER_DESC		"HS OTG USB Controller driver"
+static const char dwc_driver_name[] = "dwc_otg";
+
+/*-------------------------------------------------------------------------*/
+/* Encapsulate the module parameter settings */
+static dwc_otg_core_params_t dwc_otg_module_params = {
+	.opt = -1,
+	.otg_cap = -1,
+	.dma_enable = -1,
+	.dma_burst_size = -1,
+#if 1
+	.speed = -1,
+#else
+	.speed = 1, /* test-only: set full-speed for Beagle USB Analyzer */
+#endif
+	.host_support_fs_ls_low_power = -1,
+	.host_ls_low_power_phy_clk = -1,
+	.enable_dynamic_fifo = -1,
+	.data_fifo_size = -1,
+	.dev_rx_fifo_size = -1,
+	.dev_nperio_tx_fifo_size = -1,
+	.dev_perio_tx_fifo_size = { -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1	}, /* 15 */
+    .host_rx_fifo_size = -1,
+	.host_nperio_tx_fifo_size =-1,
+	.host_perio_tx_fifo_size = -1,
+	.max_transfer_size = -1,
+	.max_packet_count = -1,
+	.host_channels = -1,
+	.dev_endpoints = -1,
+	.phy_type = -1,
+	.phy_utmi_width = -1,
+	.phy_ulpi_ddr = -1,
+	.phy_ulpi_ext_vbus = -1,
+	.i2c_enable = -1,
+	.ulpi_fs_ls = -1,
+	.ts_dline = -1,
+	.en_multiple_tx_fifo = -1,
+	.dev_tx_fifo_size = { -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1}, /* 15 */
+	.thr_ctl = -1,
+	.tx_thr_length = -1,
+	.rx_thr_length = -1,
+};
+
+
+/* This function shows the Driver Version. */
+static ssize_t version_show(struct device_driver *dev, char *buf) {
+	return snprintf(buf, sizeof(DWC_DRIVER_VERSION) + 2, "%s\n", DWC_DRIVER_VERSION);
+}
+static DRIVER_ATTR(version, S_IRUGO, version_show, NULL);
+
+/* Global Debug Level Mask. */
+uint32_t g_dbg_lvl = 0x0;	/* OFF */
+
+/* This function shows the driver Debug Level. */
+static ssize_t dbg_level_show(struct device_driver *_drv, char *_buf) {
+	return sprintf(_buf, "0x%0x\n", g_dbg_lvl);
+}
+
+/* This function stores the driver Debug Level. */
+static ssize_t dbg_level_store(struct device_driver *_drv, const char *_buf, size_t _count) {
+	g_dbg_lvl = simple_strtoul(_buf, NULL, 16);
+	return _count;
+}
+static DRIVER_ATTR(debuglevel, S_IRUGO | S_IWUSR, dbg_level_show, dbg_level_store);
+
+/* This function is called during module intialization to verify that the module parameters are in a valid state. */
+static int check_parameters(dwc_otg_core_if_t * core_if) {
+	int i;
+	int retval = 0;
+
+/* Checks if the parameter is outside of its valid range of values */
+#define DWC_OTG_PARAM_TEST(_param_,_low_,_high_) \
+	    ((dwc_otg_module_params._param_ < (_low_)) || \
+	     (dwc_otg_module_params._param_ > (_high_)))
+/* If the parameter has been set by the user, check that the parameter value is
+ * within the value range of values.  If not, report a module error. */
+#define DWC_OTG_PARAM_ERR(_param_,_low_,_high_,_string_) \
+do { \
+	if (dwc_otg_module_params._param_ != -1) { \
+		if (DWC_OTG_PARAM_TEST(_param_, (_low_), (_high_))) { \
+			DWC_ERROR("`%d' invalid for parameter `%s'\n", \
+			    dwc_otg_module_params._param_, _string_); \
+			dwc_otg_module_params._param_ = dwc_param_##_param_##_default; \
+		    retval++; \
+		} \
+	} \
+} while (0)
+
+	DWC_OTG_PARAM_ERR(opt, 0, 1, "opt");
+	DWC_OTG_PARAM_ERR(otg_cap, 0, 2, "otg_cap");
+	DWC_OTG_PARAM_ERR(dma_enable, 0, 1, "dma_enable");
+	DWC_OTG_PARAM_ERR(speed, 0, 1, "speed");
+	DWC_OTG_PARAM_ERR(host_support_fs_ls_low_power, 0, 1, "host_support_fs_ls_low_power");
+	DWC_OTG_PARAM_ERR(host_ls_low_power_phy_clk, 0, 1, "host_ls_low_power_phy_clk");
+	DWC_OTG_PARAM_ERR(enable_dynamic_fifo, 0, 1, "enable_dynamic_fifo");
+	DWC_OTG_PARAM_ERR(data_fifo_size, 32, 32768, "data_fifo_size");
+	DWC_OTG_PARAM_ERR(dev_rx_fifo_size, 16, 32768, "dev_rx_fifo_size");
+	DWC_OTG_PARAM_ERR(dev_nperio_tx_fifo_size, 16, 32768, "dev_nperio_tx_fifo_size");
+	DWC_OTG_PARAM_ERR(host_rx_fifo_size, 16, 32768, "host_rx_fifo_size");
+	DWC_OTG_PARAM_ERR(host_nperio_tx_fifo_size, 16, 32768, "host_nperio_tx_fifo_size");
+	DWC_OTG_PARAM_ERR(host_perio_tx_fifo_size, 16, 32768, "host_perio_tx_fifo_size");
+	DWC_OTG_PARAM_ERR(max_transfer_size, 2047, 524288, "max_transfer_size");
+	DWC_OTG_PARAM_ERR(max_packet_count, 15, 511, "max_packet_count");
+	DWC_OTG_PARAM_ERR(host_channels, 1, 16, "host_channels");
+	DWC_OTG_PARAM_ERR(dev_endpoints, 1, 15, "dev_endpoints");
+	DWC_OTG_PARAM_ERR(phy_type, 0, 2, "phy_type");
+	DWC_OTG_PARAM_ERR(phy_ulpi_ddr, 0, 1, "phy_ulpi_ddr");
+	DWC_OTG_PARAM_ERR(phy_ulpi_ext_vbus, 0, 1, "phy_ulpi_ext_vbus");
+	DWC_OTG_PARAM_ERR(i2c_enable, 0, 1, "i2c_enable");
+	DWC_OTG_PARAM_ERR(ulpi_fs_ls, 0, 1, "ulpi_fs_ls");
+	DWC_OTG_PARAM_ERR(ts_dline, 0, 1, "ts_dline");
+	if (dwc_otg_module_params.dma_burst_size != -1) {
+		if (DWC_OTG_PARAM_TEST(dma_burst_size, 1, 1)
+		     && DWC_OTG_PARAM_TEST(dma_burst_size, 4, 4)
+		     && DWC_OTG_PARAM_TEST(dma_burst_size, 8, 8)
+		     && DWC_OTG_PARAM_TEST(dma_burst_size, 16, 16)
+		     && DWC_OTG_PARAM_TEST(dma_burst_size, 32, 32)
+		     && DWC_OTG_PARAM_TEST(dma_burst_size, 64, 64)
+		     && DWC_OTG_PARAM_TEST(dma_burst_size, 128, 128)
+		     && DWC_OTG_PARAM_TEST(dma_burst_size, 256, 256)) {
+			DWC_ERROR("`%d' invalid for parameter `dma_burst_size'\n", dwc_otg_module_params.dma_burst_size);
+			dwc_otg_module_params.dma_burst_size = 32;
+			retval++;
+		}
+	}
+	if (dwc_otg_module_params.phy_utmi_width != -1) {
+		if (DWC_OTG_PARAM_TEST(phy_utmi_width, 8, 8)
+		     && DWC_OTG_PARAM_TEST(phy_utmi_width, 16, 16)) {
+			DWC_ERROR("`%d'invalid for parameter `phy_utmi_width'\n",dwc_otg_module_params.phy_utmi_width);
+			dwc_otg_module_params.phy_utmi_width = 8; /*fscz 16*/
+			retval++;
+		}
+	}
+	for (i = 0; i < 15; i++) {
+		/** @todo should be like above */
+		//DWC_OTG_PARAM_ERR(dev_perio_tx_fifo_size[i],4,768,"dev_perio_tx_fifo_size");
+		if (dwc_otg_module_params.dev_perio_tx_fifo_size[i] != -1)
+			if (DWC_OTG_PARAM_TEST(dev_perio_tx_fifo_size[i], 4, 768)) {
+				DWC_ERROR("`%d' invalid for parameter `%s_%d'\n",
+					 dwc_otg_module_params.dev_perio_tx_fifo_size[i],
+					 "dev_perio_tx_fifo_size", i);
+				dwc_otg_module_params.
+					dev_perio_tx_fifo_size[i] =
+					dwc_param_dev_perio_tx_fifo_size_default;
+				retval++;
+			}
+	}
+	
+	DWC_OTG_PARAM_ERR(en_multiple_tx_fifo, 0, 1, "en_multiple_tx_fifo");
+	for (i = 0; i < 15; i++) {
+		/** @todo should be like above */
+		//DWC_OTG_PARAM_ERR(dev_tx_fifo_size[i],4,768,"dev_tx_fifo_size");
+		if (dwc_otg_module_params.dev_tx_fifo_size[i] != -1)
+			if (DWC_OTG_PARAM_TEST(dev_tx_fifo_size[i], 4, 768)) {
+				DWC_ERROR("`%d' invalid for parameter `%s_%d'\n",
+					dwc_otg_module_params.dev_tx_fifo_size[i], "dev_tx_fifo_size", i);
+				dwc_otg_module_params.dev_tx_fifo_size[i] = dwc_param_dev_tx_fifo_size_default;
+				retval++;
+			}
+	}
+	
+	DWC_OTG_PARAM_ERR(thr_ctl, 0, 7, "thr_ctl");
+	DWC_OTG_PARAM_ERR(tx_thr_length, 8, 128, "tx_thr_length");
+	DWC_OTG_PARAM_ERR(rx_thr_length, 8, 128, "rx_thr_length");
+
+	    /* At this point, all module parameters that have been set by the user
+	     * are valid, and those that have not are left unset.  Now set their
+	     * default values and/or check the parameters against the hardware
+	     * configurations of the OTG core. */
+
+/* This sets the parameter to the default value if it has not been set by the
+ * user */
+#define DWC_OTG_PARAM_SET_DEFAULT(_param_)({ \
+	int changed = 1; \
+	if (dwc_otg_module_params._param_ == -1) { \
+		changed = 0; \
+		dwc_otg_module_params._param_ = dwc_param_##_param_##_default; \
+	} \
+ 	changed; \
+})
+
+/* This checks the macro agains the hardware configuration to see if it is
+ * valid.  It is possible that the default value could be invalid.	In this
+ * case, it will report a module error if the user touched the parameter.
+ * Otherwise it will adjust the value without any error. */
+#define DWC_OTG_PARAM_CHECK_VALID(_param_,_str_,_is_valid_,_set_valid_)({ \
+ 	int error = 0,changed = DWC_OTG_PARAM_SET_DEFAULT(_param_); \
+	if (!(_is_valid_)) { \
+		if (changed) { \
+			DWC_ERROR("`%d' invalid for parameter `%s' Check HW configuration.\n", \
+				dwc_otg_module_params._param_, _str_); \
+			error = 1; \
+		}\
+ 		dwc_otg_module_params._param_ = (_set_valid_); \
+	}\
+	error;\
+})
+
+    /* OTG Cap */
+	retval += DWC_OTG_PARAM_CHECK_VALID(otg_cap, "otg_cap",({
+		int	valid;
+		valid = 1;
+		switch(dwc_otg_module_params.otg_cap) {
+			case DWC_OTG_CAP_PARAM_HNP_SRP_CAPABLE:
+				if (core_if->hwcfg2.b.op_mode != DWC_HWCFG2_OP_MODE_HNP_SRP_CAPABLE_OTG) valid = 0;
+				break;
+			 case DWC_OTG_CAP_PARAM_SRP_ONLY_CAPABLE:
+				if((core_if->hwcfg2.b.op_mode != DWC_HWCFG2_OP_MODE_HNP_SRP_CAPABLE_OTG) &&
+					(core_if->hwcfg2.b.op_mode != DWC_HWCFG2_OP_MODE_SRP_ONLY_CAPABLE_OTG) &&
+					(core_if->hwcfg2.b.op_mode != DWC_HWCFG2_OP_MODE_SRP_CAPABLE_DEVICE) &&
+					(core_if->hwcfg2.b.op_mode != DWC_HWCFG2_OP_MODE_SRP_CAPABLE_HOST))
+					valid = 0;
+				break;
+			case DWC_OTG_CAP_PARAM_NO_HNP_SRP_CAPABLE:	 /* always valid */
+				break;
+		}
+		valid;
+	}),
+	(((core_if->hwcfg2.b.op_mode == DWC_HWCFG2_OP_MODE_HNP_SRP_CAPABLE_OTG) ||
+		(core_if->hwcfg2.b.op_mode == DWC_HWCFG2_OP_MODE_SRP_ONLY_CAPABLE_OTG) ||
+		(core_if->hwcfg2.b.op_mode == DWC_HWCFG2_OP_MODE_SRP_CAPABLE_DEVICE) ||
+		(core_if->hwcfg2.b.op_mode == DWC_HWCFG2_OP_MODE_SRP_CAPABLE_HOST)) ?
+			DWC_OTG_CAP_PARAM_SRP_ONLY_CAPABLE : DWC_OTG_CAP_PARAM_NO_HNP_SRP_CAPABLE)) ;
+	retval += DWC_OTG_PARAM_CHECK_VALID(dma_enable, "dma_enable",
+				((dwc_otg_module_params.dma_enable == 1) &&
+				(core_if->hwcfg2.b.architecture == 0)) ? 0 : 1, 0);
+	retval += DWC_OTG_PARAM_CHECK_VALID(opt, "opt", 1, 0);
+	DWC_OTG_PARAM_SET_DEFAULT(dma_burst_size);
+	retval += DWC_OTG_PARAM_CHECK_VALID(host_support_fs_ls_low_power, "host_support_fs_ls_low_power", 1, 0);
+	retval += DWC_OTG_PARAM_CHECK_VALID(enable_dynamic_fifo, "enable_dynamic_fifo",
+				((dwc_otg_module_params.enable_dynamic_fifo == 0) ||
+				(core_if->hwcfg2.b.dynamic_fifo == 1)), 0);
+	retval += DWC_OTG_PARAM_CHECK_VALID(data_fifo_size, "data_fifo_size",
+				(dwc_otg_module_params.data_fifo_size <= core_if->hwcfg3.b.dfifo_depth),
+				core_if->hwcfg3.b.dfifo_depth);
+	retval += DWC_OTG_PARAM_CHECK_VALID(dev_rx_fifo_size, "dev_rx_fifo_size",
+			    (dwc_otg_module_params.dev_rx_fifo_size <=
+					dwc_read_reg32(&core_if->core_global_regs->grxfsiz)),
+				    dwc_read_reg32(&core_if->core_global_regs->grxfsiz));
+	retval += DWC_OTG_PARAM_CHECK_VALID(dev_nperio_tx_fifo_size,
+				"dev_nperio_tx_fifo_size",
+				(dwc_otg_module_params.dev_nperio_tx_fifo_size <=
+				(dwc_read_reg32(&core_if->core_global_regs->gnptxfsiz) >> 16)),
+				(dwc_read_reg32(&core_if->core_global_regs->gnptxfsiz) >> 16));
+	retval += DWC_OTG_PARAM_CHECK_VALID(host_rx_fifo_size, "host_rx_fifo_size",
+				(dwc_otg_module_params.host_rx_fifo_size <=
+				dwc_read_reg32(&core_if->core_global_regs->grxfsiz)),
+				dwc_read_reg32(&core_if->core_global_regs->grxfsiz));
+	retval += DWC_OTG_PARAM_CHECK_VALID(host_nperio_tx_fifo_size,
+				"host_nperio_tx_fifo_size",
+				(dwc_otg_module_params.host_nperio_tx_fifo_size <=
+				(dwc_read_reg32(&core_if->core_global_regs->gnptxfsiz) >> 16)),
+		  		(dwc_read_reg32(&core_if->core_global_regs->gnptxfsiz) >> 16));
+	retval += DWC_OTG_PARAM_CHECK_VALID(host_perio_tx_fifo_size,
+				"host_perio_tx_fifo_size",
+				(dwc_otg_module_params.host_perio_tx_fifo_size <=
+				((dwc_read_reg32(&core_if->core_global_regs->hptxfsiz) >> 16))),
+	 			((dwc_read_reg32(&core_if->core_global_regs->hptxfsiz) >> 16)));
+	retval += DWC_OTG_PARAM_CHECK_VALID(max_transfer_size, "max_transfer_size",
+				(dwc_otg_module_params.max_transfer_size <
+				(1 << (core_if->hwcfg3.b.xfer_size_cntr_width + 11))),
+				((1 << (core_if->hwcfg3.b.xfer_size_cntr_width + 11)) - 1));
+	retval += DWC_OTG_PARAM_CHECK_VALID(max_packet_count, "max_packet_count",
+				(dwc_otg_module_params.max_packet_count <
+				(1 << (core_if->hwcfg3.b.packet_size_cntr_width + 4))),
+				((1 << (core_if->hwcfg3.b.packet_size_cntr_width + 4)) - 1));
+	retval += DWC_OTG_PARAM_CHECK_VALID(host_channels, "host_channels",
+				(dwc_otg_module_params.host_channels <=
+				(core_if->hwcfg2.b.num_host_chan + 1)),
+				(core_if->hwcfg2.b.num_host_chan + 1));
+	retval += DWC_OTG_PARAM_CHECK_VALID(dev_endpoints, "dev_endpoints",
+				(dwc_otg_module_params.dev_endpoints <=
+				(core_if->hwcfg2.b.num_dev_ep)),
+				core_if->hwcfg2.b.num_dev_ep);
+
+/* Define the following to disable the FS PHY Hardware checking.  This is for internal testing only.
+ * #define NO_FS_PHY_HW_CHECKS */
+
+#ifdef NO_FS_PHY_HW_CHECKS
+    retval += DWC_OTG_PARAM_CHECK_VALID(phy_type, "phy_type", 1, 0);
+#else
+    retval += DWC_OTG_PARAM_CHECK_VALID(phy_type, "phy_type", ({
+		int valid = 0;
+		if ((dwc_otg_module_params.phy_type ==	DWC_PHY_TYPE_PARAM_UTMI) &&
+			((core_if->hwcfg2.b.hs_phy_type == 1) || (core_if->hwcfg2.b.hs_phy_type == 3))) 
+			valid = 1;
+		else if ((dwc_otg_module_params.phy_type == DWC_PHY_TYPE_PARAM_ULPI) &&
+			((core_if->hwcfg2.b.hs_phy_type == 2) || (core_if->hwcfg2.b.hs_phy_type == 3)))
+			valid = 1;
+		else if ((dwc_otg_module_params.phy_type == DWC_PHY_TYPE_PARAM_FS) &&
+			(core_if->hwcfg2.b.fs_phy_type == 1))  valid = 1;
+		valid;
+	}),
+	({
+		int set = DWC_PHY_TYPE_PARAM_FS;
+		if (core_if->hwcfg2.b.hs_phy_type) {
+			if ((core_if->hwcfg2.b.hs_phy_type == 3) || (core_if->hwcfg2.b.hs_phy_type ==1))
+				set = DWC_PHY_TYPE_PARAM_UTMI;
+			else set = DWC_PHY_TYPE_PARAM_ULPI;
+		}
+		set;
+	})) ;
+
+#endif	/*  */
+	retval += DWC_OTG_PARAM_CHECK_VALID(speed, "speed", (dwc_otg_module_params.speed == 0) &&
+				(dwc_otg_module_params.phy_type ==	DWC_PHY_TYPE_PARAM_FS) ? 0 : 1,
+				dwc_otg_module_params.phy_type == DWC_PHY_TYPE_PARAM_FS ? 1 : 0);
+	retval += DWC_OTG_PARAM_CHECK_VALID(host_ls_low_power_phy_clk, "host_ls_low_power_phy_clk",
+				((dwc_otg_module_params.host_ls_low_power_phy_clk == DWC_HOST_LS_LOW_POWER_PHY_CLK_PARAM_48MHZ) &&
+				(dwc_otg_module_params.phy_type == DWC_PHY_TYPE_PARAM_FS) ? 0 : 1),
+				((dwc_otg_module_params.phy_type == DWC_PHY_TYPE_PARAM_FS) ? DWC_HOST_LS_LOW_POWER_PHY_CLK_PARAM_6MHZ :
+				DWC_HOST_LS_LOW_POWER_PHY_CLK_PARAM_48MHZ));
+	DWC_OTG_PARAM_SET_DEFAULT(phy_ulpi_ddr);
+	DWC_OTG_PARAM_SET_DEFAULT(phy_ulpi_ext_vbus);
+	DWC_OTG_PARAM_SET_DEFAULT(phy_utmi_width);
+	DWC_OTG_PARAM_SET_DEFAULT(ulpi_fs_ls);
+	DWC_OTG_PARAM_SET_DEFAULT(ts_dline);
+
+#ifdef NO_FS_PHY_HW_CHECKS
+	retval += DWC_OTG_PARAM_CHECK_VALID(i2c_enable, "i2c_enable", 1, 0);
+
+#else	/*  */
+	retval += DWC_OTG_PARAM_CHECK_VALID(i2c_enable, "i2c_enable",
+				(dwc_otg_module_params.i2c_enable == 1) &&	(core_if->hwcfg3.b.i2c == 0) ? 0 : 1, 0);
+#endif	/*  */
+	for (i = 0; i < 15; i++) {
+		int changed = 1;
+		int error = 0;
+		if (dwc_otg_module_params.dev_perio_tx_fifo_size[i] == -1) {
+			changed = 0;
+			dwc_otg_module_params.dev_perio_tx_fifo_size[i] =
+				dwc_param_dev_perio_tx_fifo_size_default;
+		}
+		if (!(dwc_otg_module_params.dev_perio_tx_fifo_size[i] <=
+			(dwc_read_reg32(&core_if->core_global_regs->dptxfsiz_dieptxf[i])))) {
+			if (changed) {
+				DWC_ERROR("`%d' invalid for param `dev_perio_fifo_size_%d'. Check HW configuration.\n",
+					dwc_otg_module_params.dev_perio_tx_fifo_size[i], i);
+				error = 1;
+			}
+			dwc_otg_module_params.dev_perio_tx_fifo_size[i] =
+				dwc_read_reg32(&core_if->core_global_regs->dptxfsiz_dieptxf[i]);
+		}
+		retval += error;
+	}
+
+	retval += DWC_OTG_PARAM_CHECK_VALID(en_multiple_tx_fifo, "en_multiple_tx_fifo",
+				((dwc_otg_module_params.en_multiple_tx_fifo == 1) &&
+				(core_if->hwcfg4.b.ded_fifo_en == 0)) ? 0 : 1, 0);
+
+	for (i = 0; i < 15; i++) {
+		int changed = 1;
+		int error = 0;
+		if (dwc_otg_module_params.dev_tx_fifo_size[i] == -1) {
+			changed = 0;
+			dwc_otg_module_params.dev_tx_fifo_size[i] = dwc_param_dev_tx_fifo_size_default;
+		}
+		if (!(dwc_otg_module_params.dev_tx_fifo_size[i] <=
+		     (dwc_read_reg32(&core_if->core_global_regs->dptxfsiz_dieptxf[i])))) {
+			if (changed) {
+				DWC_ERROR("%d' invalid for parameter `dev_perio_fifo_size_%d'."
+					"Check HW configuration.\n",dwc_otg_module_params.dev_tx_fifo_size[i],i);
+				error = 1;
+			}
+			dwc_otg_module_params.dev_tx_fifo_size[i] =
+			    dwc_read_reg32(&core_if->core_global_regs->dptxfsiz_dieptxf[i]);
+		}
+		retval += error;
+	}
+	DWC_OTG_PARAM_SET_DEFAULT(thr_ctl);
+	DWC_OTG_PARAM_SET_DEFAULT(tx_thr_length);
+	DWC_OTG_PARAM_SET_DEFAULT(rx_thr_length);
+	return retval;
+}
+
+/**
+ * This function is the top level interrupt handler for the Common
+ * (Device and host modes) interrupts.
+ */
+static irqreturn_t dwc_otg_common_irq(int _irq, void *_dev)
+{
+	dwc_otg_device_t * otg_dev = _dev;
+	int32_t retval = IRQ_NONE;
+	retval = dwc_otg_handle_common_intr(otg_dev->core_if);
+	return IRQ_RETVAL(retval);
+}
+
+#ifdef OTG_EXT_CHG_PUMP
+/**
+ * This function is the interrupt handler for the OverCurrent condition
+ * from the external charge pump (if enabled)
+ */
+static irqreturn_t dwc_otg_externalchgpump_irq(int _irq, void *_dev)
+{
+	dwc_otg_device_t * otg_dev = _dev;
+	int32_t retval = IRQ_NONE;
+	dwc_otg_hcd_t *_dwc_otg_hcd = NULL;
+
+	DWC_DEBUGPL(DBG_OFF," ++OTG OverCurrent Detected (ExtChgPump Interrupt)++ \n");
+
+//	mtdcr(0x0D2, mfdcr(0x0D2) & ~0x00000020);   //Disable IRQ2 - 58
+//	mtdcr(0x0C0, 0x00000002);
+
+	if(dwc_otg_is_host_mode(otg_dev->core_if)) {
+		hprt0_data_t hprt0 = {.d32 = 0};
+		_dwc_otg_hcd = otg_dev->hcd;
+		_dwc_otg_hcd->flags.b.port_over_current_change = 1;
+
+		hprt0.b.prtpwr = 0;
+		dwc_write_reg32(_dwc_otg_hcd->core_if->host_if->hprt0,
+				hprt0.d32);
+	} else {
+		/* Device mode - This int is n/a for device mode */
+		DWC_ERROR(" DeviceMode: OTG OverCurrent Detected \n");
+	}
+
+//	mtdcr(0x0D0, 0x00000020);   //Clear the sts
+//	mtdcr(0x0D2, mfdcr(0x0D2) | 0x00000020);   //Enable  IRQ2 - 58
+
+	retval |= 1;    //dwc_otg_handle_common_intr(otg_dev->core_if);
+	return IRQ_RETVAL(retval);
+}
+#endif
+
+/**
+ * This function is called when a device is unregistered with the
+ * dwc_otg_driver. This happens, for example, when the rmmod command is
+ * executed. The device may or may not be electrically present. If it is
+ * present, the driver stops device processing. Any resources used on behalf
+ * of this device are freed.
+ *
+ * @param[in] _dev
+ */
+static int dwc_otg_driver_remove(struct platform_device *pdev){
+	dwc_otg_device_t * otg_dev = platform_get_drvdata(pdev);
+	DWC_DEBUGPL(DBG_ANY, "%s(%p)\n", __func__, _dev);
+	if (otg_dev == NULL) {
+	    /* Memory allocation for the dwc_otg_device failed. */
+		return 0;
+	}
+	/* Free the IRQ */
+	if (otg_dev->common_irq_installed) free_irq(otg_dev->irq, otg_dev);
+
+#ifndef CONFIG_DWC_DEVICE_ONLY
+	if (otg_dev->hcd != NULL) dwc_otg_hcd_remove(&pdev->dev);
+#endif	/*  */
+
+#ifndef CONFIG_DWC_HOST_ONLY
+	if (otg_dev->pcd != NULL) dwc_otg_pcd_remove(&pdev->dev);
+
+#endif	/*  */
+	if (otg_dev->core_if != NULL) dwc_otg_cil_remove(otg_dev->core_if);
+
+	/* Remove the device attributes */
+	dwc_otg_attr_remove(&pdev->dev);
+
+	/* Return the memory. */
+	if (otg_dev->base != NULL) iounmap(otg_dev->base);
+	if (otg_dev->phys_addr != 0) release_mem_region(otg_dev->phys_addr, otg_dev->base_len);
+	kfree(otg_dev);
+
+	/* Clear the drvdata pointer. */
+	platform_set_drvdata(pdev, 0);
+	return 0;
+}
+
+#ifdef CONFIG_OTG_PLB_DMA_TASKLET
+/**
+ * This function is the top level interrupt handler for the Common
+ * (Device and host modes) interrupts.
+ */
+static irqreturn_t dwc_otg_plbdma(int _irq, void *_dev){
+    dwc_otg_device_t * otg_dev = _dev;
+    int32_t retval = IRQ_HANDLED;
+
+	ppc4xx_clr_dma_status(0);
+	DWC_DEBUGPL(DBG_SP, "%s reset release_later\n",  __func__);
+	atomic_set(& release_later, 0);
+	dwc_otg_enable_global_interrupts(otg_dev->core_if);
+	//enable_irq(94);
+	return IRQ_RETVAL(retval);
+}
+#endif
+
+/**
+ * This function is called when an device is bound to a
+ * dwc_otg_driver. It creates the driver components required to
+ * control the device (CIL, HCD, and PCD) and it initializes the
+ * device. The driver components are stored in a dwc_otg_device
+ * structure. A reference to the dwc_otg_device is saved in the
+ * device. This allows the driver to access the dwc_otg_device
+ * structure on subsequent calls to driver methods for this device.
+ *
+ * @param[in] _dev  device definition
+ */
+static int dwc_otg_driver_probe(struct platform_device *pdev){
+	int retval = 0;
+	dwc_otg_device_t * dwc_otg_device;
+	int32_t snpsid;
+	struct resource *res;
+	gusbcfg_data_t usbcfg = {.d32 = 0};
+#if defined(OTG_EXT_CHG_PUMP) || defined(CONFIG_OTG_PLB_DMA_TASKLET)
+	int irq;
+#endif
+
+	dev_dbg(&pdev->dev, "dwc_otg_driver_probe (%p)\n", pdev);
+	dwc_otg_device = devm_kzalloc(&pdev->dev, sizeof(dwc_otg_device_t), GFP_KERNEL);
+	if (!dwc_otg_device) {
+		dev_err(&pdev->dev, "kzalloc of dwc_otg_device failed\n");
+		retval = -ENOMEM;
+		goto fail;
+	}
+	//memset(dwc_otg_device, 0, sizeof(*dwc_otg_device));
+	dwc_otg_device->reg_offset = 0xFFFFFFFF;
+
+    // Retrieve the memory and IRQ resources.
+	dwc_otg_device->irq = platform_get_irq(pdev, 0);
+	if (dwc_otg_device->irq == 0) {
+		dev_err(&pdev->dev, "no device irq\n");
+		retval = -ENODEV;
+		goto fail;
+	}
+	dev_dbg(&pdev->dev, "OTG - device irq: %d\n", dwc_otg_device->irq);
+	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	if (res == NULL) {
+		dev_err(&pdev->dev, "no CSR address\n");
+		retval = -ENODEV;
+		goto fail;
+	}
+	dev_dbg(&pdev->dev, "OTG - ioresource_mem start0x%08x: end:0x%08x\n", (unsigned)res->start, (unsigned)res->end);
+	dwc_otg_device->phys_addr = res->start;
+	dwc_otg_device->base_len = res->end - res->start + 1;
+	if (request_mem_region(dwc_otg_device->phys_addr, dwc_otg_device->base_len, dwc_driver_name) == NULL) {
+		dev_err(&pdev->dev, "request_mem_region failed\n");
+		retval = -EBUSY;
+		goto fail;
+	}
+
+	// Map the DWC_otg Core memory into virtual address space.
+	dwc_otg_device->base = ioremap(dwc_otg_device->phys_addr, dwc_otg_device->base_len);
+	if (dwc_otg_device->base == NULL) {
+		dev_err(&pdev->dev, "ioremap64() failed\n");
+		retval = -ENOMEM;
+		goto fail;
+	}
+	dev_dbg(&pdev->dev, "mapped base=0x%08x\n", (unsigned)dwc_otg_device->base);
+
+    /* Attempt to ensure this device is really a DWC_otg Controller.
+     * Read and verify the SNPSID register contents. The value should be
+     * 0x45F42XXX, which corresponds to "OT2", as in "OTG version 2.XX". */
+	snpsid = dwc_read_reg32((uint32_t *) ((uint8_t *) dwc_otg_device->base + 0x40));
+    // Initialize driver data to point to the global DWC_otg device structure.
+	printk(KERN_INFO "DWC OTG Hardware version: %x\n", snpsid);
+  
+	platform_set_drvdata(pdev, dwc_otg_device);
+	dev_dbg(&pdev->dev, "dwc_otg_device=0x%p\n", dwc_otg_device);
+	dwc_otg_device->core_if = dwc_otg_cil_init(dwc_otg_device->base, &dwc_otg_module_params);
+	if (dwc_otg_device->core_if == 0) {
+		dev_err(&pdev->dev, "CIL initialization failed!\n");
+		retval = -ENOMEM;
+		goto fail;
+	}
+    // Validate parameter values
+	if (check_parameters(dwc_otg_device->core_if) != 0) {
+		retval = -EINVAL;
+		goto fail;
+	}
+
+	// Added for PLB DMA phys virt mapping
+	dwc_otg_device->core_if->phys_addr = dwc_otg_device->phys_addr;
+
+    // Create Device Attributes in sysfs
+    dwc_otg_attr_create(&pdev->dev);
+    // Disable the global interrupt until all the interrupt handlers are installed.
+    dwc_otg_disable_global_interrupts(dwc_otg_device->core_if);
+
+    // Install the interrupt handler for the common interrupts before enabling common interrupts in core_init below.
+    DWC_DEBUGPL(DBG_CIL, "registering (common) handler for irq%d\n", dwc_otg_device->irq);
+	retval = request_irq(dwc_otg_device->irq, dwc_otg_common_irq, IRQF_SHARED, "dwc_otg", dwc_otg_device);
+	if (retval != 0) {
+		DWC_ERROR("request of irq%d failed retval: %d\n", dwc_otg_device->irq, retval);
+		retval = -EBUSY;
+		goto fail;
+	} else dwc_otg_device->common_irq_installed = 1;
+
+#ifdef CONFIG_MACH_IPMATE
+    set_irq_type(_lmdev->irq, IRQT_LOW);
+#endif
+	// Initialize the DWC_otg core
+	dwc_otg_core_init(dwc_otg_device->core_if);
+
+#ifdef OTG_EXT_CHG_PUMP
+	// configure GPIO to use IRQ2, IRQ=58 (IRQ2)
+	irq = platform_get_irq(pdev, 1);
+	retval = request_irq(irq, dwc_otg_externalchgpump_irq, IRQF_SHARED, "dwc_otg_ext_chg_pump", dwc_otg_device);
+	if (retval != 0) {
+		DWC_ERROR("request of irq:2(ExtInt) failed retval: %d\n", retval);
+		retval = -EBUSY;
+		goto fail;
+	} else printk(KERN_INFO "%s: (ExtChgPump-OverCurrent Detection) IRQ2 registered\n", dwc_driver_name);
+#endif
+
+#ifndef CONFIG_DWC_HOST_ONLY
+ 	/* Initialize the PCD */
+	retval = dwc_otg_pcd_init(&pdev->dev);
+
+	if (retval != 0) {
+		DWC_ERROR("dwc_otg_pcd_init failed\n");
+		dwc_otg_device->pcd = NULL;
+		goto fail;
+	}
+
+#endif	/*  */
+#ifndef CONFIG_DWC_DEVICE_ONLY
+	/* Initialize the HCD */
+#if 1	/*fscz*/
+	/* force_host_mode */
+	usbcfg.d32 = dwc_read_reg32(&dwc_otg_device->core_if->core_global_regs ->gusbcfg);
+	usbcfg.b.force_host_mode = 1;
+	dwc_write_reg32(&dwc_otg_device->core_if->core_global_regs ->gusbcfg, usbcfg.d32);
+#endif
+	retval = dwc_otg_hcd_init(&pdev->dev, dwc_otg_device);
+	if (retval != 0) {
+		DWC_ERROR("dwc_otg_hcd_init failed\n");
+		dwc_otg_device->hcd = NULL;
+		goto fail;
+	}
+
+#endif	
+	/* Enable the global interrupt after all the interrupt handlers are installed */
+	dwc_otg_enable_global_interrupts(dwc_otg_device->core_if);
+#if 1	/*fscz*/
+	usbcfg.d32 = dwc_read_reg32(&dwc_otg_device->core_if->core_global_regs ->gusbcfg);
+	usbcfg.b.force_host_mode = 0;
+	dwc_write_reg32(&dwc_otg_device->core_if->core_global_regs ->gusbcfg, usbcfg.d32);
+#endif
+
+#ifdef CONFIG_OTG_PLB_DMA_TASKLET
+	atomic_set(&release_later, 0);
+	irq = platform_get_irq(pdev, 2);
+	retval = request_irq(irq, dwc_otg_plbdma, IRQF_SHARED,
+			     "dwc_otg_plbdma", dwc_otg_device);
+	if (retval != 0) {
+		DWC_ERROR("Request of irq %d failed retval: %d\n", PLB_DMA_CH_INT, retval);
+		retval = -EBUSY;
+		goto fail;
+	} else {
+		DWC_DEBUGPL(DBG_CIL, "%s Irq %d registered\n", dwc_driver_name,  PLB_DMA_CH_INT);
+	}
+#endif
+	return 0;
+
+fail:
+	dwc_otg_driver_remove(pdev);
+	return retval;
+}
+
+
+/**
+ * This structure defines the methods to be called by a bus driver
+ * during the lifecycle of a device on that bus. Both drivers and
+ * devices are registered with a bus driver. The bus driver matches
+ * devices to drivers based on information in the device and driver
+ * structures.
+ *
+ * The probe function is called when the bus driver matches a device
+ * to this driver. The remove function is called when a device is
+ * unregistered with the bus driver.
+ */
+static struct platform_driver dwc_otg_driver = {
+	.probe = dwc_otg_driver_probe,
+	.remove = dwc_otg_driver_remove,
+	.driver = {
+		.name = (char *)dwc_driver_name,
+		.bus = &platform_bus_type,
+	},
+};
+
+/**
+ * This function is called when the dwc_otg_driver is installed with the
+ * insmod command. It registers the dwc_otg_driver structure with the
+ * appropriate bus driver. This will cause the dwc_otg_driver_probe function
+ * to be called. In addition, the bus driver will automatically expose
+ * attributes defined for the device and driver in the special sysfs file
+ * system.
+ *
+ * @return
+ */
+static int  __init dwc_otg_driver_init(void) {
+	int retval = 0, ret = 0;
+	printk(KERN_INFO "%s: version %s\n", dwc_driver_name, DWC_DRIVER_VERSION);
+	retval = platform_driver_register(&dwc_otg_driver);
+	if (retval < 0) {
+		printk(KERN_ERR "%s registration failed. retval=%d\n", dwc_driver_name, retval);
+		return retval;
+	}
+	ret = driver_create_file(&dwc_otg_driver.driver, &driver_attr_version);
+	ret = driver_create_file(&dwc_otg_driver.driver, &driver_attr_debuglevel);
+	return retval;
+}
+
+module_init(dwc_otg_driver_init);
+
+/* This function is called when the driver is removed from the kernel with the rmmod command.
+ * The driver unregisters itself with its bus driver */
+static void __exit dwc_otg_driver_cleanup(void) {
+	printk(KERN_DEBUG "dwc_otg_driver_cleanup()\n");
+	driver_remove_file(&dwc_otg_driver.driver, &driver_attr_debuglevel);
+	driver_remove_file(&dwc_otg_driver.driver, &driver_attr_version);
+	platform_driver_unregister(&dwc_otg_driver);
+	printk(KERN_INFO "%s module removed\n", dwc_driver_name);
+} module_exit(dwc_otg_driver_cleanup);
+
+MODULE_DESCRIPTION(DWC_DRIVER_DESC);
+MODULE_AUTHOR("Synopsys Inc.");
+MODULE_LICENSE("GPL");
+
+module_param_named(otg_cap, dwc_otg_module_params.otg_cap, int, 0444);
+MODULE_PARM_DESC(otg_cap, "OTG Capabilities 0=HNP&SRP 1=SRP Only 2=None");
+module_param_named(opt, dwc_otg_module_params.opt, int, 0444);
+MODULE_PARM_DESC(opt, "OPT Mode");
+module_param_named(dma_enable, dwc_otg_module_params.dma_enable, int, 0444);
+MODULE_PARM_DESC(dma_enable, "DMA Mode 0=Slave 1=DMA enabled");
+module_param_named(dma_burst_size, dwc_otg_module_params.dma_burst_size, int,0444);
+MODULE_PARM_DESC(dma_burst_size,"DMA Burst Size 1, 4, 8, 16, 32, 64, 128, 256");
+module_param_named(speed, dwc_otg_module_params.speed, int, 0444);
+MODULE_PARM_DESC(speed, "Speed 0=High Speed 1=Full Speed");
+module_param_named(host_support_fs_ls_low_power,
+	dwc_otg_module_params.host_support_fs_ls_low_power, int,0444);
+MODULE_PARM_DESC(host_support_fs_ls_low_power,
+		  "Support Low Power w/FS or LS 0=Support 1=Don't Support");
+module_param_named(host_ls_low_power_phy_clk,
+		    dwc_otg_module_params.host_ls_low_power_phy_clk, int, 0444);
+MODULE_PARM_DESC(host_ls_low_power_phy_clk,
+		  "Low Speed Low Power Clock 0=48Mhz 1=6Mhz");
+module_param_named(enable_dynamic_fifo,
+		    dwc_otg_module_params.enable_dynamic_fifo, int, 0444);
+MODULE_PARM_DESC(enable_dynamic_fifo, "0=cC Setting 1=Allow Dynamic Sizing");
+module_param_named(data_fifo_size,
+	dwc_otg_module_params.data_fifo_size, int,0444);
+MODULE_PARM_DESC(data_fifo_size,
+		  "Total number of words in the data FIFO memory 32-32768");
+module_param_named(dev_rx_fifo_size, dwc_otg_module_params.dev_rx_fifo_size,
+		    int, 0444);
+MODULE_PARM_DESC(dev_rx_fifo_size, "Number of words in the Rx FIFO 16-32768");
+module_param_named(dev_nperio_tx_fifo_size,
+		    dwc_otg_module_params.dev_nperio_tx_fifo_size, int, 0444);
+MODULE_PARM_DESC(dev_nperio_tx_fifo_size,
+		  "Number of words in the non-periodic Tx FIFO 16-32768");
+module_param_named(dev_perio_tx_fifo_size_1,
+		    dwc_otg_module_params.dev_perio_tx_fifo_size[0], int, 0444);
+MODULE_PARM_DESC(dev_perio_tx_fifo_size_1,
+		  "Number of words in the periodic Tx FIFO 4-768");
+module_param_named(dev_perio_tx_fifo_size_2,
+		    dwc_otg_module_params.dev_perio_tx_fifo_size[1], int, 0444);
+MODULE_PARM_DESC(dev_perio_tx_fifo_size_2,
+		  "Number of words in the periodic Tx FIFO 4-768");
+module_param_named(dev_perio_tx_fifo_size_3,
+		    dwc_otg_module_params.dev_perio_tx_fifo_size[2], int, 0444);
+MODULE_PARM_DESC(dev_perio_tx_fifo_size_3,
+		  "Number of words in the periodic Tx FIFO 4-768");
+module_param_named(dev_perio_tx_fifo_size_4,
+		    dwc_otg_module_params.dev_perio_tx_fifo_size[3], int, 0444);
+MODULE_PARM_DESC(dev_perio_tx_fifo_size_4,
+		  "Number of words in the periodic Tx FIFO 4-768");
+module_param_named(dev_perio_tx_fifo_size_5,
+		    dwc_otg_module_params.dev_perio_tx_fifo_size[4], int, 0444);
+MODULE_PARM_DESC(dev_perio_tx_fifo_size_5,
+		  "Number of words in the periodic Tx FIFO 4-768");
+module_param_named(dev_perio_tx_fifo_size_6,
+		    dwc_otg_module_params.dev_perio_tx_fifo_size[5], int, 0444);
+MODULE_PARM_DESC(dev_perio_tx_fifo_size_6,
+		  "Number of words in the periodic Tx FIFO 4-768");
+module_param_named(dev_perio_tx_fifo_size_7,
+		    dwc_otg_module_params.dev_perio_tx_fifo_size[6], int, 0444);
+MODULE_PARM_DESC(dev_perio_tx_fifo_size_7,
+		  "Number of words in the periodic Tx FIFO 4-768");
+module_param_named(dev_perio_tx_fifo_size_8,
+		    dwc_otg_module_params.dev_perio_tx_fifo_size[7], int, 0444);
+MODULE_PARM_DESC(dev_perio_tx_fifo_size_8,
+		  "Number of words in the periodic Tx FIFO 4-768");
+module_param_named(dev_perio_tx_fifo_size_9,
+		    dwc_otg_module_params.dev_perio_tx_fifo_size[8], int, 0444);
+MODULE_PARM_DESC(dev_perio_tx_fifo_size_9,
+		  "Number of words in the periodic Tx FIFO 4-768");
+module_param_named(dev_perio_tx_fifo_size_10,
+		    dwc_otg_module_params.dev_perio_tx_fifo_size[9], int, 0444);
+MODULE_PARM_DESC(dev_perio_tx_fifo_size_10,
+		  "Number of words in the periodic Tx FIFO 4-768");
+module_param_named(dev_perio_tx_fifo_size_11,
+		    dwc_otg_module_params.dev_perio_tx_fifo_size[10], int,0444);
+MODULE_PARM_DESC(dev_perio_tx_fifo_size_11,
+		  "Number of words in the periodic Tx FIFO 4-768");
+module_param_named(dev_perio_tx_fifo_size_12,
+		    dwc_otg_module_params.dev_perio_tx_fifo_size[11], int,0444);
+MODULE_PARM_DESC(dev_perio_tx_fifo_size_12,
+		  "Number of words in the periodic Tx FIFO 4-768");
+module_param_named(dev_perio_tx_fifo_size_13,
+		    dwc_otg_module_params.dev_perio_tx_fifo_size[12], int,0444);
+MODULE_PARM_DESC(dev_perio_tx_fifo_size_13,
+		  "Number of words in the periodic Tx FIFO 4-768");
+module_param_named(dev_perio_tx_fifo_size_14,
+		    dwc_otg_module_params.dev_perio_tx_fifo_size[13], int,0444);
+MODULE_PARM_DESC(dev_perio_tx_fifo_size_14,
+		  "Number of words in the periodic Tx FIFO 4-768");
+module_param_named(dev_perio_tx_fifo_size_15,
+		    dwc_otg_module_params.dev_perio_tx_fifo_size[14], int,0444);
+MODULE_PARM_DESC(dev_perio_tx_fifo_size_15,
+		  "Number of words in the periodic Tx FIFO 4-768");
+module_param_named(host_rx_fifo_size, dwc_otg_module_params.host_rx_fifo_size,
+		    int, 0444);
+MODULE_PARM_DESC(host_rx_fifo_size, "Number of words in the Rx FIFO 16-32768");
+module_param_named(host_nperio_tx_fifo_size,
+		    dwc_otg_module_params.host_nperio_tx_fifo_size, int, 0444);
+MODULE_PARM_DESC(host_nperio_tx_fifo_size,
+		  "Number of words in the non-periodic Tx FIFO 16-32768");
+module_param_named(host_perio_tx_fifo_size,
+		    dwc_otg_module_params.host_perio_tx_fifo_size, int, 0444);
+MODULE_PARM_DESC(host_perio_tx_fifo_size,
+		  "Number of words in the host periodic Tx FIFO 16-32768");
+module_param_named(max_transfer_size, dwc_otg_module_params.max_transfer_size,
+		    int, 0444);
+
+/** @todo Set the max to 512K, modify checks */
+MODULE_PARM_DESC(max_transfer_size,
+		 "The maximum transfer size supported in bytes 2047-65535");
+module_param_named(max_packet_count, dwc_otg_module_params.max_packet_count,
+		    int, 0444);
+MODULE_PARM_DESC(max_packet_count,
+		  "The maximum number of packets in a transfer 15-511");
+module_param_named(host_channels, dwc_otg_module_params.host_channels, int, 0444);
+MODULE_PARM_DESC(host_channels,
+		  "The number of host channel registers to use 1-16");
+module_param_named(dev_endpoints, dwc_otg_module_params.dev_endpoints, int, 0444);
+MODULE_PARM_DESC(dev_endpoints,
+		  "The number of endpoints in addition to EP0 available for device mode 1-15");
+module_param_named(phy_type, dwc_otg_module_params.phy_type, int, 0444);
+MODULE_PARM_DESC(phy_type, "0=Reserved 1=UTMI+ 2=ULPI");
+module_param_named(phy_utmi_width, dwc_otg_module_params.phy_utmi_width, int,
+		    0444);
+MODULE_PARM_DESC(phy_utmi_width,
+		  "Specifies the UTMI+ Data Width 8 or 16 bits");
+module_param_named(phy_ulpi_ddr, dwc_otg_module_params.phy_ulpi_ddr, int,
+		    0444);
+MODULE_PARM_DESC(phy_ulpi_ddr,
+#if 1 /*fscz*/
+		  "0");
+#else
+		  "ULPI at double or single data rate 0=Single 1=Double");
+#endif
+module_param_named(phy_ulpi_ext_vbus, dwc_otg_module_params.phy_ulpi_ext_vbus,
+		    int, 0444);
+MODULE_PARM_DESC(phy_ulpi_ext_vbus,
+		  "ULPI PHY using internal or external vbus 0=Internal");
+module_param_named(i2c_enable, dwc_otg_module_params.i2c_enable, int, 0444);
+MODULE_PARM_DESC(i2c_enable, "FS PHY Interface");
+module_param_named(ulpi_fs_ls, dwc_otg_module_params.ulpi_fs_ls, int, 0444);
+MODULE_PARM_DESC(ulpi_fs_ls, "ULPI PHY FS/LS mode only");
+module_param_named(ts_dline, dwc_otg_module_params.ts_dline, int, 0444);
+MODULE_PARM_DESC(ts_dline, "Term select Dline pulsing for all PHYs");
+module_param_named(debug, g_dbg_lvl, int, 0444);
+MODULE_PARM_DESC(debug, "0");
+module_param_named(en_multiple_tx_fifo,
+		     dwc_otg_module_params.en_multiple_tx_fifo, int, 0444);
+MODULE_PARM_DESC(en_multiple_tx_fifo,
+		  "Dedicated Non Periodic Tx FIFOs 0=disabled 1=enabled");
+module_param_named(dev_tx_fifo_size_1,
+		    dwc_otg_module_params.dev_tx_fifo_size[0], int, 0444);
+MODULE_PARM_DESC(dev_tx_fifo_size_1, "Number of words in the Tx FIFO 4-768");
+module_param_named(dev_tx_fifo_size_2,
+		    dwc_otg_module_params.dev_tx_fifo_size[1], int, 0444);
+MODULE_PARM_DESC(dev_tx_fifo_size_2, "Number of words in the Tx FIFO 4-768");
+module_param_named(dev_tx_fifo_size_3,
+		    dwc_otg_module_params.dev_tx_fifo_size[2], int, 0444);
+MODULE_PARM_DESC(dev_tx_fifo_size_3, "Number of words in the Tx FIFO 4-768");
+module_param_named(dev_tx_fifo_size_4,
+		    dwc_otg_module_params.dev_tx_fifo_size[3], int, 0444);
+MODULE_PARM_DESC(dev_tx_fifo_size_4, "Number of words in the Tx FIFO 4-768");
+module_param_named(dev_tx_fifo_size_5,
+		    dwc_otg_module_params.dev_tx_fifo_size[4], int, 0444);
+MODULE_PARM_DESC(dev_tx_fifo_size_5, "Number of words in the Tx FIFO 4-768");
+module_param_named(dev_tx_fifo_size_6,
+		    dwc_otg_module_params.dev_tx_fifo_size[5], int, 0444);
+MODULE_PARM_DESC(dev_tx_fifo_size_6, "Number of words in the Tx FIFO 4-768");
+module_param_named(dev_tx_fifo_size_7,
+		    dwc_otg_module_params.dev_tx_fifo_size[6], int, 0444);
+MODULE_PARM_DESC(dev_tx_fifo_size_7, "Number of words in the Tx FIFO 4-768");
+module_param_named(dev_tx_fifo_size_8,
+		    dwc_otg_module_params.dev_tx_fifo_size[7], int, 0444);
+MODULE_PARM_DESC(dev_tx_fifo_size_8, "Number of words in the Tx FIFO 4-768");
+module_param_named(dev_tx_fifo_size_9,
+		    dwc_otg_module_params.dev_tx_fifo_size[8], int, 0444);
+MODULE_PARM_DESC(dev_tx_fifo_size_9, "Number of words in the Tx FIFO 4-768");
+module_param_named(dev_tx_fifo_size_10,
+		    dwc_otg_module_params.dev_tx_fifo_size[9], int, 0444);
+MODULE_PARM_DESC(dev_tx_fifo_size_10, "Number of words in the Tx FIFO 4-768");
+module_param_named(dev_tx_fifo_size_11,
+		    dwc_otg_module_params.dev_tx_fifo_size[10], int, 0444);
+MODULE_PARM_DESC(dev_tx_fifo_size_11, "Number of words in the Tx FIFO 4-768");
+module_param_named(dev_tx_fifo_size_12,
+		    dwc_otg_module_params.dev_tx_fifo_size[11], int, 0444);
+MODULE_PARM_DESC(dev_tx_fifo_size_12, "Number of words in the Tx FIFO 4-768");
+module_param_named(dev_tx_fifo_size_13,
+		    dwc_otg_module_params.dev_tx_fifo_size[12], int, 0444);
+MODULE_PARM_DESC(dev_tx_fifo_size_13, "Number of words in the Tx FIFO 4-768");
+module_param_named(dev_tx_fifo_size_14,
+		    dwc_otg_module_params.dev_tx_fifo_size[13], int, 0444);
+MODULE_PARM_DESC(dev_tx_fifo_size_14, "Number of words in the Tx FIFO 4-768");
+module_param_named(dev_tx_fifo_size_15,
+		    dwc_otg_module_params.dev_tx_fifo_size[14], int, 0444);
+MODULE_PARM_DESC(dev_tx_fifo_size_15, "Number of words in the Tx FIFO 4-768");
+module_param_named(thr_ctl, dwc_otg_module_params.thr_ctl, int, 0444);
+MODULE_PARM_DESC(thr_ctl, "Thresholding enable flag bit"
+		"0 - non ISO Tx thr., 1 - ISO Tx thr., 2 - Rx thr.- bit 0=disabled 1=enabled");
+module_param_named(tx_thr_length, dwc_otg_module_params.tx_thr_length, int, 0444);
+MODULE_PARM_DESC(tx_thr_length, "Tx Threshold length in 32 bit DWORDs");
+module_param_named(rx_thr_length, dwc_otg_module_params.rx_thr_length, int, 0444);
+MODULE_PARM_DESC(rx_thr_length, "Rx Threshold length in 32 bit DWORDs");
+
+/** @page "Module Parameters"
+ *
+ * The following parameters may be specified when starting the module.
+ * These parameters define how the DWC_otg controller should be
+ * configured.	Parameter values are passed to the CIL initialization
+ * function dwc_otg_cil_init
+ *
+ * Example: <code>modprobe dwc_otg speed=1 otg_cap=1</code>
+ *
+
+ <table>
+ <tr><td>Parameter Name</td><td>Meaning</td></tr>
+
+ <tr>
+ <td>otg_cap</td>
+ <td>Specifies the OTG capabilities. The driver will automatically detect the
+ value for this parameter if none is specified.
+ - 0: HNP and SRP capable (default, if available)
+ - 1: SRP Only capable
+ - 2: No HNP/SRP capable
+ </td></tr>
+
+ <tr>
+ <td>dma_enable</td>
+ <td>Specifies whether to use slave or DMA mode for accessing the data FIFOs.
+ The driver will automatically detect the value for this parameter if none is
+ specified.
+ - 0: Slave
+ - 1: DMA (default, if available)
+ </td></tr>
+
+ <tr>
+ <td>dma_burst_size</td>
+ <td>The DMA Burst size (applicable only for External DMA Mode).
+ - Values: 1, 4, 8 16, 32, 64, 128, 256 (default 32)
+ </td></tr>
+
+ <tr>
+ <td>speed</td>
+ <td>Specifies the maximum speed of operation in host and device mode. The
+ actual speed depends on the speed of the attached device and the value of
+ phy_type.
+ - 0: High Speed (default)
+ - 1: Full Speed
+ </td></tr>
+
+ <tr>
+ <td>host_support_fs_ls_low_power</td>
+ <td>Specifies whether low power mode is supported when attached to a Full
+ Speed or Low Speed device in host mode.
+ - 0: Don't support low power mode (default)
+ - 1: Support low power mode
+ </td></tr>
+
+ <tr>
+ <td>host_ls_low_power_phy_clk</td>
+ <td>Specifies the PHY clock rate in low power mode when connected to a Low
+ Speed device in host mode. This parameter is applicable only if
+ HOST_SUPPORT_FS_LS_LOW_POWER is enabled.
+ - 0: 48 MHz (default)
+ - 1: 6 MHz
+ </td></tr>
+
+ <tr>
+ <td>enable_dynamic_fifo</td>
+ <td> Specifies whether FIFOs may be resized by the driver software.
+ - 0: Use cC FIFO size parameters
+ - 1: Allow dynamic FIFO sizing (default)
+ </td></tr>
+
+ <tr>
+ <td>data_fifo_size</td>
+ <td>Total number of 4-byte words in the data FIFO memory. This memory
+ includes the Rx FIFO, non-periodic Tx FIFO, and periodic Tx FIFOs.
+ - Values: 32 to 32768 (default 8192)
+
+ Note: The total FIFO memory depth in the FPGA configuration is 8192.
+ </td></tr>
+
+ <tr>
+ <td>dev_rx_fifo_size</td>
+ <td>Number of 4-byte words in the Rx FIFO in device mode when dynamic
+ FIFO sizing is enabled.
+ - Values: 16 to 32768 (default 1064)
+ </td></tr>
+
+ <tr>
+ <td>dev_nperio_tx_fifo_size</td>
+ <td>Number of 4-byte words in the non-periodic Tx FIFO in device mode when
+ dynamic FIFO sizing is enabled.
+ - Values: 16 to 32768 (default 1024)
+ </td></tr>
+
+ <tr>
+ <td>dev_perio_tx_fifo_size_n (n = 1 to 15)</td>
+ <td>Number of 4-byte words in each of the periodic Tx FIFOs in device mode
+ when dynamic FIFO sizing is enabled.
+ - Values: 4 to 768 (default 256)
+ </td></tr>
+
+ <tr>
+ <td>host_rx_fifo_size</td>
+ <td>Number of 4-byte words in the Rx FIFO in host mode when dynamic FIFO
+ sizing is enabled.
+ - Values: 16 to 32768 (default 1024)
+ </td></tr>
+
+ <tr>
+ <td>host_nperio_tx_fifo_size</td>
+ <td>Number of 4-byte words in the non-periodic Tx FIFO in host mode when
+ dynamic FIFO sizing is enabled in the core.
+ - Values: 16 to 32768 (default 1024)
+ </td></tr>
+
+ <tr>
+ <td>host_perio_tx_fifo_size</td>
+ <td>Number of 4-byte words in the host periodic Tx FIFO when dynamic FIFO
+ sizing is enabled.
+ - Values: 16 to 32768 (default 1024)
+ </td></tr>
+
+ <tr>
+ <td>max_transfer_size</td>
+ <td>The maximum transfer size supported in bytes.
+ - Values: 2047 to 65,535 (default 65,535)
+ </td></tr>
+
+ <tr>
+ <td>max_packet_count</td>
+ <td>The maximum number of packets in a transfer.
+ - Values: 15 to 511 (default 511)
+ </td></tr>
+
+ <tr>
+ <td>host_channels</td>
+ <td>The number of host channel registers to use.
+ - Values: 1 to 16 (default 12)
+
+ Note: The FPGA configuration supports a maximum of 12 host channels.
+ </td></tr>
+
+ <tr>
+ <td>dev_endpoints</td>
+ <td>The number of endpoints in addition to EP0 available for device mode
+ operations.
+ - Values: 1 to 15 (default 6 IN and OUT)
+
+ Note: The FPGA configuration supports a maximum of 6 IN and OUT endpoints in
+ addition to EP0.
+ </td></tr>
+
+ <tr>
+ <td>phy_type</td>
+ <td>Specifies the type of PHY interface to use. By default, the driver will
+ automatically detect the phy_type.
+ - 0: Full Speed
+ - 1: UTMI+ (default, if available)
+ - 2: ULPI
+ </td></tr>
+
+ <tr>
+ <td>phy_utmi_width</td>
+ <td>Specifies the UTMI+ Data Width. This parameter is applicable for a
+ phy_type of UTMI+. Also, this parameter is applicable only if the
+ OTG_HSPHY_WIDTH cC parameter was set to "8 and 16 bits", meaning that the
+ core has been configured to work at either data path width.
+ - Values: 8 or 16 bits (default 16)
+ </td></tr>
+
+ <tr>
+ <td>phy_ulpi_ddr</td>
+ <td>Specifies whether the ULPI operates at double or single data rate. This
+ parameter is only applicable if phy_type is ULPI.
+ - 0: single data rate ULPI interface with 8 bit wide data bus (default)
+ - 1: double data rate ULPI interface with 4 bit wide data bus
+ </td></tr>
+
+ <tr>
+ <td>i2c_enable</td>
+ <td>Specifies whether to use the I2C interface for full speed PHY. This
+ parameter is only applicable if PHY_TYPE is FS.
+ - 0: Disabled (default)
+ - 1: Enabled
+ </td></tr>
+
+ <tr>
+ <td>otg_en_multiple_tx_fifo</td>
+ <td>Specifies whether dedicatedto tx fifos are enabled for non periodic IN EPs.
+ The driver will automatically detect the value for this parameter if none is
+ specified.
+ - 0: Disabled
+ - 1: Enabled (default, if available)
+ </td></tr>
+
+ <tr>
+ <td>dev_tx_fifo_size_n (n = 1 to 15)</td>
+ <td>Number of 4-byte words in each of the Tx FIFOs in device mode
+ when dynamic FIFO sizing is enabled.
+ - Values: 4 to 768 (default 256)
+ </td></tr>
+
+*/
+
diff -Naur a/drivers/usb/dwc_otg/dwc_otg_driver.h b/drivers/usb/dwc_otg/dwc_otg_driver.h
--- a/drivers/usb/dwc_otg/dwc_otg_driver.h	1970-01-01 00:00:00.000000000 +0000
+++ b/drivers/usb/dwc_otg/dwc_otg_driver.h	2016-01-31 16:10:52.000000000 +0000
@@ -0,0 +1,82 @@
+/* ==========================================================================
+ * $File: //dwh/usb_iip/dev/software/otg_ipmate/linux/drivers/dwc_otg_driver.h $
+ * $Revision: #2 $
+ * $Date: 2007/02/07 $
+ * $Change: 791271 $
+ *
+ * Synopsys HS OTG Linux Software Driver and documentation (hereinafter,
+ * "Software") is an Unsupported proprietary work of Synopsys, Inc. unless
+ * otherwise expressly agreed to in writing between Synopsys and you.
+ *
+ * The Software IS NOT an item of Licensed Software or Licensed Product under
+ * any End User Software License Agreement or Agreement for Licensed Product
+ * with Synopsys or any supplement thereto. You are permitted to use and
+ * redistribute this Software in source and binary forms, with or without
+ * modification, provided that redistributions of source code must retain this
+ * notice. You may not view, use, disclose, copy or distribute this file or
+ * any information contained herein except pursuant to this license grant from
+ * Synopsys. If you do not agree with this notice, including the disclaimer
+ * below, then you are not authorized to use the Software.
+ *
+ * THIS SOFTWARE IS BEING DISTRIBUTED BY SYNOPSYS SOLELY ON AN "AS IS" BASIS
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE HEREBY DISCLAIMED. IN NO EVENT SHALL SYNOPSYS BE LIABLE FOR ANY DIRECT,
+ * INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+ * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+ * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+ * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
+ * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
+ * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH
+ * DAMAGE.
+ * ========================================================================== */
+
+#if !defined(__DWC_OTG_DRIVER_H__)
+#define __DWC_OTG_DRIVER_H__
+
+/** @file
+ * This file contains the interface to the Linux driver.
+ */
+#include "dwc_otg_cil.h"
+
+/* Type declarations */
+struct dwc_otg_pcd;
+struct dwc_otg_hcd;
+
+/**
+ * This structure is a wrapper that encapsulates the driver components used to
+ * manage a single DWC_otg controller.
+ */
+typedef struct dwc_otg_device
+{
+	/** Base address returned from ioremap() */
+	void *base;
+
+	/** Pointer to the core interface structure. */
+	dwc_otg_core_if_t *core_if;
+
+	/** Register offset for Diagnostic API.*/
+	uint32_t reg_offset;
+
+	/** Pointer to the PCD structure. */
+	struct dwc_otg_pcd *pcd;
+
+	/** Pointer to the HCD structure. */
+	struct dwc_otg_hcd *hcd;
+
+	/** Flag to indicate whether the common IRQ handler is installed. */
+	uint8_t common_irq_installed;
+
+    /** Interrupt request number. */
+	unsigned int irq;
+
+    /** Physical address of Control and Status registers, used by
+     *  release_mem_region().
+     */
+	resource_size_t phys_addr;
+
+    /** Length of memory region, used by release_mem_region(). */
+	unsigned long base_len;
+} dwc_otg_device_t;
+
+#endif
diff -Naur a/drivers/usb/dwc_otg/dwc_otg_hcd.c b/drivers/usb/dwc_otg/dwc_otg_hcd.c
--- a/drivers/usb/dwc_otg/dwc_otg_hcd.c	1970-01-01 00:00:00.000000000 +0000
+++ b/drivers/usb/dwc_otg/dwc_otg_hcd.c	2017-06-20 10:43:33.750229557 +0000
@@ -0,0 +1,2945 @@
+/* ==========================================================================
+ * $File: //dwh/usb_iip/dev/software/otg_ipmate/linux/drivers/dwc_otg_hcd.c $
+ * $Revision: #16 $
+ * $Date: 2006/12/05 $
+ * $Change: 762293 $
+ *
+ * Synopsys HS OTG Linux Software Driver and documentation (hereinafter,
+ * "Software") is an Unsupported proprietary work of Synopsys, Inc. unless
+ * otherwise expressly agreed to in writing between Synopsys and you.
+ *
+ * The Software IS NOT an item of Licensed Software or Licensed Product under
+ * any End User Software License Agreement or Agreement for Licensed Product
+ * with Synopsys or any supplement thereto. You are permitted to use and
+ * redistribute this Software in source and binary forms, with or without
+ * modification, provided that redistributions of source code must retain this
+ * notice. You may not view, use, disclose, copy or distribute this file or
+ * any information contained herein except pursuant to this license grant from
+ * Synopsys. If you do not agree with this notice, including the disclaimer
+ * below, then you are not authorized to use the Software.
+ *
+ * THIS SOFTWARE IS BEING DISTRIBUTED BY SYNOPSYS SOLELY ON AN "AS IS" BASIS
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE HEREBY DISCLAIMED. IN NO EVENT SHALL SYNOPSYS BE LIABLE FOR ANY DIRECT,
+ * INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+ * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+ * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+ * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
+ * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
+ * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH
+ * DAMAGE.
+ * ========================================================================== */
+
+#ifndef CONFIG_DWC_DEVICE_ONLY
+
+/**
+ * @file
+ *
+ * This file contains the implementation of the HCD. In Linux, the HCD
+ * implements the hc_driver API.
+ */
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/moduleparam.h>
+#include <linux/init.h>
+#include <linux/device.h>
+#include <linux/errno.h>
+#include <linux/list.h>
+#include <linux/interrupt.h>
+#include <linux/string.h>
+#include <linux/dma-mapping.h>
+
+#include "dwc_otg_driver.h"
+#include "dwc_otg_hcd.h"
+#include "dwc_otg_regs.h"
+extern atomic_t release_later;
+
+static u64 dma_mask = DMA_BIT_MASK(32);
+
+static const char dwc_otg_hcd_name[] = "dwc_otg_hcd";
+
+static int dwc_otg_hcd_suspend(struct usb_hcd *hcd)
+{
+	/* FIXME: Write code to right suspend processing */
+	return 0;
+}
+
+static int dwc_otg_hcd_resume(struct usb_hcd *hcd)
+{
+	/* FIXME: Write code to right resume processing */
+	return 0;
+}
+
+static const struct hc_driver dwc_otg_hc_driver =
+{
+	.description = dwc_otg_hcd_name,
+	.product_desc = "DWC OTG Controller",
+	.hcd_priv_size = sizeof(dwc_otg_hcd_t),
+	.irq = dwc_otg_hcd_irq,
+	.flags = HCD_MEMORY | HCD_USB2,
+	//.reset =
+	.start = dwc_otg_hcd_start,
+#ifdef	CONFIG_PM
+	.bus_suspend = dwc_otg_hcd_suspend,
+	.bus_resume = dwc_otg_hcd_resume,
+#endif
+	.stop = dwc_otg_hcd_stop,
+	.urb_enqueue = dwc_otg_hcd_urb_enqueue,
+	.urb_dequeue = dwc_otg_hcd_urb_dequeue,
+	.endpoint_disable = dwc_otg_hcd_endpoint_disable,
+	.get_frame_number = dwc_otg_hcd_get_frame_number,
+	.hub_status_data = dwc_otg_hcd_hub_status_data,
+	.hub_control = dwc_otg_hcd_hub_control,
+	//.hub_suspend =
+	//.hub_resume =
+};
+
+
+/**
+ * Work queue function for starting the HCD when A-Cable is connected.
+ * The dwc_otg_hcd_start() must be called in a process context.
+ */
+static void hcd_start_func(struct work_struct *work)
+{
+	struct dwc_otg_hcd *priv =
+		container_of(work, struct dwc_otg_hcd, start_work);
+	struct usb_hcd *usb_hcd = (struct usb_hcd *)priv->_p;
+	DWC_DEBUGPL(DBG_HCDV, "%s() %p\n", __func__, usb_hcd);
+	if (usb_hcd) {
+		dwc_otg_hcd_start(usb_hcd);
+	}
+}
+
+
+/**
+ * HCD Callback function for starting the HCD when A-Cable is
+ * connected.
+ *
+ * @param _p void pointer to the <code>struct usb_hcd</code>
+ */
+static int32_t dwc_otg_hcd_start_cb(void *_p)
+{
+	dwc_otg_hcd_t * dwc_otg_hcd = hcd_to_dwc_otg_hcd(_p);
+	dwc_otg_core_if_t * core_if = dwc_otg_hcd->core_if;
+	hprt0_data_t hprt0;
+	if (core_if->op_state == B_HOST) {
+	    /*
+	     * Reset the port.  During a HNP mode switch the reset
+	     * needs to occur within 1ms and have a duration of at
+	     * least 50ms.
+	     */
+	    hprt0.d32 = dwc_otg_read_hprt0(core_if);
+		hprt0.b.prtrst = 1;
+		dwc_write_reg32(core_if->host_if->hprt0, hprt0.d32);
+		((struct usb_hcd *)_p)->self.is_b_host = 1;
+	} else {
+		((struct usb_hcd *)_p)->self.is_b_host = 0;
+	}
+	/* Need to start the HCD in a non-interrupt context. */
+	INIT_WORK(&dwc_otg_hcd->start_work, hcd_start_func);
+	dwc_otg_hcd->_p = _p;
+	schedule_work(&dwc_otg_hcd->start_work);
+	return 1;
+}
+
+
+/**
+ * HCD Callback function for stopping the HCD.
+ *
+ * @param _p void pointer to the <code>struct usb_hcd</code>
+ */
+static int32_t dwc_otg_hcd_stop_cb(void *_p)
+{
+	struct usb_hcd *usb_hcd = (struct usb_hcd *)_p;
+	DWC_DEBUGPL(DBG_HCDV, "%s(%p)\n", __func__, _p);
+	dwc_otg_hcd_stop(usb_hcd);
+	return 1;
+}
+static void del_xfer_timers(dwc_otg_hcd_t * _hcd)
+{
+
+#ifdef CONFIG_DWC_DEBUG
+	int i;
+	int num_channels = _hcd->core_if->core_params->host_channels;
+	for (i = 0; i < num_channels; i++) {
+		del_timer(&_hcd->core_if->hc_xfer_timer[i]);
+	}
+
+#endif	/*  */
+}
+static void del_timers(dwc_otg_hcd_t * _hcd)
+{
+	del_xfer_timers(_hcd);
+	del_timer(&_hcd->conn_timer);
+}
+
+/**
+ * Processes all the URBs in a single list of QHs. Completes them with
+ * -ETIMEDOUT and frees the QTD.
+ */
+static void kill_urbs_in_qh_list(dwc_otg_hcd_t * _hcd,
+				 struct list_head *_qh_list)
+{
+	struct list_head *qh_item;
+	dwc_otg_qh_t * qh;
+	struct list_head *qtd_item;
+	dwc_otg_qtd_t * qtd;
+	list_for_each(qh_item, _qh_list) {
+		qh = list_entry(qh_item, dwc_otg_qh_t, qh_list_entry);
+		for (qtd_item = qh->qtd_list.next; qtd_item != &qh->qtd_list;
+			qtd_item = qh->qtd_list.next) {
+			qtd = list_entry(qtd_item, dwc_otg_qtd_t, qtd_list_entry);
+			if (qtd->urb != NULL) {
+				dwc_otg_hcd_complete_urb(_hcd, qtd->urb,-ETIMEDOUT);
+			}
+			dwc_otg_hcd_qtd_remove_and_free(qtd);
+		}
+	}
+}
+
+/**
+ * Responds with an error status of ETIMEDOUT to all URBs in the non-periodic
+ * and periodic schedules. The QTD associated with each URB is removed from
+ * the schedule and freed. This function may be called when a disconnect is
+ * detected or when the HCD is being stopped.
+ */
+static void kill_all_urbs(dwc_otg_hcd_t * _hcd)
+{
+	kill_urbs_in_qh_list(_hcd, &_hcd->non_periodic_sched_deferred);
+	kill_urbs_in_qh_list(_hcd, &_hcd->non_periodic_sched_inactive);
+	kill_urbs_in_qh_list(_hcd, &_hcd->non_periodic_sched_active);
+	kill_urbs_in_qh_list(_hcd, &_hcd->periodic_sched_inactive);
+	kill_urbs_in_qh_list(_hcd, &_hcd->periodic_sched_ready);
+	kill_urbs_in_qh_list(_hcd, &_hcd->periodic_sched_assigned);
+	kill_urbs_in_qh_list(_hcd, &_hcd->periodic_sched_queued);
+}
+
+/**
+ * HCD Callback function for disconnect of the HCD.
+ *
+ * @param _p void pointer to the <code>struct usb_hcd</code>
+ */
+static int32_t dwc_otg_hcd_disconnect_cb(void *_p)
+{
+	gintsts_data_t intr;
+	dwc_otg_hcd_t * dwc_otg_hcd = hcd_to_dwc_otg_hcd(_p);
+
+    //DWC_DEBUGPL(DBG_HCDV, "%s(%p)\n", __func__, _p);
+
+    /*
+     * Set status flags for the hub driver.
+     */
+    dwc_otg_hcd->flags.b.port_connect_status_change = 1;
+	dwc_otg_hcd->flags.b.port_connect_status = 0;
+
+    /*
+     * Shutdown any transfers in process by clearing the Tx FIFO Empty
+     * interrupt mask and status bits and disabling subsequent host
+     * channel interrupts.
+     */
+    intr.d32 = 0;
+	intr.b.nptxfempty = 1;
+	intr.b.ptxfempty = 1;
+	intr.b.hcintr = 1;
+	dwc_modify_reg32(&dwc_otg_hcd->core_if->core_global_regs->gintmsk,
+			  intr.d32, 0);
+	dwc_modify_reg32(&dwc_otg_hcd->core_if->core_global_regs->gintsts,
+			  intr.d32, 0);
+	del_timers(dwc_otg_hcd);
+
+    /*
+     * Turn off the vbus power only if the core has transitioned to device
+     * mode. If still in host mode, need to keep power on to detect a
+     * reconnection.
+     */
+    if (dwc_otg_is_device_mode(dwc_otg_hcd->core_if)) {
+		if (dwc_otg_hcd->core_if->op_state != A_SUSPEND) {
+			hprt0_data_t hprt0 = {.d32 = 0};
+			DWC_PRINT("Disconnect: PortPower off\n");
+			hprt0.b.prtpwr = 0;
+			dwc_write_reg32(dwc_otg_hcd->core_if->host_if->hprt0,
+					 hprt0.d32);
+		}
+		dwc_otg_disable_host_interrupts(dwc_otg_hcd->core_if);
+	}
+
+    /* Respond with an error status to all URBs in the schedule. */
+    kill_all_urbs(dwc_otg_hcd);
+	if (dwc_otg_is_host_mode(dwc_otg_hcd->core_if)) {
+	    /* Clean up any host channels that were in use. */
+		int num_channels;
+		int i;
+		dwc_hc_t * channel;
+		dwc_otg_hc_regs_t * hc_regs;
+		hcchar_data_t hcchar;
+		unsigned long flags;
+		num_channels = dwc_otg_hcd->core_if->core_params->host_channels;
+		if (!dwc_otg_hcd->core_if->dma_enable) {
+		    /* Flush out any channel requests in slave mode. */
+		    for (i = 0; i < num_channels; i++) {
+				channel = dwc_otg_hcd->hc_ptr_array[i];
+				if (list_empty(&channel->hc_list_entry)) {
+					hc_regs = dwc_otg_hcd->core_if->host_if->hc_regs[i];
+					hcchar.d32 = dwc_read_reg32(&hc_regs->hcchar);
+					if (hcchar.b.chen) {
+						hcchar.b.chen = 0;
+						hcchar.b.chdis = 1;
+						hcchar.b.epdir = 0;
+						dwc_write_reg32(&hc_regs->hcchar,hcchar.d32);
+					}
+				}
+			}
+		}
+		for (i = 0; i < num_channels; i++) {
+			channel = dwc_otg_hcd->hc_ptr_array[i];
+			if (list_empty(&channel->hc_list_entry)) {
+				hc_regs = dwc_otg_hcd->core_if->host_if->hc_regs[i];
+				hcchar.d32 = dwc_read_reg32(&hc_regs->hcchar);
+				if (hcchar.b.chen) {
+				    /* Halt the channel. */
+				    hcchar.b.chdis = 1;
+					dwc_write_reg32(&hc_regs->hcchar,hcchar.d32);
+				}
+				dwc_otg_hc_cleanup(dwc_otg_hcd->core_if,channel);
+				list_add_tail(&channel->hc_list_entry,
+					       &dwc_otg_hcd->free_hc_list);
+				local_irq_save(flags);
+				dwc_otg_hcd->available_host_channels ++;
+				local_irq_restore(flags);
+				
+			}
+		}
+	}
+
+    /* A disconnect will end the session so the B-Device is no
+     * longer a B-host. */
+    ((struct usb_hcd *)_p)->self.is_b_host = 0;
+	return 1;
+}
+
+/**
+ * Connection timeout function.  An OTG host is required to display a
+ * message if the device does not connect within 10 seconds.
+ */
+void dwc_otg_hcd_connect_timeout(unsigned long _ptr)
+{
+	DWC_DEBUGPL(DBG_HCDV, "%s(%x)\n", __func__, (int)_ptr);
+	DWC_PRINT("Connect Timeout\n");
+	DWC_ERROR("Device Not Connected/Responding\n");
+}
+
+/**
+ * Start the connection timer.  An OTG host is required to display a
+ * message if the device does not connect within 10 seconds.  The
+ * timer is deleted if a port connect interrupt occurs before the
+ * timer expires.
+ */
+static void dwc_otg_hcd_start_connect_timer(dwc_otg_hcd_t * _hcd)
+{
+	init_timer(&_hcd->conn_timer);
+	_hcd->conn_timer.function = dwc_otg_hcd_connect_timeout;
+	_hcd->conn_timer.data = (unsigned long)0;
+	_hcd->conn_timer.expires = jiffies + (HZ * 10);
+	add_timer(&_hcd->conn_timer);
+}
+
+/**
+ * HCD Callback function for disconnect of the HCD.
+ *
+ * @param _p void pointer to the <code>struct usb_hcd</code>
+ */
+static int32_t dwc_otg_hcd_session_start_cb(void *_p)
+{
+	dwc_otg_hcd_t * dwc_otg_hcd = hcd_to_dwc_otg_hcd(_p);
+	DWC_DEBUGPL(DBG_HCDV, "%s(%p)\n", __func__, _p);
+	dwc_otg_hcd_start_connect_timer(dwc_otg_hcd);
+	return 1;
+}
+
+
+/**
+ * HCD Callback structure for handling mode switching.
+ */
+static dwc_otg_cil_callbacks_t hcd_cil_callbacks =
+{
+	.start = dwc_otg_hcd_start_cb,
+	.stop = dwc_otg_hcd_stop_cb,
+	.disconnect = dwc_otg_hcd_disconnect_cb,
+	.session_start = dwc_otg_hcd_session_start_cb,
+	.p = 0,
+};
+
+
+/**
+ * Reset tasklet function
+ */
+static void reset_tasklet_func(unsigned long data)
+{
+	dwc_otg_hcd_t * dwc_otg_hcd = (dwc_otg_hcd_t *) data;
+	dwc_otg_core_if_t * core_if = dwc_otg_hcd->core_if;
+	hprt0_data_t hprt0;
+	DWC_DEBUGPL(DBG_HCDV, "USB RESET tasklet called\n");
+	hprt0.d32 = dwc_otg_read_hprt0(core_if);
+	hprt0.b.prtrst = 1;
+	dwc_write_reg32(core_if->host_if->hprt0, hprt0.d32);
+	mdelay(60);
+	hprt0.b.prtrst = 0;
+	dwc_write_reg32(core_if->host_if->hprt0, hprt0.d32);
+	dwc_otg_hcd->flags.b.port_reset_change = 1;
+	return;
+}
+static struct tasklet_struct reset_tasklet =
+{
+	.next = NULL,
+	.state = 0,
+	.count = ATOMIC_INIT(0),
+	.func = reset_tasklet_func,
+	.data = 0,
+};
+
+
+#ifdef CONFIG_OTG_PLB_DMA_TASKLET
+/**
+ * plbdma tasklet function
+ */
+static void plbdma_tasklet_func(unsigned long data)
+{
+    unsigned long flags;
+    dwc_otg_core_if_t * _core_if = (dwc_otg_core_if_t *) data;
+	dma_xfer_t	* dma_xfer = &_core_if->dma_xfer;
+
+    local_irq_save(flags);
+    DWC_DEBUGPL(DBG_SP, "Plbdma tasklet called\n");
+
+	if (_core_if->dma_xfer.dma_dir == OTG_TX_DMA) {
+	    if ((((unsigned long)dma_xfer->dma_data_buff) & 0x3) == 0) {
+    	    /* call tx_dma - src,dest,len,intr */
+        	ppc4xx_start_plb_dma(_core_if, (void *)dma_xfer->dma_data_buff,
+				 dma_xfer->dma_data_fifo, (dma_xfer->dma_count * 4), PLB_DMA_INT_ENA,
+				PLB_DMA_CH, OTG_TX_DMA);
+	    } else {
+    	    ppc4xx_start_plb_dma(_core_if, (void *)get_unaligned(dma_xfer->dma_data_buff),
+				dma_xfer->dma_data_fifo, (dma_xfer->dma_count * 4), PLB_DMA_INT_ENA,
+				PLB_DMA_CH, OTG_TX_DMA);
+    	}
+	}
+	else {
+	    DWC_DEBUGPL(DBG_HCD, "0x%p 0x%p %d\n", (void *)dma_xfer->dma_data_fifo,
+			 dma_xfer->dma_data_buff, dma_xfer->dma_count );
+
+		ppc4xx_start_plb_dma(_core_if, (void *)dma_xfer->dma_data_fifo,
+			dma_xfer->dma_data_buff, (dma_xfer->dma_count * 4), PLB_DMA_INT_ENA,
+				PLB_DMA_CH, OTG_RX_DMA);
+	}
+
+    local_irq_restore(flags);
+    return;
+}
+static struct tasklet_struct plbdma_tasklet =
+{
+    .next = NULL,
+    .state = 0,
+    .count = ATOMIC_INIT(0),
+    .func = plbdma_tasklet_func,
+    .data = 0,
+};
+
+#endif
+
+/**
+ * Initializes the HCD. This function allocates memory for and initializes the
+ * static parts of the usb_hcd and dwc_otg_hcd structures. It also registers the
+ * USB bus with the core and calls the hc_driver->start() function. It returns
+ * a negative error on failure.
+ */
+int init_hcd_usecs(dwc_otg_hcd_t *_hcd);
+
+int  __init  dwc_otg_hcd_init(struct device *_dev, dwc_otg_device_t * dwc_otg_device)
+{
+	struct usb_hcd *hcd = NULL;
+	dwc_otg_hcd_t * dwc_otg_hcd = NULL;
+	dwc_otg_device_t * otg_dev = dev_get_drvdata(_dev);
+	int num_channels;
+	int i;
+	dwc_hc_t * channel;
+	int retval = 0;
+	DWC_DEBUGPL(DBG_HCD, "DWC OTG HCD INIT\n");
+    /*
+     * Allocate memory for the base HCD plus the DWC OTG HCD.
+     * Initialize the base HCD.
+     */
+    hcd = usb_create_hcd(&dwc_otg_hc_driver, _dev, dev_name(_dev));
+	if (hcd == NULL) {
+		retval = -ENOMEM;
+		goto error1;
+	}
+	dev_set_drvdata(_dev, dwc_otg_device); /* fscz restore */
+	hcd->regs = otg_dev->base;
+	hcd->self.otg_port = 1;
+
+    /* Initialize the DWC OTG HCD. */
+    dwc_otg_hcd = hcd_to_dwc_otg_hcd(hcd);
+	dwc_otg_hcd->core_if = otg_dev->core_if;
+	otg_dev->hcd = dwc_otg_hcd;
+	spin_lock_init(&dwc_otg_hcd->lock);
+    /* Register the HCD CIL Callbacks */
+    dwc_otg_cil_register_hcd_callbacks(otg_dev->core_if,
+				       &hcd_cil_callbacks, hcd);
+
+    /* Initialize the non-periodic schedule. */
+    INIT_LIST_HEAD(&dwc_otg_hcd->non_periodic_sched_inactive);
+	INIT_LIST_HEAD(&dwc_otg_hcd->non_periodic_sched_active);
+	INIT_LIST_HEAD(&dwc_otg_hcd->non_periodic_sched_deferred);
+
+    /* Initialize the periodic schedule. */
+    INIT_LIST_HEAD(&dwc_otg_hcd->periodic_sched_inactive);
+	INIT_LIST_HEAD(&dwc_otg_hcd->periodic_sched_ready);
+	INIT_LIST_HEAD(&dwc_otg_hcd->periodic_sched_assigned);
+	INIT_LIST_HEAD(&dwc_otg_hcd->periodic_sched_queued);
+
+    /*
+     * Create a host channel descriptor for each host channel implemented
+     * in the controller. Initialize the channel descriptor array.
+     */
+    INIT_LIST_HEAD(&dwc_otg_hcd->free_hc_list);
+	num_channels = dwc_otg_hcd->core_if->core_params->host_channels;
+	for (i = 0; i < num_channels; i++) {
+		channel = kmalloc(sizeof(dwc_hc_t), GFP_KERNEL);
+		if (channel == NULL) {
+			retval = -ENOMEM;
+			DWC_ERROR("%s: host channel allocation failed\n",__func__);
+			goto error2;
+		}
+		memset(channel, 0, sizeof(dwc_hc_t));
+		channel->hc_num = i;
+		dwc_otg_hcd->hc_ptr_array[i] = channel;
+
+#ifdef CONFIG_DWC_DEBUG
+		    init_timer(&dwc_otg_hcd->core_if->hc_xfer_timer[i]);
+#endif	/*  */
+	    DWC_DEBUGPL(DBG_HCDV, "HCD Added channel #%d, hc=%p\n", i,channel);
+	}
+
+	/* Initialize the Connection timeout timer. */
+	init_timer(&dwc_otg_hcd->conn_timer);
+
+	/* Initialize reset tasklet. */
+	reset_tasklet.data = (unsigned long)dwc_otg_hcd;
+	dwc_otg_hcd->reset_tasklet = &reset_tasklet;
+
+#ifdef CONFIG_OTG_PLB_DMA_TASKLET
+    /* Initialize plbdma tasklet. */
+    plbdma_tasklet.data = (unsigned long)dwc_otg_hcd->core_if;
+    dwc_otg_hcd->core_if->plbdma_tasklet = &plbdma_tasklet;
+#endif
+
+	/* Set device flags indicating whether the HCD supports DMA. */
+	if (otg_dev->core_if->dma_enable) {
+		DWC_PRINT("Using DMA mode\n");
+		_dev->dma_mask = &dma_mask;
+		_dev->coherent_dma_mask = DMA_BIT_MASK(32);
+	} else {
+		DWC_PRINT("Using Slave mode\n");
+		_dev->dma_mask = (void *)0;
+		_dev->coherent_dma_mask = 0;
+	}
+
+	init_hcd_usecs(dwc_otg_hcd);
+
+	/*
+	 * Finish generic HCD initialization and start the HCD. This function
+	 * allocates the DMA buffer pool, registers the USB bus, requests the
+	 * IRQ line, and calls dwc_otg_hcd_start method.
+	 */
+	retval = usb_add_hcd(hcd, otg_dev->irq, IRQF_SHARED);
+	if (retval < 0) {
+		goto error2;
+	}
+    /*
+     * Allocate space for storing data on status transactions. Normally no
+     * data is sent, but this space acts as a bit bucket. This must be
+     * done after usb_add_hcd since that function allocates the DMA buffer
+     * pool.
+     */
+    if (otg_dev->core_if->dma_enable) {
+		dwc_otg_hcd->status_buf =
+		    dma_alloc_coherent(_dev, DWC_OTG_HCD_STATUS_BUF_SIZE,
+					&dwc_otg_hcd->status_buf_dma, GFP_KERNEL | GFP_DMA);
+	} else {
+		dwc_otg_hcd->status_buf = kmalloc(DWC_OTG_HCD_STATUS_BUF_SIZE, GFP_KERNEL);
+	}
+	if (dwc_otg_hcd->status_buf == NULL) {
+		retval = -ENOMEM;
+		DWC_ERROR("%s: status_buf allocation failed\n", __func__);
+		goto error3;
+	}
+	DWC_DEBUGPL(DBG_HCD,
+		      "DWC OTG HCD Initialized HCD, usbbus=%d\n",
+		      hcd->self.busnum);
+	return 0;
+
+    /* Error conditions */
+	error3:usb_remove_hcd(hcd);
+	error2:dwc_otg_hcd_free(hcd);
+	usb_put_hcd(hcd);
+	error1:return retval;
+}
+
+
+/**
+ * Removes the HCD.
+ * Frees memory and resources associated with the HCD and deregisters the bus.
+ */
+void dwc_otg_hcd_remove(struct device *_dev)
+{
+	dwc_otg_device_t * otg_dev = dev_get_drvdata(_dev);
+	dwc_otg_hcd_t * dwc_otg_hcd = otg_dev->hcd;
+	struct usb_hcd *hcd = dwc_otg_hcd_to_hcd(dwc_otg_hcd);
+	DWC_DEBUGPL(DBG_HCD, "DWC OTG HCD REMOVE\n");
+
+    /* Turn off all interrupts */
+    dwc_write_reg32(&dwc_otg_hcd->core_if->core_global_regs->gintmsk, 0);
+	dwc_modify_reg32(&dwc_otg_hcd->core_if->core_global_regs->gahbcfg, 1,0);
+	usb_remove_hcd(hcd);
+	dwc_otg_hcd_free(hcd);
+	usb_put_hcd(hcd);
+	return;
+}
+
+
+/* =========================================================================
+ *  Linux HC Driver Functions
+ * ========================================================================= */
+
+/**
+ * Initializes dynamic portions of the DWC_otg HCD state.
+ */
+static void hcd_reinit(dwc_otg_hcd_t * _hcd)
+{
+	struct list_head *item;
+	int num_channels;
+	int i;
+	dwc_hc_t * channel;
+	_hcd->flags.d32 = 0;
+	_hcd->non_periodic_qh_ptr = &_hcd->non_periodic_sched_active;
+	_hcd->available_host_channels = _hcd->core_if->core_params->host_channels;
+
+    /*
+     * Put all channels in the free channel list and clean up channel
+     * states.
+     */
+    item = _hcd->free_hc_list.next;
+	while (item != &_hcd->free_hc_list) {
+		list_del(item);
+		item = _hcd->free_hc_list.next;
+	}
+	num_channels = _hcd->core_if->core_params->host_channels;
+	for (i = 0; i < num_channels; i++) {
+		channel = _hcd->hc_ptr_array[i];
+		list_add_tail(&channel->hc_list_entry, &_hcd->free_hc_list);
+		dwc_otg_hc_cleanup(_hcd->core_if, channel);
+	}
+
+    /* Initialize the DWC core for host mode operation. */
+    dwc_otg_core_host_init(_hcd->core_if);
+}
+
+
+/** Initializes the DWC_otg controller and its root hub and prepares it for host
+ * mode operation. Activates the root port. Returns 0 on success and a negative
+ * error code on failure. */
+int dwc_otg_hcd_start(struct usb_hcd *_hcd)
+{
+	dwc_otg_hcd_t * dwc_otg_hcd = hcd_to_dwc_otg_hcd(_hcd);
+	//dwc_otg_core_if_t * core_if = dwc_otg_hcd->core_if;
+	struct usb_device *udev;
+	struct usb_bus *bus;
+
+//      int retval;
+    DWC_DEBUGPL(DBG_HCD, "DWC OTG HCD START\n");
+	bus = hcd_to_bus(_hcd);
+
+    /* Initialize the bus state.  If the core is in Device Mode
+     * HALT the USB bus and return. */
+
+	_hcd->state = HC_STATE_RUNNING;
+
+    /* Initialize and connect root hub if one is not already attached */
+    if (bus->root_hub) {
+		DWC_DEBUGPL(DBG_HCD, "DWC OTG HCD Has Root Hub\n");
+
+	    /* Inform the HUB driver to resume. */
+	    usb_hcd_resume_root_hub(_hcd);
+	}
+
+	else {
+		udev = usb_alloc_dev(NULL, bus, 0);
+		udev->speed = USB_SPEED_HIGH;
+		if (!udev) {
+			DWC_DEBUGPL(DBG_HCD, "DWC OTG HCD Error udev alloc\n");
+			return -ENODEV;
+		}
+
+	    /* Not needed - VJ
+	       if ((retval = usb_hcd_register_root_hub(udev, _hcd)) != 0) {
+   		   DWC_DEBUGPL(DBG_HCD, "DWC OTG HCD Error registering %d\n", retval);
+	       return -ENODEV;
+	       }
+	     */
+	}
+	hcd_reinit(dwc_otg_hcd);
+	return 0;
+}
+static void qh_list_free(dwc_otg_hcd_t * _hcd, struct list_head *_qh_list)
+{
+	struct list_head *item;
+	dwc_otg_qh_t * qh;
+	if (_qh_list->next == NULL) {
+	    /* The list hasn't been initialized yet. */
+	    return;
+	}
+
+    	/* Ensure there are no QTDs or URBs left. */
+	kill_urbs_in_qh_list(_hcd, _qh_list);
+	for (item = _qh_list->next; item != _qh_list; item = _qh_list->next) {
+		qh = list_entry(item, dwc_otg_qh_t, qh_list_entry);
+		dwc_otg_hcd_qh_remove_and_free(_hcd, qh);
+	}
+}
+
+
+/**
+ * Halts the DWC_otg host mode operations in a clean manner. USB transfers are
+ * stopped.
+ */
+void dwc_otg_hcd_stop(struct usb_hcd *_hcd)
+{
+	dwc_otg_hcd_t * dwc_otg_hcd = hcd_to_dwc_otg_hcd(_hcd);
+	hprt0_data_t hprt0 = {.d32 = 0};
+	DWC_DEBUGPL(DBG_HCD, "DWC OTG HCD STOP\n");
+
+    /* Turn off all host-specific interrupts. */
+    dwc_otg_disable_host_interrupts(dwc_otg_hcd->core_if);
+
+    /*
+     * The root hub should be disconnected before this function is called.
+     * The disconnect will clear the QTD lists (via ..._hcd_urb_dequeue)
+	 * and the QH lists (via ..._hcd_endpoint_disable).
+     */
+
+    /* Turn off the vbus power */
+	DWC_PRINT("PortPower off\n");
+	hprt0.b.prtpwr = 0;
+	dwc_write_reg32(dwc_otg_hcd->core_if->host_if->hprt0, hprt0.d32);
+	return;
+}
+
+
+/** Returns the current frame number. */
+int dwc_otg_hcd_get_frame_number(struct usb_hcd *_hcd)
+{
+	dwc_otg_hcd_t * dwc_otg_hcd = hcd_to_dwc_otg_hcd(_hcd);
+	hfnum_data_t hfnum;
+	hfnum.d32 = dwc_read_reg32(&dwc_otg_hcd->core_if->host_if->
+					host_global_regs->hfnum);
+
+#ifdef DEBUG_SOF
+	    DWC_DEBUGPL(DBG_HCDV, "DWC OTG HCD GET FRAME NUMBER %d\n",
+			hfnum.b.frnum);
+#endif	/*  */
+	return hfnum.b.frnum;
+}
+
+
+/**
+ * Frees secondary storage associated with the dwc_otg_hcd structure contained
+ * in the struct usb_hcd field.
+ */
+void dwc_otg_hcd_free(struct usb_hcd *_hcd)
+{
+	dwc_otg_hcd_t * dwc_otg_hcd = hcd_to_dwc_otg_hcd(_hcd);
+	int i;
+	DWC_DEBUGPL(DBG_HCD, "DWC OTG HCD FREE\n");
+	del_timers(dwc_otg_hcd);
+
+    /* Free memory for QH/QTD lists */
+    qh_list_free(dwc_otg_hcd,
+	&dwc_otg_hcd->non_periodic_sched_inactive);
+	qh_list_free(dwc_otg_hcd, &dwc_otg_hcd->non_periodic_sched_deferred);
+	qh_list_free(dwc_otg_hcd, &dwc_otg_hcd->non_periodic_sched_active);
+	qh_list_free(dwc_otg_hcd, &dwc_otg_hcd->periodic_sched_inactive);
+	qh_list_free(dwc_otg_hcd, &dwc_otg_hcd->periodic_sched_ready);
+	qh_list_free(dwc_otg_hcd, &dwc_otg_hcd->periodic_sched_assigned);
+	qh_list_free(dwc_otg_hcd, &dwc_otg_hcd->periodic_sched_queued);
+
+	/* Free memory for the host channels. */
+	for (i = 0; i < MAX_EPS_CHANNELS; i++) {
+		dwc_hc_t * hc = dwc_otg_hcd->hc_ptr_array[i];
+		if (hc != NULL) {
+			DWC_DEBUGPL(DBG_HCDV, "HCD Free channel #%i, hc=%p\n",i, hc);
+			kfree(hc);
+		}
+	}
+	if (dwc_otg_hcd->core_if->dma_enable) {
+		if (dwc_otg_hcd->status_buf_dma) {
+			dma_free_coherent(_hcd->self.controller,
+					   DWC_OTG_HCD_STATUS_BUF_SIZE,
+					   dwc_otg_hcd->status_buf,
+					   dwc_otg_hcd->status_buf_dma);
+		}
+	} else if (dwc_otg_hcd->status_buf != NULL) {
+		kfree(dwc_otg_hcd->status_buf);
+	}
+	return;
+}
+
+
+#ifdef CONFIG_DWC_DEBUG
+static void dump_urb_info(struct urb *_urb, char *_fn_name)
+{
+	DWC_PRINT("%s, urb %p\n", _fn_name, _urb);
+	DWC_PRINT("  Device address: %d\n", usb_pipedevice(_urb->pipe));
+	DWC_PRINT("  Endpoint: %d, %s\n", usb_pipeendpoint(_urb->pipe),
+		   (usb_pipein(_urb->pipe) ? "IN" : "OUT"));
+	DWC_PRINT("  Endpoint type: %s\n", ( {
+			char *pipetype;
+			switch (usb_pipetype(_urb->pipe)) {
+			case PIPE_CONTROL:
+				pipetype = "CONTROL"; break;
+			case PIPE_BULK:
+				pipetype = "BULK"; break;
+			case PIPE_INTERRUPT:
+				pipetype = "INTERRUPT"; break;
+			case PIPE_ISOCHRONOUS:
+				pipetype = "ISOCHRONOUS"; break;
+			default:
+				pipetype = "UNKNOWN"; break;
+			};
+			pipetype;
+	} )) ;
+	DWC_PRINT("  Speed: %s\n", ( {
+			char *speed;
+			switch (_urb->dev->speed) {
+			case USB_SPEED_HIGH:
+				speed = "HIGH"; break;
+			case USB_SPEED_FULL:
+				speed = "FULL"; break;
+			case USB_SPEED_LOW:
+				speed = "LOW"; break;
+			default:
+				speed = "UNKNOWN"; break;
+			};
+			speed;
+	} )) ;
+	DWC_PRINT("  Max packet size: %d\n",
+		   usb_maxpacket(_urb->dev, _urb->pipe, usb_pipeout(_urb->pipe)));
+	DWC_PRINT("  Data buffer length: %d\n", _urb->transfer_buffer_length);
+	DWC_PRINT("  Transfer buffer: %p, Transfer DMA: %p\n",
+		   _urb->transfer_buffer, (void *)_urb->transfer_dma);
+	DWC_PRINT("  Setup buffer: %p, Setup DMA: %p\n", _urb->setup_packet,
+		   (void *)_urb->setup_dma);
+	DWC_PRINT("  Interval: %d\n", _urb->interval);
+	if (usb_pipetype(_urb->pipe) == PIPE_ISOCHRONOUS) {
+		int i;
+		for (i = 0; i < _urb->number_of_packets; i++) {
+			DWC_PRINT("  ISO Desc %d:\n", i);
+			DWC_PRINT("    offset: %d, length %d\n",
+				   _urb->iso_frame_desc[i].offset,
+				   _urb->iso_frame_desc[i].length);
+		}
+	}
+}
+static void dump_channel_info(dwc_otg_hcd_t * _hcd,  dwc_otg_qh_t * qh)
+{
+	if (qh->channel != NULL) {
+		dwc_hc_t * hc = qh->channel;
+		struct list_head *item;
+		dwc_otg_qh_t * qh_item;
+		int num_channels = _hcd->core_if->core_params->host_channels;
+		int i;
+		dwc_otg_hc_regs_t * hc_regs;
+		hcchar_data_t hcchar;
+		hcsplt_data_t hcsplt;
+		hctsiz_data_t hctsiz;
+		uint32_t hcdma;
+		hc_regs = _hcd->core_if->host_if->hc_regs[hc->hc_num];
+		hcchar.d32 = dwc_read_reg32(&hc_regs->hcchar);
+		hcsplt.d32 = dwc_read_reg32(&hc_regs->hcsplt);
+		hctsiz.d32 = dwc_read_reg32(&hc_regs->hctsiz);
+		hcdma = dwc_read_reg32(&hc_regs->hcdma);
+		DWC_PRINT("  Assigned to channel %p:\n", hc);
+		DWC_PRINT("    hcchar 0x%08x, hcsplt 0x%08x\n", hcchar.d32, hcsplt.d32);
+		DWC_PRINT("    hctsiz 0x%08x, hcdma 0x%08x\n", hctsiz.d32, hcdma);
+		DWC_PRINT("    dev_addr: %d, ep_num: %d, ep_is_in: %d\n",
+			   hc->dev_addr, hc->ep_num, hc->ep_is_in);
+		DWC_PRINT("    ep_type: %d\n", hc->ep_type);
+		DWC_PRINT("    max_packet: %d\n", hc->max_packet);
+		DWC_PRINT("    data_pid_start: %d\n", hc->data_pid_start);
+		DWC_PRINT("    xfer_started: %d\n", hc->xfer_started);
+		DWC_PRINT("    halt_status: %d\n", hc->halt_status);
+		DWC_PRINT("    xfer_buff: %p\n", hc->xfer_buff);
+		DWC_PRINT("    xfer_len: %d\n", hc->xfer_len);
+		DWC_PRINT("    qh: %p\n", hc->qh);
+		DWC_PRINT("  NP inactive sched:\n");
+		list_for_each(item, &_hcd->non_periodic_sched_inactive) {
+			qh_item = list_entry(item, dwc_otg_qh_t, qh_list_entry);
+			DWC_PRINT("    %p\n", qh_item);
+		} DWC_PRINT("  NP active sched:\n");
+		list_for_each(item, &_hcd->non_periodic_sched_deferred) {
+			qh_item = list_entry(item, dwc_otg_qh_t, qh_list_entry);
+			DWC_PRINT("    %p\n", qh_item);
+		} DWC_PRINT("  NP deferred sched:\n");
+		list_for_each(item, &_hcd->non_periodic_sched_active) {
+			qh_item = list_entry(item, dwc_otg_qh_t, qh_list_entry);
+			DWC_PRINT("    %p\n", qh_item);
+		} DWC_PRINT("  Channels: \n");
+		for (i = 0; i < num_channels; i++) {
+			dwc_hc_t * hc = _hcd->hc_ptr_array[i];
+			DWC_PRINT("    %2d: %p\n", i, hc);
+		}
+	}
+}
+
+#endif	/*  */
+
+/** Starts processing a USB transfer request specified by a USB Request Block
+ * (URB). mem_flags indicates the type of memory allocation to use while
+ * processing this URB. */
+int dwc_otg_hcd_urb_enqueue(struct usb_hcd *_hcd,
+			    struct urb *_urb,
+			    gfp_t _mem_flags)
+{
+	unsigned long flags;
+	int retval;
+	dwc_otg_hcd_t * dwc_otg_hcd = hcd_to_dwc_otg_hcd(_hcd);
+	dwc_otg_qtd_t * qtd;
+
+	local_irq_save(flags);
+	retval = usb_hcd_link_urb_to_ep(_hcd, _urb);
+	if (retval) {
+		local_irq_restore(flags);
+		return retval;
+	}
+#ifdef CONFIG_DWC_DEBUG
+	if (CHK_DEBUG_LEVEL(DBG_HCDV | DBG_HCD_URB)) {
+		dump_urb_info(_urb, "dwc_otg_hcd_urb_enqueue");
+	}
+#endif	/*  */
+    if (!dwc_otg_hcd->flags.b.port_connect_status) {
+	    /* No longer connected. */
+	    usb_hcd_unlink_urb_from_ep(_hcd, _urb);
+	    local_irq_restore(flags);
+	    return -ENODEV;
+	}
+	qtd = dwc_otg_hcd_qtd_create(_urb);
+	if (qtd == NULL) {
+		usb_hcd_unlink_urb_from_ep(_hcd, _urb);
+		local_irq_restore(flags);
+		DWC_ERROR("DWC OTG HCD URB Enqueue failed creating QTD\n");
+		return -ENOMEM;
+	}
+	retval = dwc_otg_hcd_qtd_add(qtd, dwc_otg_hcd);
+	if (retval < 0) {
+		DWC_ERROR("DWC OTG HCD URB Enqueue failed adding QTD. "
+			   "Error status %d\n", retval);
+		usb_hcd_unlink_urb_from_ep(_hcd, _urb);
+		dwc_otg_hcd_qtd_free(qtd);
+	}
+	local_irq_restore(flags);
+	return retval;
+}
+
+
+/** Aborts/cancels a USB transfer request. Always returns 0 to indicate
+ * success.  */
+int dwc_otg_hcd_urb_dequeue(struct usb_hcd *_hcd, struct urb *_urb, int _status)
+{
+	unsigned long flags;
+	dwc_otg_hcd_t * dwc_otg_hcd;
+	dwc_otg_qtd_t * urb_qtd;
+	dwc_otg_qh_t * qh;
+	struct usb_host_endpoint *_ep = dwc_urb_to_endpoint(_urb);
+	int retval;
+
+	DWC_DEBUGPL(DBG_HCD, "DWC OTG HCD URB Dequeue\n");
+
+	if (!_ep)
+		return -EINVAL;
+
+	local_irq_save(flags);
+	retval = usb_hcd_check_unlink_urb(_hcd, _urb, _status);
+	if (retval) {
+		local_irq_restore(flags);
+		return retval;
+	}
+
+	dwc_otg_hcd = hcd_to_dwc_otg_hcd(_hcd);
+
+	urb_qtd = (dwc_otg_qtd_t *) _urb->hcpriv;
+	if (urb_qtd == NULL) {
+		printk("urb_qtd is NULL for _urb %08x\n",(unsigned)_urb);
+		goto done;
+	}
+	qh = (dwc_otg_qh_t *) urb_qtd->qtd_qh_ptr;
+	if (qh == NULL) {
+		goto done;
+	}
+#ifdef CONFIG_DWC_DEBUG
+    if (CHK_DEBUG_LEVEL(DBG_HCDV | DBG_HCD_URB)) {
+		dump_urb_info(_urb, "dwc_otg_hcd_urb_dequeue");
+		if (urb_qtd == qh->qtd_in_process) {
+			dump_channel_info(dwc_otg_hcd, qh);
+		}
+	}
+
+#endif	/*  */
+    if (urb_qtd == qh->qtd_in_process) {
+	    /* The QTD is in process (it has been assigned to a channel). */
+	    if (dwc_otg_hcd->flags.b.port_connect_status) {
+
+		    /*
+		     * If still connected (i.e. in host mode), halt the
+		     * channel so it can be used for other transfers. If
+		     * no longer connected, the host registers can't be
+		     * written to halt the channel since the core is in
+		     * device mode.
+		     */
+		    dwc_otg_hc_halt(dwc_otg_hcd->core_if, qh->channel,
+					    DWC_OTG_HC_XFER_URB_DEQUEUE);
+		}
+	}
+
+    /*
+     * Free the QTD and clean up the associated QH. Leave the QH in the
+     * schedule if it has any remaining QTDs.
+     */
+    dwc_otg_hcd_qtd_remove_and_free(urb_qtd);
+	if (urb_qtd == qh->qtd_in_process) {
+		dwc_otg_hcd_qh_deactivate(dwc_otg_hcd, qh, 0);
+		qh->channel = NULL;
+		qh->qtd_in_process = NULL;
+	} else if (list_empty(&qh->qtd_list)) {
+		dwc_otg_hcd_qh_remove(dwc_otg_hcd, qh);
+	}
+done:
+	_urb->hcpriv = NULL;
+
+      /* Higher layer software sets URB status. */
+	usb_hcd_unlink_urb_from_ep(_hcd, _urb);
+	usb_hcd_giveback_urb(_hcd, _urb, _status);
+
+	local_irq_restore(flags);
+
+	if (CHK_DEBUG_LEVEL(DBG_HCDV | DBG_HCD_URB)) {
+		DWC_PRINT("Called usb_hcd_giveback_urb()\n");
+		DWC_PRINT("  urb->status = %d\n", _status);
+	}
+	return 0;
+}
+
+
+/** Frees resources in the DWC_otg controller related to a given endpoint. Also
+ * clears state in the HCD related to the endpoint. Any URBs for the endpoint
+ * must already be dequeued. */
+void dwc_otg_hcd_endpoint_disable(struct usb_hcd *_hcd,
+				  struct usb_host_endpoint *_ep)
+{
+	dwc_otg_qh_t * qh;
+	dwc_otg_hcd_t * dwc_otg_hcd = hcd_to_dwc_otg_hcd(_hcd);
+	unsigned long flags;
+	int retry = 0;
+
+	DWC_DEBUGPL(DBG_HCD, "DWC OTG HCD EP DISABLE: _bEndpointAddress=0x%02x, "
+		      "endpoint=%d\n", _ep->desc.bEndpointAddress,
+		      dwc_ep_addr_to_endpoint(_ep->desc.bEndpointAddress));
+
+rescan:
+	local_irq_save(flags);
+
+	qh = (dwc_otg_qh_t *) (_ep->hcpriv);
+	if (qh != NULL) {
+
+		/** Check that the QTD list is really empty */
+	    if (!list_empty(&qh->qtd_list)) {
+		if (retry++ < 250) {
+			local_irq_restore(flags);
+			schedule_timeout_uninterruptible(1);
+			goto rescan;
+		}
+#ifdef CONFIG_DWC_DEBUG
+			DWC_WARN("DWC OTG HCD EP DISABLE:"
+				  " QTD List for this endpoint is not empty\n");
+#endif	/*  */
+		}
+
+	    dwc_otg_hcd_qh_remove_and_free(dwc_otg_hcd, qh);
+		_ep->hcpriv = NULL;
+	}
+
+	local_irq_restore(flags);
+
+	return;
+}
+
+/** Handles host mode interrupts for the DWC_otg controller. Returns IRQ_NONE if
+ * there was no interrupt to handle. Returns IRQ_HANDLED if there was a valid
+ * interrupt.
+ *
+ * This function is called by the USB core when an interrupt occurs */
+irqreturn_t dwc_otg_hcd_irq(struct usb_hcd * _hcd)
+{
+	dwc_otg_hcd_t * dwc_otg_hcd = hcd_to_dwc_otg_hcd(_hcd);
+	return IRQ_RETVAL(dwc_otg_hcd_handle_intr(dwc_otg_hcd));
+}
+
+/** Creates Status Change bitmap for the root hub and root port. The bitmap is
+ * returned in buf. Bit 0 is the status change indicator for the root hub. Bit 1
+ * is the status change indicator for the single root port. Returns 1 if either
+ * change indicator is 1, otherwise returns 0. */
+int dwc_otg_hcd_hub_status_data(struct usb_hcd *_hcd, char *_buf)
+{
+	dwc_otg_hcd_t * dwc_otg_hcd = hcd_to_dwc_otg_hcd(_hcd);
+	_buf[0] = 0;
+	_buf[0] |= (dwc_otg_hcd->flags.b.port_connect_status_change
+		     || dwc_otg_hcd->flags.b.port_reset_change
+		     || dwc_otg_hcd->flags.b.port_enable_change
+		     || dwc_otg_hcd->flags.b.port_suspend_change
+		     || dwc_otg_hcd->flags.b.port_over_current_change) << 1;
+
+#ifdef CONFIG_DWC_DEBUG
+	    if (_buf[0]) {
+		DWC_DEBUGPL(DBG_HCD, "DWC OTG HCD HUB STATUS DATA:"
+			     " Root port status changed\n");
+		DWC_DEBUGPL(DBG_HCDV, "  port_connect_status_change: %d\n",
+			     dwc_otg_hcd->flags.b.port_connect_status_change);
+		DWC_DEBUGPL(DBG_HCDV, "  port_reset_change: %d\n",
+			     dwc_otg_hcd->flags.b.port_reset_change);
+		DWC_DEBUGPL(DBG_HCDV, "  port_enable_change: %d\n",
+			     dwc_otg_hcd->flags.b.port_enable_change);
+		DWC_DEBUGPL(DBG_HCDV, "  port_suspend_change: %d\n",
+			     dwc_otg_hcd->flags.b.port_suspend_change);
+		DWC_DEBUGPL(DBG_HCDV, "  port_over_current_change: %d\n",
+			     dwc_otg_hcd->flags.b.port_over_current_change);
+	}
+
+#endif	/*  */
+	    return (_buf[0] != 0);
+}
+
+
+#ifdef DWC_HS_ELECT_TST
+/*
+ * Quick and dirty hack to implement the HS Electrical Test
+ * SINGLE_STEP_GET_DEVICE_DESCRIPTOR feature.
+ *
+ * This code was copied from our userspace app "hset". It sends a
+ * Get Device Descriptor control sequence in two parts, first the
+ * Setup packet by itself, followed some time later by the In and
+ * Ack packets. Rather than trying to figure out how to add this
+ * functionality to the normal driver code, we just hijack the
+ * hardware, using these two function to drive the hardware
+ * directly.
+ */
+dwc_otg_core_global_regs_t * global_regs;
+dwc_otg_host_global_regs_t * hc_global_regs;
+dwc_otg_hc_regs_t * hc_regs;
+uint32_t * data_fifo;
+
+static void do_setup(void)
+{
+	gintsts_data_t gintsts;
+	hctsiz_data_t hctsiz;
+	hcchar_data_t hcchar;
+	haint_data_t haint;
+	hcint_data_t hcint;
+
+	/* Enable HAINTs */
+	dwc_write_reg32(&hc_global_regs->haintmsk, 0x0001);
+
+	/* Enable HCINTs */
+	dwc_write_reg32(&hc_regs->hcintmsk, 0x04a3);
+
+	/* Read GINTSTS */
+	gintsts.d32 = dwc_read_reg32(&global_regs->gintsts);
+
+	//fprintf(stderr, "GINTSTS: %08x\n", gintsts.d32);
+
+	/* Read HAINT */
+	haint.d32 = dwc_read_reg32(&hc_global_regs->haint);
+
+	//fprintf(stderr, "HAINT: %08x\n", haint.d32);
+
+	/* Read HCINT */
+	hcint.d32 = dwc_read_reg32(&hc_regs->hcint);
+
+	//fprintf(stderr, "HCINT: %08x\n", hcint.d32);
+
+	/* Read HCCHAR */
+	hcchar.d32 = dwc_read_reg32(&hc_regs->hcchar);
+
+	//fprintf(stderr, "HCCHAR: %08x\n", hcchar.d32);
+
+	/* Clear HCINT */
+	dwc_write_reg32(&hc_regs->hcint, hcint.d32);
+
+	/* Clear HAINT */
+	dwc_write_reg32(&hc_global_regs->haint, haint.d32);
+
+	/* Clear GINTSTS */
+	dwc_write_reg32(&global_regs->gintsts, gintsts.d32);
+
+	/* Read GINTSTS */
+	gintsts.d32 = dwc_read_reg32(&global_regs->gintsts);
+
+	//fprintf(stderr, "GINTSTS: %08x\n", gintsts.d32);
+
+	/*
+	 * Send Setup packet (Get Device Descriptor)
+	 */
+
+	/* Make sure channel is disabled */
+	hcchar.d32 = dwc_read_reg32(&hc_regs->hcchar);
+	if (hcchar.b.chen) {
+
+	    //fprintf(stderr, "Channel already enabled 1, HCCHAR = %08x\n", hcchar.d32);
+	    hcchar.b.chdis = 1;
+
+//              hcchar.b.chen = 1;
+	    dwc_write_reg32(&hc_regs->hcchar, hcchar.d32);
+
+		//sleep(1);
+		mdelay(1000);
+
+		/* Read GINTSTS */
+		gintsts.d32 = dwc_read_reg32(&global_regs->gintsts);
+
+		//fprintf(stderr, "GINTSTS: %08x\n", gintsts.d32);
+
+		/* Read HAINT */
+		haint.d32 = dwc_read_reg32(&hc_global_regs->haint);
+
+		//fprintf(stderr, "HAINT: %08x\n", haint.d32);
+
+		/* Read HCINT */
+		hcint.d32 = dwc_read_reg32(&hc_regs->hcint);
+
+		//fprintf(stderr, "HCINT: %08x\n", hcint.d32);
+
+		/* Read HCCHAR */
+		hcchar.d32 = dwc_read_reg32(&hc_regs->hcchar);
+
+		//fprintf(stderr, "HCCHAR: %08x\n", hcchar.d32);
+
+		/* Clear HCINT */
+		dwc_write_reg32(&hc_regs->hcint, hcint.d32);
+
+		/* Clear HAINT */
+		dwc_write_reg32(&hc_global_regs->haint, haint.d32);
+
+		/* Clear GINTSTS */
+		dwc_write_reg32(&global_regs->gintsts, gintsts.d32);
+		hcchar.d32 = dwc_read_reg32(&hc_regs->hcchar);
+
+	    //if (hcchar.b.chen) {
+	    //      fprintf(stderr, "** Channel _still_ enabled 1, HCCHAR = %08x **\n", hcchar.d32);
+	    //}
+	}
+
+	/* Set HCTSIZ */
+	hctsiz.d32 = 0;
+	hctsiz.b.xfersize = 8;
+	hctsiz.b.pktcnt = 1;
+	hctsiz.b.pid = DWC_OTG_HC_PID_SETUP;
+	dwc_write_reg32(&hc_regs->hctsiz, hctsiz.d32);
+
+	/* Set HCCHAR */
+	hcchar.d32 = dwc_read_reg32(&hc_regs->hcchar);
+	hcchar.b.eptype = DWC_OTG_EP_TYPE_CONTROL;
+	hcchar.b.epdir = 0;
+	hcchar.b.epnum = 0;
+	hcchar.b.mps = 8;
+	hcchar.b.chen = 1;
+	dwc_write_reg32(&hc_regs->hcchar, hcchar.d32);
+
+	/* Fill FIFO with Setup data for Get Device Descriptor */
+	data_fifo = (uint32_t *) ((char *)global_regs + 0x1000);
+	dwc_write_reg32(data_fifo++, 0x01000680);
+	dwc_write_reg32(data_fifo++, 0x00080000);
+	gintsts.d32 = dwc_read_reg32(&global_regs->gintsts);
+
+	//fprintf(stderr, "Waiting for HCINTR intr 1, GINTSTS = %08x\n", gintsts.d32);
+
+	/* Wait for host channel interrupt */
+	do {
+		gintsts.d32 = dwc_read_reg32(&global_regs->gintsts);
+	} while (gintsts.b.hcintr == 0);
+
+	//fprintf(stderr, "Got HCINTR intr 1, GINTSTS = %08x\n", gintsts.d32);
+
+	/* Disable HCINTs */
+	dwc_write_reg32(&hc_regs->hcintmsk, 0x0000);
+
+	/* Disable HAINTs */
+	dwc_write_reg32(&hc_global_regs->haintmsk, 0x0000);
+
+	/* Read HAINT */
+	haint.d32 = dwc_read_reg32(&hc_global_regs->haint);
+
+	//fprintf(stderr, "HAINT: %08x\n", haint.d32);
+
+	/* Read HCINT */
+	hcint.d32 = dwc_read_reg32(&hc_regs->hcint);
+
+	//fprintf(stderr, "HCINT: %08x\n", hcint.d32);
+
+	/* Read HCCHAR */
+	hcchar.d32 = dwc_read_reg32(&hc_regs->hcchar);
+
+	//fprintf(stderr, "HCCHAR: %08x\n", hcchar.d32);
+
+	/* Clear HCINT */
+	dwc_write_reg32(&hc_regs->hcint, hcint.d32);
+
+	/* Clear HAINT */
+	dwc_write_reg32(&hc_global_regs->haint, haint.d32);
+
+	/* Clear GINTSTS */
+	dwc_write_reg32(&global_regs->gintsts, gintsts.d32);
+
+	/* Read GINTSTS */
+	gintsts.d32 = dwc_read_reg32(&global_regs->gintsts);
+
+	//fprintf(stderr, "GINTSTS: %08x\n", gintsts.d32);
+}
+
+static void do_in_ack(void)
+{
+	gintsts_data_t gintsts;
+	hctsiz_data_t hctsiz;
+	hcchar_data_t hcchar;
+	haint_data_t haint;
+	hcint_data_t hcint;
+	host_grxsts_data_t grxsts;
+
+	/* Enable HAINTs */
+	dwc_write_reg32(&hc_global_regs->haintmsk, 0x0001);
+
+	/* Enable HCINTs */
+	dwc_write_reg32(&hc_regs->hcintmsk, 0x04a3);
+
+	/* Read GINTSTS */
+	gintsts.d32 = dwc_read_reg32(&global_regs->gintsts);
+
+	//fprintf(stderr, "GINTSTS: %08x\n", gintsts.d32);
+
+	/* Read HAINT */
+	haint.d32 = dwc_read_reg32(&hc_global_regs->haint);
+
+	//fprintf(stderr, "HAINT: %08x\n", haint.d32);
+
+	/* Read HCINT */
+	hcint.d32 = dwc_read_reg32(&hc_regs->hcint);
+
+	//fprintf(stderr, "HCINT: %08x\n", hcint.d32);
+
+	/* Read HCCHAR */
+	hcchar.d32 = dwc_read_reg32(&hc_regs->hcchar);
+
+	//fprintf(stderr, "HCCHAR: %08x\n", hcchar.d32);
+
+	/* Clear HCINT */
+	dwc_write_reg32(&hc_regs->hcint, hcint.d32);
+
+	/* Clear HAINT */
+	dwc_write_reg32(&hc_global_regs->haint, haint.d32);
+
+	/* Clear GINTSTS */
+	dwc_write_reg32(&global_regs->gintsts, gintsts.d32);
+
+	/* Read GINTSTS */
+	gintsts.d32 = dwc_read_reg32(&global_regs->gintsts);
+
+	//fprintf(stderr, "GINTSTS: %08x\n", gintsts.d32);
+
+	/*
+	 * Receive Control In packet
+	 */
+
+	/* Make sure channel is disabled */
+	hcchar.d32 = dwc_read_reg32(&hc_regs->hcchar);
+
+	if (hcchar.b.chen) {
+		//fprintf(stderr, "Channel already enabled 2, HCCHAR = %08x\n", hcchar.d32);
+		hcchar.b.chdis = 1;
+		hcchar.b.chen = 1;
+		dwc_write_reg32(&hc_regs->hcchar, hcchar.d32);
+
+		//sleep(1);
+		mdelay(1000);
+
+		/* Read GINTSTS */
+		gintsts.d32 = dwc_read_reg32(&global_regs->gintsts);
+
+		//fprintf(stderr, "GINTSTS: %08x\n", gintsts.d32);
+
+		/* Read HAINT */
+		haint.d32 = dwc_read_reg32(&hc_global_regs->haint);
+
+		//fprintf(stderr, "HAINT: %08x\n", haint.d32);
+
+		/* Read HCINT */
+		hcint.d32 = dwc_read_reg32(&hc_regs->hcint);
+
+		//fprintf(stderr, "HCINT: %08x\n", hcint.d32);
+
+		/* Read HCCHAR */
+		hcchar.d32 = dwc_read_reg32(&hc_regs->hcchar);
+
+		//fprintf(stderr, "HCCHAR: %08x\n", hcchar.d32);
+
+		/* Clear HCINT */
+		dwc_write_reg32(&hc_regs->hcint, hcint.d32);
+
+		/* Clear HAINT */
+		dwc_write_reg32(&hc_global_regs->haint, haint.d32);
+
+		/* Clear GINTSTS */
+		dwc_write_reg32(&global_regs->gintsts, gintsts.d32);
+		hcchar.d32 = dwc_read_reg32(&hc_regs->hcchar);
+
+		//if (hcchar.b.chen) {
+		//      fprintf(stderr, "** Channel _still_ enabled 2, HCCHAR = %08x **\n", hcchar.d32);
+		//}
+	}
+
+    /* Set HCTSIZ */
+    hctsiz.d32 = 0;
+	hctsiz.b.xfersize = 8;
+	hctsiz.b.pktcnt = 1;
+	hctsiz.b.pid = DWC_OTG_HC_PID_DATA1;
+	dwc_write_reg32(&hc_regs->hctsiz, hctsiz.d32);
+
+    /* Set HCCHAR */
+    hcchar.d32 = dwc_read_reg32(&hc_regs->hcchar);
+	hcchar.b.eptype = DWC_OTG_EP_TYPE_CONTROL;
+	hcchar.b.epdir = 1;
+	hcchar.b.epnum = 0;
+	hcchar.b.mps = 8;
+	hcchar.b.chen = 1;
+	dwc_write_reg32(&hc_regs->hcchar, hcchar.d32);
+	gintsts.d32 = dwc_read_reg32(&global_regs->gintsts);
+
+    //fprintf(stderr, "Waiting for RXSTSQLVL intr 1, GINTSTS = %08x\n", gintsts.d32);
+
+    /* Wait for receive status queue interrupt */
+    do {
+		gintsts.d32 = dwc_read_reg32(&global_regs->gintsts);
+	} while (gintsts.b.rxstsqlvl == 0);
+
+    //fprintf(stderr, "Got RXSTSQLVL intr 1, GINTSTS = %08x\n", gintsts.d32);
+
+    /* Read RXSTS */
+    grxsts.d32 = dwc_read_reg32(&global_regs->grxstsp);
+
+    //fprintf(stderr, "GRXSTS: %08x\n", grxsts.d32);
+
+    /* Clear RXSTSQLVL in GINTSTS */
+    gintsts.d32 = 0;
+	gintsts.b.rxstsqlvl = 1;
+	dwc_write_reg32(&global_regs->gintsts, gintsts.d32);
+	switch (grxsts.b.pktsts) {
+	case DWC_GRXSTS_PKTSTS_IN:
+	    /* Read the data into the host buffer */
+	    if (grxsts.b.bcnt > 0) {
+			int i;
+			int word_count = (grxsts.b.bcnt + 3) / 4;
+			data_fifo = (uint32_t *) ((char *)global_regs + 0x1000);
+			for (i = 0; i < word_count; i++) {
+				(void)dwc_read_reg32(data_fifo++);
+			}
+		}
+	    //fprintf(stderr, "Received %u bytes\n", (unsigned)grxsts.b.bcnt);
+		break;
+	default:
+	    //fprintf(stderr, "** Unexpected GRXSTS packet status 1 **\n");
+	    break;
+	}
+	gintsts.d32 = dwc_read_reg32(&global_regs->gintsts);
+
+    //fprintf(stderr, "Waiting for RXSTSQLVL intr 2, GINTSTS = %08x\n", gintsts.d32);
+
+    /* Wait for receive status queue interrupt */
+    do {
+		gintsts.d32 = dwc_read_reg32(&global_regs->gintsts);
+	} while (gintsts.b.rxstsqlvl == 0);
+
+    //fprintf(stderr, "Got RXSTSQLVL intr 2, GINTSTS = %08x\n", gintsts.d32);
+
+    /* Read RXSTS */
+    grxsts.d32 = dwc_read_reg32(&global_regs->grxstsp);
+
+    //fprintf(stderr, "GRXSTS: %08x\n", grxsts.d32);
+
+    /* Clear RXSTSQLVL in GINTSTS */
+    gintsts.d32 = 0;
+	gintsts.b.rxstsqlvl = 1;
+	dwc_write_reg32(&global_regs->gintsts, gintsts.d32);
+	switch (grxsts.b.pktsts) {
+	case DWC_GRXSTS_PKTSTS_IN_XFER_COMP:
+		break;
+	default:
+	    //fprintf(stderr, "** Unexpected GRXSTS packet status 2 **\n");
+	    break;
+	}
+	gintsts.d32 = dwc_read_reg32(&global_regs->gintsts);
+
+    //fprintf(stderr, "Waiting for HCINTR intr 2, GINTSTS = %08x\n", gintsts.d32);
+
+    /* Wait for host channel interrupt */
+    do {
+		gintsts.d32 = dwc_read_reg32(&global_regs->gintsts);
+	} while (gintsts.b.hcintr == 0);
+
+	//fprintf(stderr, "Got HCINTR intr 2, GINTSTS = %08x\n", gintsts.d32);
+
+	/* Read HAINT */
+	haint.d32 = dwc_read_reg32(&hc_global_regs->haint);
+
+	//fprintf(stderr, "HAINT: %08x\n", haint.d32);
+
+	/* Read HCINT */
+	hcint.d32 = dwc_read_reg32(&hc_regs->hcint);
+
+	//fprintf(stderr, "HCINT: %08x\n", hcint.d32);
+
+	/* Read HCCHAR */
+	hcchar.d32 = dwc_read_reg32(&hc_regs->hcchar);
+
+	//fprintf(stderr, "HCCHAR: %08x\n", hcchar.d32);
+
+	/* Clear HCINT */
+	dwc_write_reg32(&hc_regs->hcint, hcint.d32);
+
+	/* Clear HAINT */
+	dwc_write_reg32(&hc_global_regs->haint, haint.d32);
+
+	/* Clear GINTSTS */
+	dwc_write_reg32(&global_regs->gintsts, gintsts.d32);
+
+	/* Read GINTSTS */
+	gintsts.d32 = dwc_read_reg32(&global_regs->gintsts);
+
+	//fprintf(stderr, "GINTSTS: %08x\n", gintsts.d32);
+
+	//      usleep(100000);
+	//      mdelay(100);
+	mdelay(1);
+
+	/*
+	 * Send handshake packet
+	 */
+
+	/* Read HAINT */
+	haint.d32 = dwc_read_reg32(&hc_global_regs->haint);
+
+	//fprintf(stderr, "HAINT: %08x\n", haint.d32);
+
+	/* Read HCINT */
+	hcint.d32 = dwc_read_reg32(&hc_regs->hcint);
+
+	//fprintf(stderr, "HCINT: %08x\n", hcint.d32);
+
+	/* Read HCCHAR */
+	hcchar.d32 = dwc_read_reg32(&hc_regs->hcchar);
+
+	//fprintf(stderr, "HCCHAR: %08x\n", hcchar.d32);
+
+	/* Clear HCINT */
+	dwc_write_reg32(&hc_regs->hcint, hcint.d32);
+
+	/* Clear HAINT */
+	dwc_write_reg32(&hc_global_regs->haint, haint.d32);
+
+	/* Clear GINTSTS */
+	dwc_write_reg32(&global_regs->gintsts, gintsts.d32);
+
+	/* Read GINTSTS */
+	gintsts.d32 = dwc_read_reg32(&global_regs->gintsts);
+
+	//fprintf(stderr, "GINTSTS: %08x\n", gintsts.d32);
+
+	/* Make sure channel is disabled */
+	hcchar.d32 = dwc_read_reg32(&hc_regs->hcchar);
+	if (hcchar.b.chen) {
+
+	    //fprintf(stderr, "Channel already enabled 3, HCCHAR = %08x\n", hcchar.d32);
+	    hcchar.b.chdis = 1;
+		hcchar.b.chen = 1;
+		dwc_write_reg32(&hc_regs->hcchar, hcchar.d32);
+
+		//sleep(1);
+		mdelay(1000);
+
+		/* Read GINTSTS */
+		gintsts.d32 = dwc_read_reg32(&global_regs->gintsts);
+
+		//fprintf(stderr, "GINTSTS: %08x\n", gintsts.d32);
+
+		/* Read HAINT */
+		haint.d32 = dwc_read_reg32(&hc_global_regs->haint);
+
+		//fprintf(stderr, "HAINT: %08x\n", haint.d32);
+
+		/* Read HCINT */
+		hcint.d32 = dwc_read_reg32(&hc_regs->hcint);
+
+		//fprintf(stderr, "HCINT: %08x\n", hcint.d32);
+
+		/* Read HCCHAR */
+		hcchar.d32 = dwc_read_reg32(&hc_regs->hcchar);
+
+		//fprintf(stderr, "HCCHAR: %08x\n", hcchar.d32);
+
+		/* Clear HCINT */
+		dwc_write_reg32(&hc_regs->hcint, hcint.d32);
+
+		/* Clear HAINT */
+		dwc_write_reg32(&hc_global_regs->haint, haint.d32);
+
+		/* Clear GINTSTS */
+		dwc_write_reg32(&global_regs->gintsts, gintsts.d32);
+		hcchar.d32 = dwc_read_reg32(&hc_regs->hcchar);
+
+		//if (hcchar.b.chen) {
+		//      fprintf(stderr, "** Channel _still_ enabled 3, HCCHAR = %08x **\n", hcchar.d32);
+		//}
+	}
+
+    /* Set HCTSIZ */
+    hctsiz.d32 = 0;
+	hctsiz.b.xfersize = 0;
+	hctsiz.b.pktcnt = 1;
+	hctsiz.b.pid = DWC_OTG_HC_PID_DATA1;
+	dwc_write_reg32(&hc_regs->hctsiz, hctsiz.d32);
+
+    /* Set HCCHAR */
+    hcchar.d32 = dwc_read_reg32(&hc_regs->hcchar);
+	hcchar.b.eptype = DWC_OTG_EP_TYPE_CONTROL;
+	hcchar.b.epdir = 0;
+	hcchar.b.epnum = 0;
+	hcchar.b.mps = 8;
+	hcchar.b.chen = 1;
+	dwc_write_reg32(&hc_regs->hcchar, hcchar.d32);
+	gintsts.d32 = dwc_read_reg32(&global_regs->gintsts);
+
+    //fprintf(stderr, "Waiting for HCINTR intr 3, GINTSTS = %08x\n", gintsts.d32);
+
+    /* Wait for host channel interrupt */
+    do {
+		gintsts.d32 = dwc_read_reg32(&global_regs->gintsts);
+	} while (gintsts.b.hcintr == 0);
+
+	//fprintf(stderr, "Got HCINTR intr 3, GINTSTS = %08x\n", gintsts.d32);
+
+	/* Disable HCINTs */
+	dwc_write_reg32(&hc_regs->hcintmsk, 0x0000);
+
+	/* Disable HAINTs */
+	dwc_write_reg32(&hc_global_regs->haintmsk, 0x0000);
+
+	/* Read HAINT */
+	haint.d32 = dwc_read_reg32(&hc_global_regs->haint);
+
+	//fprintf(stderr, "HAINT: %08x\n", haint.d32);
+
+	/* Read HCINT */
+	hcint.d32 = dwc_read_reg32(&hc_regs->hcint);
+
+	//fprintf(stderr, "HCINT: %08x\n", hcint.d32);
+
+	/* Read HCCHAR */
+	hcchar.d32 = dwc_read_reg32(&hc_regs->hcchar);
+
+	//fprintf(stderr, "HCCHAR: %08x\n", hcchar.d32);
+
+	/* Clear HCINT */
+	dwc_write_reg32(&hc_regs->hcint, hcint.d32);
+
+	/* Clear HAINT */
+	dwc_write_reg32(&hc_global_regs->haint, haint.d32);
+
+	/* Clear GINTSTS */
+	dwc_write_reg32(&global_regs->gintsts, gintsts.d32);
+
+	/* Read GINTSTS */
+	gintsts.d32 = dwc_read_reg32(&global_regs->gintsts);
+
+	//fprintf(stderr, "GINTSTS: %08x\n", gintsts.d32);
+}
+
+#endif	/* DWC_HS_ELECT_TST */
+
+/** Handles hub class-specific requests.*/
+int dwc_otg_hcd_hub_control(struct usb_hcd *_hcd, u16 _typeReq, u16 _wValue,
+			    u16 _wIndex, char *_buf, u16 _wLength)
+{
+	int retval = 0;
+	dwc_otg_hcd_t * dwc_otg_hcd = hcd_to_dwc_otg_hcd(_hcd);
+	dwc_otg_core_if_t * core_if = hcd_to_dwc_otg_hcd(_hcd)->core_if;
+	struct usb_hub_descriptor *desc;
+	hprt0_data_t hprt0 = {.d32 = 0};
+	uint32_t port_status;
+	switch (_typeReq) {
+	case ClearHubFeature:
+		DWC_DEBUGPL(DBG_HCD, "DWC OTG HCD HUB CONTROL - "
+			     "ClearHubFeature 0x%x\n", _wValue);
+		switch (_wValue) {
+		case C_HUB_LOCAL_POWER:
+		case C_HUB_OVER_CURRENT:
+		    /* Nothing required here */
+		    break;
+		default:
+			retval = -EINVAL;
+			DWC_ERROR("DWC OTG HCD - ClearHubFeature request %xh unknown\n",
+				   _wValue);
+		}
+		break;
+	case ClearPortFeature:
+		if (!_wIndex || _wIndex > 1)
+			goto error;
+		switch (_wValue) {
+		case USB_PORT_FEAT_ENABLE:
+			DWC_DEBUGPL(DBG_ANY, "DWC OTG HCD HUB CONTROL - "
+				     "ClearPortFeature USB_PORT_FEAT_ENABLE\n");
+			hprt0.d32 = dwc_otg_read_hprt0(core_if);
+			hprt0.b.prtena = 1;
+			dwc_write_reg32(core_if->host_if->hprt0, hprt0.d32);
+			break;
+		case USB_PORT_FEAT_SUSPEND:
+			DWC_DEBUGPL(DBG_HCD, "DWC OTG HCD HUB CONTROL - "
+				     "ClearPortFeature USB_PORT_FEAT_SUSPEND\n");
+			hprt0.d32 = dwc_otg_read_hprt0(core_if);
+			hprt0.b.prtres = 1;
+			dwc_write_reg32(core_if->host_if->hprt0, hprt0.d32);
+
+		    /* Clear Resume bit */
+		    mdelay(100);
+			hprt0.b.prtres = 0;
+			dwc_write_reg32(core_if->host_if->hprt0, hprt0.d32);
+			break;
+		case USB_PORT_FEAT_POWER:
+			DWC_DEBUGPL(DBG_HCD, "DWC OTG HCD HUB CONTROL - "
+				     "ClearPortFeature USB_PORT_FEAT_POWER\n");
+			hprt0.d32 = dwc_otg_read_hprt0(core_if);
+			hprt0.b.prtpwr = 0;
+			dwc_write_reg32(core_if->host_if->hprt0, hprt0.d32);
+			break;
+		case USB_PORT_FEAT_INDICATOR:
+			DWC_DEBUGPL(DBG_HCD, "DWC OTG HCD HUB CONTROL - "
+				     "ClearPortFeature USB_PORT_FEAT_INDICATOR\n");
+
+			/* Port inidicator not supported */
+			break;
+		case USB_PORT_FEAT_C_CONNECTION:
+			/* Clears drivers internal connect status change
+			 * flag */
+			DWC_DEBUGPL(DBG_HCD, "DWC OTG HCD HUB CONTROL - "
+					"ClearPortFeature USB_PORT_FEAT_C_CONNECTION\n");
+			dwc_otg_hcd->flags.b.port_connect_status_change = 0;
+			break;
+		case USB_PORT_FEAT_C_RESET:
+			/* Clears the driver's internal Port Reset Change
+			 * flag */
+			DWC_DEBUGPL(DBG_HCD, "DWC OTG HCD HUB CONTROL - "
+					"ClearPortFeature USB_PORT_FEAT_C_RESET\n");
+			dwc_otg_hcd->flags.b.port_reset_change = 0;
+			break;
+		case USB_PORT_FEAT_C_ENABLE:
+			/* Clears the driver's internal Port
+			 * Enable/Disable Change flag */
+			DWC_DEBUGPL(DBG_HCD, "DWC OTG HCD HUB CONTROL - "
+					"ClearPortFeature USB_PORT_FEAT_C_ENABLE\n");
+			dwc_otg_hcd->flags.b.port_enable_change = 0;
+			break;
+		case USB_PORT_FEAT_C_SUSPEND:
+		    /* Clears the driver's internal Port Suspend
+		     * Change flag, which is set when resume signaling on
+		     * the host port is complete */
+		    DWC_DEBUGPL(DBG_HCD, "DWC OTG HCD HUB CONTROL - "
+					"ClearPortFeature USB_PORT_FEAT_C_SUSPEND\n");
+			dwc_otg_hcd->flags.b.port_suspend_change = 0;
+			break;
+		case USB_PORT_FEAT_C_OVER_CURRENT:
+			DWC_DEBUGPL(DBG_HCD, "DWC OTG HCD HUB CONTROL - "
+				     "ClearPortFeature USB_PORT_FEAT_C_OVER_CURRENT\n");
+			dwc_otg_hcd->flags.b.port_over_current_change = 0;
+			break;
+		default:
+			retval = -EINVAL;
+			DWC_ERROR("DWC OTG HCD - "
+				   "ClearPortFeature request %xh "
+				   "unknown or unsupported\n", _wValue);
+		}
+		break;
+	case GetHubDescriptor:
+		DWC_DEBUGPL(DBG_HCD, "DWC OTG HCD HUB CONTROL - "
+			     "GetHubDescriptor\n");
+		desc = (struct usb_hub_descriptor *)_buf;
+		desc->bDescLength = 9;
+		desc->bDescriptorType = 0x29;
+		desc->bNbrPorts = 1;
+		desc->wHubCharacteristics = 0x08;
+		desc->bPwrOn2PwrGood = 1;
+		desc->bHubContrCurrent = 0;
+		desc->u.ss.bHubHdrDecLat = 0;
+		desc->u.ss.wHubDelay = 0;
+		desc->u.ss.DeviceRemovable = 0xff;
+//		desc->bitmap[0] = 0;
+//		desc->bitmap[1] = 0xff;
+		break;
+	case GetHubStatus:
+		DWC_DEBUGPL(DBG_HCD, "DWC OTG HCD HUB CONTROL - "
+			     "GetHubStatus\n");
+		memset(_buf, 0, 4);
+		break;
+	case GetPortStatus:
+		DWC_DEBUGPL(DBG_HCD, "DWC OTG HCD HUB CONTROL - "
+			     "GetPortStatus\n");
+		if (!_wIndex || _wIndex > 1)
+			goto error;
+		port_status = 0;
+		if (dwc_otg_hcd->flags.b.port_connect_status_change)
+			port_status |= (1 << USB_PORT_FEAT_C_CONNECTION);
+		if (dwc_otg_hcd->flags.b.port_enable_change)
+			port_status |= (1 << USB_PORT_FEAT_C_ENABLE);
+		if (dwc_otg_hcd->flags.b.port_suspend_change)
+			port_status |= (1 << USB_PORT_FEAT_C_SUSPEND);
+		if (dwc_otg_hcd->flags.b.port_reset_change)
+			port_status |= (1 << USB_PORT_FEAT_C_RESET);
+		if (dwc_otg_hcd->flags.b.port_over_current_change) {
+			DWC_ERROR("Device Not Supported\n");
+			port_status |= (1 << USB_PORT_FEAT_C_OVER_CURRENT);
+		}
+		if (!dwc_otg_hcd->flags.b.port_connect_status) {
+		    /*
+		     * The port is disconnected, which means the core is
+		     * either in device mode or it soon will be. Just
+		     * return 0's for the remainder of the port status
+		     * since the port register can't be read if the core
+		     * is in device mode.
+		     */
+		    *((__le32 *) _buf) = cpu_to_le32(port_status);
+			break;
+		}
+		hprt0.d32 = dwc_read_reg32(core_if->host_if->hprt0);
+		DWC_DEBUGPL(DBG_HCDV, "  HPRT0: 0x%08x\n", hprt0.d32);
+		if (hprt0.b.prtconnsts)
+			port_status |= (1 << USB_PORT_FEAT_CONNECTION);
+		if (hprt0.b.prtena)
+			port_status |= (1 << USB_PORT_FEAT_ENABLE);
+		if (hprt0.b.prtsusp)
+			port_status |= (1 << USB_PORT_FEAT_SUSPEND);
+		if (hprt0.b.prtovrcurract)
+			port_status |= (1 << USB_PORT_FEAT_OVER_CURRENT);
+		if (hprt0.b.prtrst)
+			port_status |= (1 << USB_PORT_FEAT_RESET);
+		if (hprt0.b.prtpwr)
+			port_status |= (1 << USB_PORT_FEAT_POWER);
+		if (hprt0.b.prtspd == DWC_HPRT0_PRTSPD_HIGH_SPEED)
+			port_status |= USB_PORT_STAT_HIGH_SPEED;
+
+		else if (hprt0.b.prtspd == DWC_HPRT0_PRTSPD_LOW_SPEED)
+			port_status |= (1 << USB_PORT_FEAT_LOWSPEED);
+		if (hprt0.b.prttstctl)
+			port_status |= (1 << USB_PORT_FEAT_TEST);
+
+	    /* USB_PORT_FEAT_INDICATOR unsupported always 0 */
+	    *((__le32 *) _buf) = cpu_to_le32(port_status);
+		break;
+	case SetHubFeature:
+		DWC_DEBUGPL(DBG_HCD, "DWC OTG HCD HUB CONTROL - "
+			     "SetHubFeature\n");
+
+	    /* No HUB features supported */
+	    break;
+	case SetPortFeature:
+		if (_wValue != USB_PORT_FEAT_TEST && (!_wIndex || _wIndex > 1))
+			goto error;
+		if (!dwc_otg_hcd->flags.b.port_connect_status) {
+		    /*
+		     * The port is disconnected, which means the core is
+		     * either in device mode or it soon will be. Just
+		     * return without doing anything since the port
+		     * register can't be written if the core is in device
+		     * mode.
+		     */
+		    break;
+		}
+		switch (_wValue) {
+		case USB_PORT_FEAT_SUSPEND:
+			DWC_DEBUGPL(DBG_HCD, "DWC OTG HCD HUB CONTROL - "
+				     "SetPortFeature - USB_PORT_FEAT_SUSPEND\n");
+			if (_hcd->self.otg_port == _wIndex
+			     && _hcd->self.b_hnp_enable) {
+				gotgctl_data_t gotgctl = {.d32 = 0};
+				gotgctl.b.hstsethnpen = 1;
+				dwc_modify_reg32(&core_if->core_global_regs->
+						  gotgctl, 0, gotgctl.d32);
+				core_if->op_state = A_SUSPEND;
+			}
+			hprt0.d32 = dwc_otg_read_hprt0(core_if);
+			hprt0.b.prtsusp = 1;
+			dwc_write_reg32(core_if->host_if->hprt0, hprt0.d32);
+
+		    //DWC_PRINT( "SUSPEND: HPRT0=%0x\n", hprt0.d32);
+		    /* Suspend the Phy Clock */
+			{
+				pcgcctl_data_t pcgcctl = {.d32 = 0};
+				pcgcctl.b.stoppclk = 1;
+				dwc_write_reg32(core_if->pcgcctl, pcgcctl.d32);
+			}
+
+		    /* For HNP the bus must be suspended for at least 200ms. */
+		    if (_hcd->self.b_hnp_enable) {
+				mdelay(200);
+
+			    //DWC_PRINT( "SUSPEND: wait complete! (%d)\n", _hcd->state);
+			}
+			break;
+		case USB_PORT_FEAT_POWER:
+			DWC_DEBUGPL(DBG_HCD, "DWC OTG HCD HUB CONTROL - "
+				     "SetPortFeature - USB_PORT_FEAT_POWER\n");
+			hprt0.d32 = dwc_otg_read_hprt0(core_if);
+			hprt0.b.prtpwr = 1;
+			dwc_write_reg32(core_if->host_if->hprt0, hprt0.d32);
+			break;
+		case USB_PORT_FEAT_RESET:
+			DWC_DEBUGPL(DBG_HCD, "DWC OTG HCD HUB CONTROL - "
+				     "SetPortFeature - USB_PORT_FEAT_RESET\n");
+			hprt0.d32 = dwc_otg_read_hprt0(core_if);
+
+		    /* When B-Host the Port reset bit is set in
+		     * the Start HCD Callback function, so that
+		     * the reset is started within 1ms of the HNP
+		     * success interrupt. */
+		    if (!_hcd->self.is_b_host) {
+				hprt0.b.prtrst = 1;
+				dwc_write_reg32(core_if->host_if->hprt0, hprt0.d32);
+			}
+
+		    /* Clear reset bit in 10ms (FS/LS) or 50ms (HS) */
+		    	MDELAY(60);
+			hprt0.b.prtrst = 0;
+			dwc_write_reg32(core_if->host_if->hprt0, hprt0.d32);
+			break;
+
+#ifdef DWC_HS_ELECT_TST
+		case USB_PORT_FEAT_TEST:
+			 {
+				uint32_t t;
+				gintmsk_data_t gintmsk;
+				t = (_wIndex >> 8);	/* MSB wIndex USB */
+				DWC_DEBUGPL(DBG_HCD,
+					     "DWC OTG HCD HUB CONTROL - "
+					     "SetPortFeature - USB_PORT_FEAT_TEST %d\n",
+					     t);
+				warn("USB_PORT_FEAT_TEST %d\n", t);
+				if (t < 6) {
+					hprt0.d32 = dwc_otg_read_hprt0(core_if);
+					hprt0.b.prttstctl = t;
+					dwc_write_reg32(core_if->host_if->hprt0, hprt0.d32);
+				} else {
+				    /* Setup global vars with reg addresses (quick and
+				     * dirty hack, should be cleaned up)
+				     */
+				    global_regs = core_if->core_global_regs;
+					hc_global_regs = core_if->host_if->host_global_regs;
+					hc_regs = (dwc_otg_hc_regs_t *) ((char *) global_regs + 0x500);
+					data_fifo = (uint32_t *) ((char *)global_regs + 0x1000);
+					if (t == 6) {	/* HS_HOST_PORT_SUSPEND_RESUME */
+						/* Save current interrupt mask */
+						gintmsk.d32 =dwc_read_reg32(&global_regs->gintmsk);
+
+						/* Disable all interrupts while we muck with
+						 * the hardware directly
+						 */
+						dwc_write_reg32(&global_regs->gintmsk, 0);
+
+						/* 15 second delay per the test spec */
+						mdelay(15000);
+
+						/* Drive suspend on the root port */
+						hprt0.d32 = dwc_otg_read_hprt0(core_if);
+						hprt0.b.prtsusp = 1;
+						hprt0.b.prtres = 0;
+						dwc_write_reg32(core_if->host_if->hprt0,hprt0.d32);
+
+						/* 15 second delay per the test spec */
+						mdelay(15000);
+
+						/* Drive resume on the root port */
+						hprt0.d32 = dwc_otg_read_hprt0(core_if);
+						hprt0.b.prtsusp = 0;
+						hprt0.b.prtres = 1;
+						dwc_write_reg32(core_if->host_if->hprt0,hprt0.d32);
+						mdelay(100);
+
+						/* Clear the resume bit */
+						hprt0.b.prtres = 0;
+						dwc_write_reg32(core_if->host_if->hprt0,hprt0.d32);
+
+					    /* Restore interrupts */
+					    dwc_write_reg32(&global_regs->gintmsk,gintmsk.d32);
+					} else if (t == 7) {	/* SINGLE_STEP_GET_DEVICE_DESCRIPTOR setup */
+						/* Save current interrupt mask */
+						gintmsk.d32 = dwc_read_reg32(&global_regs->gintmsk);
+
+						/* Disable all interrupts while we muck with
+						 * the hardware directly
+						 */
+						dwc_write_reg32(&global_regs->gintmsk, 0);
+
+						/* 15 second delay per the test spec */
+						mdelay(15000);
+
+						/* Send the Setup packet */
+						do_setup();
+
+						/* 15 second delay so nothing else happens for awhile */
+						mdelay(15000);
+
+						/* Restore interrupts */
+						dwc_write_reg32(&global_regs->gintmsk,gintmsk.d32);
+					} else if (t == 8) {	/* SINGLE_STEP_GET_DEVICE_DESCRIPTOR execute */
+						/* Save current interrupt mask */
+						gintmsk.d32 = dwc_read_reg32(&global_regs->gintmsk);
+
+						/* Disable all interrupts while we muck with
+						 * the hardware directly
+						 */
+						dwc_write_reg32(&global_regs->gintmsk, 0);
+
+						/* Send the Setup packet */
+						do_setup();
+
+						/* 15 second delay so nothing else happens for awhile */
+						mdelay(15000);
+
+						/* Send the In and Ack packets */
+						do_in_ack();
+
+						/* 15 second delay so nothing else happens for awhile */
+						mdelay(15000);
+
+						/* Restore interrupts */
+						dwc_write_reg32(&global_regs->gintmsk,gintmsk.d32);
+					}
+				}
+				break;
+			}
+
+#endif	/* DWC_HS_ELECT_TST */
+		case USB_PORT_FEAT_INDICATOR:
+			DWC_DEBUGPL(DBG_HCD, "DWC OTG HCD HUB CONTROL - "
+				     "SetPortFeature - USB_PORT_FEAT_INDICATOR\n");
+			/* Not supported */
+			break;
+		default:
+			retval = -EINVAL;
+			DWC_ERROR("DWC OTG HCD - "
+				   "SetPortFeature request %xh "
+				   "unknown or unsupported\n", _wValue);
+			break;
+		}
+		break;
+	default:
+		error:retval = -EINVAL;
+		DWC_WARN("DWC OTG HCD - "
+			  "Unknown hub control request type or invalid typeReq: %xh wIndex: %xh wValue: %xh\n",
+			  _typeReq, _wIndex, _wValue);
+		break;
+	}
+	return retval;
+}
+
+
+/**
+ * Assigns transactions from a QTD to a free host channel and initializes the
+ * host channel to perform the transactions. The host channel is removed from
+ * the free list.
+ *
+ * @param _hcd The HCD state structure.
+ * @param _qh Transactions from the first QTD for this QH are selected and
+ * assigned to a free host channel.
+ */
+static void assign_and_init_hc(dwc_otg_hcd_t * _hcd, dwc_otg_qh_t * _qh)
+{
+	dwc_hc_t * hc;
+	dwc_otg_qtd_t * qtd;
+	struct urb *urb;
+	DWC_DEBUGPL(DBG_HCDV, "%s(%p,%p)\n", __func__, _hcd, _qh);
+	hc = list_entry(_hcd->free_hc_list.next, dwc_hc_t, hc_list_entry);
+
+	/* Remove the host channel from the free list. */
+	list_del_init(&hc->hc_list_entry);
+	qtd = list_entry(_qh->qtd_list.next, dwc_otg_qtd_t, qtd_list_entry);
+	urb = qtd->urb;
+	_qh->channel = hc;
+	_qh->qtd_in_process = qtd;
+
+	/*
+	 * Use usb_pipedevice to determine device address. This address is
+	 * 0 before the SET_ADDRESS command and the correct address afterward.
+	 */
+	hc->dev_addr = usb_pipedevice(urb->pipe);
+	hc->ep_num = usb_pipeendpoint(urb->pipe);
+	if (urb->dev->speed == USB_SPEED_LOW) {
+		hc->speed = DWC_OTG_EP_SPEED_LOW;
+	} else if (urb->dev->speed == USB_SPEED_FULL) {
+		hc->speed = DWC_OTG_EP_SPEED_FULL;
+	} else {
+		hc->speed = DWC_OTG_EP_SPEED_HIGH;
+	}
+	hc->max_packet = dwc_max_packet(_qh->maxp);
+	hc->xfer_started = 0;
+	hc->halt_status = DWC_OTG_HC_XFER_NO_HALT_STATUS;
+	hc->error_state = (qtd->error_count > 0);
+	hc->halt_on_queue = 0;
+	hc->halt_pending = 0;
+	hc->requests = 0;
+
+	/*
+	 * The following values may be modified in the transfer type section
+	 * below. The xfer_len value may be reduced when the transfer is
+	 * started to accommodate the max widths of the XferSize and PktCnt
+	 * fields in the HCTSIZn register.
+	 */
+	hc->do_ping = _qh->ping_state;
+	hc->ep_is_in = (usb_pipein(urb->pipe) != 0);
+	hc->data_pid_start = _qh->data_toggle;
+	hc->multi_count = 1;
+	if (_hcd->core_if->dma_enable) {
+		hc->xfer_buff =
+			(uint8_t *)(u32)urb->transfer_dma + urb->actual_length;
+	} else {
+		hc->xfer_buff =
+		    (uint8_t *) urb->transfer_buffer + urb->actual_length;
+	}
+	hc->xfer_len = urb->transfer_buffer_length - urb->actual_length;
+	hc->xfer_count = 0;
+
+	/*
+	 * Set the split attributes
+	 */
+	hc->do_split = 0;
+	if (_qh->do_split) {
+		hc->do_split = 1;
+		hc->xact_pos = qtd->isoc_split_pos;
+		hc->complete_split = qtd->complete_split;
+		hc->hub_addr = urb->dev->tt->hub->devnum;
+		hc->port_addr = urb->dev->ttport;
+	}
+	switch (usb_pipetype(urb->pipe)) {
+	case PIPE_CONTROL:
+		hc->ep_type = DWC_OTG_EP_TYPE_CONTROL;
+		switch (qtd->control_phase) {
+		case DWC_OTG_CONTROL_SETUP:
+			DWC_DEBUGPL(DBG_HCDV, "  Control setup transaction\n");
+			hc->do_ping = 0;
+			hc->ep_is_in = 0;
+			hc->data_pid_start = DWC_OTG_HC_PID_SETUP;
+			if (_hcd->core_if->dma_enable) {
+				hc->xfer_buff = (uint8_t *)(u32)urb->setup_dma;
+			} else {
+				hc->xfer_buff = (uint8_t *) urb->setup_packet;
+			}
+			hc->xfer_len = 8;
+			break;
+		case DWC_OTG_CONTROL_DATA:
+			DWC_DEBUGPL(DBG_HCDV, "  Control data transaction\n");
+			hc->data_pid_start = qtd->data_toggle;
+			break;
+		case DWC_OTG_CONTROL_STATUS:
+
+			/*
+			 * Direction is opposite of data direction or IN if no
+			 * data.
+			 */
+			DWC_DEBUGPL(DBG_HCDV,
+					"  Control status transaction\n");
+			if (urb->transfer_buffer_length == 0) {
+				hc->ep_is_in = 1;
+			} else {
+				hc->ep_is_in = (usb_pipein(urb->pipe) != USB_DIR_IN);
+			}
+			if (hc->ep_is_in) {
+				hc->do_ping = 0;
+			}
+			hc->data_pid_start = DWC_OTG_HC_PID_DATA1;
+			hc->xfer_len = 0;
+			if (_hcd->core_if->dma_enable) {
+				hc->xfer_buff = (uint8_t *)(u32)_hcd->status_buf_dma;
+			} else {
+				hc->xfer_buff = (uint8_t *) _hcd->status_buf;
+			}
+			break;
+		}
+		break;
+	case PIPE_BULK:
+		hc->ep_type = DWC_OTG_EP_TYPE_BULK;
+		break;
+	case PIPE_INTERRUPT:
+		hc->ep_type = DWC_OTG_EP_TYPE_INTR;
+		break;
+	case PIPE_ISOCHRONOUS:
+		{
+			struct usb_iso_packet_descriptor *frame_desc;
+			frame_desc = &urb->iso_frame_desc[qtd->isoc_frame_index];
+			hc->ep_type = DWC_OTG_EP_TYPE_ISOC;
+			if (_hcd->core_if->dma_enable) {
+				hc->xfer_buff = (uint8_t *)(u32)urb->transfer_dma;
+			} else {
+				hc->xfer_buff = (uint8_t *) urb->transfer_buffer;
+			}
+			hc->xfer_buff += frame_desc->offset + qtd->isoc_split_offset;
+			hc->xfer_len = frame_desc->length - qtd->isoc_split_offset;
+			if (hc->xact_pos == DWC_HCSPLIT_XACTPOS_ALL) {
+				if (hc->xfer_len <= 188) {
+					hc->xact_pos = DWC_HCSPLIT_XACTPOS_ALL;
+				} else {
+					hc->xact_pos = DWC_HCSPLIT_XACTPOS_BEGIN;
+				}
+			}
+		}
+		break;
+	}
+
+	if (hc->ep_type == DWC_OTG_EP_TYPE_INTR
+	   || hc->ep_type == DWC_OTG_EP_TYPE_ISOC) {
+		/*
+		 * This value may be modified when the transfer is started to
+		 * reflect the actual transfer length.
+		 */
+		hc->multi_count = dwc_hb_mult(_qh->maxp);
+	}
+	dwc_otg_hc_init(_hcd->core_if, hc);
+	hc->qh = _qh;
+}
+
+
+/**
+ * This function selects transactions from the HCD transfer schedule and
+ * assigns them to available host channels. It is called from HCD interrupt
+ * handler functions.
+ *
+ * @param _hcd The HCD state structure.
+ *
+ * @return The types of new transactions that were assigned to host channels.
+ */
+dwc_otg_transaction_type_e dwc_otg_hcd_select_transactions(dwc_otg_hcd_t *_hcd)
+{
+	struct list_head *qh_ptr;
+	dwc_otg_qh_t * qh;
+	int num_channels;
+	unsigned long flags;
+	dwc_otg_transaction_type_e ret_val = DWC_OTG_TRANSACTION_NONE;
+
+#ifdef DEBUG_SOF
+	    DWC_DEBUGPL(DBG_HCD, "  Select Transactions\n");
+#endif	/*  */
+
+	/* Process entries in the periodic ready list. */
+	num_channels = _hcd->core_if->core_params->host_channels;
+	qh_ptr = _hcd->periodic_sched_ready.next;
+	while (qh_ptr != &_hcd->periodic_sched_ready
+		&& !list_empty(&_hcd->free_hc_list)) {
+
+		// Make sure we leave one channel for non periodic transactions.
+		local_irq_save(flags);
+		if (_hcd->available_host_channels <= 1) {
+			local_irq_restore(flags);
+			break;
+		}
+		_hcd->available_host_channels--;
+		local_irq_restore(flags);
+
+		qh = list_entry(qh_ptr, dwc_otg_qh_t, qh_list_entry);
+		assign_and_init_hc(_hcd, qh);
+		/*
+		 * Move the QH from the periodic ready schedule to the
+		 * periodic assigned schedule.
+		 */
+		qh_ptr = qh_ptr->next;
+		local_irq_save(flags);
+		list_move(&qh->qh_list_entry, &_hcd->periodic_sched_assigned);
+		local_irq_restore(flags);
+		ret_val = DWC_OTG_TRANSACTION_PERIODIC;
+	}
+	/*
+	 * Process entries in the deferred portion of the non-periodic list.
+	 * A NAK put them here and, at the right time, they need to be
+	 * placed on the sched_inactive list.
+	 */
+	qh_ptr = _hcd->non_periodic_sched_deferred.next;
+	while (qh_ptr != &_hcd->non_periodic_sched_deferred) {
+		uint16_t frame_number =
+			dwc_otg_hcd_get_frame_number(dwc_otg_hcd_to_hcd(_hcd));
+		qh = list_entry(qh_ptr, dwc_otg_qh_t, qh_list_entry);
+		qh_ptr = qh_ptr->next;
+
+		if (dwc_frame_num_le(qh->sched_frame, frame_number)) {
+			// NAK did this
+			/*
+			 * Move the QH from the non periodic deferred schedule to
+			 * the non periodic inactive schedule.
+			 */
+			local_irq_save(flags);
+			list_move(&qh->qh_list_entry,
+				  &_hcd->non_periodic_sched_inactive);
+		        local_irq_restore(flags);
+		}
+	}
+
+	/*
+	 * Process entries in the inactive portion of the non-periodic
+	 * schedule. Some free host channels may not be used if they are
+	 * reserved for periodic transfers.
+	 */
+	qh_ptr = _hcd->non_periodic_sched_inactive.next;
+	num_channels = _hcd->core_if->core_params->host_channels;
+	while (qh_ptr != &_hcd->non_periodic_sched_inactive
+		&& !list_empty(&_hcd->free_hc_list)) {
+
+		local_irq_save(flags);
+		if (_hcd->available_host_channels < 1) {
+			local_irq_restore(flags);
+			break;
+		}
+		_hcd->available_host_channels--;
+		local_irq_restore(flags);
+
+		qh = list_entry(qh_ptr, dwc_otg_qh_t, qh_list_entry);
+		assign_and_init_hc(_hcd, qh);
+
+		/*
+		 * Move the QH from the non-periodic inactive schedule to the
+		 * non-periodic active schedule.
+		 */
+		qh_ptr = qh_ptr->next;
+		local_irq_save(flags);
+		list_move(&qh->qh_list_entry,
+			   &_hcd->non_periodic_sched_active);
+		local_irq_restore(flags);
+		if (ret_val == DWC_OTG_TRANSACTION_NONE) {
+			ret_val = DWC_OTG_TRANSACTION_NON_PERIODIC;
+		} else {
+			ret_val = DWC_OTG_TRANSACTION_ALL;
+		}
+	}
+	return ret_val;
+}
+
+/**
+ * Attempts to queue a single transaction request for a host channel
+ * associated with either a periodic or non-periodic transfer. This function
+ * assumes that there is space available in the appropriate request queue. For
+ * an OUT transfer or SETUP transaction in Slave mode, it checks whether space
+ * is available in the appropriate Tx FIFO.
+ *
+ * @param _hcd The HCD state structure.
+ * @param _hc Host channel descriptor associated with either a periodic or
+ * non-periodic transfer.
+ * @param _fifo_dwords_avail Number of DWORDs available in the periodic Tx
+ * FIFO for periodic transfers or the non-periodic Tx FIFO for non-periodic
+ * transfers.
+ *
+ * @return 1 if a request is queued and more requests may be needed to
+ * complete the transfer, 0 if no more requests are required for this
+ * transfer, -1 if there is insufficient space in the Tx FIFO.
+ */
+static int queue_transaction(dwc_otg_hcd_t * _hcd,
+			     dwc_hc_t * _hc,  uint16_t _fifo_dwords_avail)
+{
+	int retval;
+	if (_hcd->core_if->dma_enable) {
+		if (!_hc->xfer_started) {
+			dwc_otg_hc_start_transfer(_hcd->core_if, _hc);
+			_hc->qh->ping_state = 0;
+		}
+		retval = 0;
+	} else if (_hc->halt_pending) {
+		/* Don't queue a request if the channel has been halted. */
+		retval = 0;
+	} else if (_hc->halt_on_queue) {
+		dwc_otg_hc_halt(_hcd->core_if, _hc, _hc->halt_status);
+		retval = 0;
+	} else if (_hc->do_ping) {
+		if (!_hc->xfer_started) {
+			dwc_otg_hc_start_transfer(_hcd->core_if, _hc);
+		}
+		retval = 0;
+	} else if (!_hc->ep_is_in || _hc->data_pid_start == DWC_OTG_HC_PID_SETUP) {
+		if ((_fifo_dwords_avail * 4) >= _hc->max_packet) {
+			if (!_hc->xfer_started) {
+				dwc_otg_hc_start_transfer(_hcd->core_if, _hc);
+				retval = 1;
+			} else {
+				retval = dwc_otg_hc_continue_transfer(_hcd->core_if, _hc);
+			}
+		} else {
+			retval = -1;
+		}
+	} else {
+		if (!_hc->xfer_started) {
+			dwc_otg_hc_start_transfer(_hcd->core_if, _hc);
+			retval = 1;
+		} else {
+			retval = dwc_otg_hc_continue_transfer(_hcd->core_if, _hc);
+		}
+	}
+	return retval;
+}
+
+
+/**
+ * Processes active non-periodic channels and queues transactions for these
+ * channels to the DWC_otg controller. After queueing transactions, the NP Tx
+ * FIFO Empty interrupt is enabled if there are more transactions to queue as
+ * NP Tx FIFO or request queue space becomes available. Otherwise, the NP Tx
+ * FIFO Empty interrupt is disabled.
+ */
+static void process_non_periodic_channels(dwc_otg_hcd_t * _hcd)
+{
+	gnptxsts_data_t tx_status;
+	struct list_head *orig_qh_ptr;
+	dwc_otg_qh_t * qh;
+	int status;
+	int no_queue_space = 0;
+	int no_fifo_space = 0;
+	int more_to_do = 0;
+	dwc_otg_core_global_regs_t * global_regs =
+	    _hcd->core_if->core_global_regs;
+	DWC_DEBUGPL(DBG_HCDV, "Queue non-periodic transactions\n");
+
+#ifdef CONFIG_DWC_DEBUG
+	tx_status.d32 = dwc_read_reg32(&global_regs->gnptxsts);
+	DWC_DEBUGPL(DBG_HCDV, "  NP Tx Req Queue Space Avail (before queue): %d\n",
+		     tx_status.b.nptxqspcavail);
+	DWC_DEBUGPL(DBG_HCDV, "  NP Tx FIFO Space Avail (before queue): %d\n",
+		     tx_status.b.nptxfspcavail);
+#endif	/*  */
+	/*
+	 * Keep track of the starting point. Skip over the start-of-list
+	 * entry.
+	 */
+	if (_hcd->non_periodic_qh_ptr == &_hcd->non_periodic_sched_active) {
+		_hcd->non_periodic_qh_ptr = _hcd->non_periodic_qh_ptr->next;
+	}
+	orig_qh_ptr = _hcd->non_periodic_qh_ptr;
+
+	/*
+	 * Process once through the active list or until no more space is
+	 * available in the request queue or the Tx FIFO.
+	 */
+	do {
+
+		tx_status.d32 = dwc_read_reg32(&global_regs->gnptxsts);
+		if (!_hcd->core_if->dma_enable
+		     && tx_status.b.nptxqspcavail == 0) {
+			no_queue_space = 1;
+			break;
+		}
+		qh =
+		    list_entry(_hcd->non_periodic_qh_ptr, dwc_otg_qh_t,
+			       qh_list_entry);
+		status =
+		    queue_transaction(_hcd, qh->channel,
+				      tx_status.b.nptxfspcavail);
+
+		if (status > 0) {
+			more_to_do = 1;
+		} else if (status < 0) {
+			no_fifo_space = 1;
+			break;
+		}
+#ifdef CONFIG_OTG_PLB_DMA_TASKLET
+		if (atomic_read(&release_later)) {
+			break;
+		}
+#endif
+
+		/* Advance to next QH, skipping start-of-list entry. */
+		_hcd->non_periodic_qh_ptr = _hcd->non_periodic_qh_ptr->next;
+		if (_hcd->non_periodic_qh_ptr == &_hcd->non_periodic_sched_active) {
+			_hcd->non_periodic_qh_ptr = _hcd->non_periodic_qh_ptr->next;
+		}
+	} while (_hcd->non_periodic_qh_ptr != orig_qh_ptr);
+	if (!_hcd->core_if->dma_enable) {
+		gintmsk_data_t intr_mask = {.d32 = 0};
+		intr_mask.b.nptxfempty = 1;
+
+#ifndef CONFIG_OTG_PLB_DMA_TASKLET
+#ifdef CONFIG_DWC_DEBUG
+	    tx_status.d32 = dwc_read_reg32(&global_regs->gnptxsts);
+		DWC_DEBUGPL(DBG_HCDV, "  NP Tx Req Queue Space Avail (after queue): %d\n",
+			     tx_status.b.nptxqspcavail);
+		DWC_DEBUGPL(DBG_HCDV, "  NP Tx FIFO Space Avail (after queue): %d\n",
+			     tx_status.b.nptxfspcavail);
+#endif	/*  */
+#endif
+
+	    if (more_to_do || no_queue_space || no_fifo_space) {
+
+			/*
+			 * May need to queue more transactions as the request
+			 * queue or Tx FIFO empties. Enable the non-periodic
+			 * Tx FIFO empty interrupt. (Always use the half-empty
+			 * level to ensure that new requests are loaded as
+			 * soon as possible.)
+			 */
+			dwc_modify_reg32(&global_regs->gintmsk, 0,intr_mask.d32);
+		} else {
+			/*
+			 * Disable the Tx FIFO empty interrupt since there are
+			 * no more transactions that need to be queued right
+			 * now. This function is called from interrupt
+			 * handlers to queue more transactions as transfer
+			 * states change.
+			 */
+			dwc_modify_reg32(&global_regs->gintmsk,intr_mask.d32, 0);
+		}
+	}
+}
+
+/**
+ * Processes periodic channels for the next frame and queues transactions for
+ * these channels to the DWC_otg controller. After queueing transactions, the
+ * Periodic Tx FIFO Empty interrupt is enabled if there are more transactions
+ * to queue as Periodic Tx FIFO or request queue space becomes available.
+ * Otherwise, the Periodic Tx FIFO Empty interrupt is disabled.
+ */
+static void process_periodic_channels(dwc_otg_hcd_t * _hcd)
+{
+	hptxsts_data_t tx_status;
+	struct list_head *qh_ptr;
+	dwc_otg_qh_t * qh;
+	int status;
+	int no_queue_space = 0;
+	int no_fifo_space = 0;
+	dwc_otg_host_global_regs_t * host_regs;
+	host_regs = _hcd->core_if->host_if->host_global_regs;
+	DWC_DEBUGPL(DBG_HCDV, "Queue periodic transactions\n");
+
+#ifdef CONFIG_DWC_DEBUG
+    tx_status.d32 = dwc_read_reg32(&host_regs->hptxsts);
+	DWC_DEBUGPL(DBG_HCDV, "  P Tx Req Queue Space Avail (before queue): %d\n",
+		     tx_status.b.ptxqspcavail);
+	DWC_DEBUGPL(DBG_HCDV, "  P Tx FIFO Space Avail (before queue): %d\n",
+		     tx_status.b.ptxfspcavail);
+
+#endif	/*  */
+    qh_ptr = _hcd->periodic_sched_assigned.next;
+	while (qh_ptr != &_hcd->periodic_sched_assigned) {
+		tx_status.d32 = dwc_read_reg32(&host_regs->hptxsts);
+		if (tx_status.b.ptxqspcavail == 0) {
+			no_queue_space = 1;
+			break;
+		}
+		qh = list_entry(qh_ptr, dwc_otg_qh_t, qh_list_entry);
+
+		/*
+		 * Set a flag if we're queuing high-bandwidth in slave mode.
+		 * The flag prevents any halts to get into the request queue in
+		 * the middle of multiple high-bandwidth packets getting queued.
+		 */
+		if ((!_hcd->core_if->dma_enable) &&
+			(qh->channel->multi_count > 1)) {
+			_hcd->core_if->queuing_high_bandwidth = 1;
+		}
+		status = queue_transaction(_hcd, qh->channel,tx_status.b.ptxfspcavail);
+		if (status < 0) {
+			no_fifo_space = 1;
+			break;
+		}
+
+		/*
+		 * In Slave mode, stay on the current transfer until there is
+		 * nothing more to do or the high-bandwidth request count is
+		 * reached. In DMA mode, only need to queue one request. The
+		 * controller automatically handles multiple packets for
+		 * high-bandwidth transfers.
+		 */
+		if (_hcd->core_if->dma_enable ||
+			(status == 0 || qh->channel->requests == qh->channel->multi_count)) {
+			qh_ptr = qh_ptr->next;
+
+			/*
+			 * Move the QH from the periodic assigned schedule to
+			 * the periodic queued schedule.
+			 */
+			list_move(&qh->qh_list_entry,
+			      &_hcd->periodic_sched_queued);
+
+			/* done queuing high bandwidth */
+			_hcd->core_if->queuing_high_bandwidth = 0;
+		}
+	}
+	if (!_hcd->core_if->dma_enable) {
+		dwc_otg_core_global_regs_t * global_regs;
+		gintmsk_data_t intr_mask = {.d32 = 0};
+		global_regs = _hcd->core_if->core_global_regs;
+		intr_mask.b.ptxfempty = 1;
+
+#ifdef CONFIG_DWC_DEBUG
+	    tx_status.d32 = dwc_read_reg32(&host_regs->hptxsts);
+		DWC_DEBUGPL(DBG_HCDV,"  P Tx Req Queue Space Avail (after queue): %d\n",
+			     tx_status.b.ptxqspcavail);
+		DWC_DEBUGPL(DBG_HCDV,"  P Tx FIFO Space Avail (after queue): %d\n",
+			     tx_status.b.ptxfspcavail);
+
+#endif	/*  */
+	    if (!(list_empty(&_hcd->periodic_sched_assigned))
+			|| no_queue_space || no_fifo_space) {
+
+			/*
+			 * May need to queue more transactions as the request
+			 * queue or Tx FIFO empties. Enable the periodic Tx
+			 * FIFO empty interrupt. (Always use the half-empty
+			 * level to ensure that new requests are loaded as
+			 * soon as possible.)
+			 */
+			dwc_modify_reg32(&global_regs->gintmsk, 0,intr_mask.d32);
+		} else {
+			/*
+			 * Disable the Tx FIFO empty interrupt since there are
+			 * no more transactions that need to be queued right
+			 * now. This function is called from interrupt
+			 * handlers to queue more transactions as transfer
+			 * states change.
+			 */
+			dwc_modify_reg32(&global_regs->gintmsk,intr_mask.d32, 0);
+		}
+	}
+}
+
+
+
+/**
+ * This function processes the currently active host channels and queues
+ * transactions for these channels to the DWC_otg controller. It is called
+ * from HCD interrupt handler functions.
+ *
+ * @param _hcd The HCD state structure.
+ * @param _tr_type The type(s) of transactions to queue (non-periodic,
+ * periodic, or both).
+ */
+void dwc_otg_hcd_queue_transactions(dwc_otg_hcd_t * _hcd,
+				    dwc_otg_transaction_type_e _tr_type)
+{
+
+#ifdef DEBUG_SOF
+	    DWC_DEBUGPL(DBG_HCD, "Queue Transactions\n");
+
+#endif	/*  */
+	    /* Process host channels associated with periodic transfers. */
+	if ((_tr_type == DWC_OTG_TRANSACTION_PERIODIC
+		 || _tr_type == DWC_OTG_TRANSACTION_ALL)
+		&& !list_empty(&_hcd->periodic_sched_assigned)) {
+		process_periodic_channels(_hcd);
+	}
+
+	/* Process host channels associated with non-periodic transfers. */
+	if ((_tr_type == DWC_OTG_TRANSACTION_NON_PERIODIC
+		|| _tr_type == DWC_OTG_TRANSACTION_ALL)) {
+		if (!list_empty(&_hcd->non_periodic_sched_active)) {
+			process_non_periodic_channels(_hcd);
+		} else {
+			/*
+			 * Ensure NP Tx FIFO empty interrupt is disabled when
+			 * there are no non-periodic transfers to process.
+			 */
+			gintmsk_data_t gintmsk = {.d32 = 0};
+			gintmsk.b.nptxfempty = 1;
+			dwc_modify_reg32(&_hcd->core_if->core_global_regs->gintmsk, gintmsk.d32, 0);
+		}
+	}
+}
+
+/**
+ * Sets the final status of an URB and returns it to the device driver. Any
+ * required cleanup of the URB is performed.
+ */
+void dwc_otg_hcd_complete_urb(dwc_otg_hcd_t * _hcd, struct urb *_urb,
+			      int _status)
+__releases(_hcd->lock)
+__acquires(_hcd->lock)
+{
+
+#ifdef CONFIG_DWC_DEBUG
+   if (CHK_DEBUG_LEVEL(DBG_HCDV | DBG_HCD_URB)) {
+		DWC_PRINT("%s: urb %p, device %d, ep %d %s, status=%d\n",
+			   __func__, _urb, usb_pipedevice(_urb->pipe),
+			   usb_pipeendpoint(_urb->pipe),
+			   usb_pipein(_urb->pipe) ? "IN" : "OUT", _status);
+		if (usb_pipetype(_urb->pipe) == PIPE_ISOCHRONOUS) {
+			int i;
+			for (i = 0; i < _urb->number_of_packets; i++) {
+				DWC_PRINT("  ISO Desc %d status: %d\n", i,
+					   _urb->iso_frame_desc[i].status);
+			}
+		}
+	}
+
+#endif	/*  */
+	spin_lock(&_hcd->lock);
+	_urb->hcpriv = NULL;
+	usb_hcd_unlink_urb_from_ep(dwc_otg_hcd_to_hcd(_hcd), _urb);
+	usb_hcd_giveback_urb(dwc_otg_hcd_to_hcd(_hcd), _urb, _status);
+	spin_unlock(&_hcd->lock);
+}
+
+
+/*
+ * Returns the Queue Head for an URB.
+ */
+dwc_otg_qh_t * dwc_urb_to_qh(struct urb *_urb)
+{
+	struct usb_host_endpoint *ep = dwc_urb_to_endpoint(_urb);
+	return (dwc_otg_qh_t *) ep->hcpriv;
+}
+
+
+#ifdef CONFIG_DWC_DEBUG
+void dwc_print_setup_data(uint8_t * setup)
+{
+	int i;
+	if (CHK_DEBUG_LEVEL(DBG_HCD)) {
+		DWC_PRINT("Setup Data = MSB ");
+		for (i = 7; i >= 0; i--)
+			DWC_PRINT("%02x ", setup[i]);
+		DWC_PRINT("\n");
+		DWC_PRINT("  bmRequestType Tranfer = %s\n",
+			   (setup[0] & 0x80) ? "Device-to-Host" :
+			   "Host-to-Device");
+		DWC_PRINT("  bmRequestType Type = ");
+		switch ((setup[0] & 0x60) >> 5) {
+		case 0:
+			DWC_PRINT("Standard\n");
+			break;
+		case 1:
+			DWC_PRINT("Class\n");
+			break;
+		case 2:
+			DWC_PRINT("Vendor\n");
+			break;
+		case 3:
+			DWC_PRINT("Reserved\n");
+			break;
+		}
+		DWC_PRINT("  bmRequestType Recipient = ");
+		switch (setup[0] & 0x1f) {
+		case 0:
+			DWC_PRINT("Device\n");
+			break;
+		case 1:
+			DWC_PRINT("Interface\n");
+			break;
+		case 2:
+			DWC_PRINT("Endpoint\n");
+			break;
+		case 3:
+			DWC_PRINT("Other\n");
+			break;
+		default:
+			DWC_PRINT("Reserved\n");
+			break;
+		}
+		DWC_PRINT("  bRequest = 0x%0x\n", setup[1]);
+		DWC_PRINT("  wValue = 0x%0x\n", *((uint16_t *) & setup[2]));
+		DWC_PRINT("  wIndex = 0x%0x\n", *((uint16_t *) & setup[4]));
+		DWC_PRINT("  wLength = 0x%0x\n\n", *((uint16_t *) & setup[6]));
+	}
+}
+
+
+#endif	/*  */
+void dwc_otg_hcd_dump_frrem(dwc_otg_hcd_t * _hcd)
+{
+
+/*
+#ifdef CONFIG_DWC_DEBUG
+	DWC_PRINT("Frame remaining at SOF:\n");
+	DWC_PRINT("  samples %u, accum %llu, avg %llu\n",
+		  _hcd->frrem_samples, _hcd->frrem_accum,
+		  (_hcd->frrem_samples > 0) ?
+		  _hcd->frrem_accum/_hcd->frrem_samples : 0);
+
+	DWC_PRINT("\n");
+	DWC_PRINT("Frame remaining at start_transfer (uframe 7):\n");
+	DWC_PRINT("  samples %u, accum %llu, avg %llu\n",
+		  _hcd->core_if->hfnum_7_samples, _hcd->core_if->hfnum_7_frrem_accum,
+		  (_hcd->core_if->hfnum_7_samples > 0) ?
+		  _hcd->core_if->hfnum_7_frrem_accum/_hcd->core_if->hfnum_7_samples : 0);
+	DWC_PRINT("Frame remaining at start_transfer (uframe 0):\n");
+	DWC_PRINT("  samples %u, accum %llu, avg %llu\n",
+		  _hcd->core_if->hfnum_0_samples, _hcd->core_if->hfnum_0_frrem_accum,
+		  (_hcd->core_if->hfnum_0_samples > 0) ?
+		  _hcd->core_if->hfnum_0_frrem_accum/_hcd->core_if->hfnum_0_samples : 0);
+	DWC_PRINT("Frame remaining at start_transfer (uframe 1-6):\n");
+	DWC_PRINT("  samples %u, accum %llu, avg %llu\n",
+		  _hcd->core_if->hfnum_other_samples, _hcd->core_if->hfnum_other_frrem_accum,
+		  (_hcd->core_if->hfnum_other_samples > 0) ?
+		  _hcd->core_if->hfnum_other_frrem_accum/_hcd->core_if->hfnum_other_samples : 0);
+
+	DWC_PRINT("\n");
+	DWC_PRINT("Frame remaining at sample point A (uframe 7):\n");
+	DWC_PRINT("  samples %u, accum %llu, avg %llu\n",
+		  _hcd->hfnum_7_samples_a, _hcd->hfnum_7_frrem_accum_a,
+		  (_hcd->hfnum_7_samples_a > 0) ?
+		  _hcd->hfnum_7_frrem_accum_a/_hcd->hfnum_7_samples_a : 0);
+	DWC_PRINT("Frame remaining at sample point A (uframe 0):\n");
+	DWC_PRINT("  samples %u, accum %llu, avg %llu\n",
+		  _hcd->hfnum_0_samples_a, _hcd->hfnum_0_frrem_accum_a,
+		  (_hcd->hfnum_0_samples_a > 0) ?
+		  _hcd->hfnum_0_frrem_accum_a/_hcd->hfnum_0_samples_a : 0);
+	DWC_PRINT("Frame remaining at sample point A (uframe 1-6):\n");
+	DWC_PRINT("  samples %u, accum %llu, avg %llu\n",
+		  _hcd->hfnum_other_samples_a, _hcd->hfnum_other_frrem_accum_a,
+		  (_hcd->hfnum_other_samples_a > 0) ?
+		  _hcd->hfnum_other_frrem_accum_a/_hcd->hfnum_other_samples_a : 0);
+
+	DWC_PRINT("\n");
+	DWC_PRINT("Frame remaining at sample point B (uframe 7):\n");
+	DWC_PRINT("  samples %u, accum %llu, avg %llu\n",
+		  _hcd->hfnum_7_samples_b, _hcd->hfnum_7_frrem_accum_b,
+		  (_hcd->hfnum_7_samples_b > 0) ?
+		  _hcd->hfnum_7_frrem_accum_b/_hcd->hfnum_7_samples_b : 0);
+	DWC_PRINT("Frame remaining at sample point B (uframe 0):\n");
+	DWC_PRINT("  samples %u, accum %llu, avg %llu\n",
+		  _hcd->hfnum_0_samples_b, _hcd->hfnum_0_frrem_accum_b,
+		  (_hcd->hfnum_0_samples_b > 0) ?
+		  _hcd->hfnum_0_frrem_accum_b/_hcd->hfnum_0_samples_b : 0);
+	DWC_PRINT("Frame remaining at sample point B (uframe 1-6):\n");
+	DWC_PRINT("  samples %u, accum %llu, avg %llu\n",
+		  _hcd->hfnum_other_samples_b, _hcd->hfnum_other_frrem_accum_b,
+		  (_hcd->hfnum_other_samples_b > 0) ?
+		  _hcd->hfnum_other_frrem_accum_b/_hcd->hfnum_other_samples_b : 0);
+#endif
+*/
+} void dwc_otg_hcd_dump_state(dwc_otg_hcd_t * _hcd)
+{
+
+#ifdef CONFIG_DWC_DEBUG
+	int num_channels;
+	int i;
+	gnptxsts_data_t np_tx_status;
+	hptxsts_data_t p_tx_status;
+	num_channels = _hcd->core_if->core_params->host_channels;
+	DWC_PRINT("\n");
+	DWC_PRINT
+	    ("************************************************************\n");
+	DWC_PRINT("HCD State:\n");
+	DWC_PRINT("  Num channels: %d\n", num_channels);
+	for (i = 0; i < num_channels; i++) {
+		dwc_hc_t * hc = _hcd->hc_ptr_array[i];
+		DWC_PRINT("  Channel %d:\n", i);
+		DWC_PRINT("    dev_addr: %d, ep_num: %d, ep_is_in: %d\n",
+			   hc->dev_addr, hc->ep_num, hc->ep_is_in);
+		DWC_PRINT("    speed: %d\n", hc->speed);
+		DWC_PRINT("    ep_type: %d\n", hc->ep_type);
+		DWC_PRINT("    max_packet: %d\n", hc->max_packet);
+		DWC_PRINT("    data_pid_start: %d\n", hc->data_pid_start);
+		DWC_PRINT("    multi_count: %d\n", hc->multi_count);
+		DWC_PRINT("    xfer_started: %d\n", hc->xfer_started);
+		DWC_PRINT("    xfer_buff: %p\n", hc->xfer_buff);
+		DWC_PRINT("    xfer_len: %d\n", hc->xfer_len);
+		DWC_PRINT("    xfer_count: %d\n", hc->xfer_count);
+		DWC_PRINT("    halt_on_queue: %d\n", hc->halt_on_queue);
+		DWC_PRINT("    halt_pending: %d\n", hc->halt_pending);
+		DWC_PRINT("    halt_status: %d\n", hc->halt_status);
+		DWC_PRINT("    do_split: %d\n", hc->do_split);
+		DWC_PRINT("    complete_split: %d\n", hc->complete_split);
+		DWC_PRINT("    hub_addr: %d\n", hc->hub_addr);
+		DWC_PRINT("    port_addr: %d\n", hc->port_addr);
+		DWC_PRINT("    xact_pos: %d\n", hc->xact_pos);
+		DWC_PRINT("    requests: %d\n", hc->requests);
+		DWC_PRINT("    qh: %p\n", hc->qh);
+		if (hc->xfer_started) {
+			hfnum_data_t hfnum;
+			hcchar_data_t hcchar;
+			hctsiz_data_t hctsiz;
+			hcint_data_t hcint;
+			hcintmsk_data_t hcintmsk;
+			hfnum.d32 =
+			    dwc_read_reg32(&_hcd->core_if->host_if->
+					   host_global_regs->hfnum);
+			hcchar.d32 =
+			    dwc_read_reg32(&_hcd->core_if->host_if->hc_regs[i]->
+					   hcchar);
+			hctsiz.d32 =
+			    dwc_read_reg32(&_hcd->core_if->host_if->hc_regs[i]->
+					   hctsiz);
+			hcint.d32 =
+			    dwc_read_reg32(&_hcd->core_if->host_if->hc_regs[i]->
+					   hcint);
+			hcintmsk.d32 =
+			    dwc_read_reg32(&_hcd->core_if->host_if->hc_regs[i]->
+					   hcintmsk);
+			DWC_PRINT("    hfnum: 0x%08x\n", hfnum.d32);
+			DWC_PRINT("    hcchar: 0x%08x\n", hcchar.d32);
+			DWC_PRINT("    hctsiz: 0x%08x\n", hctsiz.d32);
+			DWC_PRINT("    hcint: 0x%08x\n", hcint.d32);
+			DWC_PRINT("    hcintmsk: 0x%08x\n", hcintmsk.d32);
+		}
+		if (hc->xfer_started && (hc->qh != NULL)
+		     && (hc->qh->qtd_in_process != NULL)) {
+			dwc_otg_qtd_t * qtd;
+			struct urb *urb;
+			qtd = hc->qh->qtd_in_process;
+			urb = qtd->urb;
+			DWC_PRINT("    URB Info:\n");
+			DWC_PRINT("      qtd: %p, urb: %p\n", qtd, urb);
+			if (urb != NULL) {
+				DWC_PRINT("      Dev: %d, EP: %d %s\n",
+					   usb_pipedevice(urb->pipe),
+					   usb_pipeendpoint(urb->pipe),
+					   usb_pipein(urb->
+						       pipe) ? "IN" : "OUT");
+				DWC_PRINT("      Max packet size: %d\n",
+					   usb_maxpacket(urb->dev, urb->pipe,
+							  usb_pipeout(urb->
+								      pipe)));
+				DWC_PRINT("      transfer_buffer: %p\n",
+					   urb->transfer_buffer);
+				DWC_PRINT("      transfer_dma: %p\n",
+					   (void *)urb->transfer_dma);
+				DWC_PRINT("      transfer_buffer_length: %d\n",
+					   urb->transfer_buffer_length);
+				DWC_PRINT("      actual_length: %d\n",
+					   urb->actual_length);
+			}
+		}
+	}
+	DWC_PRINT("  periodic_usecs: %d\n", _hcd->periodic_usecs);
+	np_tx_status.d32 =
+	    dwc_read_reg32(&_hcd->core_if->core_global_regs->gnptxsts);
+	DWC_PRINT("  NP Tx Req Queue Space Avail: %d\n",
+		   np_tx_status.b.nptxqspcavail);
+	DWC_PRINT("  NP Tx FIFO Space Avail: %d\n",
+		   np_tx_status.b.nptxfspcavail);
+	p_tx_status.d32 =
+	    dwc_read_reg32(&_hcd->core_if->host_if->host_global_regs->hptxsts);
+	DWC_PRINT("  P Tx Req Queue Space Avail: %d\n",
+		   p_tx_status.b.ptxqspcavail);
+	DWC_PRINT("  P Tx FIFO Space Avail: %d\n", p_tx_status.b.ptxfspcavail);
+	dwc_otg_hcd_dump_frrem(_hcd);
+	dwc_otg_dump_global_registers(_hcd->core_if);
+	dwc_otg_dump_host_registers(_hcd->core_if);
+	DWC_PRINT
+	    ("************************************************************\n");
+	DWC_PRINT("\n");
+
+#endif	/*  */
+}
+#endif	/* CONFIG_DWC_DEVICE_ONLY */
diff -Naur a/drivers/usb/dwc_otg/dwc_otg_hcd.h b/drivers/usb/dwc_otg/dwc_otg_hcd.h
--- a/drivers/usb/dwc_otg/dwc_otg_hcd.h	1970-01-01 00:00:00.000000000 +0000
+++ b/drivers/usb/dwc_otg/dwc_otg_hcd.h	2017-06-20 08:44:52.484665432 +0000
@@ -0,0 +1,667 @@
+/* ==========================================================================
+ * $File: //dwh/usb_iip/dev/software/otg_ipmate/linux/drivers/dwc_otg_hcd.h $
+ * $Revision: #6 $
+ * $Date: 2006/12/05 $
+ * $Change: 762293 $
+ *
+ * Synopsys HS OTG Linux Software Driver and documentation (hereinafter,
+ * "Software") is an Unsupported proprietary work of Synopsys, Inc. unless
+ * otherwise expressly agreed to in writing between Synopsys and you.
+ *
+ * The Software IS NOT an item of Licensed Software or Licensed Product under
+ * any End User Software License Agreement or Agreement for Licensed Product
+ * with Synopsys or any supplement thereto. You are permitted to use and
+ * redistribute this Software in source and binary forms, with or without
+ * modification, provided that redistributions of source code must retain this
+ * notice. You may not view, use, disclose, copy or distribute this file or
+ * any information contained herein except pursuant to this license grant from
+ * Synopsys. If you do not agree with this notice, including the disclaimer
+ * below, then you are not authorized to use the Software.
+ *
+ * THIS SOFTWARE IS BEING DISTRIBUTED BY SYNOPSYS SOLELY ON AN "AS IS" BASIS
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE HEREBY DISCLAIMED. IN NO EVENT SHALL SYNOPSYS BE LIABLE FOR ANY DIRECT,
+ * INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+ * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+ * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+ * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
+ * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
+ * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH
+ * DAMAGE.
+ * ========================================================================== */
+#ifndef CONFIG_DWC_DEVICE_ONLY
+#if !defined(__DWC_HCD_H__)
+#define __DWC_HCD_H__
+
+#include <linux/list.h>
+#include <linux/usb.h>
+#include <linux/usb/hcd.h>
+
+struct lm_device;
+struct dwc_otg_device;
+
+#include "dwc_otg_cil.h"
+
+/**
+ * @file
+ *
+ * This file contains the structures, constants, and interfaces for
+ * the Host Contoller Driver (HCD).
+ *
+ * The Host Controller Driver (HCD) is responsible for translating requests
+ * from the USB Driver into the appropriate actions on the DWC_otg controller.
+ * It isolates the USBD from the specifics of the controller by providing an
+ * API to the USBD.
+ */
+
+/**
+ * Phases for control transfers.
+ */
+typedef enum dwc_otg_control_phase {
+	DWC_OTG_CONTROL_SETUP,
+	DWC_OTG_CONTROL_DATA,
+	DWC_OTG_CONTROL_STATUS
+} dwc_otg_control_phase_e;
+
+/** Transaction types. */
+typedef enum dwc_otg_transaction_type {
+	DWC_OTG_TRANSACTION_NONE,
+	DWC_OTG_TRANSACTION_PERIODIC,
+	DWC_OTG_TRANSACTION_NON_PERIODIC,
+	DWC_OTG_TRANSACTION_ALL
+} dwc_otg_transaction_type_e;
+
+/**
+ * A Queue Transfer Descriptor (QTD) holds the state of a bulk, control,
+ * interrupt, or isochronous transfer. A single QTD is created for each URB
+ * (of one of these types) submitted to the HCD. The transfer associated with
+ * a QTD may require one or multiple transactions.
+ *
+ * A QTD is linked to a Queue Head, which is entered in either the
+ * non-periodic or periodic schedule for execution. When a QTD is chosen for
+ * execution, some or all of its transactions may be executed. After
+ * execution, the state of the QTD is updated. The QTD may be retired if all
+ * its transactions are complete or if an error occurred. Otherwise, it
+ * remains in the schedule so more transactions can be executed later.
+ */
+
+struct dwc_otg_qh;
+
+typedef struct dwc_otg_qtd {
+	/**
+	 * Determines the PID of the next data packet for the data phase of
+	 * control transfers. Ignored for other transfer types.<br>
+	 * One of the following values:
+	 *	- DWC_OTG_HC_PID_DATA0
+	 *	- DWC_OTG_HC_PID_DATA1
+	 */
+	uint8_t			data_toggle;
+
+	/** Current phase for control transfers (Setup, Data, or Status). */
+	dwc_otg_control_phase_e	control_phase;
+
+	/** Keep track of the current split type
+	 * for FS/LS endpoints on a HS Hub */
+	uint8_t                 complete_split;
+
+	/** How many bytes transferred during SSPLIT OUT */
+	uint32_t                ssplit_out_xfer_count;
+
+	/**
+	 * Holds the number of bus errors that have occurred for a transaction
+	 * within this transfer.
+	 */
+	uint8_t 		error_count;
+
+	/**
+	 * Index of the next frame descriptor for an isochronous transfer. A
+	 * frame descriptor describes the buffer position and length of the
+	 * data to be transferred in the next scheduled (micro)frame of an
+	 * isochronous transfer. It also holds status for that transaction.
+	 * The frame index starts at 0.
+	 */
+	int			isoc_frame_index;
+
+	/** Position of the ISOC split on full/low speed */
+	uint8_t                 isoc_split_pos;
+
+	/** Position of the ISOC split in the buffer for the current frame */
+	uint16_t                isoc_split_offset;
+
+	/** URB for this transfer */
+	struct urb 		*urb;
+
+	/** This list of QTDs */
+	struct list_head  	qtd_list_entry;
+
+	/* Field to track the qh pointer */
+	struct dwc_otg_qh *qtd_qh_ptr;
+} dwc_otg_qtd_t;
+
+/**
+ * A Queue Head (QH) holds the static characteristics of an endpoint and
+ * maintains a list of transfers (QTDs) for that endpoint. A QH structure may
+ * be entered in either the non-periodic or periodic schedule.
+ */
+typedef struct dwc_otg_qh {
+	/**
+	 * Endpoint type.
+	 * One of the following values:
+	 * 	- USB_ENDPOINT_XFER_CONTROL
+	 *	- USB_ENDPOINT_XFER_ISOC
+	 *	- USB_ENDPOINT_XFER_BULK
+	 *	- USB_ENDPOINT_XFER_INT
+	 */
+	uint8_t 		ep_type;
+	uint8_t 		ep_is_in;
+
+	/** wMaxPacketSize Field of Endpoint Descriptor. */
+	uint16_t		maxp;
+
+	/**
+	 * Determines the PID of the next data packet for non-control
+	 * transfers. Ignored for control transfers.<br>
+	 * One of the following values:
+	 *	- DWC_OTG_HC_PID_DATA0
+	 * 	- DWC_OTG_HC_PID_DATA1
+	 */
+	uint8_t			data_toggle;
+
+	/** Ping state if 1. */
+	uint8_t 		ping_state;
+
+	/**
+	 * List of QTDs for this QH.
+	 */
+	struct list_head 	qtd_list;
+
+	/** Host channel currently processing transfers for this QH. */
+	dwc_hc_t		*channel;
+
+	/** QTD currently assigned to a host channel for this QH. */
+	dwc_otg_qtd_t		*qtd_in_process;
+
+	/** Full/low speed endpoint on high-speed hub requires split. */
+	uint8_t                 do_split;
+
+	/** @name Periodic schedule information */
+	/** @{ */
+
+	/** Bandwidth in microseconds per (micro)frame. */
+	uint8_t			usecs;
+
+	/** Interval between transfers in (micro)frames. */
+	uint16_t		interval;
+
+	/**
+	 * (micro)frame to initialize a periodic transfer. The transfer
+	 * executes in the following (micro)frame.
+	 */
+	uint16_t		sched_frame;
+
+	/** (micro)frame at which last start split was initialized. */
+	uint16_t		start_split_frame;
+
+	/** @} */
+
+	uint16_t speed;
+	uint16_t frame_usecs[8];
+
+	/** Entry for QH in either the periodic or non-periodic schedule. */
+	struct list_head        qh_list_entry;
+} dwc_otg_qh_t;
+
+/**
+ * This structure holds the state of the HCD, including the non-periodic and
+ * periodic schedules.
+ */
+typedef struct dwc_otg_hcd {
+
+	spinlock_t		lock;
+
+	/** DWC OTG Core Interface Layer */
+	dwc_otg_core_if_t       *core_if;
+
+	/** Internal DWC HCD Flags */
+	volatile union dwc_otg_hcd_internal_flags {
+		uint32_t d32;
+		struct {
+			unsigned port_connect_status_change : 1;
+			unsigned port_connect_status : 1;
+			unsigned port_reset_change : 1;
+			unsigned port_enable_change : 1;
+			unsigned port_suspend_change : 1;
+			unsigned port_over_current_change : 1;
+			unsigned reserved : 27;
+		} b;
+	} flags;
+
+	/**
+	 * Inactive items in the non-periodic schedule. This is a list of
+	 * Queue Heads. Transfers associated with these Queue Heads are not
+	 * currently assigned to a host channel.
+	 */
+	struct list_head 	non_periodic_sched_inactive;
+
+	/**
+	 * Deferred items in the non-periodic schedule. This is a list of
+	 * Queue Heads. Transfers associated with these Queue Heads are not
+	 * currently assigned to a host channel.
+	 * When we get an NAK, the QH goes here.
+	 */
+	struct list_head 	non_periodic_sched_deferred;
+
+	/**
+	 * Active items in the non-periodic schedule. This is a list of
+	 * Queue Heads. Transfers associated with these Queue Heads are
+	 * currently assigned to a host channel.
+	 */
+	struct list_head 	non_periodic_sched_active;
+
+	/**
+	 * Pointer to the next Queue Head to process in the active
+	 * non-periodic schedule.
+	 */
+	struct list_head 	*non_periodic_qh_ptr;
+
+	/**
+	 * Inactive items in the periodic schedule. This is a list of QHs for
+	 * periodic transfers that are _not_ scheduled for the next frame.
+	 * Each QH in the list has an interval counter that determines when it
+	 * needs to be scheduled for execution. This scheduling mechanism
+	 * allows only a simple calculation for periodic bandwidth used (i.e.
+	 * must assume that all periodic transfers may need to execute in the
+	 * same frame). However, it greatly simplifies scheduling and should
+	 * be sufficient for the vast majority of OTG hosts, which need to
+	 * connect to a small number of peripherals at one time.
+	 *
+	 * Items move from this list to periodic_sched_ready when the QH
+	 * interval counter is 0 at SOF.
+	 */
+	struct list_head	periodic_sched_inactive;
+
+	/**
+	 * List of periodic QHs that are ready for execution in the next
+	 * frame, but have not yet been assigned to host channels.
+	 *
+	 * Items move from this list to periodic_sched_assigned as host
+	 * channels become available during the current frame.
+	 */
+	struct list_head	periodic_sched_ready;
+
+	/**
+	 * List of periodic QHs to be executed in the next frame that are
+	 * assigned to host channels.
+	 *
+	 * Items move from this list to periodic_sched_queued as the
+	 * transactions for the QH are queued to the DWC_otg controller.
+	 */
+	struct list_head	periodic_sched_assigned;
+
+	/**
+	 * List of periodic QHs that have been queued for execution.
+	 *
+	 * Items move from this list to either periodic_sched_inactive or
+	 * periodic_sched_ready when the channel associated with the transfer
+	 * is released. If the interval for the QH is 1, the item moves to
+	 * periodic_sched_ready because it must be rescheduled for the next
+	 * frame. Otherwise, the item moves to periodic_sched_inactive.
+	 */
+	struct list_head	periodic_sched_queued;
+
+	/**
+	 * Total bandwidth claimed so far for periodic transfers. This value
+	 * is in microseconds per (micro)frame. The assumption is that all
+	 * periodic transfers may occur in the same (micro)frame.
+	 */
+	uint16_t		periodic_usecs;
+
+        /**
+	 * Total bandwidth claimed so far for all periodic transfers
+	 * in a frame.
+	 * This will include a mixture of HS and FS transfers.
+	 * Units are microseconds per (micro)frame.
+	 * We have a budget per frame and have to schedule
+	 * transactions accordingly.
+	 * Watch out for the fact that things are actually scheduled for the
+	 * "next frame".
+	 */
+	uint16_t                frame_usecs[8];
+
+	/**
+	 * Frame number read from the core at SOF. The value ranges from 0 to
+	 * DWC_HFNUM_MAX_FRNUM.
+	 */
+	uint16_t		frame_number;
+
+	/**
+	 * Free host channels in the controller. This is a list of
+	 * dwc_hc_t items.
+	 */
+	struct list_head 	free_hc_list;
+
+	/**
+	 * Number of available host channels.
+	 */
+	int			available_host_channels;
+
+	/**
+	 * Array of pointers to the host channel descriptors. Allows accessing
+	 * a host channel descriptor given the host channel number. This is
+	 * useful in interrupt handlers.
+	 */
+	dwc_hc_t		*hc_ptr_array[MAX_EPS_CHANNELS];
+
+	/**
+	 * Buffer to use for any data received during the status phase of a
+	 * control transfer. Normally no data is transferred during the status
+	 * phase. This buffer is used as a bit bucket.
+	 */
+	uint8_t			*status_buf;
+
+	/**
+	 * DMA address for status_buf.
+	 */
+	dma_addr_t		status_buf_dma;
+#define DWC_OTG_HCD_STATUS_BUF_SIZE 64
+
+	/**
+	 * Structure to allow starting the HCD in a non-interrupt context
+	 * during an OTG role change.
+	 */
+	struct work_struct	start_work;
+	struct usb_hcd		*_p;
+
+	/**
+	 * Connection timer. An OTG host must display a message if the device
+	 * does not connect. Started when the VBus power is turned on via
+	 * sysfs attribute "buspower".
+	 */
+        struct timer_list 	conn_timer;
+
+	/* Tasket to do a reset */
+	struct tasklet_struct   *reset_tasklet;
+
+#ifdef CONFIG_DWC_DEBUG
+	uint32_t 		frrem_samples;
+	uint64_t 		frrem_accum;
+
+	uint32_t		hfnum_7_samples_a;
+	uint64_t		hfnum_7_frrem_accum_a;
+	uint32_t		hfnum_0_samples_a;
+	uint64_t		hfnum_0_frrem_accum_a;
+	uint32_t		hfnum_other_samples_a;
+	uint64_t		hfnum_other_frrem_accum_a;
+
+	uint32_t		hfnum_7_samples_b;
+	uint64_t		hfnum_7_frrem_accum_b;
+	uint32_t		hfnum_0_samples_b;
+	uint64_t		hfnum_0_frrem_accum_b;
+	uint32_t		hfnum_other_samples_b;
+	uint64_t		hfnum_other_frrem_accum_b;
+#endif
+
+} dwc_otg_hcd_t;
+
+/** Gets the dwc_otg_hcd from a struct usb_hcd */
+static inline dwc_otg_hcd_t *hcd_to_dwc_otg_hcd(struct usb_hcd *hcd)
+{
+	return (dwc_otg_hcd_t *)(hcd->hcd_priv);
+}
+
+/** Gets the struct usb_hcd that contains a dwc_otg_hcd_t. */
+static inline struct usb_hcd *dwc_otg_hcd_to_hcd(dwc_otg_hcd_t *dwc_otg_hcd)
+{
+	return container_of((void *)dwc_otg_hcd, struct usb_hcd, hcd_priv);
+}
+
+/** @name HCD Create/Destroy Functions */
+/** @{ */
+extern int  __init dwc_otg_hcd_init(struct device *_dev, dwc_otg_device_t * dwc_otg_device);
+extern void dwc_otg_hcd_remove(struct device *_dev);
+/** @} */
+
+/** @name Linux HC Driver API Functions */
+/** @{ */
+
+extern int dwc_otg_hcd_start(struct usb_hcd *hcd);
+extern void dwc_otg_hcd_stop(struct usb_hcd *hcd);
+extern int dwc_otg_hcd_get_frame_number(struct usb_hcd *hcd);
+extern void dwc_otg_hcd_free(struct usb_hcd *hcd);
+extern int dwc_otg_hcd_urb_enqueue(struct usb_hcd *hcd,
+				   struct urb *urb,
+				   gfp_t mem_flags);
+extern int dwc_otg_hcd_urb_dequeue(struct usb_hcd *hcd,
+/*				   struct usb_host_endpoint *ep,*/
+				   struct urb *urb, int status);
+extern void dwc_otg_hcd_endpoint_disable(struct usb_hcd *hcd,
+					 struct usb_host_endpoint *ep);
+extern irqreturn_t dwc_otg_hcd_irq(struct usb_hcd *hcd);
+extern int dwc_otg_hcd_hub_status_data(struct usb_hcd *hcd,
+				       char *buf);
+extern int dwc_otg_hcd_hub_control(struct usb_hcd *hcd,
+				   u16 typeReq,
+				   u16 wValue,
+				   u16 wIndex,
+				   char *buf,
+				   u16 wLength);
+
+/** @} */
+
+/** @name Transaction Execution Functions */
+/** @{ */
+extern dwc_otg_transaction_type_e dwc_otg_hcd_select_transactions(dwc_otg_hcd_t *_hcd);
+extern void dwc_otg_hcd_queue_transactions(dwc_otg_hcd_t *_hcd,
+					   dwc_otg_transaction_type_e _tr_type);
+extern void dwc_otg_hcd_complete_urb(dwc_otg_hcd_t *_hcd, struct urb *_urb,
+				     int _status);
+/** @} */
+
+/** @name Interrupt Handler Functions */
+/** @{ */
+extern int32_t dwc_otg_hcd_handle_intr (dwc_otg_hcd_t *_dwc_otg_hcd);
+extern int32_t dwc_otg_hcd_handle_sof_intr (dwc_otg_hcd_t *_dwc_otg_hcd);
+extern int32_t dwc_otg_hcd_handle_rx_status_q_level_intr (dwc_otg_hcd_t *_dwc_otg_hcd);
+extern int32_t dwc_otg_hcd_handle_np_tx_fifo_empty_intr (dwc_otg_hcd_t *_dwc_otg_hcd);
+extern int32_t dwc_otg_hcd_handle_perio_tx_fifo_empty_intr (dwc_otg_hcd_t *_dwc_otg_hcd);
+extern int32_t dwc_otg_hcd_handle_incomplete_periodic_intr(dwc_otg_hcd_t *_dwc_otg_hcd);
+extern int32_t dwc_otg_hcd_handle_port_intr (dwc_otg_hcd_t *_dwc_otg_hcd);
+extern int32_t dwc_otg_hcd_handle_conn_id_status_change_intr (dwc_otg_hcd_t *_dwc_otg_hcd);
+extern int32_t dwc_otg_hcd_handle_disconnect_intr (dwc_otg_hcd_t *_dwc_otg_hcd);
+extern int32_t dwc_otg_hcd_handle_hc_intr (dwc_otg_hcd_t *_dwc_otg_hcd);
+extern int32_t dwc_otg_hcd_handle_hc_n_intr (dwc_otg_hcd_t *_dwc_otg_hcd, uint32_t _num);
+extern int32_t dwc_otg_hcd_handle_session_req_intr (dwc_otg_hcd_t *_dwc_otg_hcd);
+extern int32_t dwc_otg_hcd_handle_wakeup_detected_intr (dwc_otg_hcd_t *_dwc_otg_hcd);
+/** @} */
+
+
+/** @name Schedule Queue Functions */
+/** @{ */
+
+/* Implemented in dwc_otg_hcd_queue.c */
+extern dwc_otg_qh_t *dwc_otg_hcd_qh_create (dwc_otg_hcd_t *_hcd, struct urb *_urb);
+extern void dwc_otg_hcd_qh_init (dwc_otg_hcd_t *_hcd, dwc_otg_qh_t *_qh, struct urb *_urb);
+extern void dwc_otg_hcd_qh_free (dwc_otg_qh_t *_qh);
+extern int dwc_otg_hcd_qh_add (dwc_otg_hcd_t *_hcd, dwc_otg_qh_t *_qh);
+extern void dwc_otg_hcd_qh_remove (dwc_otg_hcd_t *_hcd, dwc_otg_qh_t *_qh);
+extern void dwc_otg_hcd_qh_deactivate (dwc_otg_hcd_t *_hcd, dwc_otg_qh_t *_qh, int sched_csplit);
+extern int dwc_otg_hcd_qh_deferr (dwc_otg_hcd_t *_hcd, dwc_otg_qh_t *_qh, int delay);
+
+/** Remove and free a QH */
+static inline void dwc_otg_hcd_qh_remove_and_free (dwc_otg_hcd_t *_hcd,
+						   dwc_otg_qh_t *_qh)
+{
+	dwc_otg_hcd_qh_remove (_hcd, _qh);
+	dwc_otg_hcd_qh_free (_qh);
+}
+
+/** Allocates memory for a QH structure.
+ * @return Returns the memory allocate or NULL on error. */
+static inline dwc_otg_qh_t *dwc_otg_hcd_qh_alloc (void)
+{
+	return (dwc_otg_qh_t *) kmalloc (sizeof(dwc_otg_qh_t), GFP_KERNEL);
+}
+
+extern dwc_otg_qtd_t *dwc_otg_hcd_qtd_create (struct urb *urb);
+extern void dwc_otg_hcd_qtd_init (dwc_otg_qtd_t *qtd, struct urb *urb);
+extern int dwc_otg_hcd_qtd_add (dwc_otg_qtd_t *qtd, dwc_otg_hcd_t *dwc_otg_hcd);
+
+/** Allocates memory for a QTD structure.
+ * @return Returns the memory allocate or NULL on error. */
+static inline dwc_otg_qtd_t *dwc_otg_hcd_qtd_alloc (void)
+{
+	return (dwc_otg_qtd_t *) kmalloc (sizeof(dwc_otg_qtd_t), GFP_KERNEL);
+}
+
+/** Frees the memory for a QTD structure.  QTD should already be removed from
+ * list.
+ * @param[in] _qtd QTD to free.*/
+static inline void dwc_otg_hcd_qtd_free (dwc_otg_qtd_t *_qtd)
+{
+	kfree (_qtd);
+}
+
+/** Removes a QTD from list.
+ * @param[in] _qtd QTD to remove from list. */
+static inline void dwc_otg_hcd_qtd_remove (dwc_otg_qtd_t *_qtd)
+{
+	unsigned long flags;
+	local_irq_save (flags);
+	list_del (&_qtd->qtd_list_entry);
+	local_irq_restore (flags);
+}
+
+/** Remove and free a QTD */
+static inline void dwc_otg_hcd_qtd_remove_and_free (dwc_otg_qtd_t *_qtd)
+{
+	dwc_otg_hcd_qtd_remove (_qtd);
+	dwc_otg_hcd_qtd_free (_qtd);
+}
+
+/** @} */
+
+
+/** @name Internal Functions */
+/** @{ */
+dwc_otg_qh_t *dwc_urb_to_qh(struct urb *_urb);
+void dwc_otg_hcd_dump_frrem(dwc_otg_hcd_t *_hcd);
+void dwc_otg_hcd_dump_state(dwc_otg_hcd_t *_hcd);
+/** @} */
+
+/** Gets the usb_host_endpoint associated with an URB. */
+static inline struct usb_host_endpoint *dwc_urb_to_endpoint(struct urb *_urb)
+{
+	struct usb_device *dev = _urb->dev;
+	int ep_num = usb_pipeendpoint(_urb->pipe);
+
+	if (usb_pipein(_urb->pipe))
+		return dev->ep_in[ep_num];
+	else
+		return dev->ep_out[ep_num];
+}
+
+/**
+ * Gets the endpoint number from a _bEndpointAddress argument. The endpoint is
+ * qualified with its direction (possible 32 endpoints per device).
+ */
+#define dwc_ep_addr_to_endpoint(_bEndpointAddress_) \
+	((_bEndpointAddress_ & USB_ENDPOINT_NUMBER_MASK) | \
+    ((_bEndpointAddress_ & USB_DIR_IN) != 0) << 4)
+
+/** Gets the QH that contains the list_head */
+#define dwc_list_to_qh(_list_head_ptr_) (container_of(_list_head_ptr_,dwc_otg_qh_t,qh_list_entry))
+
+/** Gets the QTD that contains the list_head */
+#define dwc_list_to_qtd(_list_head_ptr_) (container_of(_list_head_ptr_,dwc_otg_qtd_t,qtd_list_entry))
+
+/** Check if QH is non-periodic  */
+#define dwc_qh_is_non_per(_qh_ptr_) ((_qh_ptr_->ep_type == USB_ENDPOINT_XFER_BULK) || \
+                                     (_qh_ptr_->ep_type == USB_ENDPOINT_XFER_CONTROL))
+
+/** High bandwidth multiplier as encoded in highspeed endpoint descriptors */
+#define dwc_hb_mult(wMaxPacketSize) (1 + (((wMaxPacketSize) >> 11) & 0x03))
+
+/** Packet size for any kind of endpoint descriptor */
+#define dwc_max_packet(wMaxPacketSize) ((wMaxPacketSize) & 0x07ff)
+
+/**
+ * Returns true if _frame1 is less than or equal to _frame2. The comparison is
+ * done modulo DWC_HFNUM_MAX_FRNUM. This accounts for the rollover of the
+ * frame number when the max frame number is reached.
+ */
+static inline int dwc_frame_num_le(uint16_t _frame1, uint16_t _frame2)
+{
+	return ((_frame2 - _frame1) & DWC_HFNUM_MAX_FRNUM) <=
+		(DWC_HFNUM_MAX_FRNUM >> 1);
+}
+
+/**
+ * Returns true if _frame1 is greater than _frame2. The comparison is done
+ * modulo DWC_HFNUM_MAX_FRNUM. This accounts for the rollover of the frame
+ * number when the max frame number is reached.
+ */
+static inline int dwc_frame_num_gt(uint16_t _frame1, uint16_t _frame2)
+{
+	return (_frame1 != _frame2) &&
+		(((_frame1 - _frame2) & DWC_HFNUM_MAX_FRNUM) <
+		 (DWC_HFNUM_MAX_FRNUM >> 1));
+}
+
+/**
+ * Increments _frame by the amount specified by _inc. The addition is done
+ * modulo DWC_HFNUM_MAX_FRNUM. Returns the incremented value.
+ */
+static inline uint16_t dwc_frame_num_inc(uint16_t _frame, uint16_t _inc)
+{
+	return (_frame + _inc) & DWC_HFNUM_MAX_FRNUM;
+}
+
+static inline uint16_t dwc_full_frame_num (uint16_t _frame)
+{
+	return ((_frame) & DWC_HFNUM_MAX_FRNUM) >> 3;
+}
+
+static inline uint16_t dwc_micro_frame_num (uint16_t _frame)
+{
+	return (_frame) & 0x7;
+}
+
+#ifdef CONFIG_DWC_DEBUG
+/**
+ * Macro to sample the remaining PHY clocks left in the current frame. This
+ * may be used during debugging to determine the average time it takes to
+ * execute sections of code. There are two possible sample points, "a" and
+ * "b", so the _letter argument must be one of these values.
+ *
+ * To dump the average sample times, read the "hcd_frrem" sysfs attribute. For
+ * example, "cat /sys/devices/lm0/hcd_frrem".
+ */
+#define dwc_sample_frrem(_hcd, _qh, _letter) \
+{ \
+	hfnum_data_t hfnum; \
+	dwc_otg_qtd_t *qtd; \
+	qtd = list_entry(_qh->qtd_list.next, dwc_otg_qtd_t, qtd_list_entry); \
+	if (usb_pipeint(qtd->urb->pipe) && _qh->start_split_frame != 0 && !qtd->complete_split) { \
+		hfnum.d32 = dwc_read_reg32(&_hcd->core_if->host_if->host_global_regs->hfnum); \
+		switch (hfnum.b.frnum & 0x7) { \
+		case 7: \
+			_hcd->hfnum_7_samples_##_letter++; \
+			_hcd->hfnum_7_frrem_accum_##_letter += hfnum.b.frrem; \
+			break; \
+		case 0: \
+			_hcd->hfnum_0_samples_##_letter++; \
+			_hcd->hfnum_0_frrem_accum_##_letter += hfnum.b.frrem; \
+			break; \
+		default: \
+			_hcd->hfnum_other_samples_##_letter++; \
+			_hcd->hfnum_other_frrem_accum_##_letter += hfnum.b.frrem; \
+			break; \
+		} \
+	} \
+}
+#else
+#define dwc_sample_frrem(_hcd, _qh, _letter)
+#endif
+#endif
+#endif /* DWC_DEVICE_ONLY */
diff -Naur a/drivers/usb/dwc_otg/dwc_otg_hcd_intr.c b/drivers/usb/dwc_otg/dwc_otg_hcd_intr.c
--- a/drivers/usb/dwc_otg/dwc_otg_hcd_intr.c	1970-01-01 00:00:00.000000000 +0000
+++ b/drivers/usb/dwc_otg/dwc_otg_hcd_intr.c	2016-01-31 16:10:52.000000000 +0000
@@ -0,0 +1,1754 @@
+/* ==========================================================================
+ * $File: //dwh/usb_iip/dev/software/otg_ipmate/linux/drivers/dwc_otg_hcd_intr.c $
+ * $Revision: #7 $
+ * $Date: 2005/11/02 $
+ * $Change: 553126 $
+ *
+ * Synopsys HS OTG Linux Software Driver and documentation (hereinafter,
+ * "Software") is an Unsupported proprietary work of Synopsys, Inc. unless
+ * otherwise expressly agreed to in writing between Synopsys and you.
+ *
+ * The Software IS NOT an item of Licensed Software or Licensed Product under
+ * any End User Software License Agreement or Agreement for Licensed Product
+ * with Synopsys or any supplement thereto. You are permitted to use and
+ * redistribute this Software in source and binary forms, with or without
+ * modification, provided that redistributions of source code must retain this
+ * notice. You may not view, use, disclose, copy or distribute this file or
+ * any information contained herein except pursuant to this license grant from
+ * Synopsys. If you do not agree with this notice, including the disclaimer
+ * below, then you are not authorized to use the Software.
+ *
+ * THIS SOFTWARE IS BEING DISTRIBUTED BY SYNOPSYS SOLELY ON AN "AS IS" BASIS
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE HEREBY DISCLAIMED. IN NO EVENT SHALL SYNOPSYS BE LIABLE FOR ANY DIRECT,
+ * INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+ * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+ * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+ * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
+ * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
+ * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH
+ * DAMAGE.
+ * ========================================================================== */
+
+#ifndef CONFIG_DWC_DEVICE_ONLY
+
+#include "dwc_otg_driver.h"
+#include "dwc_otg_hcd.h"
+#include "dwc_otg_regs.h"
+
+const int erratum_usb09_patched = 0;
+const int deferral_on = 1;
+const int nak_deferral_delay = 8;
+const int nyet_deferral_delay = 1;
+
+/** @file
+ * This file contains the implementation of the HCD Interrupt handlers.
+ */
+
+/** This function handles interrupts for the HCD. */
+int32_t dwc_otg_hcd_handle_intr(dwc_otg_hcd_t * _dwc_otg_hcd)
+{
+	int retval = 0;
+	dwc_otg_core_if_t * core_if = _dwc_otg_hcd->core_if;
+	gintsts_data_t gintsts;
+
+#ifdef CONFIG_DWC_DEBUG
+    dwc_otg_core_global_regs_t * global_regs = core_if->core_global_regs;
+
+#endif	/*  */
+
+    /* Check if HOST Mode */
+    if (dwc_otg_is_host_mode(core_if)) {
+		gintsts.d32 = dwc_otg_read_core_intr(core_if);
+		if (!gintsts.d32) {
+			return 0;
+		}
+#ifdef CONFIG_DWC_DEBUG
+	    /* Don't print debug message in the interrupt handler on SOF */
+#ifndef DEBUG_SOF
+	    if (gintsts.d32 != DWC_SOF_INTR_MASK)
+#endif
+		    DWC_DEBUGPL(DBG_HCD, "\n");
+#endif	/*  */
+
+#ifdef CONFIG_DWC_DEBUG
+#ifndef DEBUG_SOF
+	    if (gintsts.d32 != DWC_SOF_INTR_MASK)
+#endif
+		    DWC_DEBUGPL(DBG_HCD,"DWC OTG HCD Interrupt Detected gintsts&gintmsk=0x%08x\n",
+					gintsts.d32);
+#endif	/*  */
+	    if (gintsts.b.sofintr) {
+			retval |= dwc_otg_hcd_handle_sof_intr(_dwc_otg_hcd);
+		}
+#ifdef CONFIG_OTG_PLB_DMA_TASKLET
+		if (!atomic_read(&release_later) && gintsts.b.rxstsqlvl) {
+#else
+		if (gintsts.b.rxstsqlvl) {
+#endif
+			retval |= dwc_otg_hcd_handle_rx_status_q_level_intr(_dwc_otg_hcd);
+		}
+#ifdef CONFIG_OTG_PLB_DMA_TASKLET
+		if (!atomic_read(&release_later) && gintsts.b.nptxfempty) {
+#else
+		if (gintsts.b.nptxfempty) {
+#endif
+			retval |= dwc_otg_hcd_handle_np_tx_fifo_empty_intr(_dwc_otg_hcd);
+		}
+		if (gintsts.b.i2cintr) {
+			/** @todo Implement i2cintr handler. */
+		}
+		if (gintsts.b.portintr) {
+			retval |= dwc_otg_hcd_handle_port_intr(_dwc_otg_hcd);
+		}
+		if (gintsts.b.hcintr) {
+			retval |= dwc_otg_hcd_handle_hc_intr(_dwc_otg_hcd);
+		}
+		if (gintsts.b.ptxfempty) {
+			retval |= dwc_otg_hcd_handle_perio_tx_fifo_empty_intr(_dwc_otg_hcd);
+		}
+
+#ifdef CONFIG_DWC_DEBUG
+#ifndef DEBUG_SOF
+	    if (gintsts.d32 != DWC_SOF_INTR_MASK)
+#endif
+		{
+			DWC_DEBUGPL(DBG_HCD,
+				     "DWC OTG HCD Finished Servicing Interrupts\n");
+			DWC_DEBUGPL(DBG_HCDV, "DWC OTG HCD gintsts=0x%08x\n",
+				     dwc_read_reg32(&global_regs->gintsts));
+			DWC_DEBUGPL(DBG_HCDV, "DWC OTG HCD gintmsk=0x%08x\n",
+				     dwc_read_reg32(&global_regs->gintmsk));
+		}
+#endif	/*  */
+
+#ifdef CONFIG_DWC_DEBUG
+#ifndef DEBUG_SOF
+	    if (gintsts.d32 != DWC_SOF_INTR_MASK)
+#endif
+		    DWC_DEBUGPL(DBG_HCD, "\n");
+#endif	/*  */
+	}
+	return retval;
+}
+
+
+#ifdef DWC_TRACK_MISSED_SOFS
+#warning Compiling code to track missed SOFs
+#define FRAME_NUM_ARRAY_SIZE 1000
+/**
+ * This function is for debug only.
+ */
+static inline void track_missed_sofs(uint16_t _curr_frame_number)
+{
+	static uint16_t frame_num_array[FRAME_NUM_ARRAY_SIZE];
+	static uint16_t last_frame_num_array[FRAME_NUM_ARRAY_SIZE];
+	static int frame_num_idx = 0;
+	static uint16_t last_frame_num = DWC_HFNUM_MAX_FRNUM;
+	static int dumped_frame_num_array = 0;
+	if (frame_num_idx < FRAME_NUM_ARRAY_SIZE) {
+		if ((((last_frame_num + 1) & DWC_HFNUM_MAX_FRNUM) !=
+		      _curr_frame_number)) {
+			frame_num_array[frame_num_idx] = _curr_frame_number;
+			last_frame_num_array[frame_num_idx++] = last_frame_num;
+		}
+	} else if (!dumped_frame_num_array) {
+		int i;
+		printk(KERN_EMERG USB_DWC "Frame     Last Frame\n");
+		printk(KERN_EMERG USB_DWC "-----     ----------\n");
+		for (i = 0; i < FRAME_NUM_ARRAY_SIZE; i++) {
+			printk(KERN_EMERG USB_DWC "0x%04x    0x%04x\n",
+				frame_num_array[i], last_frame_num_array[i]);
+		}
+		dumped_frame_num_array = 1;
+	}
+	last_frame_num = _curr_frame_number;
+}
+#endif	/*  */
+
+/**
+ * Handles the start-of-frame interrupt in host mode. Non-periodic
+ * transactions may be queued to the DWC_otg controller for the current
+ * (micro)frame. Periodic transactions may be queued to the controller for the
+ * next (micro)frame.
+ */
+int32_t dwc_otg_hcd_handle_sof_intr(dwc_otg_hcd_t * _hcd)
+{
+	hfnum_data_t hfnum;
+	struct list_head *qh_entry;
+	dwc_otg_qh_t * qh;
+	dwc_otg_transaction_type_e tr_type;
+	gintsts_data_t gintsts = {.d32 = 0};
+	hfnum.d32 = dwc_read_reg32(&_hcd->core_if->host_if->host_global_regs->hfnum);
+
+#ifdef DEBUG_SOF
+    DWC_DEBUGPL(DBG_HCD, "--Start of Frame Interrupt--\n");
+#endif	/*  */
+    _hcd->frame_number = hfnum.b.frnum;
+#ifdef CONFIG_DWC_DEBUG
+    _hcd->frrem_accum += hfnum.b.frrem;
+	_hcd->frrem_samples++;
+#endif	/*  */
+
+#ifdef DWC_TRACK_MISSED_SOFS
+    track_missed_sofs(_hcd->frame_number);
+#endif	/*  */
+
+    /* Determine whether any periodic QHs should be executed. */
+    qh_entry = _hcd->periodic_sched_inactive.next;
+	while (qh_entry != &_hcd->periodic_sched_inactive) {
+		qh = list_entry(qh_entry, dwc_otg_qh_t, qh_list_entry);
+		qh_entry = qh_entry->next;
+		if (dwc_frame_num_le(qh->sched_frame, _hcd->frame_number)) {
+		    /*
+		     * Move QH to the ready list to be executed next
+		     * (micro)frame.
+		     */
+		    list_move(&qh->qh_list_entry,&_hcd->periodic_sched_ready);
+		}
+	}
+	tr_type = dwc_otg_hcd_select_transactions(_hcd);
+	if (tr_type != DWC_OTG_TRANSACTION_NONE) {
+		dwc_otg_hcd_queue_transactions(_hcd, tr_type);
+		//schedule_work(&_hcd->hcd_queue_work);
+	}
+
+    /* Clear interrupt */
+    gintsts.b.sofintr = 1;
+	dwc_write_reg32(&_hcd->core_if->core_global_regs->gintsts,gintsts.d32);
+	return 1;
+}
+
+/** Handles the Rx Status Queue Level Interrupt, which indicates that there is at
+ * least one packet in the Rx FIFO.  The packets are moved from the FIFO to
+ * memory if the DWC_otg controller is operating in Slave mode. */
+int32_t dwc_otg_hcd_handle_rx_status_q_level_intr(dwc_otg_hcd_t *_dwc_otg_hcd)
+{
+	host_grxsts_data_t grxsts;
+	dwc_hc_t * hc = NULL;
+	DWC_DEBUGPL(DBG_HCD, "--RxStsQ Level Interrupt--\n");
+	grxsts.d32 = dwc_read_reg32(&_dwc_otg_hcd->core_if->core_global_regs->grxstsp);
+	hc = _dwc_otg_hcd->hc_ptr_array[grxsts.b.chnum];
+
+    /* Packet Status */
+    DWC_DEBUGPL(DBG_HCDV, "    Ch num = %d\n", grxsts.b.chnum);
+	DWC_DEBUGPL(DBG_HCDV, "    Count = %d\n", grxsts.b.bcnt);
+	DWC_DEBUGPL(DBG_HCDV, "    DPID = %d, hc.dpid = %d\n", grxsts.b.dpid,
+		     hc->data_pid_start);
+	DWC_DEBUGPL(DBG_HCDV, "    PStatus = %d\n", grxsts.b.pktsts);
+	switch (grxsts.b.pktsts) {
+	case DWC_GRXSTS_PKTSTS_IN:
+	    /* Read the data into the host buffer. */
+	    if (grxsts.b.bcnt > 0) {
+			dwc_otg_read_packet(_dwc_otg_hcd->core_if,
+					     hc->xfer_buff, grxsts.b.bcnt);
+
+		    /* Update the HC fields for the next packet received. */
+		    hc->xfer_count += grxsts.b.bcnt;
+			hc->xfer_buff += grxsts.b.bcnt;
+		}
+	case DWC_GRXSTS_PKTSTS_IN_XFER_COMP:
+	case DWC_GRXSTS_PKTSTS_DATA_TOGGLE_ERR:
+	case DWC_GRXSTS_PKTSTS_CH_HALTED:
+		    /* Handled in interrupt, just ignore data */
+		    break;
+	default:
+		DWC_ERROR("RX_STS_Q Interrupt: Unknown status %d\n",
+			   grxsts.b.pktsts);
+		break;
+	}
+	return 1;
+}
+
+
+/** This interrupt occurs when the non-periodic Tx FIFO is half-empty. More
+ * data packets may be written to the FIFO for OUT transfers. More requests
+ * may be written to the non-periodic request queue for IN transfers. This
+ * interrupt is enabled only in Slave mode. */
+int32_t dwc_otg_hcd_handle_np_tx_fifo_empty_intr(dwc_otg_hcd_t *
+						     _dwc_otg_hcd)
+{
+	DWC_DEBUGPL(DBG_HCD, "--Non-Periodic TxFIFO Empty Interrupt--\n");
+	dwc_otg_hcd_queue_transactions(_dwc_otg_hcd,
+					DWC_OTG_TRANSACTION_NON_PERIODIC);
+	//schedule_work(&_dwc_otg_hcd->hcd_queue_work);
+	return 1;
+}
+
+
+/** This interrupt occurs when the periodic Tx FIFO is half-empty. More data
+ * packets may be written to the FIFO for OUT transfers. More requests may be
+ * written to the periodic request queue for IN transfers. This interrupt is
+ * enabled only in Slave mode. */
+int32_t dwc_otg_hcd_handle_perio_tx_fifo_empty_intr(dwc_otg_hcd_t *
+							_dwc_otg_hcd)
+{
+	DWC_DEBUGPL(DBG_HCD, "--Periodic TxFIFO Empty Interrupt--\n");
+	dwc_otg_hcd_queue_transactions(_dwc_otg_hcd,
+					DWC_OTG_TRANSACTION_PERIODIC);
+	//schedule_work(&_dwc_otg_hcd->hcd_queue_work);
+	return 1;
+}
+
+
+/** There are multiple conditions that can cause a port interrupt. This function
+ * determines which interrupt conditions have occurred and handles them
+ * appropriately. */
+int32_t dwc_otg_hcd_handle_port_intr(dwc_otg_hcd_t * _dwc_otg_hcd)
+{
+	int retval = 0;
+	hprt0_data_t hprt0;
+	hprt0_data_t hprt0_modify;
+	hprt0.d32 = dwc_read_reg32(_dwc_otg_hcd->core_if->host_if->hprt0);
+	hprt0_modify.d32 = dwc_read_reg32(_dwc_otg_hcd->core_if->host_if->hprt0);
+
+    /* Clear appropriate bits in HPRT0 to clear the interrupt bit in
+     * GINTSTS */
+    hprt0_modify.b.prtena = 0;
+	hprt0_modify.b.prtconndet = 0;
+	hprt0_modify.b.prtenchng = 0;
+	hprt0_modify.b.prtovrcurrchng = 0;
+
+    /* Port Connect Detected
+     * Set flag and clear if detected */
+    if (hprt0.b.prtconndet) {
+		DWC_DEBUGPL(DBG_HCD, "--Port Interrupt HPRT0=0x%08x "
+			     "Port Connect Detected--\n", hprt0.d32);
+		_dwc_otg_hcd->flags.b.port_connect_status_change = 1;
+		_dwc_otg_hcd->flags.b.port_connect_status = 1;
+		hprt0_modify.b.prtconndet = 1;
+
+	    /* B-Device has connected, Delete the connection timer.  */
+	    del_timer(&_dwc_otg_hcd->conn_timer);
+
+	    /* The Hub driver asserts a reset when it sees port connect
+	     * status change flag
+		 */
+	    retval |= 1;
+	}
+
+    /* Port Enable Changed
+     * Clear if detected - Set internal flag if disabled */
+    if (hprt0.b.prtenchng) {
+		DWC_DEBUGPL(DBG_HCD, "  --Port Interrupt HPRT0=0x%08x "
+			     "Port Enable Changed--\n", hprt0.d32);
+		hprt0_modify.b.prtenchng = 1;
+		if (hprt0.b.prtena == 1) {
+			int do_reset = 0;
+			dwc_otg_core_params_t * params =
+			    _dwc_otg_hcd->core_if->core_params;
+			dwc_otg_core_global_regs_t * global_regs =
+			    _dwc_otg_hcd->core_if->core_global_regs;
+			dwc_otg_host_if_t * host_if =
+			    _dwc_otg_hcd->core_if->host_if;
+
+		    /* Check if we need to adjust the PHY clock speed for
+		     * low power and adjust it */
+		    if (params->host_support_fs_ls_low_power) {
+				gusbcfg_data_t usbcfg;
+				usbcfg.d32 = dwc_read_reg32(&global_regs->gusbcfg);
+				if ((hprt0.b.prtspd == DWC_HPRT0_PRTSPD_LOW_SPEED) ||
+					(hprt0.b.prtspd == DWC_HPRT0_PRTSPD_FULL_SPEED)) {
+				    /*
+				     * Low power
+				     */
+				    hcfg_data_t hcfg;
+					if (usbcfg.b.phylpwrclksel == 0) {
+					    /* Set PHY low power clock select for FS/LS devices */
+					    usbcfg.b.phylpwrclksel = 1;
+						dwc_write_reg32(&global_regs->gusbcfg,usbcfg.d32);
+						do_reset = 1;
+					}
+					hcfg.d32 = dwc_read_reg32(&host_if->host_global_regs->hcfg);
+					if ((hprt0.b.prtspd == DWC_HPRT0_PRTSPD_LOW_SPEED) &&
+						(params->host_ls_low_power_phy_clk ==
+						DWC_HOST_LS_LOW_POWER_PHY_CLK_PARAM_6MHZ)) {
+					    /* 6 MHZ */
+					    DWC_DEBUGPL(DBG_CIL,"FS_PHY programming HCFG to 6 MHz (Low Power)\n");
+						if (hcfg.b.fslspclksel != DWC_HCFG_6_MHZ) {
+							hcfg.b.fslspclksel = DWC_HCFG_6_MHZ;
+							dwc_write_reg32(&host_if->host_global_regs->hcfg, hcfg.d32);
+							do_reset = 1;
+						}
+					} else {
+					    /* 48 MHZ */
+					    DWC_DEBUGPL(DBG_CIL, "FS_PHY programming HCFG to 48 MHz ()\n");
+						if (hcfg.b.fslspclksel != DWC_HCFG_48_MHZ) {
+							hcfg.b.fslspclksel = DWC_HCFG_48_MHZ;
+							dwc_write_reg32(&host_if->host_global_regs->hcfg, hcfg.d32);
+							do_reset = 1;
+						}
+					}
+				} else {
+				    /*
+				     * Not low power
+				     */
+				    if (usbcfg.b.phylpwrclksel == 1) {
+						usbcfg.b.phylpwrclksel = 0;
+						dwc_write_reg32(&global_regs->gusbcfg,usbcfg.d32);
+						do_reset = 1;
+					}
+				}
+				if (do_reset) {
+					tasklet_schedule(_dwc_otg_hcd->reset_tasklet);
+				}
+			}
+			if (!do_reset) {
+			    /* Port has been enabled set the reset change flag */
+			    _dwc_otg_hcd->flags.b.port_reset_change = 1;
+			}
+		} else {
+			_dwc_otg_hcd->flags.b.port_enable_change = 1;
+		}
+		retval |= 1;
+	}
+
+	/** Overcurrent Change Interrupt */
+    if (hprt0.b.prtovrcurrchng) {
+		DWC_DEBUGPL(DBG_HCD, "  --Port Interrupt HPRT0=0x%08x "
+			     "Port Overcurrent Changed--\n", hprt0.d32);
+		_dwc_otg_hcd->flags.b.port_over_current_change = 1;
+		hprt0_modify.b.prtovrcurrchng = 1;
+		retval |= 1;
+	}
+
+    /* Clear Port Interrupts */
+    dwc_write_reg32(_dwc_otg_hcd->core_if->host_if->hprt0,hprt0_modify.d32);
+	return retval;
+}
+
+/** This interrupt indicates that one or more host channels has a pending
+ * interrupt. There are multiple conditions that can cause each host channel
+ * interrupt. This function determines which conditions have occurred for each
+ * host channel interrupt and handles them appropriately. */
+int32_t dwc_otg_hcd_handle_hc_intr(dwc_otg_hcd_t * _dwc_otg_hcd)
+{
+	int i;
+	int retval = 0;
+	haint_data_t haint;
+
+    /* Clear appropriate bits in HCINTn to clear the interrupt bit in
+     * GINTSTS */
+    haint.d32 = dwc_otg_read_host_all_channels_intr(_dwc_otg_hcd->core_if);
+	for (i = 0; i < _dwc_otg_hcd->core_if->core_params->host_channels;i++) {
+		if (haint.b2.chint & (1 << i)) {
+			retval |= dwc_otg_hcd_handle_hc_n_intr(_dwc_otg_hcd, i);
+		}
+	}
+	return retval;
+}
+
+/* Macro used to clear one channel interrupt */
+#define clear_hc_int(_hc_regs_,_intr_) \
+    do { \
+		hcint_data_t hcint_clear = { .d32 = 0}; \
+		hcint_clear.b._intr_ = 1; \
+		dwc_write_reg32(&((_hc_regs_)->hcint), hcint_clear.d32); \
+	} while (0)
+
+/*
+ * Macro used to disable one channel interrupt. Channel interrupts are
+ * disabled when the channel is halted or released by the interrupt handler.
+ * There is no need to handle further interrupts of that type until the
+ * channel is re-assigned. In fact, subsequent handling may cause crashes
+ * because the channel structures are cleaned up when the channel is released.
+ */
+#define disable_hc_int(_hc_regs_,_intr_) \
+    do { \
+		hcintmsk_data_t hcintmsk = {.d32 = 0}; \
+		hcintmsk.b._intr_ = 1; \
+		dwc_modify_reg32(&((_hc_regs_)->hcintmsk), hcintmsk.d32, 0); \
+	} while (0)
+
+/**
+ * Gets the actual length of a transfer after the transfer halts. _halt_status
+ * holds the reason for the halt.
+ *
+ * For IN transfers where _halt_status is DWC_OTG_HC_XFER_COMPLETE,
+ * *_short_read is set to 1 upon return if less than the requested
+ * number of bytes were transferred. Otherwise, *_short_read is set to 0 upon
+ * return. _short_read may also be NULL on entry, in which case it remains
+ * unchanged.
+ */
+static uint32_t get_actual_xfer_length(dwc_hc_t * _hc,
+       dwc_otg_hc_regs_t * _hc_regs, dwc_otg_qtd_t * _qtd,
+       dwc_otg_halt_status_e _halt_status, int *_short_read)
+{
+	hctsiz_data_t hctsiz;
+	uint32_t length;
+	if (_short_read != NULL) {
+		*_short_read = 0;
+	}
+	hctsiz.d32 = dwc_read_reg32(&_hc_regs->hctsiz);
+	if (_halt_status == DWC_OTG_HC_XFER_COMPLETE) {
+		if (_hc->ep_is_in) {
+			length = _hc->xfer_len - hctsiz.b.xfersize;
+			if (_short_read != NULL) {
+				*_short_read = (hctsiz.b.xfersize != 0);
+			}
+		} else if (_hc->qh->do_split) {
+			length = _qtd->ssplit_out_xfer_count;
+		} else {
+			length = _hc->xfer_len;
+		}
+	} else {
+	    /*
+	     * Must use the hctsiz.pktcnt field to determine how much data
+	     * has been transferred. This field reflects the number of
+	     * packets that have been transferred via the USB. This is
+	     * always an integral number of packets if the transfer was
+	     * halted before its normal completion. (Can't use the
+	     * hctsiz.xfersize field because that reflects the number of
+	     * bytes transferred via the AHB, not the USB).
+	     */
+	    length = (_hc->start_pkt_count - hctsiz.b.pktcnt) * _hc->max_packet;
+	}
+	return length;
+}
+
+/**
+ * Updates the state of the URB after a Transfer Complete interrupt on the
+ * host channel. Updates the actual_length field of the URB based on the
+ * number of bytes transferred via the host channel. Sets the URB status
+ * if the data transfer is finished.
+ *
+ * @return 1 if the data transfer specified by the URB is completely finished,
+ * 0 otherwise.
+ */
+static int update_urb_state_xfer_comp(dwc_hc_t * _hc,
+				      dwc_otg_hc_regs_t * _hc_regs, struct urb *_urb,
+				      dwc_otg_qtd_t * _qtd, int *status)
+{
+	int xfer_done = 0;
+	int short_read = 0;
+	_urb->actual_length += get_actual_xfer_length(_hc, _hc_regs, _qtd,
+				   DWC_OTG_HC_XFER_COMPLETE, &short_read);
+	if (short_read || (_urb->actual_length == _urb->transfer_buffer_length)) {
+		xfer_done = 1;
+		if (_urb->actual_length == _urb->transfer_buffer_length) {
+			*status = 0;
+		} else if (short_read && (_urb->transfer_flags & URB_SHORT_NOT_OK)) {
+			*status = -EREMOTEIO;
+		} else {
+			*status = 0;
+		}
+	}
+
+#ifdef CONFIG_DWC_DEBUG
+	{
+		hctsiz_data_t hctsiz;
+		hctsiz.d32 = dwc_read_reg32(&_hc_regs->hctsiz);
+		DWC_DEBUGPL(DBG_HCDV, "DWC_otg: %s: %s, channel %d\n",
+			     __func__, (_hc->ep_is_in ? "IN" : "OUT"), _hc->hc_num);
+		DWC_DEBUGPL(DBG_HCDV, "  hc->xfer_len %d\n", _hc->xfer_len);
+		DWC_DEBUGPL(DBG_HCDV, "  hctsiz.xfersize %d\n",hctsiz.b.xfersize);
+		DWC_DEBUGPL(DBG_HCDV, "  urb->transfer_buffer_length %d\n",
+			     _urb->transfer_buffer_length);
+		DWC_DEBUGPL(DBG_HCDV, "  urb->actual_length %d\n",
+			     _urb->actual_length);
+		DWC_DEBUGPL(DBG_HCDV, "  short_read %d, xfer_done %d\n",
+			     short_read, xfer_done);
+	}
+#endif	/*  */
+    return xfer_done;
+}
+
+/*
+ * Save the starting data toggle for the next transfer. The data toggle is
+ * saved in the QH for non-control transfers and it's saved in the QTD for
+ * control transfers.
+ */
+static void save_data_toggle(dwc_hc_t * _hc,
+	dwc_otg_hc_regs_t * _hc_regs, dwc_otg_qtd_t * _qtd)
+{
+	hctsiz_data_t hctsiz;
+	hctsiz.d32 = dwc_read_reg32(&_hc_regs->hctsiz);
+	if (_hc->ep_type != DWC_OTG_EP_TYPE_CONTROL) {
+		dwc_otg_qh_t * qh = _hc->qh;
+		if (hctsiz.b.pid == DWC_HCTSIZ_DATA0) {
+			qh->data_toggle = DWC_OTG_HC_PID_DATA0;
+		} else {
+			qh->data_toggle = DWC_OTG_HC_PID_DATA1;
+		}
+	} else {
+		if (hctsiz.b.pid == DWC_HCTSIZ_DATA0) {
+			_qtd->data_toggle = DWC_OTG_HC_PID_DATA0;
+		} else {
+			_qtd->data_toggle = DWC_OTG_HC_PID_DATA1;
+		}
+	}
+}
+
+/**
+ * Frees the first QTD in the QH's list if free_qtd is 1. For non-periodic
+ * QHs, removes the QH from the active non-periodic schedule. If any QTDs are
+ * still linked to the QH, the QH is added to the end of the inactive
+ * non-periodic schedule. For periodic QHs, removes the QH from the periodic
+ * schedule if no more QTDs are linked to the QH.
+ */
+static void deactivate_qh(dwc_otg_hcd_t * _hcd,
+			  dwc_otg_qh_t * _qh,  int free_qtd)
+{
+	int continue_split = 0;
+	dwc_otg_qtd_t * qtd;
+	DWC_DEBUGPL(DBG_HCDV, "  %s(%p,%p,%d)\n", __func__, _hcd, _qh,
+		      free_qtd);
+	qtd = list_entry(_qh->qtd_list.next, dwc_otg_qtd_t, qtd_list_entry);
+	if (qtd->complete_split) {
+		continue_split = 1;
+	} else if ((qtd->isoc_split_pos == DWC_HCSPLIT_XACTPOS_MID) ||
+		(qtd->isoc_split_pos == DWC_HCSPLIT_XACTPOS_END)) {
+		continue_split = 1;
+	}
+
+	if (free_qtd) {
+		/*
+		 * Note that this was previously a call to
+		 * dwc_otg_hcd_qtd_remove_and_free(qtd), which frees the qtd.
+		 * However, that call frees the qtd memory, and we continue in the
+		 * interrupt logic to access it many more times, including writing
+		 * to it.  With slub debugging on, it is clear that we were writing
+		 * to memory we had freed.
+		 * Call this instead, and now I have moved the freeing of the memory to
+		 * the end of processing this interrupt.
+		 */
+		dwc_otg_hcd_qtd_remove(qtd);
+
+		continue_split = 0;
+	}
+	_qh->channel = NULL;
+	_qh->qtd_in_process = NULL;
+	dwc_otg_hcd_qh_deactivate(_hcd, _qh, continue_split);
+}
+
+/**
+ * Updates the state of an Isochronous URB when the transfer is stopped for
+ * any reason. The fields of the current entry in the frame descriptor array
+ * are set based on the transfer state and the input _halt_status. Completes
+ * the Isochronous URB if all the URB frames have been completed.
+ *
+ * @return DWC_OTG_HC_XFER_COMPLETE if there are more frames remaining to be
+ * transferred in the URB. Otherwise return DWC_OTG_HC_XFER_URB_COMPLETE.
+ */
+static dwc_otg_halt_status_e update_isoc_urb_state(dwc_otg_hcd_t * _hcd,
+	  dwc_hc_t * _hc, dwc_otg_hc_regs_t * _hc_regs, dwc_otg_qtd_t * _qtd,
+	  dwc_otg_halt_status_e _halt_status)
+{
+	struct urb *urb = _qtd->urb;
+	dwc_otg_halt_status_e ret_val = _halt_status;
+	struct usb_iso_packet_descriptor *frame_desc;
+	frame_desc = &urb->iso_frame_desc[_qtd->isoc_frame_index];
+	switch (_halt_status) {
+	case DWC_OTG_HC_XFER_COMPLETE:
+		frame_desc->status = 0;
+		frame_desc->actual_length =
+			get_actual_xfer_length(_hc, _hc_regs, _qtd, _halt_status,NULL);
+		break;
+	case DWC_OTG_HC_XFER_FRAME_OVERRUN:
+		urb->error_count++;
+		if (_hc->ep_is_in) {
+			frame_desc->status = -ENOSR;
+		} else {
+			frame_desc->status = -ECOMM;
+		}
+		frame_desc->actual_length = 0;
+		break;
+	case DWC_OTG_HC_XFER_BABBLE_ERR:
+		urb->error_count++;
+		frame_desc->status = -EOVERFLOW;
+
+	    /* Don't need to update actual_length in this case. */
+	    break;
+	case DWC_OTG_HC_XFER_XACT_ERR:
+		urb->error_count++;
+		frame_desc->status = -EPROTO;
+		frame_desc->actual_length =
+		    get_actual_xfer_length(_hc, _hc_regs, _qtd, _halt_status,NULL);
+		break;
+	default:
+		DWC_ERROR("%s: Unhandled _halt_status (%d)\n", __func__, _halt_status);
+		BUG();
+		break;
+	}
+	if (++_qtd->isoc_frame_index == urb->number_of_packets) {
+	    /*
+	     * urb->status is not used for isoc transfers.
+	     * The individual frame_desc statuses are used instead.
+	     */
+	    dwc_otg_hcd_complete_urb(_hcd, urb, 0);
+		ret_val = DWC_OTG_HC_XFER_URB_COMPLETE;
+	} else {
+		ret_val = DWC_OTG_HC_XFER_COMPLETE;
+	}
+	return ret_val;
+}
+
+/**
+ * Releases a host channel for use by other transfers. Attempts to select and
+ * queue more transactions since at least one host channel is available.
+ *
+ * @param _hcd The HCD state structure.
+ * @param _hc The host channel to release.
+ * @param _qtd The QTD associated with the host channel. This QTD may be freed
+ * if the transfer is complete or an error has occurred.
+ * @param _halt_status Reason the channel is being released. This status
+ * determines the actions taken by this function.
+ */
+
+static void release_channel(dwc_otg_hcd_t * _hcd,
+    dwc_hc_t * _hc, dwc_otg_qtd_t * _qtd, dwc_otg_halt_status_e _halt_status, int *must_free)  {
+	dwc_otg_transaction_type_e tr_type;
+	int free_qtd;
+	dwc_otg_qh_t * _qh;
+	int deact = 1;
+	int retry_delay = 1;
+	unsigned long flags;
+
+	DWC_DEBUGPL(DBG_HCDV, "  %s: channel %d, halt_status %d\n", __func__,
+		      _hc->hc_num, _halt_status);
+	switch (_halt_status) {
+	case DWC_OTG_HC_XFER_NYET:
+	case DWC_OTG_HC_XFER_NAK:
+		if (_halt_status == DWC_OTG_HC_XFER_NYET) {
+			retry_delay = nyet_deferral_delay;
+		} else {
+			retry_delay = nak_deferral_delay;
+		}
+		free_qtd = 0;
+		if (deferral_on && _hc->do_split) {
+			_qh = _hc->qh;
+			if (_qh) {
+				deact = dwc_otg_hcd_qh_deferr(_hcd, _qh , retry_delay);
+			}
+		}
+	        break;
+
+	case DWC_OTG_HC_XFER_URB_COMPLETE:
+		free_qtd = 1;
+		break;
+	case DWC_OTG_HC_XFER_AHB_ERR:
+	case DWC_OTG_HC_XFER_STALL:
+	case DWC_OTG_HC_XFER_BABBLE_ERR:
+		free_qtd = 1;
+		break;
+	case DWC_OTG_HC_XFER_XACT_ERR:
+		if (_qtd->error_count >= 3) {
+			DWC_DEBUGPL(DBG_HCDV, "  Complete URB with transaction error\n");
+			free_qtd = 1;
+			dwc_otg_hcd_complete_urb(_hcd, _qtd->urb, -EPROTO);
+		} else {
+			free_qtd = 0;
+		}
+		break;
+	case DWC_OTG_HC_XFER_URB_DEQUEUE:
+	    /*
+	     * The QTD has already been removed and the QH has been
+	     * deactivated. Don't want to do anything except release the
+	     * host channel and try to queue more transfers.
+	     */
+	    goto cleanup;
+	case DWC_OTG_HC_XFER_NO_HALT_STATUS:
+#ifdef CONFIG_DWC_DEBUG
+		DWC_ERROR("%s: No halt_status, channel %d\n", __func__,
+			   _hc->hc_num);
+#endif
+		free_qtd = 1;
+		dwc_otg_hcd_complete_urb(_hcd, _qtd->urb, -EPROTO);
+		break;
+	default:
+		free_qtd = 0;
+		break;
+	}
+	if (free_qtd) {
+		/* Only change must_free to true (do not set to zero here -- it is
+		 * pre-initialized to zero).
+		 */
+		*must_free = 1;
+	}
+	if (deact) {
+		deactivate_qh(_hcd, _hc->qh, free_qtd);
+	}
+cleanup:
+    /*
+     * Release the host channel for use by other transfers. The cleanup
+     * function clears the channel interrupt enables and conditions, so
+     * there's no need to clear the Channel Halted interrupt separately.
+     */
+    dwc_otg_hc_cleanup(_hcd->core_if, _hc);
+	list_add_tail(&_hc->hc_list_entry, &_hcd->free_hc_list);
+	local_irq_save(flags);
+	_hcd->available_host_channels++;
+	local_irq_restore(flags);
+
+	/* Try to queue more transfers now that there's a free channel, */
+	/* unless erratum_usb09_patched is set */
+	if (!erratum_usb09_patched) {
+		tr_type = dwc_otg_hcd_select_transactions(_hcd);
+		if (tr_type != DWC_OTG_TRANSACTION_NONE) {
+			dwc_otg_hcd_queue_transactions(_hcd, tr_type);
+		}
+	}
+}
+
+/**
+ * Halts a host channel. If the channel cannot be halted immediately because
+ * the request queue is full, this function ensures that the FIFO empty
+ * interrupt for the appropriate queue is enabled so that the halt request can
+ * be queued when there is space in the request queue.
+ *
+ * This function may also be called in DMA mode. In that case, the channel is
+ * simply released since the core always halts the channel automatically in
+ * DMA mode.
+ */
+static void halt_channel(dwc_otg_hcd_t * _hcd,
+	dwc_hc_t * _hc, dwc_otg_qtd_t * _qtd, dwc_otg_halt_status_e _halt_status, int *must_free)
+{
+	if (_hcd->core_if->dma_enable) {
+		release_channel(_hcd, _hc, _qtd, _halt_status, must_free);
+		return;
+	}
+
+    /* Slave mode processing... */
+    dwc_otg_hc_halt(_hcd->core_if, _hc, _halt_status);
+	if (_hc->halt_on_queue) {
+		gintmsk_data_t gintmsk = {.d32 = 0};
+		dwc_otg_core_global_regs_t * global_regs;
+		global_regs = _hcd->core_if->core_global_regs;
+		if (_hc->ep_type == DWC_OTG_EP_TYPE_CONTROL ||
+			_hc->ep_type == DWC_OTG_EP_TYPE_BULK) {
+		    /*
+		     * Make sure the Non-periodic Tx FIFO empty interrupt
+		     * is enabled so that the non-periodic schedule will
+		     * be processed.
+		     */
+		    gintmsk.b.nptxfempty = 1;
+			dwc_modify_reg32(&global_regs->gintmsk, 0, gintmsk.d32);
+		} else {
+		    /*
+		     * Move the QH from the periodic queued schedule to
+		     * the periodic assigned schedule. This allows the
+		     * halt to be queued when the periodic schedule is
+		     * processed.
+		     */
+		    list_move(&_hc->qh->qh_list_entry,
+			      &_hcd->periodic_sched_assigned);
+
+		    /*
+		     * Make sure the Periodic Tx FIFO Empty interrupt is
+		     * enabled so that the periodic schedule will be
+		     * processed.
+		     */
+		    gintmsk.b.ptxfempty = 1;
+			dwc_modify_reg32(&global_regs->gintmsk, 0,gintmsk.d32);
+		}
+	}
+}
+
+/**
+ * Performs common cleanup for non-periodic transfers after a Transfer
+ * Complete interrupt. This function should be called after any endpoint type
+ * specific handling is finished to release the host channel.
+ */
+static void complete_non_periodic_xfer(dwc_otg_hcd_t * _hcd,
+	dwc_hc_t * _hc, dwc_otg_hc_regs_t * _hc_regs, dwc_otg_qtd_t * _qtd,
+	dwc_otg_halt_status_e _halt_status, int *must_free)
+{
+	hcint_data_t hcint;
+	_qtd->error_count = 0;
+	hcint.d32 = dwc_read_reg32(&_hc_regs->hcint);
+	if (hcint.b.nyet) {
+	    /*
+	     * Got a NYET on the last transaction of the transfer. This
+	     * means that the endpoint should be in the PING state at the
+	     * beginning of the next transfer.
+	     */
+	    _hc->qh->ping_state = 1;
+		clear_hc_int(_hc_regs, nyet);
+	}
+
+    /*
+     * Always halt and release the host channel to make it available for
+     * more transfers. There may still be more phases for a control
+     * transfer or more data packets for a bulk transfer at this point,
+     * but the host channel is still halted. A channel will be reassigned
+     * to the transfer when the non-periodic schedule is processed after
+     * the channel is released. This allows transactions to be queued
+     * properly via dwc_otg_hcd_queue_transactions, which also enables the
+     * Tx FIFO Empty interrupt if necessary.
+     */
+    if (_hc->ep_is_in) {
+	    /*
+	     * IN transfers in Slave mode require an explicit disable to
+	     * halt the channel. (In DMA mode, this call simply releases
+	     * the channel.)
+	     */
+	    halt_channel(_hcd, _hc, _qtd, _halt_status, must_free);
+	} else {
+	    /*
+	     * The channel is automatically disabled by the core for OUT
+	     * transfers in Slave mode.
+	     */
+	    release_channel(_hcd, _hc, _qtd, _halt_status, must_free);
+	}
+}
+
+/**
+ * Performs common cleanup for periodic transfers after a Transfer Complete
+ * interrupt. This function should be called after any endpoint type specific
+ * handling is finished to release the host channel.
+ */
+static void complete_periodic_xfer(dwc_otg_hcd_t * _hcd,
+	dwc_hc_t * _hc, dwc_otg_hc_regs_t * _hc_regs, dwc_otg_qtd_t * _qtd,
+	dwc_otg_halt_status_e _halt_status, int *must_free)
+{
+	hctsiz_data_t hctsiz;
+	_qtd->error_count = 0;
+	hctsiz.d32 = dwc_read_reg32(&_hc_regs->hctsiz);
+	if (!_hc->ep_is_in || hctsiz.b.pktcnt == 0) {
+	    /* Core halts channel in these cases. */
+	    release_channel(_hcd, _hc, _qtd, _halt_status, must_free);
+	} else {
+	    /* Flush any outstanding requests from the Tx queue. */
+	    halt_channel(_hcd, _hc, _qtd, _halt_status, must_free);
+	}
+}
+
+/**
+ * Handles a host channel Transfer Complete interrupt. This handler may be
+ * called in either DMA mode or Slave mode.
+ */
+static int32_t handle_hc_xfercomp_intr(dwc_otg_hcd_t * _hcd,
+	dwc_hc_t * _hc, dwc_otg_hc_regs_t * _hc_regs, dwc_otg_qtd_t * _qtd, int *must_free)
+{
+	int urb_xfer_done;
+	dwc_otg_halt_status_e halt_status = DWC_OTG_HC_XFER_COMPLETE;
+	struct urb *urb = _qtd->urb;
+	int pipe_type = usb_pipetype(urb->pipe);
+	int status = -EINPROGRESS;
+
+	DWC_DEBUGPL(DBG_HCD, "--Host Channel %d Interrupt: "
+		      "Transfer Complete--\n", _hc->hc_num);
+
+    /*
+     * Handle xfer complete on CSPLIT.
+     */
+    if (_hc->qh->do_split) {
+		_qtd->complete_split = 0;
+	}
+
+    /* Update the QTD and URB states. */
+    switch (pipe_type) {
+	case PIPE_CONTROL:
+		switch (_qtd->control_phase) {
+		case DWC_OTG_CONTROL_SETUP:
+			if (urb->transfer_buffer_length > 0) {
+				_qtd->control_phase = DWC_OTG_CONTROL_DATA;
+			} else {
+				_qtd->control_phase = DWC_OTG_CONTROL_STATUS;
+			}
+			DWC_DEBUGPL(DBG_HCDV,
+				     "  Control setup transaction done\n");
+			halt_status = DWC_OTG_HC_XFER_COMPLETE;
+			break;
+		case DWC_OTG_CONTROL_DATA:{
+			urb_xfer_done = update_urb_state_xfer_comp(_hc, _hc_regs,urb, _qtd, &status);
+				if (urb_xfer_done) {
+					_qtd->control_phase = DWC_OTG_CONTROL_STATUS;
+					DWC_DEBUGPL(DBG_HCDV,"  Control data transfer done\n");
+				} else {
+					save_data_toggle(_hc, _hc_regs, _qtd);
+				}
+				halt_status = DWC_OTG_HC_XFER_COMPLETE;
+				break;
+			}
+		case DWC_OTG_CONTROL_STATUS:
+			DWC_DEBUGPL(DBG_HCDV, "  Control transfer complete\n");
+			if (status == -EINPROGRESS) {
+				status = 0;
+			}
+			dwc_otg_hcd_complete_urb(_hcd, urb, status);
+			halt_status = DWC_OTG_HC_XFER_URB_COMPLETE;
+			break;
+		}
+		complete_non_periodic_xfer(_hcd, _hc, _hc_regs, _qtd,
+					     halt_status, must_free);
+		break;
+	case PIPE_BULK:
+		DWC_DEBUGPL(DBG_HCDV, "  Bulk transfer complete\n");
+		urb_xfer_done = update_urb_state_xfer_comp(_hc, _hc_regs, urb, _qtd, &status);
+		if (urb_xfer_done) {
+			dwc_otg_hcd_complete_urb(_hcd, urb, status);
+			halt_status = DWC_OTG_HC_XFER_URB_COMPLETE;
+		} else {
+			halt_status = DWC_OTG_HC_XFER_COMPLETE;
+		}
+		save_data_toggle(_hc, _hc_regs, _qtd);
+		complete_non_periodic_xfer(_hcd, _hc, _hc_regs, _qtd,halt_status, must_free);
+		break;
+	case PIPE_INTERRUPT:
+		DWC_DEBUGPL(DBG_HCDV, "  Interrupt transfer complete\n");
+		update_urb_state_xfer_comp(_hc, _hc_regs, urb, _qtd, &status);
+	    /*
+	     * Interrupt URB is done on the first transfer complete
+	     * interrupt.
+	     */
+	    dwc_otg_hcd_complete_urb(_hcd, urb, status);
+		save_data_toggle(_hc, _hc_regs, _qtd);
+		complete_periodic_xfer(_hcd, _hc, _hc_regs, _qtd,
+					DWC_OTG_HC_XFER_URB_COMPLETE, must_free);
+		break;
+	case PIPE_ISOCHRONOUS:
+		DWC_DEBUGPL(DBG_HCDV, "  Isochronous transfer complete\n");
+		if (_qtd->isoc_split_pos == DWC_HCSPLIT_XACTPOS_ALL) {
+			halt_status = update_isoc_urb_state(_hcd, _hc, _hc_regs, _qtd,
+							  DWC_OTG_HC_XFER_COMPLETE);
+		}
+		complete_periodic_xfer(_hcd, _hc, _hc_regs, _qtd, halt_status, must_free);
+		break;
+	}
+	disable_hc_int(_hc_regs, xfercompl);
+	return 1;
+}
+
+/**
+ * Handles a host channel STALL interrupt. This handler may be called in
+ * either DMA mode or Slave mode.
+ */
+static int32_t handle_hc_stall_intr(dwc_otg_hcd_t * _hcd,
+	dwc_hc_t * _hc, dwc_otg_hc_regs_t * _hc_regs, dwc_otg_qtd_t * _qtd, int *must_free)
+{
+	struct urb *urb = _qtd->urb;
+	int pipe_type = usb_pipetype(urb->pipe);
+	DWC_DEBUGPL(DBG_HCD, "--Host Channel %d Interrupt: "
+		      "STALL Received--\n", _hc->hc_num);
+	if (pipe_type == PIPE_CONTROL) {
+		dwc_otg_hcd_complete_urb(_hcd, _qtd->urb, -EPIPE);
+	}
+	if (pipe_type == PIPE_BULK || pipe_type == PIPE_INTERRUPT) {
+		dwc_otg_hcd_complete_urb(_hcd, _qtd->urb, -EPIPE);
+	    /*
+	     * USB protocol requires resetting the data toggle for bulk
+	     * and interrupt endpoints when a CLEAR_FEATURE(ENDPOINT_HALT)
+	     * setup command is issued to the endpoint. Anticipate the
+	     * CLEAR_FEATURE command since a STALL has occurred and reset
+	     * the data toggle now.
+	     */
+	    _hc->qh->data_toggle = 0;
+	}
+	halt_channel(_hcd, _hc, _qtd, DWC_OTG_HC_XFER_STALL, must_free);
+	disable_hc_int(_hc_regs, stall);
+	return 1;
+}
+
+/*
+ * Updates the state of the URB when a transfer has been stopped due to an
+ * abnormal condition before the transfer completes. Modifies the
+ * actual_length field of the URB to reflect the number of bytes that have
+ * actually been transferred via the host channel.
+ */
+static void update_urb_state_xfer_intr(dwc_hc_t * _hc,
+	dwc_otg_hc_regs_t * _hc_regs, struct urb *_urb, dwc_otg_qtd_t * _qtd,
+	dwc_otg_halt_status_e _halt_status)
+{
+	uint32_t bytes_transferred =
+	    get_actual_xfer_length(_hc, _hc_regs, _qtd, _halt_status, NULL);
+	_urb->actual_length += bytes_transferred;
+
+#ifdef CONFIG_DWC_DEBUG
+	{
+		hctsiz_data_t hctsiz;
+		hctsiz.d32 = dwc_read_reg32(&_hc_regs->hctsiz);
+		DWC_DEBUGPL(DBG_HCDV, "DWC_otg: %s: %s, channel %d\n",
+			     __func__, (_hc->ep_is_in ? "IN" : "OUT"),_hc->hc_num);
+		DWC_DEBUGPL(DBG_HCDV, "  _hc->start_pkt_count %d\n",
+			     _hc->start_pkt_count);
+		DWC_DEBUGPL(DBG_HCDV, "  hctsiz.pktcnt %d\n", hctsiz.b.pktcnt);
+		DWC_DEBUGPL(DBG_HCDV, "  _hc->max_packet %d\n",_hc->max_packet);
+		DWC_DEBUGPL(DBG_HCDV, "  bytes_transferred %d\n",
+			     bytes_transferred);
+		DWC_DEBUGPL(DBG_HCDV, "  _urb->actual_length %d\n",
+			     _urb->actual_length);
+		DWC_DEBUGPL(DBG_HCDV, "  _urb->transfer_buffer_length %d\n",
+			     _urb->transfer_buffer_length);
+	}
+#endif	/*  */
+}
+
+/**
+ * Handles a host channel NAK interrupt. This handler may be called in either
+ * DMA mode or Slave mode.
+ */
+static int32_t handle_hc_nak_intr(dwc_otg_hcd_t * _hcd,
+	dwc_hc_t * _hc, dwc_otg_hc_regs_t * _hc_regs, dwc_otg_qtd_t * _qtd, int *must_free)  {
+	DWC_DEBUGPL(DBG_HCD, "--Host Channel %d Interrupt: "
+		     "NAK Received--\n", _hc->hc_num);
+    /*
+     * Handle NAK for IN/OUT SSPLIT/CSPLIT transfers, bulk, control, and
+     * interrupt.  Re-start the SSPLIT transfer.
+     */
+    if (_hc->do_split) {
+		if (_hc->complete_split) {
+			_qtd->error_count = 0;
+		}
+		_qtd->complete_split = 0;
+		halt_channel(_hcd, _hc, _qtd, DWC_OTG_HC_XFER_NAK, must_free);
+		goto handle_nak_done;
+	}
+	switch (usb_pipetype(_qtd->urb->pipe)) {
+	case PIPE_CONTROL:
+	case PIPE_BULK:
+		if (_hcd->core_if->dma_enable && _hc->ep_is_in) {
+		    /*
+		     * NAK interrupts are enabled on bulk/control IN
+		     * transfers in DMA mode for the sole purpose of
+		     * resetting the error count after a transaction error
+		     * occurs. The core will continue transferring data.
+		     */
+		    _qtd->error_count = 0;
+			goto handle_nak_done;
+		}
+
+	    /*
+	     * NAK interrupts normally occur during OUT transfers in DMA
+	     * or Slave mode. For IN transfers, more requests will be
+	     * queued as request queue space is available.
+	     */
+	    _qtd->error_count = 0;
+		if (!_hc->qh->ping_state) {
+			update_urb_state_xfer_intr(_hc, _hc_regs, _qtd->urb,
+						    _qtd, DWC_OTG_HC_XFER_NAK);
+			save_data_toggle(_hc, _hc_regs, _qtd);
+			if (_qtd->urb->dev->speed == USB_SPEED_HIGH) {
+				_hc->qh->ping_state = 1;
+			}
+		}
+
+	    /*
+	     * Halt the channel so the transfer can be re-started from
+	     * the appropriate point or the PING protocol will
+	     * start/continue.
+	     */
+	    halt_channel(_hcd, _hc, _qtd, DWC_OTG_HC_XFER_NAK, must_free);
+		break;
+	case PIPE_INTERRUPT:
+		_qtd->error_count = 0;
+		halt_channel(_hcd, _hc, _qtd, DWC_OTG_HC_XFER_NAK, must_free);
+		break;
+	case PIPE_ISOCHRONOUS:
+	    /* Should never get called for isochronous transfers. */
+		BUG();
+		break;
+	}
+	handle_nak_done:disable_hc_int(_hc_regs, nak);
+	return 1;
+}
+
+/**
+ * Handles a host channel ACK interrupt. This interrupt is enabled when
+ * performing the PING protocol in Slave mode, when errors occur during
+ * either Slave mode or DMA mode, and during Start Split transactions.
+ */
+static int32_t handle_hc_ack_intr(dwc_otg_hcd_t * _hcd,
+	dwc_hc_t * _hc, dwc_otg_hc_regs_t * _hc_regs, dwc_otg_qtd_t * _qtd, int *must_free)
+{
+	DWC_DEBUGPL(DBG_HCD, "--Host Channel %d Interrupt: "
+		     "ACK Received--\n", _hc->hc_num);
+	if (_hc->do_split) {
+	    /*
+	     * Handle ACK on SSPLIT.
+	     * ACK should not occur in CSPLIT.
+	     */
+	    if ((!_hc->ep_is_in) && (_hc->data_pid_start != DWC_OTG_HC_PID_SETUP)) {
+			_qtd->ssplit_out_xfer_count = _hc->xfer_len;
+		}
+		if (!(_hc->ep_type == DWC_OTG_EP_TYPE_ISOC && !_hc->ep_is_in)) {
+			    /* Don't need complete for isochronous out transfers. */
+			    _qtd->complete_split = 1;
+		}
+
+	    /* ISOC OUT */
+	    if ((_hc->ep_type == DWC_OTG_EP_TYPE_ISOC) && !_hc->ep_is_in) {
+			switch (_hc->xact_pos) {
+			case DWC_HCSPLIT_XACTPOS_ALL:
+				break;
+			case DWC_HCSPLIT_XACTPOS_END:
+				_qtd->isoc_split_pos = DWC_HCSPLIT_XACTPOS_ALL;
+				_qtd->isoc_split_offset = 0;
+				break;
+			case DWC_HCSPLIT_XACTPOS_BEGIN:
+			case DWC_HCSPLIT_XACTPOS_MID:
+			    /*
+			     * For BEGIN or MID, calculate the length for
+			     * the next microframe to determine the correct
+			     * SSPLIT token, either MID or END.
+			     */
+			    do {
+					struct usb_iso_packet_descriptor *frame_desc;
+					frame_desc = &_qtd->urb->iso_frame_desc[_qtd->isoc_frame_index];
+					_qtd->isoc_split_offset += 188;
+					if ((frame_desc->length - _qtd->isoc_split_offset) <=188) {
+						_qtd->isoc_split_pos = DWC_HCSPLIT_XACTPOS_END;
+					} else {
+						_qtd->isoc_split_pos = DWC_HCSPLIT_XACTPOS_MID;
+					}
+				} while (0);
+				break;
+			}
+		} else {
+			halt_channel(_hcd, _hc, _qtd, DWC_OTG_HC_XFER_ACK, must_free);
+		}
+	} else {
+#if 0
+		_qtd->error_count = 0;
+		if (_hc->qh->ping_state) {
+			_hc->qh->ping_state = 0;
+
+		    /*
+		     * Halt the channel so the transfer can be re-started
+		     * from the appropriate point. This only happens in
+		     * Slave mode. In DMA mode, the ping_state is cleared
+		     * when the transfer is started because the core
+		     * automatically executes the PING, then the transfer.
+		     */
+		    halt_channel(_hcd, _hc, _qtd, DWC_OTG_HC_XFER_ACK, must_free);
+		} else {
+		    halt_channel(_hcd, _hc, _qtd, _hc->halt_status, must_free);
+		}
+#endif
+	}
+
+    /*
+     * If the ACK occurred when _not_ in the PING state, let the channel
+     * continue transferring data after clearing the error count.
+     */
+    disable_hc_int(_hc_regs, ack);
+	return 1;
+}
+
+/**
+ * Handles a host channel NYET interrupt. This interrupt should only occur on
+ * Bulk and Control OUT endpoints and for complete split transactions. If a
+ * NYET occurs at the same time as a Transfer Complete interrupt, it is
+ * handled in the xfercomp interrupt handler, not here. This handler may be
+ * called in either DMA mode or Slave mode.
+ */
+static int32_t handle_hc_nyet_intr(dwc_otg_hcd_t * _hcd,
+	dwc_hc_t * _hc, dwc_otg_hc_regs_t * _hc_regs, dwc_otg_qtd_t * _qtd, int *must_free)
+{
+	DWC_DEBUGPL(DBG_HCD, "--Host Channel %d Interrupt: "
+		     "NYET Received--\n", _hc->hc_num);
+
+    /*
+     * NYET on CSPLIT
+     * re-do the CSPLIT immediately on non-periodic
+     */
+    if ((_hc->do_split) && (_hc->complete_split)) {
+		if ((_hc->ep_type == DWC_OTG_EP_TYPE_INTR) ||
+		     (_hc->ep_type == DWC_OTG_EP_TYPE_ISOC)) {
+			int frnum = dwc_otg_hcd_get_frame_number(dwc_otg_hcd_to_hcd
+							 (_hcd));
+			if (dwc_full_frame_num(frnum) !=
+			      dwc_full_frame_num(_hc->qh->sched_frame)) {
+
+			    /*
+			     * No longer in the same full speed frame.
+			     * Treat this as a transaction error.
+			     */
+#if 0
+				/** @todo Fix system performance so this can
+				 * be treated as an error. Right now complete
+				 * splits cannot be scheduled precisely enough
+				 * due to other system activity, so this error
+				 * occurs regularly in Slave mode.
+				 */
+				    _qtd->error_count++;
+
+#endif	/*  */
+			    _qtd->complete_split = 0;
+				halt_channel(_hcd, _hc, _qtd, DWC_OTG_HC_XFER_XACT_ERR, must_free);
+
+				/** @todo add support for isoc release */
+			    goto handle_nyet_done;
+			}
+		}
+		halt_channel(_hcd, _hc, _qtd, DWC_OTG_HC_XFER_NYET, must_free);
+		goto handle_nyet_done;
+	}
+	_hc->qh->ping_state = 1;
+	_qtd->error_count = 0;
+	update_urb_state_xfer_intr(_hc, _hc_regs, _qtd->urb, _qtd,
+				     DWC_OTG_HC_XFER_NYET);
+	save_data_toggle(_hc, _hc_regs, _qtd);
+
+    /*
+     * Halt the channel and re-start the transfer so the PING
+     * protocol will start.
+     */
+    halt_channel(_hcd, _hc, _qtd, DWC_OTG_HC_XFER_NYET, must_free);
+handle_nyet_done:
+	disable_hc_int(_hc_regs, nyet);
+	clear_hc_int(_hc_regs, nyet);
+
+	return 1;
+}
+
+/**
+ * Handles a host channel babble interrupt. This handler may be called in
+ * either DMA mode or Slave mode.
+ */
+static int32_t handle_hc_babble_intr(dwc_otg_hcd_t * _hcd,
+	dwc_hc_t * _hc, dwc_otg_hc_regs_t * _hc_regs, dwc_otg_qtd_t * _qtd, int *must_free)
+{
+	DWC_DEBUGPL(DBG_HCD, "--Host Channel %d Interrupt: "
+		     "Babble Error--\n", _hc->hc_num);
+	if (_hc->ep_type != DWC_OTG_EP_TYPE_ISOC) {
+		dwc_otg_hcd_complete_urb(_hcd, _qtd->urb, -EOVERFLOW);
+		halt_channel(_hcd, _hc, _qtd, DWC_OTG_HC_XFER_BABBLE_ERR, must_free);
+	} else {
+		dwc_otg_halt_status_e halt_status;
+		halt_status = update_isoc_urb_state(_hcd, _hc, _hc_regs, _qtd,
+					  DWC_OTG_HC_XFER_BABBLE_ERR);
+		halt_channel(_hcd, _hc, _qtd, halt_status, must_free);
+	}
+	disable_hc_int(_hc_regs, bblerr);
+	return 1;
+}
+
+/**
+ * Handles a host channel AHB error interrupt. This handler is only called in
+ * DMA mode.
+ */
+static int32_t handle_hc_ahberr_intr(dwc_otg_hcd_t * _hcd,
+	dwc_hc_t * _hc, dwc_otg_hc_regs_t * _hc_regs, dwc_otg_qtd_t * _qtd)
+{
+	hcchar_data_t hcchar;
+	hcsplt_data_t hcsplt;
+	hctsiz_data_t hctsiz;
+	uint32_t hcdma;
+	struct urb *urb = _qtd->urb;
+	DWC_DEBUGPL(DBG_HCD, "--Host Channel %d Interrupt: "
+		      "AHB Error--\n", _hc->hc_num);
+	hcchar.d32 = dwc_read_reg32(&_hc_regs->hcchar);
+	hcsplt.d32 = dwc_read_reg32(&_hc_regs->hcsplt);
+	hctsiz.d32 = dwc_read_reg32(&_hc_regs->hctsiz);
+	hcdma = dwc_read_reg32(&_hc_regs->hcdma);
+	DWC_ERROR("AHB ERROR, Channel %d\n", _hc->hc_num);
+	DWC_ERROR("  hcchar 0x%08x, hcsplt 0x%08x\n", hcchar.d32, hcsplt.d32);
+	DWC_ERROR("  hctsiz 0x%08x, hcdma 0x%08x\n", hctsiz.d32, hcdma);
+	DWC_DEBUGPL(DBG_HCD, "DWC OTG HCD URB Enqueue\n");
+	DWC_ERROR("  Device address: %d\n", usb_pipedevice(urb->pipe));
+	DWC_ERROR("  Endpoint: %d, %s\n", usb_pipeendpoint(urb->pipe),
+			(usb_pipein(urb->pipe) ? "IN" : "OUT"));
+	DWC_ERROR("  Endpoint type: %s\n", ( {
+			char *pipetype;
+		    switch (usb_pipetype(urb->pipe)) {
+			case PIPE_CONTROL:
+				pipetype = "CONTROL"; break;
+			case PIPE_BULK:
+				pipetype = "BULK"; break;
+			case PIPE_INTERRUPT:
+				pipetype = "INTERRUPT"; break;
+			case PIPE_ISOCHRONOUS:
+				pipetype = "ISOCHRONOUS"; break;
+			default:
+				pipetype = "UNKNOWN"; break;
+			};
+			pipetype;
+	} )) ;
+	DWC_ERROR("  Speed: %s\n", ( {
+			char *speed;
+			switch (urb->dev->speed) {
+			case USB_SPEED_HIGH:
+				speed = "HIGH"; break;
+			case USB_SPEED_FULL:
+				speed = "FULL"; break;
+			case USB_SPEED_LOW:
+				speed = "LOW"; break;
+			default:
+				speed = "UNKNOWN"; break;
+			};
+			speed;
+	} )) ;
+	DWC_ERROR("  Max packet size: %d\n",
+		   usb_maxpacket(urb->dev, urb->pipe, usb_pipeout(urb->pipe)));
+	DWC_ERROR("  Data buffer length: %d\n", urb->transfer_buffer_length);
+	DWC_ERROR("  Transfer buffer: %p, Transfer DMA: %p\n",
+		  urb->transfer_buffer, (void *)(u32)urb->transfer_dma);
+	DWC_ERROR("  Setup buffer: %p, Setup DMA: %p\n", urb->setup_packet,
+		  (void *)(u32)urb->setup_dma);
+	DWC_ERROR("  Interval: %d\n", urb->interval);
+	dwc_otg_hcd_complete_urb(_hcd, urb, -EIO);
+
+    /*
+     * Force a channel halt. Don't call halt_channel because that won't
+     * write to the HCCHARn register in DMA mode to force the halt.
+     */
+    dwc_otg_hc_halt(_hcd->core_if, _hc, DWC_OTG_HC_XFER_AHB_ERR);
+	disable_hc_int(_hc_regs, ahberr);
+	return 1;
+}
+
+/**
+ * Handles a host channel transaction error interrupt. This handler may be
+ * called in either DMA mode or Slave mode.
+ */
+static int32_t handle_hc_xacterr_intr(dwc_otg_hcd_t * _hcd,
+	dwc_hc_t * _hc, dwc_otg_hc_regs_t * _hc_regs, dwc_otg_qtd_t * _qtd, int *must_free)
+{
+	DWC_DEBUGPL(DBG_HCD, "--Host Channel %d Interrupt: "
+		     "Transaction Error--\n", _hc->hc_num);
+	switch (usb_pipetype(_qtd->urb->pipe)) {
+	case PIPE_CONTROL:
+	case PIPE_BULK:
+		_qtd->error_count++;
+		if (!_hc->qh->ping_state) {
+			update_urb_state_xfer_intr(_hc, _hc_regs, _qtd->urb,
+				    _qtd, DWC_OTG_HC_XFER_XACT_ERR);
+			save_data_toggle(_hc, _hc_regs, _qtd);
+			if (!_hc->ep_is_in && _qtd->urb->dev->speed == USB_SPEED_HIGH) {
+				_hc->qh->ping_state = 1;
+			}
+		}
+
+	    /*
+	     * Halt the channel so the transfer can be re-started from
+	     * the appropriate point or the PING protocol will start.
+	     */
+	    halt_channel(_hcd, _hc, _qtd, DWC_OTG_HC_XFER_XACT_ERR, must_free);
+		break;
+	case PIPE_INTERRUPT:
+		_qtd->error_count++;
+		if ((_hc->do_split) && (_hc->complete_split)) {
+			_qtd->complete_split = 0;
+		}
+		halt_channel(_hcd, _hc, _qtd, DWC_OTG_HC_XFER_XACT_ERR, must_free);
+		break;
+	case PIPE_ISOCHRONOUS:
+		 {
+			dwc_otg_halt_status_e halt_status;
+			halt_status = update_isoc_urb_state(_hcd, _hc, _hc_regs, _qtd,
+						  DWC_OTG_HC_XFER_XACT_ERR);
+			halt_channel(_hcd, _hc, _qtd, halt_status, must_free);
+		}
+		break;
+	}
+	disable_hc_int(_hc_regs, xacterr);
+	return 1;
+}
+
+/**
+ * Handles a host channel frame overrun interrupt. This handler may be called
+ * in either DMA mode or Slave mode.
+ */
+static int32_t handle_hc_frmovrun_intr(dwc_otg_hcd_t * _hcd,
+	dwc_hc_t * _hc, dwc_otg_hc_regs_t * _hc_regs, dwc_otg_qtd_t * _qtd, int *must_free)
+{
+	DWC_DEBUGPL(DBG_HCD, "--Host Channel %d Interrupt: "
+		     "Frame Overrun--\n", _hc->hc_num);
+	switch (usb_pipetype(_qtd->urb->pipe)) {
+	case PIPE_CONTROL:
+	case PIPE_BULK:
+		break;
+	case PIPE_INTERRUPT:
+		halt_channel(_hcd, _hc, _qtd, DWC_OTG_HC_XFER_FRAME_OVERRUN, must_free);
+		break;
+	case PIPE_ISOCHRONOUS:
+		 {
+			dwc_otg_halt_status_e halt_status;
+			halt_status = update_isoc_urb_state(_hcd, _hc, _hc_regs, _qtd,
+						  DWC_OTG_HC_XFER_FRAME_OVERRUN);
+			halt_channel(_hcd, _hc, _qtd, halt_status, must_free);
+		}
+		break;
+	}
+	disable_hc_int(_hc_regs, frmovrun);
+	return 1;
+}
+
+/**
+ * Handles a host channel data toggle error interrupt. This handler may be
+ * called in either DMA mode or Slave mode.
+ */
+static int32_t handle_hc_datatglerr_intr(dwc_otg_hcd_t * _hcd,
+	dwc_hc_t * _hc, dwc_otg_hc_regs_t * _hc_regs, dwc_otg_qtd_t * _qtd, int *must_free)
+{
+	DWC_DEBUGPL(DBG_HCD, "--Host Channel %d Interrupt: "
+		     "Data Toggle Error--\n", _hc->hc_num);
+	if (_hc->ep_is_in) {
+		_qtd->error_count = 0;
+	} else {
+		DWC_ERROR("Data Toggle Error on OUT transfer,"
+			   "channel %d\n", _hc->hc_num);
+	}
+	disable_hc_int(_hc_regs, datatglerr);
+	return 1;
+}
+
+#ifdef CONFIG_DWC_DEBUG
+/**
+ * This function is for debug only. It checks that a valid halt status is set
+ * and that HCCHARn.chdis is clear. If there's a problem, corrective action is
+ * taken and a warning is issued.
+ * @return 1 if halt status is ok, 0 otherwise.
+ */
+static inline int halt_status_ok(dwc_otg_hcd_t * _hcd,
+	dwc_hc_t * _hc, dwc_otg_hc_regs_t * _hc_regs, dwc_otg_qtd_t * _qtd, int *must_free)
+{
+	hcchar_data_t hcchar;
+	hctsiz_data_t hctsiz;
+	hcint_data_t hcint;
+	hcintmsk_data_t hcintmsk;
+	hcsplt_data_t hcsplt;
+	if (_hc->halt_status == DWC_OTG_HC_XFER_NO_HALT_STATUS) {
+	    /*
+	     * This code is here only as a check. This condition should
+	     * never happen. Ignore the halt if it does occur.
+	     */
+	    hcchar.d32 = dwc_read_reg32(&_hc_regs->hcchar);
+		hctsiz.d32 = dwc_read_reg32(&_hc_regs->hctsiz);
+		hcint.d32 = dwc_read_reg32(&_hc_regs->hcint);
+		hcintmsk.d32 = dwc_read_reg32(&_hc_regs->hcintmsk);
+		hcsplt.d32 = dwc_read_reg32(&_hc_regs->hcsplt);
+		DWC_WARN("%s: _hc->halt_status == DWC_OTG_HC_XFER_NO_HALT_STATUS, "
+		      "channel %d, hcchar 0x%08x, hctsiz 0x%08x, "
+		     "hcint 0x%08x, hcintmsk 0x%08x, "
+		     "hcsplt 0x%08x, qtd->complete_split %d\n", __func__,
+		     _hc->hc_num, hcchar.d32, hctsiz.d32, hcint.d32,
+		     hcintmsk.d32, hcsplt.d32, _qtd->complete_split);
+		DWC_WARN("%s: no halt status, channel %d, ignoring interrupt\n",
+		     __func__, _hc->hc_num);
+		DWC_WARN("\n");
+		clear_hc_int(_hc_regs, chhltd);
+		return 0;
+	}
+
+    /*
+     * This code is here only as a check. hcchar.chdis should
+     * never be set when the halt interrupt occurs. Halt the
+     * channel again if it does occur.
+     */
+    hcchar.d32 = dwc_read_reg32(&_hc_regs->hcchar);
+	if (hcchar.b.chdis) {
+		DWC_WARN("%s: hcchar.chdis set unexpectedly, "
+			  "hcchar 0x%08x, trying to halt again\n", __func__,
+			  hcchar.d32);
+		clear_hc_int(_hc_regs, chhltd);
+		_hc->halt_pending = 0;
+		halt_channel(_hcd, _hc, _qtd, _hc->halt_status, must_free);
+		return 0;
+	}
+	return 1;
+}
+#endif	/*  */
+
+/**
+ * Handles a host Channel Halted interrupt in DMA mode. This handler
+ * determines the reason the channel halted and proceeds accordingly.
+ */
+static void handle_hc_chhltd_intr_dma(dwc_otg_hcd_t * _hcd,
+	dwc_hc_t * _hc, dwc_otg_hc_regs_t * _hc_regs, dwc_otg_qtd_t * _qtd, int *must_free)
+{
+	hcint_data_t hcint;
+	hcintmsk_data_t hcintmsk;
+	if (_hc->halt_status == DWC_OTG_HC_XFER_URB_DEQUEUE ||
+		_hc->halt_status == DWC_OTG_HC_XFER_AHB_ERR) {
+	    /*
+	     * Just release the channel. A dequeue can happen on a
+	     * transfer timeout. In the case of an AHB Error, the channel
+	     * was forced to halt because there's no way to gracefully
+	     * recover.
+	     */
+	    release_channel(_hcd, _hc, _qtd, _hc->halt_status, must_free);
+		return;
+	}
+
+    /* Read the HCINTn register to determine the cause for the halt. */
+    hcint.d32 = dwc_read_reg32(&_hc_regs->hcint);
+	hcintmsk.d32 = dwc_read_reg32(&_hc_regs->hcintmsk);
+	if (hcint.b.xfercomp) {
+
+		/** @todo This is here because of a possible hardware bug.  Spec
+		 * says that on SPLIT-ISOC OUT transfers in DMA mode that a HALT
+		 * interrupt w/ACK bit set should occur, but I only see the
+		 * XFERCOMP bit, even with it masked out.  This is a workaround
+		 * for that behavior.  Should fix this when hardware is fixed.
+		 */
+	    if ((_hc->ep_type == DWC_OTG_EP_TYPE_ISOC) && (!_hc->ep_is_in)) {
+			handle_hc_ack_intr(_hcd, _hc, _hc_regs, _qtd, must_free);
+		}
+		handle_hc_xfercomp_intr(_hcd, _hc, _hc_regs, _qtd, must_free);
+	} else if (hcint.b.stall) {
+		handle_hc_stall_intr(_hcd, _hc, _hc_regs, _qtd, must_free);
+	} else if (hcint.b.xacterr) {
+	    /*
+	     * Must handle xacterr before nak or ack. Could get a xacterr
+	     * at the same time as either of these on a BULK/CONTROL OUT
+	     * that started with a PING. The xacterr takes precedence.
+	     */
+	    handle_hc_xacterr_intr(_hcd, _hc, _hc_regs, _qtd, must_free);
+	} else if (hcint.b.nyet) {
+	    /*
+	     * Must handle nyet before nak or ack. Could get a nyet at the
+	     * same time as either of those on a BULK/CONTROL OUT that
+	     * started with a PING. The nyet takes precedence.
+	     */
+	    handle_hc_nyet_intr(_hcd, _hc, _hc_regs, _qtd, must_free);
+	} else if (hcint.b.bblerr) {
+		handle_hc_babble_intr(_hcd, _hc, _hc_regs, _qtd, must_free);
+	} else if (hcint.b.frmovrun) {
+		handle_hc_frmovrun_intr(_hcd, _hc, _hc_regs, _qtd, must_free);
+	} else if (hcint.b.datatglerr) {
+		handle_hc_datatglerr_intr(_hcd, _hc, _hc_regs, _qtd, must_free);
+		_hc->qh->data_toggle = 0;
+		halt_channel(_hcd, _hc, _qtd, _hc->halt_status, must_free);
+	} else if (hcint.b.nak && !hcintmsk.b.nak) {
+		/*
+	     * If nak is not masked, it's because a non-split IN transfer
+	     * is in an error state. In that case, the nak is handled by
+	     * the nak interrupt handler, not here. Handle nak here for
+	     * BULK/CONTROL OUT transfers, which halt on a NAK to allow
+	     * rewinding the buffer pointer.
+	     */
+	    handle_hc_nak_intr(_hcd, _hc, _hc_regs, _qtd, must_free);
+	} else if (hcint.b.ack && !hcintmsk.b.ack) {
+	    /*
+	     * If ack is not masked, it's because a non-split IN transfer
+	     * is in an error state. In that case, the ack is handled by
+	     * the ack interrupt handler, not here. Handle ack here for
+	     * split transfers. Start splits halt on ACK.
+	     */
+	    handle_hc_ack_intr(_hcd, _hc, _hc_regs, _qtd, must_free);
+	} else {
+		if (_hc->ep_type == DWC_OTG_EP_TYPE_INTR ||
+			_hc->ep_type == DWC_OTG_EP_TYPE_ISOC) {
+		    /*
+		     * A periodic transfer halted with no other channel
+		     * interrupts set. Assume it was halted by the core
+		     * because it could not be completed in its scheduled
+		     * (micro)frame.
+		     */
+#ifdef CONFIG_DWC_DEBUG
+		    DWC_PRINT("%s: Halt channel %d (assume incomplete periodic transfer)\n",
+			     __func__, _hc->hc_num);
+
+#endif	/*  */
+		    halt_channel(_hcd, _hc, _qtd,
+					 DWC_OTG_HC_XFER_PERIODIC_INCOMPLETE, must_free);
+		} else {
+#ifdef CONFIG_DWC_DEBUG
+			DWC_ERROR("%s: Channel %d, DMA Mode -- ChHltd set, but reason "
+			     "for halting is unknown, nyet %d, hcint 0x%08x, intsts 0x%08x\n",
+			     __func__, _hc->hc_num, hcint.b.nyet, hcint.d32,
+				 dwc_read_reg32(&_hcd->core_if->core_global_regs->gintsts));
+#endif
+			halt_channel(_hcd, _hc, _qtd, DWC_OTG_HC_XFER_NO_HALT_STATUS, must_free);
+		}
+	}
+}
+
+/**
+ * Handles a host channel Channel Halted interrupt.
+ *
+ * In slave mode, this handler is called only when the driver specifically
+ * requests a halt. This occurs during handling other host channel interrupts
+ * (e.g. nak, xacterr, stall, nyet, etc.).
+ *
+ * In DMA mode, this is the interrupt that occurs when the core has finished
+ * processing a transfer on a channel. Other host channel interrupts (except
+ * ahberr) are disabled in DMA mode.
+ */
+static int32_t handle_hc_chhltd_intr(dwc_otg_hcd_t * _hcd,
+	dwc_hc_t * _hc, dwc_otg_hc_regs_t * _hc_regs, dwc_otg_qtd_t * _qtd, int *must_free)
+{
+	DWC_DEBUGPL(DBG_HCD, "--Host Channel %d Interrupt: "
+		     "Channel Halted--\n", _hc->hc_num);
+	if (_hcd->core_if->dma_enable) {
+		handle_hc_chhltd_intr_dma(_hcd, _hc, _hc_regs, _qtd, must_free);
+	} else {
+#ifdef CONFIG_DWC_DEBUG
+	    if (!halt_status_ok(_hcd, _hc, _hc_regs, _qtd, must_free)) {
+			return 1;
+		}
+#endif	/*  */
+	    release_channel(_hcd, _hc, _qtd, _hc->halt_status, must_free);
+	}
+	return 1;
+}
+
+/** Handles interrupt for a specific Host Channel */
+int32_t dwc_otg_hcd_handle_hc_n_intr(dwc_otg_hcd_t * _dwc_otg_hcd, uint32_t _num)
+{
+	int must_free = 0;
+	int retval = 0;
+	hcint_data_t hcint;
+	hcintmsk_data_t hcintmsk;
+	dwc_hc_t * hc;
+	dwc_otg_hc_regs_t * hc_regs;
+	dwc_otg_qtd_t * qtd;
+	DWC_DEBUGPL(DBG_HCDV, "--Host Channel Interrupt--, Channel %d\n",_num);
+	hc = _dwc_otg_hcd->hc_ptr_array[_num];
+	hc_regs = _dwc_otg_hcd->core_if->host_if->hc_regs[_num];
+	qtd = list_entry(hc->qh->qtd_list.next, dwc_otg_qtd_t, qtd_list_entry);
+	hcint.d32 = dwc_read_reg32(&hc_regs->hcint);
+	hcintmsk.d32 = dwc_read_reg32(&hc_regs->hcintmsk);
+	DWC_DEBUGPL(DBG_HCDV, " hcint 0x%08x, hcintmsk 0x%08x, hcint&hcintmsk 0x%08x\n",
+		     hcint.d32, hcintmsk.d32, (hcint.d32 & hcintmsk.d32));
+	hcint.d32 = hcint.d32 & hcintmsk.d32;
+	if (!_dwc_otg_hcd->core_if->dma_enable) {
+		if ((hcint.b.chhltd) && (hcint.d32 != 0x2)) {
+			hcint.b.chhltd = 0;
+		}
+	}
+	if (hcint.b.xfercomp) {
+		retval |= handle_hc_xfercomp_intr(_dwc_otg_hcd, hc, hc_regs, qtd, &must_free);
+	    /*
+	     * If NYET occurred at same time as Xfer Complete, the NYET is
+	     * handled by the Xfer Complete interrupt handler. Don't want
+	     * to call the NYET interrupt handler in this case.
+	     */
+	    hcint.b.nyet = 0;
+	}
+	if (hcint.b.chhltd) {
+		retval |= handle_hc_chhltd_intr(_dwc_otg_hcd, hc, hc_regs, qtd, &must_free);
+	}
+	if (hcint.b.ahberr) {
+		retval |= handle_hc_ahberr_intr(_dwc_otg_hcd, hc, hc_regs, qtd);
+	}
+	if (hcint.b.stall) {
+		retval |= handle_hc_stall_intr(_dwc_otg_hcd, hc, hc_regs, qtd, &must_free);
+	}
+	if (hcint.b.nak) {
+		retval |= handle_hc_nak_intr(_dwc_otg_hcd, hc, hc_regs, qtd, &must_free);
+	}
+	if (hcint.b.ack) {
+		retval |= handle_hc_ack_intr(_dwc_otg_hcd, hc, hc_regs, qtd, &must_free);
+	}
+	if (hcint.b.nyet) {
+		retval |= handle_hc_nyet_intr(_dwc_otg_hcd, hc, hc_regs, qtd, &must_free);
+	}
+	if (hcint.b.xacterr) {
+		retval |= handle_hc_xacterr_intr(_dwc_otg_hcd, hc, hc_regs, qtd, &must_free);
+	}
+	if (hcint.b.bblerr) {
+		retval |= handle_hc_babble_intr(_dwc_otg_hcd, hc, hc_regs, qtd, &must_free);
+	}
+	if (hcint.b.frmovrun) {
+		retval |= handle_hc_frmovrun_intr(_dwc_otg_hcd, hc, hc_regs, qtd, &must_free);
+	}
+	if (hcint.b.datatglerr) {
+		retval |= handle_hc_datatglerr_intr(_dwc_otg_hcd, hc, hc_regs, qtd, &must_free);
+	}
+	/*
+	 * Logic to free the qtd here, at the end of the hc intr
+	 * processing, if the handling of this interrupt determined
+	 * that it needs to be freed.
+	 */
+	if (must_free) {
+		/* Free the qtd here now that we are done using it. */
+		dwc_otg_hcd_qtd_free(qtd);
+	}
+	return retval;
+}
+
+#endif	/* DWC_DEVICE_ONLY */
diff -Naur a/drivers/usb/dwc_otg/dwc_otg_hcd_queue.c b/drivers/usb/dwc_otg/dwc_otg_hcd_queue.c
--- a/drivers/usb/dwc_otg/dwc_otg_hcd_queue.c	1970-01-01 00:00:00.000000000 +0000
+++ b/drivers/usb/dwc_otg/dwc_otg_hcd_queue.c	2016-01-31 16:10:52.000000000 +0000
@@ -0,0 +1,795 @@
+/* ==========================================================================
+ * $File: //dwh/usb_iip/dev/software/otg_ipmate/linux/drivers/dwc_otg_hcd_queue.c $
+ * $Revision: #4 $
+ * $Date: 2005/09/15 $
+ * $Change: 537387 $
+ *
+ * Synopsys HS OTG Linux Software Driver and documentation (hereinafter,
+ * "Software") is an Unsupported proprietary work of Synopsys, Inc. unless
+ * otherwise expressly agreed to in writing between Synopsys and you.
+ *
+ * The Software IS NOT an item of Licensed Software or Licensed Product under
+ * any End User Software License Agreement or Agreement for Licensed Product
+ * with Synopsys or any supplement thereto. You are permitted to use and
+ * redistribute this Software in source and binary forms, with or without
+ * modification, provided that redistributions of source code must retain this
+ * notice. You may not view, use, disclose, copy or distribute this file or
+ * any information contained herein except pursuant to this license grant from
+ * Synopsys. If you do not agree with this notice, including the disclaimer
+ * below, then you are not authorized to use the Software.
+ *
+ * THIS SOFTWARE IS BEING DISTRIBUTED BY SYNOPSYS SOLELY ON AN "AS IS" BASIS
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE HEREBY DISCLAIMED. IN NO EVENT SHALL SYNOPSYS BE LIABLE FOR ANY DIRECT,
+ * INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+ * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+ * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+ * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
+ * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
+ * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH
+ * DAMAGE.
+ * ========================================================================== */
+
+#ifndef CONFIG_DWC_DEVICE_ONLY
+
+/**
+ * @file
+ *
+ * This file contains the functions to manage Queue Heads and Queue
+ * Transfer Descriptors.
+ */
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/moduleparam.h>
+#include <linux/init.h>
+#include <linux/device.h>
+#include <linux/errno.h>
+#include <linux/list.h>
+#include <linux/interrupt.h>
+#include <linux/string.h>
+
+#include "dwc_otg_driver.h"
+#include "dwc_otg_hcd.h"
+#include "dwc_otg_regs.h"
+
+/**
+ * This function allocates and initializes a QH.
+ *
+ * @param _hcd The HCD state structure for the DWC OTG controller.
+ * @param[in] _urb Holds the information about the device/endpoint that we need
+ * to initialize the QH.
+ *
+ * @return Returns pointer to the newly allocated QH, or NULL on error. */
+dwc_otg_qh_t * dwc_otg_hcd_qh_create(dwc_otg_hcd_t * _hcd,
+					 struct urb * _urb)
+{
+	dwc_otg_qh_t * qh;
+
+	/* Allocate memory */
+	/** @todo add memflags argument */
+	qh = dwc_otg_hcd_qh_alloc();
+	if (qh == NULL) {
+		return NULL;
+	}
+	dwc_otg_hcd_qh_init(_hcd, qh, _urb);
+	return qh;
+}
+
+/** Free each QTD in the QH's QTD-list then free the QH.  QH should already be
+ * removed from a list.  QTD list should already be empty if called from URB
+ * Dequeue.
+ *
+ * @param[in] _qh The QH to free.
+ */
+void dwc_otg_hcd_qh_free(dwc_otg_qh_t * _qh)
+{
+	dwc_otg_qtd_t * qtd;
+	struct list_head *pos;
+	unsigned long flags;
+
+	/* Free each QTD in the QTD list */
+	local_irq_save(flags);
+	for (pos = _qh->qtd_list.next; pos != &_qh->qtd_list;
+	      pos = _qh->qtd_list.next) {
+		list_del(pos);
+		qtd = dwc_list_to_qtd(pos);
+		dwc_otg_hcd_qtd_free(qtd);
+	}
+	local_irq_restore(flags);
+	kfree(_qh);
+	return;
+}
+
+/** Initializes a QH structure.
+ *
+ * @param[in] _hcd The HCD state structure for the DWC OTG controller.
+ * @param[in] _qh The QH to init.
+ * @param[in] _urb Holds the information about the device/endpoint that we need
+ * to initialize the QH. */
+#define SCHEDULE_SLOP 10
+void dwc_otg_hcd_qh_init(dwc_otg_hcd_t * _hcd, dwc_otg_qh_t * _qh,
+			 struct urb *_urb)
+{
+	memset(_qh, 0, sizeof(dwc_otg_qh_t));
+
+	/* Initialize QH */
+	switch (usb_pipetype(_urb->pipe)) {
+	case PIPE_CONTROL:
+		_qh->ep_type = USB_ENDPOINT_XFER_CONTROL;
+		break;
+	case PIPE_BULK:
+		_qh->ep_type = USB_ENDPOINT_XFER_BULK;
+		break;
+	case PIPE_ISOCHRONOUS:
+		_qh->ep_type = USB_ENDPOINT_XFER_ISOC;
+		break;
+	case PIPE_INTERRUPT:
+		_qh->ep_type = USB_ENDPOINT_XFER_INT;
+		break;
+	}
+	_qh->ep_is_in = usb_pipein(_urb->pipe) ? 1 : 0;
+	_qh->data_toggle = DWC_OTG_HC_PID_DATA0;
+	_qh->maxp = usb_maxpacket(_urb->dev, _urb->pipe, !(usb_pipein(_urb->pipe)));
+	INIT_LIST_HEAD(&_qh->qtd_list);
+	INIT_LIST_HEAD(&_qh->qh_list_entry);
+	_qh->channel = NULL;
+
+	/* FS/LS Enpoint on HS Hub
+	 * NOT virtual root hub */
+	_qh->do_split = 0;
+	_qh->speed = _urb->dev->speed;
+
+	if (((_urb->dev->speed == USB_SPEED_LOW) ||
+		(_urb->dev->speed == USB_SPEED_FULL)) &&
+		(_urb->dev->tt) && (_urb->dev->tt->hub) && (_urb->dev->tt->hub->devnum != 1)) {
+		DWC_DEBUGPL(DBG_HCD, "QH init: EP %d: TT found at hub addr %d, for port %d\n",
+		     usb_pipeendpoint(_urb->pipe), _urb->dev->tt->hub->devnum, _urb->dev->ttport);
+		_qh->do_split = 1;
+	}
+	if (_qh->ep_type == USB_ENDPOINT_XFER_INT
+		|| _qh->ep_type == USB_ENDPOINT_XFER_ISOC) {
+
+		/* Compute scheduling parameters once and save them. */
+		hprt0_data_t hprt;
+
+		/** @todo Account for split transfers in the bus time. */
+		int bytecount = dwc_hb_mult(_qh->maxp) * dwc_max_packet(_qh->maxp);
+		_qh->usecs = NS_TO_US(usb_calc_bus_time(_urb->dev->speed,
+							usb_pipein(_urb->pipe),
+					(_qh->ep_type == USB_ENDPOINT_XFER_ISOC),bytecount));
+
+		/* Start in a slightly future (micro)frame. */
+		_qh->sched_frame = dwc_frame_num_inc(_hcd->frame_number, SCHEDULE_SLOP);
+		_qh->interval = _urb->interval;
+
+#if 0
+		    /* Increase interrupt polling rate for debugging. */
+		    if (_qh->ep_type == USB_ENDPOINT_XFER_INT) {
+			_qh->interval = 8;
+		}
+
+#endif	/*  */
+	    hprt.d32 = dwc_read_reg32(_hcd->core_if->host_if->hprt0);
+		if ((hprt.b.prtspd == DWC_HPRT0_PRTSPD_HIGH_SPEED) &&
+			((_urb->dev->speed == USB_SPEED_LOW) ||
+			(_urb->dev->speed == USB_SPEED_FULL))) {
+			_qh->interval *= 8;
+			_qh->sched_frame |= 0x7;
+			_qh->start_split_frame = _qh->sched_frame;
+		}
+	}
+	DWC_DEBUGPL(DBG_HCD, "DWC OTG HCD QH Initialized\n");
+	DWC_DEBUGPL(DBG_HCDV, "DWC OTG HCD QH  - qh = %p\n", _qh);
+	DWC_DEBUGPL(DBG_HCDV, "DWC OTG HCD QH  - Device Address = %d\n",
+		    _urb->dev->devnum);
+	DWC_DEBUGPL(DBG_HCDV, "DWC OTG HCD QH  - Endpoint %d, %s\n",
+		    usb_pipeendpoint(_urb->pipe),
+		    usb_pipein(_urb->pipe) == USB_DIR_IN ? "IN" : "OUT");
+	DWC_DEBUGPL(DBG_HCDV, "DWC OTG HCD QH  - Speed = %s\n", ( {
+			char *speed;
+			switch(_urb->dev->speed) {
+			case USB_SPEED_LOW:
+				speed = "low"; break;
+			case USB_SPEED_FULL:
+				speed = "full"; break;
+			case USB_SPEED_HIGH:
+				speed = "high"; break;
+			default:
+				speed = "?";
+				break;
+			};
+			speed;
+	} )) ;
+	DWC_DEBUGPL(DBG_HCDV, "DWC OTG HCD QH  - Type = %s\n", ( {
+			char *type;
+			switch (_qh->ep_type) {
+			case USB_ENDPOINT_XFER_ISOC:
+				type = "isochronous"; break;
+			case USB_ENDPOINT_XFER_INT:
+				type = "interrupt"; break;
+			case USB_ENDPOINT_XFER_CONTROL:
+				type = "control"; break;
+			case USB_ENDPOINT_XFER_BULK:
+				type = "bulk"; break;
+			default:
+				type = "?";break;
+			};
+			type;
+	} )) ;
+
+#ifdef CONFIG_DWC_DEBUG
+	if (_qh->ep_type == USB_ENDPOINT_XFER_INT) {
+		DWC_DEBUGPL(DBG_HCDV, "DWC OTG HCD QH - usecs = %d\n",
+			     _qh->usecs);
+		DWC_DEBUGPL(DBG_HCDV, "DWC OTG HCD QH - interval = %d\n",
+			     _qh->interval);
+	}
+
+#endif	/*  */
+	return;
+}
+
+/**
+ * Microframe scheduler
+ * track the total use in hcd->frame_usecs
+ * keep each qh use in qh->frame_usecs
+ * when surrendering the qh then donate the time back
+ */
+const unsigned short max_uframe_usecs[]={ 100, 100, 100, 100, 100, 100, 30, 0 };
+
+/*
+ * called from dwc_otg_hcd.c:dwc_otg_hcd_init
+ */
+int init_hcd_usecs(dwc_otg_hcd_t *_hcd)
+{
+	int i;
+	for (i=0; i<8; i++) {
+		_hcd->frame_usecs[i] = max_uframe_usecs[i];
+	}
+	return 0;
+}
+
+static int find_single_uframe(dwc_otg_hcd_t * _hcd, dwc_otg_qh_t * _qh)
+{
+	int i;
+	unsigned short utime;
+	int t_left;
+	int ret;
+	int done;
+
+	ret = -1;
+	utime = _qh->usecs;
+	t_left = utime;
+	i = 0;
+	done = 0;
+	while (done == 0) {
+		/* At the start _hcd->frame_usecs[i] = max_uframe_usecs[i]; */
+		if (utime <= _hcd->frame_usecs[i]) {
+			_hcd->frame_usecs[i] -= utime;
+			_qh->frame_usecs[i] += utime;
+			t_left -= utime;
+			ret = i;
+			done = 1;
+			return ret;
+		} else {
+			i++;
+			if (i == 8) {
+				done = 1;
+				ret = -1;
+			}
+		}
+	}
+	return ret;
+}
+
+/*
+ * use this for FS apps that can span multiple uframes
+ */
+static int find_multi_uframe(dwc_otg_hcd_t * _hcd, dwc_otg_qh_t * _qh)
+{
+	int i;
+	int j;
+	unsigned short utime;
+	int t_left;
+	int ret;
+	int done;
+	unsigned short xtime;
+
+	ret = -1;
+	utime = _qh->usecs;
+	t_left = utime;
+	i = 0;
+	done = 0;
+loop:
+	while (done == 0) {
+		if(_hcd->frame_usecs[i] <= 0) {
+			i++;
+			if (i == 8) {
+				done = 1;
+				ret = -1;
+			}
+			goto loop;
+		}
+
+		/*
+		 * we need n consequtive slots
+		 * so use j as a start slot j plus j+1 must be enough time (for now)
+		 */
+		xtime= _hcd->frame_usecs[i];
+		for (j = i+1 ; j < 8 ; j++ ) {
+			/*
+			 * if we add this frame remaining time to xtime we may
+			 * be OK, if not we need to test j for a complete frame
+			 */
+			if ((xtime+_hcd->frame_usecs[j]) < utime) {
+				if (_hcd->frame_usecs[j] < max_uframe_usecs[j]) {
+					j = 8;
+					ret = -1;
+					continue;
+				}
+			}
+			if (xtime >= utime) {
+				ret = i;
+				j = 8;	/* stop loop with a good value ret */
+				continue;
+			}
+			/* add the frame time to x time */
+			xtime += _hcd->frame_usecs[j];
+			/* we must have a fully available next frame or break */
+			if ((xtime < utime)
+			    && (_hcd->frame_usecs[j] == max_uframe_usecs[j])) {
+				ret = -1;
+				j = 8;	/* stop loop with a bad value ret */
+				continue;
+			}
+		}
+		if (ret >= 0) {
+			t_left = utime;
+			for (j = i; (t_left>0) && (j < 8); j++ ) {
+				t_left -= _hcd->frame_usecs[j];
+				if ( t_left <= 0 ) {
+					_qh->frame_usecs[j] += _hcd->frame_usecs[j] + t_left;
+					_hcd->frame_usecs[j]= -t_left;
+					ret = i;
+					done = 1;
+				} else {
+					_qh->frame_usecs[j] += _hcd->frame_usecs[j];
+					_hcd->frame_usecs[j] = 0;
+				}
+			}
+		} else {
+			i++;
+			if (i == 8) {
+				done = 1;
+				ret = -1;
+			}
+		}
+	}
+	return ret;
+}
+
+static int find_uframe(dwc_otg_hcd_t * _hcd, dwc_otg_qh_t * _qh)
+{
+	int ret;
+	ret = -1;
+
+	if (_qh->speed == USB_SPEED_HIGH) {
+		/* if this is a hs transaction we need a full frame */
+		ret = find_single_uframe(_hcd, _qh);
+	} else {
+		/* if this is a fs transaction we may need a sequence of frames */
+		ret = find_multi_uframe(_hcd, _qh);
+	}
+	return ret;
+}
+
+/**
+ * Checks that the max transfer size allowed in a host channel is large enough
+ * to handle the maximum data transfer in a single (micro)frame for a periodic
+ * transfer.
+ *
+ * @param _hcd The HCD state structure for the DWC OTG controller.
+ * @param _qh QH for a periodic endpoint.
+ *
+ * @return 0 if successful, negative error code otherwise.
+ */
+static int check_max_xfer_size(dwc_otg_hcd_t * _hcd, dwc_otg_qh_t * _qh)
+{
+	int status;
+	uint32_t max_xfer_size;
+	uint32_t max_channel_xfer_size;
+	status = 0;
+	max_xfer_size = dwc_max_packet(_qh->maxp) * dwc_hb_mult(_qh->maxp);
+	max_channel_xfer_size = _hcd->core_if->core_params->max_transfer_size;
+	if (max_xfer_size > max_channel_xfer_size) {
+		DWC_NOTICE("%s: Periodic xfer length %d > "
+			    "max xfer length for channel %d\n", __func__,
+			    max_xfer_size, max_channel_xfer_size);
+		status = -ENOSPC;
+	}
+	return status;
+}
+
+/**
+ * Schedules an interrupt or isochronous transfer in the periodic schedule.
+ *
+ * @param _hcd The HCD state structure for the DWC OTG controller.
+ * @param _qh QH for the periodic transfer. The QH should already contain the
+ * scheduling information.
+ *
+ * @return 0 if successful, negative error code otherwise.
+ */
+static int schedule_periodic(dwc_otg_hcd_t * _hcd, dwc_otg_qh_t * _qh)
+{
+	int status = 0;
+	int frame;
+	status = find_uframe(_hcd, _qh);
+	frame = -1;
+	if (status == 0) {
+		frame = 7;
+	} else {
+		if (status > 0 )
+			frame = status-1;
+	}
+	/* Set the new frame up */
+	if (frame > -1) {
+		_qh->sched_frame &= ~0x7;
+		_qh->sched_frame |= (frame & 7);
+	}
+
+	if (status != -1 )
+		status = 0;
+
+	if (status) {
+		DWC_NOTICE("%s: Insufficient periodic bandwidth for "
+			    "periodic transfer.\n", __func__);
+		return status;
+	}
+	status = check_max_xfer_size(_hcd, _qh);
+	if (status) {
+		DWC_NOTICE("%s: Channel max transfer size too small "
+			    "for periodic transfer.\n", __func__);
+		return status;
+	}
+
+	/* Always start in the inactive schedule. */
+	list_add_tail(&_qh->qh_list_entry, &_hcd->periodic_sched_inactive);
+
+	/* Update claimed usecs per (micro)frame. */
+	_hcd->periodic_usecs += _qh->usecs;
+
+	/* Update average periodic bandwidth claimed and # periodic reqs for usbfs. */
+	hcd_to_bus(dwc_otg_hcd_to_hcd(_hcd))->bandwidth_allocated +=
+						_qh->usecs / _qh->interval;
+
+	if (_qh->ep_type == USB_ENDPOINT_XFER_INT) {
+		hcd_to_bus(dwc_otg_hcd_to_hcd(_hcd))->bandwidth_int_reqs++;
+		DWC_DEBUGPL(DBG_HCD,
+			     "Scheduled intr: qh %p, usecs %d, period %d\n",
+			     _qh, _qh->usecs, _qh->interval);
+	} else {
+		hcd_to_bus(dwc_otg_hcd_to_hcd(_hcd))->bandwidth_isoc_reqs++;
+		DWC_DEBUGPL(DBG_HCD,
+			     "Scheduled isoc: qh %p, usecs %d, period %d\n",
+			     _qh, _qh->usecs, _qh->interval);
+	}
+	return status;
+}
+
+/**
+ * This function adds a QH to either the non periodic or periodic schedule if
+ * it is not already in the schedule. If the QH is already in the schedule, no
+ * action is taken.
+ *
+ * @return 0 if successful, negative error code otherwise.
+ */
+int dwc_otg_hcd_qh_add(dwc_otg_hcd_t * _hcd, dwc_otg_qh_t * _qh)
+{
+	unsigned long flags;
+	int status = 0;
+	local_irq_save(flags);
+	if (!list_empty(&_qh->qh_list_entry)) {
+		/* QH already in a schedule. */
+		goto done;
+	}
+
+	/* Add the new QH to the appropriate schedule */
+	if (dwc_qh_is_non_per(_qh)) {
+		/* Always start in the inactive schedule. */
+		list_add_tail(&_qh->qh_list_entry,
+				  &_hcd->non_periodic_sched_inactive);
+	} else {
+		status = schedule_periodic(_hcd, _qh);
+	}
+
+done:local_irq_restore(flags);
+	return status;
+}
+/**
+ * This function adds a QH to the non periodic deferred schedule.
+ *
+ * @return 0 if successful, negative error code otherwise.
+ */
+int dwc_otg_hcd_qh_add_deferred(dwc_otg_hcd_t * _hcd, dwc_otg_qh_t * _qh)
+{
+	unsigned long flags;
+	local_irq_save(flags);
+	if (!list_empty(&_qh->qh_list_entry)) {
+		/* QH already in a schedule. */
+		goto done;
+	}
+
+	/* Add the new QH to the non periodic deferred schedule */
+	if (dwc_qh_is_non_per(_qh)) {
+		list_add_tail(&_qh->qh_list_entry,
+			      &_hcd->non_periodic_sched_deferred);
+	}
+done:
+	local_irq_restore(flags);
+	return 0;
+}
+
+/**
+ * Removes an interrupt or isochronous transfer from the periodic schedule.
+ *
+ * @param _hcd The HCD state structure for the DWC OTG controller.
+ * @param _qh QH for the periodic transfer.
+ */
+static void deschedule_periodic(dwc_otg_hcd_t * _hcd, dwc_otg_qh_t * _qh)
+{
+	int i;
+	list_del_init(&_qh->qh_list_entry);
+
+	/* Update claimed usecs per (micro)frame. */
+	_hcd->periodic_usecs -= _qh->usecs;
+
+	for (i = 0; i < 8; i++) {
+		_hcd->frame_usecs[i] += _qh->frame_usecs[i];
+		_qh->frame_usecs[i] = 0;
+	}
+
+	/* Update average periodic bandwidth claimed and # periodic reqs for usbfs. */
+	hcd_to_bus(dwc_otg_hcd_to_hcd(_hcd))->bandwidth_allocated -=
+					_qh->usecs / _qh->interval;
+
+	if (_qh->ep_type == USB_ENDPOINT_XFER_INT) {
+		hcd_to_bus(dwc_otg_hcd_to_hcd(_hcd))->bandwidth_int_reqs--;
+		DWC_DEBUGPL(DBG_HCD,
+			     "Descheduled intr: qh %p, usecs %d, period %d\n",
+			     _qh, _qh->usecs, _qh->interval);
+	} else {
+		hcd_to_bus(dwc_otg_hcd_to_hcd(_hcd))->bandwidth_isoc_reqs--;
+		DWC_DEBUGPL(DBG_HCD,
+			     "Descheduled isoc: qh %p, usecs %d, period %d\n",
+			     _qh, _qh->usecs, _qh->interval);
+	}
+}
+
+/**
+ * Removes a QH from either the non-periodic or periodic schedule.  Memory is
+ * not freed.
+ *
+ * @param[in] _hcd The HCD state structure.
+ * @param[in] _qh QH to remove from schedule. */
+void dwc_otg_hcd_qh_remove(dwc_otg_hcd_t * _hcd, dwc_otg_qh_t * _qh)
+{
+	unsigned long flags;
+	local_irq_save(flags);
+	if (list_empty(&_qh->qh_list_entry)) {
+		/* QH is not in a schedule. */
+		goto done;
+	}
+	if (dwc_qh_is_non_per(_qh)) {
+		if (_hcd->non_periodic_qh_ptr == &_qh->qh_list_entry) {
+			_hcd->non_periodic_qh_ptr = _hcd->non_periodic_qh_ptr->next;
+		}
+		list_del_init(&_qh->qh_list_entry);
+	} else {
+		deschedule_periodic(_hcd, _qh);
+	}
+
+done:local_irq_restore(flags);
+}
+
+/**
+ * Defers a QH. For non-periodic QHs, removes the QH from the active
+ * non-periodic schedule. The QH is added to the deferred non-periodic
+ * schedule if any QTDs are still attached to the QH.
+ */
+int dwc_otg_hcd_qh_deferr(dwc_otg_hcd_t * _hcd, dwc_otg_qh_t * _qh, int delay)
+{
+        int deact = 1;
+	unsigned long flags;
+	local_irq_save(flags);
+	if (dwc_qh_is_non_per(_qh)) {
+	        _qh->sched_frame =
+		  dwc_frame_num_inc(_hcd->frame_number,
+				    delay);
+		_qh->channel = NULL;
+		_qh->qtd_in_process = NULL;
+		deact = 0;
+		dwc_otg_hcd_qh_remove(_hcd, _qh);
+		if (!list_empty(&_qh->qtd_list)) {
+			/* Add back to deferred non-periodic schedule. */
+			dwc_otg_hcd_qh_add_deferred(_hcd, _qh);
+		}
+	}
+	local_irq_restore(flags);
+	return deact;
+}
+/**
+ * Deactivates a QH. For non-periodic QHs, removes the QH from the active
+ * non-periodic schedule. The QH is added to the inactive non-periodic
+ * schedule if any QTDs are still attached to the QH.
+ *
+ * For periodic QHs, the QH is removed from the periodic queued schedule. If
+ * there are any QTDs still attached to the QH, the QH is added to either the
+ * periodic inactive schedule or the periodic ready schedule and its next
+ * scheduled frame is calculated. The QH is placed in the ready schedule if
+ * the scheduled frame has been reached already. Otherwise it's placed in the
+ * inactive schedule. If there are no QTDs attached to the QH, the QH is
+ * completely removed from the periodic schedule.
+ */
+void dwc_otg_hcd_qh_deactivate(dwc_otg_hcd_t * _hcd, dwc_otg_qh_t * _qh,
+			       int sched_next_periodic_split)
+{
+	unsigned long flags;
+	local_irq_save(flags);
+	if (dwc_qh_is_non_per(_qh)) {
+		dwc_otg_hcd_qh_remove(_hcd, _qh);
+		if (!list_empty(&_qh->qtd_list)) {
+			/* Add back to inactive non-periodic schedule. */
+			dwc_otg_hcd_qh_add(_hcd, _qh);
+		}
+	} else {
+		uint16_t frame_number =
+		    dwc_otg_hcd_get_frame_number(dwc_otg_hcd_to_hcd(_hcd));
+		if (_qh->do_split) {
+			/* Schedule the next continuing periodic split transfer */
+			if (sched_next_periodic_split) {
+				_qh->sched_frame = frame_number;
+				if (dwc_frame_num_le(frame_number,
+					dwc_frame_num_inc(_qh->start_split_frame,1))) {
+					/*
+					 * Allow one frame to elapse after start
+					 * split microframe before scheduling
+					 * complete split, but DONT if we are
+					 * doing the next start split in the
+					 * same frame for an ISOC out.
+					 */
+					if ((_qh->ep_type != USB_ENDPOINT_XFER_ISOC)
+						|| (_qh->ep_is_in != 0)) {
+						_qh->sched_frame = dwc_frame_num_inc(_qh->sched_frame,1);
+					}
+				}
+			} else {
+				_qh->sched_frame = dwc_frame_num_inc(_qh->start_split_frame,
+						      _qh->interval);
+				if (dwc_frame_num_le(_qh->sched_frame, frame_number)) {
+					_qh->sched_frame = frame_number;
+				}
+				_qh->sched_frame |= 0x7;
+				_qh->start_split_frame = _qh->sched_frame;
+			}
+		} else {
+			_qh->sched_frame =
+			    dwc_frame_num_inc(_qh->sched_frame, _qh->interval);
+			if (dwc_frame_num_le(_qh->sched_frame, frame_number)) {
+				_qh->sched_frame = frame_number;
+			}
+		}
+		if (list_empty(&_qh->qtd_list)) {
+			dwc_otg_hcd_qh_remove(_hcd, _qh);
+		} else {
+			/*
+			 * Remove from periodic_sched_queued and move to
+			 * appropriate queue.
+			 */
+			if (dwc_frame_num_le(_qh->sched_frame, frame_number)) {
+				list_move(&_qh->qh_list_entry,
+					   &_hcd->periodic_sched_ready);
+			} else {
+				list_move(&_qh->qh_list_entry,
+					   &_hcd->periodic_sched_inactive);
+			}
+		}
+	}
+	local_irq_restore(flags);
+}
+
+/**
+ * This function allocates and initializes a QTD.
+ *
+ * @param[in] _urb The URB to create a QTD from.  Each URB-QTD pair will end up
+ * pointing to each other so each pair should have a unique correlation.
+ *
+ * @return Returns pointer to the newly allocated QTD, or NULL on error. */
+dwc_otg_qtd_t * dwc_otg_hcd_qtd_create(struct urb *_urb)
+{
+	dwc_otg_qtd_t * qtd;
+	qtd = dwc_otg_hcd_qtd_alloc();
+	if (qtd == NULL) {
+		return NULL;
+	}
+	dwc_otg_hcd_qtd_init(qtd, _urb);
+	return qtd;
+}
+
+/**
+ * Initializes a QTD structure.
+ *
+ * @param[in] _qtd The QTD to initialize.
+ * @param[in] _urb The URB to use for initialization.  */
+void dwc_otg_hcd_qtd_init(dwc_otg_qtd_t * _qtd, struct urb *_urb)
+{
+	memset(_qtd, 0, sizeof(dwc_otg_qtd_t));
+	_qtd->urb = _urb;
+	if (usb_pipecontrol(_urb->pipe)) {
+		/*
+		 * The only time the QTD data toggle is used is on the data
+		 * phase of control transfers. This phase always starts with
+		 * DATA1.
+		 */
+		_qtd->data_toggle = DWC_OTG_HC_PID_DATA1;
+		_qtd->control_phase = DWC_OTG_CONTROL_SETUP;
+	}
+
+	/* start split */
+	_qtd->complete_split = 0;
+	_qtd->isoc_split_pos = DWC_HCSPLIT_XACTPOS_ALL;
+	_qtd->isoc_split_offset = 0;
+
+	/* Store the qtd ptr in the urb to reference what QTD. */
+	_urb->hcpriv = _qtd;
+	return;
+}
+
+/**
+ * This function adds a QTD to the QTD-list of a QH.  It will find the correct
+ * QH to place the QTD into.  If it does not find a QH, then it will create a
+ * new QH. If the QH to which the QTD is added is not currently scheduled, it
+ * is placed into the proper schedule based on its EP type.
+ *
+ * @param[in] _qtd The QTD to add
+ * @param[in] _dwc_otg_hcd The DWC HCD structure
+ *
+ * @return 0 if successful, negative error code otherwise.
+ */
+int dwc_otg_hcd_qtd_add(dwc_otg_qtd_t * _qtd,  dwc_otg_hcd_t * _dwc_otg_hcd)
+{
+	struct usb_host_endpoint *ep;
+	dwc_otg_qh_t * qh;
+	unsigned long flags;
+	int retval = 0;
+	struct urb *urb = _qtd->urb;
+	local_irq_save(flags);
+
+	/*
+	 * Get the QH which holds the QTD-list to insert to. Create QH if it
+	 * doesn't exist.
+	 */
+	ep = dwc_urb_to_endpoint(urb);
+	qh = (dwc_otg_qh_t *) ep->hcpriv;
+	if (qh == NULL) {
+		qh = dwc_otg_hcd_qh_create(_dwc_otg_hcd, urb);
+		if (qh == NULL) {
+			retval = -1;
+			goto done;
+		}
+		ep->hcpriv = qh;
+	}
+	_qtd->qtd_qh_ptr = qh;
+	retval = dwc_otg_hcd_qh_add(_dwc_otg_hcd, qh);
+	if (retval == 0) {
+		list_add_tail(&_qtd->qtd_list_entry, &qh->qtd_list);
+	}
+
+done:
+	local_irq_restore(flags);
+
+	return retval;
+}
+
+
+#endif	/* DWC_DEVICE_ONLY */
diff -Naur a/drivers/usb/dwc_otg/dwc_otg_pcd.c b/drivers/usb/dwc_otg/dwc_otg_pcd.c
--- a/drivers/usb/dwc_otg/dwc_otg_pcd.c	1970-01-01 00:00:00.000000000 +0000
+++ b/drivers/usb/dwc_otg/dwc_otg_pcd.c	2017-06-21 20:00:52.894436778 +0000
@@ -0,0 +1,1229 @@
+ /* ==========================================================================
+  * $File: //dwh/usb_iip/dev/software/otg_ipmate/linux/drivers/dwc_otg_pcd.c $
+  * $Revision: #18 $
+  * $Date: 2007/02/07 $
+  * $Change: 791271 $
+  *
+  * Synopsys HS OTG Linux Software Driver and documentation (hereinafter,
+  * "Software") is an Unsupported proprietary work of Synopsys, Inc. unless
+  * otherwise expressly agreed to in writing between Synopsys and you.
+  *
+  * The Software IS NOT an item of Licensed Software or Licensed Product under
+  * any End User Software License Agreement or Agreement for Licensed Product
+  * with Synopsys or any supplement thereto. You are permitted to use and
+  * redistribute this Software in source and binary forms, with or without
+  * modification, provided that redistributions of source code must retain this
+  * notice. You may not view, use, disclose, copy or distribute this file or
+  * any information contained herein except pursuant to this license grant from
+  * Synopsys. If you do not agree with this notice, including the disclaimer
+  * below, then you are not authorized to use the Software.
+  *
+  * THIS SOFTWARE IS BEING DISTRIBUTED BY SYNOPSYS SOLELY ON AN "AS IS" BASIS
+  * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+  * ARE HEREBY DISCLAIMED. IN NO EVENT SHALL SYNOPSYS BE LIABLE FOR ANY DIRECT,
+  * INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+  * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
+  * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
+  * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH
+  * DAMAGE.
+  * ========================================================================== */
+
+#ifndef CONFIG_DWC_HOST_ONLY
+
+/** @file
+ * This file implements the Peripheral Controller Driver.
+ *
+ * The Peripheral Controller Driver (PCD) is responsible for
+ * translating requests from the Function Driver into the appropriate
+ * actions on the DWC_otg controller. It isolates the Function Driver
+ * from the specifics of the controller by providing an API to the
+ * Function Driver.
+ *
+ * The Peripheral Controller Driver for Linux will implement the
+ * Gadget API, so that the existing Gadget drivers can be used.
+ * (Gadget Driver is the Linux terminology for a Function Driver.)
+ *
+ * The Linux Gadget API is defined in the header file
+ * <code><linux/usb/gadget.h></code>.  The USB EP operations API is
+ * defined in the structure <code>usb_ep_ops</code> and the USB
+ * Controller API is defined in the structure
+ * <code>usb_gadget_ops</code>.
+ *
+ * An important function of the PCD is managing interrupts generated
+ * by the DWC_otg controller. The implementation of the DWC_otg device
+ * mode interrupt service routines is in dwc_otg_pcd_intr.c.
+ *
+ * @todo Add Device Mode test modes (Test J mode, Test K mode, etc).
+ * @todo Does it work when the request size is greater than DEPTSIZ
+ * transfer size
+ *
+ */
+
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/moduleparam.h>
+#include <linux/init.h>
+#include <linux/device.h>
+#include <linux/errno.h>
+#include <linux/list.h>
+#include <linux/interrupt.h>
+#include <linux/string.h>
+#include <linux/dma-mapping.h>
+
+#include <linux/usb/ch9.h>
+#include <linux/usb/gadget.h>
+
+#include "dwc_otg_driver.h"
+#include "dwc_otg_pcd.h"
+
+/* Static PCD pointer for use in usb_gadget_register_driver and
+ * usb_gadget_unregister_driver.  Initialized in dwc_otg_pcd_init.*/
+static dwc_otg_pcd_t *s_pcd = 0;
+
+/* Display the contents of the buffer */
+extern void dump_msg(const u8 * buf, unsigned int length);
+
+/* This function completes a request.  It call's the request call back. */
+void request_done(dwc_otg_pcd_ep_t * _ep, dwc_otg_pcd_request_t * _req, int _status) {
+	unsigned stopped = _ep->stopped;
+	DWC_DEBUGPL(DBG_PCDV, "%s(%p)\n", __func__, _ep);
+	if (_req->mapped) {
+		dma_unmap_single(_ep->pcd->gadget.dev.parent,	_req->req.dma, _req->req.length,
+			_ep->dwc_ep.is_in ? DMA_TO_DEVICE : DMA_FROM_DEVICE);
+		_req->req.dma = DMA_ADDR_INVALID;
+		_req->mapped = 0;
+	} else
+		dma_sync_single_for_cpu(_ep->pcd->gadget.dev.parent, _req->req.dma, _req->req.length,
+			_ep->dwc_ep.is_in ? DMA_TO_DEVICE : DMA_FROM_DEVICE);
+
+	list_del_init(&_req->queue);
+	if (_req->req.status == -EINPROGRESS) _req->req.status = _status;
+	else _status = _req->req.status;
+
+	/* don't modify queue heads during completion callback */
+	_ep->stopped = 1;
+	SPIN_UNLOCK(&_ep->pcd->lock);
+	_req->req.complete(&_ep->ep, &_req->req);
+	SPIN_LOCK(&_ep->pcd->lock);
+	if (_ep->pcd->request_pending > 0) {
+		--_ep->pcd->request_pending;
+	}
+	_ep->stopped = stopped;
+
+#ifdef CONFIG_405EZ
+	/*
+	 * Added-sr: 2007-07-26
+	 *
+	 * Finally, when the current request is done, mark this endpoint
+	 * as not active, so that new requests can be processed.
+	 */
+	_ep->dwc_ep.active = 0;
+#endif
+}
+
+/**
+ * This function terminates all the requsts in the EP request queue.
+ */
+void request_nuke(dwc_otg_pcd_ep_t * _ep)
+{
+	dwc_otg_pcd_request_t * req;
+	_ep->stopped = 1;
+	/* called with irqs blocked?? */
+	while (!list_empty(&_ep->queue)) {
+		req = list_entry(_ep->queue.next, dwc_otg_pcd_request_t, queue);
+		request_done(_ep, req, -ESHUTDOWN);
+	}
+}
+
+/* USB Endpoint Operations */
+/*
+ * The following sections briefly describe the behavior of the Gadget
+ * API endpoint operations implemented in the DWC_otg driver
+ * software. Detailed descriptions of the generic behavior of each of
+ * these functions can be found in the Linux header file
+ * include/linux/usb_gadget.h.
+ *
+ * The Gadget API provides wrapper functions for each of the function
+ * pointers defined in usb_ep_ops. The Gadget Driver calls the wrapper
+ * function, which then calls the underlying PCD function. The
+ * following sections are named according to the wrapper
+ * functions. Within each section, the corresponding DWC_otg PCD
+ * function name is specified.
+ *
+ */
+
+/**
+ * This function assigns periodic Tx FIFO to an periodic EP
+ * in shared Tx FIFO mode
+ */
+static uint32_t assign_perio_tx_fifo(dwc_otg_core_if_t * core_if)
+{
+	uint32_t PerTxMsk = 1;
+	int i;
+	for (i = 0; i < core_if->hwcfg4.b.num_dev_perio_in_ep; ++i) {
+		if ((PerTxMsk & core_if->p_tx_msk) == 0) {
+			core_if->p_tx_msk |= PerTxMsk;
+			return i + 1;
+		}
+		PerTxMsk <<= 1;
+	}
+	return 0;
+}
+
+/**
+ * This function releases periodic Tx FIFO
+ * in shared Tx FIFO mode
+ */
+static void release_perio_tx_fifo(dwc_otg_core_if_t * core_if, uint32_t fifo_num) {
+	core_if->p_tx_msk = (core_if->p_tx_msk & (1 << (fifo_num - 1))) ^ core_if->p_tx_msk;
+}
+
+/* This function assigns periodic Tx FIFO to an periodic EP in shared Tx FIFO mode */
+static uint32_t assign_tx_fifo(dwc_otg_core_if_t * core_if) {
+	uint32_t TxMsk = 1;
+	int i;
+	for (i = 0; i < core_if->hwcfg4.b.num_in_eps; ++i) {
+		if ((TxMsk & core_if->tx_msk) == 0) {
+			core_if->tx_msk |= TxMsk;
+			return i + 1;
+		}
+		TxMsk <<= 1;
+	}
+	return 0;
+}
+
+/* This function releases periodic Tx FIFO in shared Tx FIFO mode */
+static void release_tx_fifo(dwc_otg_core_if_t * core_if, uint32_t fifo_num)
+{
+	core_if->tx_msk = (core_if->tx_msk & (1 << (fifo_num - 1))) ^ core_if->tx_msk;
+}
+
+/* This function is called by the Gadget Driver for each EP to be
+ * configured for the current configuration (SET_CONFIGURATION).
+ * This function initializes the dwc_otg_ep_t data structure, and then
+ * calls dwc_otg_ep_activate. */
+static int dwc_otg_pcd_ep_enable(struct usb_ep *_ep, const struct usb_endpoint_descriptor *_desc) {
+	dwc_otg_pcd_ep_t * ep = 0;
+	dwc_otg_pcd_t * pcd = 0;
+	unsigned long flags;
+	DWC_DEBUGPL(DBG_PCDV, "%s(%p,%p)\n", __func__, _ep, _desc);
+	ep = container_of(_ep, dwc_otg_pcd_ep_t, ep);
+	if (!_ep || !_desc || ep->desc || _desc->bDescriptorType != USB_DT_ENDPOINT) {
+		DWC_WARN("%s, bad ep or descriptor\n", __func__);
+		return -EINVAL;
+	}
+	if (ep == &ep->pcd->ep0) {
+		DWC_WARN("%s, bad ep(0)\n", __func__);
+		return -EINVAL;
+	}
+
+	/* Check FIFO size? */
+	if (!_desc->wMaxPacketSize) {
+		DWC_WARN("%s, bad %s maxpacket\n", __func__, _ep->name);
+		return -ERANGE;
+	}
+	pcd = ep->pcd;
+	if (!pcd->driver || pcd->gadget.speed == USB_SPEED_UNKNOWN) {
+		DWC_WARN("%s, bogus device state\n", __func__);
+		return -ESHUTDOWN;
+	}
+	SPIN_LOCK_IRQSAVE(&pcd->lock, flags);
+	ep->desc = _desc;
+	ep->ep.maxpacket = le16_to_cpu(_desc->wMaxPacketSize);
+
+	/* Activate the EP */
+	ep->stopped = 0;
+	ep->dwc_ep.is_in = (USB_DIR_IN & _desc->bEndpointAddress) != 0;
+	ep->dwc_ep.maxpacket = ep->ep.maxpacket;
+	ep->dwc_ep.type = _desc->bmAttributes & USB_ENDPOINT_XFERTYPE_MASK;
+	if (ep->dwc_ep.is_in) {
+		if (!pcd->otg_dev->core_if->en_multiple_tx_fifo) {
+			ep->dwc_ep.tx_fifo_num = 0;
+			if ((_desc->bmAttributes & USB_ENDPOINT_XFERTYPE_MASK) == USB_ENDPOINT_XFER_ISOC)
+				/* if ISOC EP then assign a Periodic Tx FIFO. */
+				ep->dwc_ep.tx_fifo_num = assign_perio_tx_fifo(pcd->otg_dev->core_if);
+		} else /* if Dedicated FIFOs mode is on then assign a Tx FIFO. */
+			ep->dwc_ep.tx_fifo_num = assign_tx_fifo(pcd->otg_dev->core_if);
+	}
+
+	/* Set initial data PID. */
+	if ((_desc->bmAttributes & USB_ENDPOINT_XFERTYPE_MASK) ==	USB_ENDPOINT_XFER_BULK)
+		ep->dwc_ep.data_pid_start = 0;
+	DWC_DEBUGPL(DBG_PCD, "Activate %s-%s: type=%d, mps=%d desc=%p\n", ep->ep.name, (ep->dwc_ep.is_in ? "IN" : "OUT"),
+		      ep->dwc_ep.type, ep->dwc_ep.maxpacket, ep->desc);
+	dwc_otg_ep_activate(GET_CORE_IF(pcd), &ep->dwc_ep);
+	SPIN_UNLOCK_IRQRESTORE(&pcd->lock, flags);
+	return 0;
+}
+
+
+/**
+ * This function is called when an EP is disabled due to disconnect or
+ * change in configuration. Any pending requests will terminate with a
+ * status of -ESHUTDOWN.
+ *
+ * This function modifies the dwc_otg_ep_t data structure for this EP,
+ * and then calls dwc_otg_ep_deactivate.
+ */
+static int dwc_otg_pcd_ep_disable(struct usb_ep *_ep) {
+	dwc_otg_pcd_ep_t * ep;
+	unsigned long flags;
+	DWC_DEBUGPL(DBG_PCDV, "%s(%p)\n", __func__, _ep);
+	ep = container_of(_ep, dwc_otg_pcd_ep_t, ep);
+	if (!_ep || !ep->desc) {
+		DWC_DEBUGPL(DBG_PCD, "%s, %s not enabled\n", __func__, _ep ? ep->ep.name : NULL);
+		return -EINVAL;
+	}
+	SPIN_LOCK_IRQSAVE(&ep->pcd->lock, flags);
+	request_nuke(ep);
+	dwc_otg_ep_deactivate(GET_CORE_IF(ep->pcd), &ep->dwc_ep);
+	ep->desc = 0;
+	ep->stopped = 1;
+	if (ep->dwc_ep.is_in) {
+		release_perio_tx_fifo(GET_CORE_IF(ep->pcd),ep->dwc_ep.tx_fifo_num);
+		release_tx_fifo(GET_CORE_IF(ep->pcd), ep->dwc_ep.tx_fifo_num);
+	}
+	SPIN_UNLOCK_IRQRESTORE(&ep->pcd->lock, flags);
+	DWC_DEBUGPL(DBG_PCD, "%s disabled\n", _ep->name);
+	return 0;
+}
+
+
+/**
+ * This function allocates a request object to use with the specified
+ * endpoint.
+ *
+ * @param _ep The endpoint to be used with with the request
+ * @param _gfp_flags the GFP_* flags to use.
+ */
+static struct usb_request *dwc_otg_pcd_alloc_request(struct usb_ep *_ep, gfp_t _gfp_flags)
+{
+	dwc_otg_pcd_request_t * req;
+	DWC_DEBUGPL(DBG_PCDV, "%s(%p,%d)\n", __func__, _ep, _gfp_flags);
+	if (0 == _ep) {
+		DWC_WARN("%s() %s\n", __func__, "Invalid EP!\n");
+		return 0;
+	}
+	req = kmalloc(sizeof(dwc_otg_pcd_request_t), _gfp_flags);
+	if (0 == req) {
+		DWC_WARN("%s() %s\n", __func__,"request allocation failed!\n");
+		return 0;
+	}
+	memset(req, 0, sizeof(dwc_otg_pcd_request_t));
+	req->req.dma = DMA_ADDR_INVALID;
+	INIT_LIST_HEAD(&req->queue);
+	return &req->req;
+}
+
+
+/* This function frees a request object.
+ * @param _ep The endpoint associated with the request
+ * @param _req The request being freed */
+static void dwc_otg_pcd_free_request(struct usb_ep *_ep, struct usb_request *_req) {
+	dwc_otg_pcd_request_t * req;
+	DWC_DEBUGPL(DBG_PCDV, "%s(%p,%p)\n", __func__, _ep, _req);
+	if (0 == _ep || 0 == _req) {
+		DWC_WARN("%s() %s\n", __func__,"Invalid ep or req argument!\n");
+		return;
+	}
+	req = container_of(_req, dwc_otg_pcd_request_t, req);
+	kfree(req);
+}
+
+
+/**
+ * This function is used to submit an I/O Request to an EP.
+ *
+ *	- When the request completes the request's completion callback
+ *	  is called to return the request to the driver.
+ *	- An EP, except control EPs, may have multiple requests
+ *	  pending.
+ *	- Once submitted the request cannot be examined or modified.
+ *	- Each request is turned into one or more packets.
+ *	- A BULK EP can queue any amount of data; the transfer is
+ *	  packetized.
+ *	- Zero length Packets are specified with the request 'zero'
+ *	  flag.
+ */
+static int dwc_otg_pcd_ep_queue(struct usb_ep *_ep, struct usb_request *_req, gfp_t _gfp_flags) {
+	int prevented = 0;
+	dwc_otg_pcd_request_t * req;
+	dwc_otg_pcd_ep_t * ep;
+	dwc_otg_pcd_t * pcd;
+	unsigned long flags = 0;
+
+	DWC_DEBUGPL(DBG_PCDV, "%s(%p,%p,%d)\n", __func__, _ep, _req, _gfp_flags);
+	req = container_of(_req, dwc_otg_pcd_request_t, req);
+	if (!_req || !_req->complete || !_req->buf || !list_empty(&req->queue)) {
+		DWC_WARN("%s, bad params\n", __func__);
+		return -EINVAL;
+	}
+	ep = container_of(_ep, dwc_otg_pcd_ep_t, ep);
+	if (!_ep || (!ep->desc && ep->dwc_ep.num != 0)) {
+		DWC_WARN("%s, bad ep\n", __func__);
+		return -EINVAL;
+	}
+	pcd = ep->pcd;
+	if (!pcd->driver || pcd->gadget.speed == USB_SPEED_UNKNOWN) {
+		DWC_DEBUGPL(DBG_PCDV, "gadget.speed=%d\n", pcd->gadget.speed);
+		DWC_WARN("%s, bogus device state\n", __func__);
+		return -ESHUTDOWN;
+	}
+	DWC_DEBUGPL(DBG_PCD, "%s queue req %p, len %d buf %p\n", _ep->name, _req, _req->length, _req->buf);
+	if (!GET_CORE_IF(pcd)->core_params->opt) {
+		if (ep->dwc_ep.num != 0) {
+			DWC_ERROR("%s queue req %p, len %d buf %p\n", _ep->name, _req, _req->length, _req->buf);
+		}
+	}
+	SPIN_LOCK_IRQSAVE(&ep->pcd->lock, flags);
+
+#if defined(CONFIG_DWC_DEBUG) & defined(VERBOSE)
+    dump_msg(_req->buf, _req->length);
+
+#endif	/*  */
+    _req->status = -EINPROGRESS;
+	_req->actual = 0;
+
+	/* For EP0 IN without premature status, zlp is required? */
+	if (ep->dwc_ep.num == 0 && ep->dwc_ep.is_in) {
+		DWC_DEBUGPL(DBG_PCDV, "%s-OUT ZLP\n", _ep->name);
+	    //_req->zero = 1;
+	}
+
+	/* map virtual address to hardware */
+	if (_req->dma == DMA_ADDR_INVALID) {
+		_req->dma = dma_map_single(ep->pcd->gadget.dev.parent, _req->buf, _req->length, ep->dwc_ep.is_in ? DMA_TO_DEVICE:DMA_FROM_DEVICE);
+		req->mapped = 1;
+	} else {
+		dma_sync_single_for_device(ep->pcd->gadget.dev.parent, _req->dma, _req->length, ep->dwc_ep.is_in ? DMA_TO_DEVICE:DMA_FROM_DEVICE);
+		req->mapped = 0;
+	}
+
+	/* Start the transfer */
+	if (list_empty(&ep->queue) && !ep->stopped) {
+		/* EP0 Transfer? */
+		if (ep->dwc_ep.num == 0) {
+			switch (pcd->ep0state) {
+			case EP0_IN_DATA_PHASE:
+				DWC_DEBUGPL(DBG_PCD, "%s ep0: EP0_IN_DATA_PHASE\n", __func__);
+				break;
+			case EP0_OUT_DATA_PHASE:
+				DWC_DEBUGPL(DBG_PCD, "%s ep0: EP0_OUT_DATA_PHASE\n", __func__);
+				if (pcd->request_config) {
+					/* Complete STATUS PHASE */
+					ep->dwc_ep.is_in = 1;
+					pcd->ep0state = EP0_STATUS;
+				}
+				break;
+			default:
+				DWC_DEBUGPL(DBG_ANY, "ep0: odd state %d\n", pcd->ep0state);
+				SPIN_UNLOCK_IRQRESTORE(&pcd->lock, flags);
+				return -EL2HLT;
+			}
+			ep->dwc_ep.dma_addr = _req->dma;
+			ep->dwc_ep.start_xfer_buff = _req->buf;
+			ep->dwc_ep.xfer_buff = _req->buf;
+			ep->dwc_ep.xfer_len = _req->length;
+			ep->dwc_ep.xfer_count = 0;
+			ep->dwc_ep.sent_zlp = 0;
+			ep->dwc_ep.total_len = ep->dwc_ep.xfer_len;
+			dwc_otg_ep0_start_transfer(GET_CORE_IF(pcd), &ep->dwc_ep);
+		} else {
+			/* Setup and start the Transfer */
+			ep->dwc_ep.dma_addr = _req->dma;
+			ep->dwc_ep.start_xfer_buff = _req->buf;
+			ep->dwc_ep.xfer_buff = _req->buf;
+			ep->dwc_ep.xfer_len = _req->length;
+			ep->dwc_ep.xfer_count = 0;
+			ep->dwc_ep.sent_zlp = 0;
+			ep->dwc_ep.total_len = ep->dwc_ep.xfer_len; dwc_otg_ep_start_transfer(GET_CORE_IF(pcd), &ep->dwc_ep);
+		}
+	}
+	if ((req != 0) || prevented) {
+		++pcd->request_pending;
+		list_add_tail(&req->queue, &ep->queue);
+		if (ep->dwc_ep.is_in && ep->stopped && !(GET_CORE_IF(pcd)->dma_enable)) {
+			/** @todo NGS Create a function for this. */
+			diepmsk_data_t diepmsk = {.d32 = 0};
+			diepmsk.b.intktxfemp = 1;
+			dwc_modify_reg32(&GET_CORE_IF(pcd)->dev_if->dev_global_regs->diepmsk, 0, diepmsk.d32);
+		}
+	}
+	SPIN_UNLOCK_IRQRESTORE(&pcd->lock, flags);
+	return 0;
+}
+
+/* This function cancels an I/O request from an EP.*/
+static int dwc_otg_pcd_ep_dequeue(struct usb_ep *_ep, struct usb_request *_req) {
+	dwc_otg_pcd_request_t * req;
+	dwc_otg_pcd_ep_t * ep;
+	dwc_otg_pcd_t * pcd;
+	unsigned long flags;
+	DWC_DEBUGPL(DBG_PCDV, "%s(%p,%p)\n", __func__, _ep, _req);
+	ep = container_of(_ep, dwc_otg_pcd_ep_t, ep);
+	if (!_ep || !_req || (!ep->desc && ep->dwc_ep.num != 0)) {
+		DWC_WARN("%s, bad argument\n", __func__);
+		return -EINVAL;
+	}
+	pcd = ep->pcd;
+	if (!pcd->driver || pcd->gadget.speed == USB_SPEED_UNKNOWN) {
+		DWC_WARN("%s, bogus device state\n", __func__);
+		return -ESHUTDOWN;
+	}
+	SPIN_LOCK_IRQSAVE(&pcd->lock, flags);
+	DWC_DEBUGPL(DBG_PCDV, "%s %s %s %p\n", __func__, _ep->name, ep->dwc_ep.is_in ? "IN" : "OUT", _req);
+
+	/* make sure it's actually queued on this endpoint */
+	list_for_each_entry(req, &ep->queue, queue) {
+		if (&req->req == _req) break;
+	}
+	if (&req->req != _req) {
+		SPIN_UNLOCK_IRQRESTORE(&pcd->lock, flags);
+		return -EINVAL;
+	}
+	if (!list_empty(&req->queue)) {
+		request_done(ep, req, -ECONNRESET);
+	} else req = 0;
+	SPIN_UNLOCK_IRQRESTORE(&pcd->lock, flags);
+	return req ? 0 : -EOPNOTSUPP;
+}
+
+/**
+ * usb_ep_set_halt stalls an endpoint.
+ *
+ * usb_ep_clear_halt clears an endpoint halt and resets its data
+ * toggle.
+ *
+ * Both of these functions are implemented with the same underlying
+ * function. The behavior depends on the value argument.
+ *
+ * @param[in] _ep the Endpoint to halt or clear halt.
+ * @param[in] _value
+ *	- 0 means clear_halt.
+ *	- 1 means set_halt,
+ *	- 2 means clear stall lock flag.
+ *	- 3 means set  stall lock flag.
+ */
+static int dwc_otg_pcd_ep_set_halt(struct usb_ep *_ep, int _value) {
+	int retval = 0;
+	unsigned long flags;
+	dwc_otg_pcd_ep_t * ep = 0;
+	DWC_DEBUGPL(DBG_PCD, "HALT %s %d\n", _ep->name, _value);
+	ep = container_of(_ep, dwc_otg_pcd_ep_t, ep);
+	if (!_ep || (!ep->desc && ep != &ep->pcd->ep0) || ep->desc->bmAttributes == USB_ENDPOINT_XFER_ISOC) {
+		DWC_WARN("%s, bad ep\n", __func__);
+		return -EINVAL;
+	}
+	SPIN_LOCK_IRQSAVE(&ep->pcd->lock, flags);
+	if (ep->dwc_ep.is_in && !list_empty(&ep->queue)) {
+		DWC_WARN("%s() %s XFer In process\n", __func__, _ep->name);
+		retval = -EAGAIN;
+	} else if (_value == 0) dwc_otg_ep_clear_stall(ep->pcd->otg_dev->core_if,&ep->dwc_ep);
+	else if (_value == 1) {
+		if (ep->dwc_ep.num == 0) ep->pcd->ep0state = EP0_STALL;
+		ep->stopped = 1;
+		dwc_otg_ep_set_stall(ep->pcd->otg_dev->core_if, &ep->dwc_ep);
+	} else if (_value == 2) ep->dwc_ep.stall_clear_flag = 0;
+	else if (_value == 3) 	ep->dwc_ep.stall_clear_flag = 1;
+	SPIN_UNLOCK_IRQRESTORE(&ep->pcd->lock, flags);
+	return retval;
+}
+
+static struct usb_ep_ops dwc_otg_pcd_ep_ops = {
+	.enable = dwc_otg_pcd_ep_enable,
+	.disable = dwc_otg_pcd_ep_disable,
+	.alloc_request = dwc_otg_pcd_alloc_request,
+	.free_request = dwc_otg_pcd_free_request,
+	.queue = dwc_otg_pcd_ep_queue,
+	.dequeue = dwc_otg_pcd_ep_dequeue,
+	.set_halt = dwc_otg_pcd_ep_set_halt,
+	.fifo_status = 0,
+	.fifo_flush = 0,
+};
+
+/*	Gadget Operations */
+/**
+ * The following gadget operations will be implemented in the DWC_otg
+ * PCD. Functions in the API that are not described below are not
+ * implemented.
+ *
+ * The Gadget API provides wrapper functions for each of the function
+ * pointers defined in usb_gadget_ops. The Gadget Driver calls the
+ * wrapper function, which then calls the underlying PCD function. The
+ * following sections are named according to the wrapper functions
+ * (except for ioctl, which doesn't have a wrapper function). Within
+ * each section, the corresponding DWC_otg PCD function name is
+ * specified.
+ *
+ */
+
+/**
+ *Gets the USB Frame number of the last SOF.
+ */
+static int dwc_otg_pcd_get_frame(struct usb_gadget *_gadget) {
+	dwc_otg_pcd_t * pcd;
+	DWC_DEBUGPL(DBG_PCDV, "%s(%p)\n", __func__, _gadget);
+	if (_gadget == 0) {
+		return -ENODEV;
+	} else {
+		pcd = container_of(_gadget, dwc_otg_pcd_t, gadget);
+		dwc_otg_get_frame_number(GET_CORE_IF(pcd));
+	}
+	return 0;
+}
+void dwc_otg_pcd_initiate_srp(dwc_otg_pcd_t * _pcd)
+{
+	uint32_t * addr = (uint32_t *) &(GET_CORE_IF(_pcd)->core_global_regs->gotgctl);
+	gotgctl_data_t mem;
+	gotgctl_data_t val;
+	val.d32 = dwc_read_reg32(addr);
+	if (val.b.sesreq) {
+		DWC_ERROR("Session Request Already active!\n");
+		return;
+	}
+	DWC_NOTICE("Session Request Initated\n");
+	mem.d32 = dwc_read_reg32(addr);
+	mem.b.sesreq = 1;
+	dwc_write_reg32(addr, mem.d32);
+
+	/* Start the SRP timer */
+	dwc_otg_pcd_start_srp_timer(_pcd);
+	return;
+}
+void dwc_otg_pcd_remote_wakeup(dwc_otg_pcd_t * _pcd, int set)
+{
+	dctl_data_t dctl = {.d32 = 0};
+	volatile uint32_t *addr = &(GET_CORE_IF(_pcd)->dev_if->dev_global_regs->dctl);
+	if (dwc_otg_is_device_mode(GET_CORE_IF(_pcd))) {
+		if (_pcd->remote_wakeup_enable) {
+			if (set) {
+				dctl.b.rmtwkupsig = 1;
+				dwc_modify_reg32(addr, 0, dctl.d32);
+				DWC_DEBUGPL(DBG_PCD, "Set Remote Wakeup\n");
+				mdelay(1);
+				dwc_modify_reg32(addr, dctl.d32, 0);
+				DWC_DEBUGPL(DBG_PCD, "Clear Remote Wakeup\n");
+			} else {
+			}
+		} else {
+			DWC_DEBUGPL(DBG_PCD, "Remote Wakeup is disabled\n");
+		}
+	}
+	return;
+}
+
+
+/**
+ * Initiates Session Request Protocol (SRP) to wakeup the host if no
+ * session is in progress. If a session is already in progress, but
+ * the device is suspended, remote wakeup signaling is started.
+ *
+ */
+static int dwc_otg_pcd_wakeup(struct usb_gadget *_gadget)
+{
+	unsigned long flags;
+	dwc_otg_pcd_t * pcd;
+	dsts_data_t dsts;
+	gotgctl_data_t gotgctl;
+	DWC_DEBUGPL(DBG_PCDV, "%s(%p)\n", __func__, _gadget);
+	if (_gadget == 0) {
+		return -ENODEV;
+	} else {
+		pcd = container_of(_gadget, dwc_otg_pcd_t, gadget);
+	}
+	SPIN_LOCK_IRQSAVE(&pcd->lock, flags);
+
+	/*
+	 * This function starts the Protocol if no session is in progress. If
+	 * a session is already in progress, but the device is suspended,
+	 * remote wakeup signaling is started.
+	 */
+
+	/* Check if valid session */
+	gotgctl.d32 = dwc_read_reg32(&(GET_CORE_IF(pcd)->core_global_regs->gotgctl));
+	if (gotgctl.b.bsesvld) {
+
+		/* Check if suspend state */
+		dsts.d32 = dwc_read_reg32(&(GET_CORE_IF(pcd)->dev_if->dev_global_regs->dsts));
+		if (dsts.b.suspsts) {
+			dwc_otg_pcd_remote_wakeup(pcd, 1);
+		}
+	} else {
+		dwc_otg_pcd_initiate_srp(pcd);
+	}
+	SPIN_UNLOCK_IRQRESTORE(&pcd->lock, flags);
+	return 0;
+}
+
+static const struct usb_gadget_ops dwc_otg_pcd_ops = {
+	.get_frame = dwc_otg_pcd_get_frame,
+	.wakeup = dwc_otg_pcd_wakeup,
+    // current versions must always be self-powered
+};
+
+/* This function updates the otg values in the gadget structure */
+void dwc_otg_pcd_update_otg(dwc_otg_pcd_t * _pcd, const unsigned _reset) {
+	if (!_pcd->gadget.is_otg) return;
+	if (_reset) {
+		_pcd->b_hnp_enable = 0;
+		_pcd->a_hnp_support = 0;
+		_pcd->a_alt_hnp_support = 0;
+	}
+	_pcd->gadget.b_hnp_enable = _pcd->b_hnp_enable;
+	_pcd->gadget.a_hnp_support = _pcd->a_hnp_support;
+	_pcd->gadget.a_alt_hnp_support = _pcd->a_alt_hnp_support;
+}
+
+/* This function is the top level PCD interrupt handler */
+static irqreturn_t  dwc_otg_pcd_irq(int _irq, void *_dev) {
+	dwc_otg_pcd_t * pcd = _dev;
+	int32_t retval = IRQ_NONE;
+	retval = dwc_otg_pcd_handle_intr(pcd);
+	return IRQ_RETVAL(retval);
+}
+
+/* PCD Callback function for initializing the PCD when switching to device mode */
+static int32_t dwc_otg_pcd_start_cb(void *_p) {
+	dwc_otg_pcd_t * pcd = (dwc_otg_pcd_t *) _p;
+
+	/* Initialized the Core for Device mode */
+	if (dwc_otg_is_device_mode(GET_CORE_IF(pcd))) dwc_otg_core_dev_init(GET_CORE_IF(pcd));
+	return 1;
+}
+
+/* PCD Callback function for stopping the PCD when switching to Host mode */
+static int32_t dwc_otg_pcd_stop_cb(void *_p) {
+	dwc_otg_pcd_t * pcd = (dwc_otg_pcd_t *) _p;
+	extern void dwc_otg_pcd_stop(dwc_otg_pcd_t * _pcd);
+	dwc_otg_pcd_stop(pcd);
+	return 1;
+}
+
+/**
+ * PCD Callback function for notifying the PCD when resuming from
+ * suspend.
+ *
+ * @param _p void pointer to the <code>dwc_otg_pcd_t</code>
+ */
+static int32_t dwc_otg_pcd_suspend_cb(void *_p) {
+	dwc_otg_pcd_t * pcd = (dwc_otg_pcd_t *) _p;
+	if (pcd->driver && pcd->driver->resume) {
+		SPIN_UNLOCK(&pcd->lock);
+		pcd->driver->suspend(&pcd->gadget);
+		SPIN_LOCK(&pcd->lock);
+	}
+	return 1;
+}
+
+/**
+ * PCD Callback function for notifying the PCD when resuming from
+ * suspend.
+ *
+ * @param _p void pointer to the <code>dwc_otg_pcd_t</code>
+ */
+static int32_t dwc_otg_pcd_resume_cb(void *_p)
+{
+	dwc_otg_pcd_t * pcd = (dwc_otg_pcd_t *) _p;
+	if (pcd->driver && pcd->driver->resume) {
+		SPIN_UNLOCK(&pcd->lock);
+		pcd->driver->resume(&pcd->gadget);
+		SPIN_LOCK(&pcd->lock);
+	}
+
+	/* Stop the SRP timeout timer. */
+	if ((GET_CORE_IF(pcd)->core_params->phy_type !=
+		DWC_PHY_TYPE_PARAM_FS) || (!GET_CORE_IF(pcd)->core_params->i2c_enable)) {
+		if (GET_CORE_IF(pcd)->srp_timer_started) {
+			GET_CORE_IF(pcd)->srp_timer_started = 0;
+			del_timer(&pcd->srp_timer);
+		}
+	}
+	return 1;
+}
+
+/**
+ * PCD Callback structure for handling mode switching.
+ */
+static dwc_otg_cil_callbacks_t pcd_callbacks =
+{
+	.start = dwc_otg_pcd_start_cb,
+	.stop = dwc_otg_pcd_stop_cb,
+	.suspend = dwc_otg_pcd_suspend_cb,
+	.resume_wakeup = dwc_otg_pcd_resume_cb,
+	.p = 0, /* Set at registration */
+};
+
+/**
+ * This function is called when the SRP timer expires.	The SRP should
+ * complete within 6 seconds.
+ */
+static void srp_timeout(unsigned long _ptr) {
+	gotgctl_data_t gotgctl;
+	dwc_otg_core_if_t * core_if = (dwc_otg_core_if_t *) _ptr;
+	volatile uint32_t *addr = &core_if->core_global_regs->gotgctl;
+	gotgctl.d32 = dwc_read_reg32(addr);
+	core_if->srp_timer_started = 0;
+	if ((core_if->core_params->phy_type == DWC_PHY_TYPE_PARAM_FS) &&
+		(core_if->core_params->i2c_enable)) {
+		DWC_PRINT("SRP Timeout\n");
+		if ((core_if->srp_success) && (gotgctl.b.bsesvld)) {
+			if (core_if->pcd_cb && core_if->pcd_cb->resume_wakeup) {
+				core_if->pcd_cb->resume_wakeup(core_if->pcd_cb->p);
+			}
+
+			/* Clear Session Request */
+			gotgctl.d32 = 0;
+			gotgctl.b.sesreq = 1;
+			dwc_modify_reg32(&core_if->core_global_regs->gotgctl,gotgctl.d32, 0);
+			core_if->srp_success = 0;
+		} else {
+			DWC_ERROR("Device not connected/responding\n");
+			gotgctl.b.sesreq = 0;
+			dwc_write_reg32(addr, gotgctl.d32);
+		}
+	} else if (gotgctl.b.sesreq) {
+		DWC_PRINT("SRP Timeout\n");
+		DWC_ERROR("Device not connected/responding\n");
+		gotgctl.b.sesreq = 0;
+		dwc_write_reg32(addr, gotgctl.d32);
+	} else {
+		DWC_PRINT(" SRP GOTGCTL=%0x\n", gotgctl.d32);
+	}
+}
+
+/**
+ * Start the SRP timer to detect when the SRP does not complete within
+ * 6 seconds.
+ *
+ * @param _pcd the pcd structure.
+ */
+void dwc_otg_pcd_start_srp_timer(dwc_otg_pcd_t * _pcd)
+{
+	struct timer_list *srp_timer = &_pcd->srp_timer;
+	GET_CORE_IF(_pcd)->srp_timer_started = 1;
+	init_timer(srp_timer);
+	srp_timer->function = srp_timeout;
+	srp_timer->data = (unsigned long)GET_CORE_IF(_pcd);
+	srp_timer->expires = jiffies + (HZ * 6);
+	add_timer(srp_timer);
+}
+
+/* Tasklet */
+extern void start_next_request(dwc_otg_pcd_ep_t * _ep);
+
+static void start_xfer_tasklet_func(unsigned long data) {
+	dwc_otg_pcd_t * pcd = (dwc_otg_pcd_t *) data;
+	dwc_otg_core_if_t * core_if = pcd->otg_dev->core_if;
+	int i;
+	depctl_data_t diepctl;
+	DWC_DEBUGPL(DBG_PCDV, "Start xfer tasklet\n");
+	diepctl.d32 =
+	    dwc_read_reg32(&core_if->dev_if->in_ep_regs[0]->diepctl);
+	if (pcd->ep0.queue_sof) {
+		pcd->ep0.queue_sof = 0;
+		start_next_request(&pcd->ep0);
+		// break;
+	}
+	for (i = 0; i < core_if->dev_if->num_in_eps; i++) {
+		depctl_data_t diepctl;
+		diepctl.d32 =
+		    dwc_read_reg32(&core_if->dev_if->in_ep_regs[i]->diepctl);
+		if (pcd->in_ep[i].queue_sof) {
+			pcd->in_ep[i].queue_sof = 0;
+			start_next_request(&pcd->in_ep[i]);
+			// break;
+		}
+	}
+	return;
+}
+
+static struct tasklet_struct start_xfer_tasklet = {
+	.next = NULL,
+	.state = 0,
+	.count = ATOMIC_INIT(0),
+	.func = start_xfer_tasklet_func,
+	.data = 0,
+};
+
+/**
+ * This function initialized the pcd Dp structures to there default
+ * state.
+ *
+ * @param _pcd the pcd structure.
+ */
+void dwc_otg_pcd_reinit(dwc_otg_pcd_t * _pcd)
+{
+	static const char *names[] =
+    {
+		"ep0", "ep1in", "ep2in", "ep3in", "ep4in", "ep5in",
+		"ep6in", "ep7in", "ep8in", "ep9in", "ep10in", "ep11in", "ep12in", "ep13in",
+		"ep14in", "ep15in", "ep1out", "ep2out", "ep3out", "ep4out", "ep5out",
+		"ep6out", "ep7out", "ep8out", "ep9out", "ep10out", "ep11out", "ep12out",
+		"ep13out", "ep14out", "ep15out"
+	};
+
+	int i;
+	int in_ep_cntr, out_ep_cntr;
+	uint32_t hwcfg1;
+	uint32_t num_in_eps = (GET_CORE_IF(_pcd))->dev_if->num_in_eps;
+	uint32_t num_out_eps = (GET_CORE_IF(_pcd))->dev_if->num_out_eps;
+	dwc_otg_pcd_ep_t * ep;
+	DWC_DEBUGPL(DBG_PCDV, "%s(%p)\n", __func__, _pcd);
+	INIT_LIST_HEAD(&_pcd->gadget.ep_list);
+	_pcd->gadget.ep0 = &_pcd->ep0.ep;
+	_pcd->gadget.speed = USB_SPEED_UNKNOWN;
+	INIT_LIST_HEAD(&_pcd->gadget.ep0->ep_list);
+
+	/* Initialize the EP0 structure */
+	ep = &_pcd->ep0;
+
+	/* Init EP structure */
+	ep->desc = 0;
+	ep->pcd = _pcd;
+	ep->stopped = 1;
+
+	/* Init DWC ep structure */
+	ep->dwc_ep.num = 0;
+	ep->dwc_ep.active = 0;
+	ep->dwc_ep.tx_fifo_num = 0;
+
+	/* Control until ep is actvated */
+	ep->dwc_ep.type = DWC_OTG_EP_TYPE_CONTROL;
+	ep->dwc_ep.maxpacket = MAX_PACKET_SIZE;
+	ep->dwc_ep.dma_addr = 0;
+	ep->dwc_ep.start_xfer_buff = 0;
+	ep->dwc_ep.xfer_buff = 0;
+	ep->dwc_ep.xfer_len = 0;
+	ep->dwc_ep.xfer_count = 0;
+	ep->dwc_ep.sent_zlp = 0;
+	ep->dwc_ep.total_len = 0;
+	ep->queue_sof = 0;
+
+	/* Init the usb_ep structure. */
+	ep->ep.name = names[0];
+	ep->ep.ops = &dwc_otg_pcd_ep_ops;
+
+	/* @todo NGS: What should the max packet size be set to here?  Before EP type is set? */
+	ep->ep.maxpacket = MAX_PACKET_SIZE;
+	list_add_tail(&ep->ep.ep_list, &_pcd->gadget.ep_list);
+	INIT_LIST_HEAD(&ep->queue);
+
+	/* Initialize the EP structures */
+	in_ep_cntr = 0;
+	hwcfg1 = (GET_CORE_IF(_pcd))->hwcfg1.d32 >> 3;
+	for (i = 1; in_ep_cntr < num_in_eps; i++) {
+		if ((hwcfg1 & 0x1) == 0) {
+			dwc_otg_pcd_ep_t * ep = &_pcd->in_ep[in_ep_cntr];
+			in_ep_cntr++;
+
+			/* Init EP structure */
+			ep->desc = 0;
+			ep->pcd = _pcd;
+			ep->stopped = 1;
+
+			/* Init DWC ep structure */
+			ep->dwc_ep.is_in = 1;
+			ep->dwc_ep.num = i;
+			ep->dwc_ep.active = 0;
+			ep->dwc_ep.tx_fifo_num = 0;
+
+			/* Control until ep is actvated */
+			ep->dwc_ep.type = DWC_OTG_EP_TYPE_CONTROL;
+			ep->dwc_ep.maxpacket = MAX_PACKET_SIZE;
+			ep->dwc_ep.dma_addr = 0;
+			ep->dwc_ep.start_xfer_buff = 0;
+			ep->dwc_ep.xfer_buff = 0;
+			ep->dwc_ep.xfer_len = 0;
+			ep->dwc_ep.xfer_count = 0;
+			ep->dwc_ep.sent_zlp = 0;
+			ep->dwc_ep.total_len = 0;
+			ep->queue_sof = 0;
+
+			/* Init the usb_ep structure. */
+			/**
+			 * @todo NGS: Add direction to EP, based on contents
+			 * of HWCFG1.  Need a copy of HWCFG1 in pcd structure?
+			 * sprintf( ";r
+			 */
+			ep->ep.name = names[i];
+			ep->ep.ops = &dwc_otg_pcd_ep_ops;
+
+			/**
+			 * @todo NGS: What should the max packet size be set to
+			 * here?  Before EP type is set?
+			 */
+			ep->ep.maxpacket = MAX_PACKET_SIZE;
+			list_add_tail(&ep->ep.ep_list, &_pcd->gadget.ep_list);
+			INIT_LIST_HEAD(&ep->queue);
+		}
+		hwcfg1 >>= 2;
+	}
+	out_ep_cntr = 0;
+	hwcfg1 = (GET_CORE_IF(_pcd))->hwcfg1.d32 >> 2;
+	for (i = 1; out_ep_cntr < num_out_eps; i++) {
+		if ((hwcfg1 & 0x1) == 0) {
+			dwc_otg_pcd_ep_t * ep = &_pcd->out_ep[out_ep_cntr];
+			out_ep_cntr++;
+
+			/* Init EP structure */
+			ep->desc = 0;
+			ep->pcd = _pcd;
+			ep->stopped = 1;
+
+			/* Init DWC ep structure */
+			ep->dwc_ep.is_in = 0;
+			ep->dwc_ep.num = i;
+			ep->dwc_ep.active = 0;
+			ep->dwc_ep.tx_fifo_num = 0;
+
+			/* Control until ep is actvated */
+			ep->dwc_ep.type = DWC_OTG_EP_TYPE_CONTROL;
+			ep->dwc_ep.maxpacket = MAX_PACKET_SIZE;
+			ep->dwc_ep.dma_addr = 0;
+			ep->dwc_ep.start_xfer_buff = 0;
+			ep->dwc_ep.xfer_buff = 0;
+			ep->dwc_ep.xfer_len = 0;
+			ep->dwc_ep.xfer_count = 0;
+			ep->dwc_ep.sent_zlp = 0;
+			ep->dwc_ep.total_len = 0;
+			ep->queue_sof = 0;
+
+			/* Init the usb_ep structure. */
+			/**
+			 * @todo NGS: Add direction to EP, based on contents
+			 * of HWCFG1.  Need a copy of HWCFG1 in pcd structure?
+			 * sprintf( ";r
+			 */
+			ep->ep.name = names[15 + i];
+			ep->ep.ops = &dwc_otg_pcd_ep_ops;
+
+			/* @todo NGS: What should the max packet size be set to here?  Before EP type is set? */
+			ep->ep.maxpacket = MAX_PACKET_SIZE;
+			list_add_tail(&ep->ep.ep_list, &_pcd->gadget.ep_list);
+			INIT_LIST_HEAD(&ep->queue);
+		}
+		hwcfg1 >>= 2;
+	}
+
+	/* remove ep0 from the list.  There is a ep0 pointer. */
+	list_del_init(&_pcd->ep0.ep.ep_list);
+	_pcd->ep0state = EP0_DISCONNECT;
+	_pcd->ep0.ep.maxpacket = MAX_EP0_SIZE;
+	_pcd->ep0.dwc_ep.maxpacket = MAX_EP0_SIZE;
+	_pcd->ep0.dwc_ep.type = DWC_OTG_EP_TYPE_CONTROL;
+}
+
+/* This function releases the Gadget device. required by device_unregister() */
+static void dwc_otg_pcd_gadget_release(struct device *_dev) {
+	DWC_DEBUGPL(DBG_PCDV, "%s(%p)\n", __func__, _dev);
+}
+
+/* This function initialized the PCD portion of the driver */
+int  __init  dwc_otg_pcd_init(struct device *_dev)
+{
+	static char pcd_name[] = "dwc_otg_pcd";
+	dwc_otg_pcd_t * pcd;
+	dwc_otg_device_t * otg_dev = dev_get_drvdata(_dev);
+	int retval = 0;
+	DWC_DEBUGPL(DBG_PCDV, "%s(%p)\n", __func__, _dev);
+
+	/* Allocate PCD structure */
+	pcd = kzalloc(sizeof(dwc_otg_pcd_t), GFP_KERNEL);
+	if (pcd == 0) {
+		return -ENOMEM;
+	}
+	//memset(pcd, 0, sizeof(dwc_otg_pcd_t));
+	spin_lock_init(&pcd->lock);
+	otg_dev->pcd = pcd;
+	s_pcd = pcd;
+	pcd->gadget.name = pcd_name;
+	dev_set_name(&pcd->gadget.dev, "gadget");
+	pcd->otg_dev = dev_get_drvdata(_dev);
+	pcd->gadget.dev.parent = _dev;
+	pcd->gadget.dev.release = dwc_otg_pcd_gadget_release;
+	pcd->gadget.ops = &dwc_otg_pcd_ops;
+	if (GET_CORE_IF(pcd)->hwcfg4.b.ded_fifo_en) {
+		DWC_PRINT("Dedicated Tx FIFOs mode\n");
+	} else {
+		DWC_PRINT("Shared Tx FIFO mode\n");
+	}
+
+	/* If the module is set to FS or if the PHY_TYPE is FS then the gadget
+	 * should not report as dual-speed capable.      replace the following line
+	 * with the block of code below it once the software is debugged for
+	 * this.  If is_dualspeed = 0 then the gadget driver should not report
+	 * a device qualifier descriptor when queried. 
+	if ((GET_CORE_IF(pcd)->core_params->speed == DWC_SPEED_PARAM_FULL)
+		|| ((GET_CORE_IF(pcd)->hwcfg2.b.hs_phy_type == 2)
+		&& (GET_CORE_IF(pcd)->hwcfg2.b.fs_phy_type == 1)
+		&& (GET_CORE_IF(pcd)->core_params->ulpi_fs_ls))) {
+		pcd->gadget.is_dualspeed = 0;
+	} else {
+		pcd->gadget.is_dualspeed = 1;
+	}*/
+	if ((otg_dev->core_if->hwcfg2.b.op_mode == DWC_HWCFG2_OP_MODE_NO_SRP_CAPABLE_DEVICE)
+		|| (otg_dev->core_if->hwcfg2.b.op_mode == DWC_HWCFG2_OP_MODE_NO_SRP_CAPABLE_HOST)
+		|| (otg_dev->core_if->hwcfg2.b.op_mode == DWC_HWCFG2_OP_MODE_SRP_CAPABLE_DEVICE)
+		|| (otg_dev->core_if->hwcfg2.b.op_mode == DWC_HWCFG2_OP_MODE_SRP_CAPABLE_HOST)) {
+		pcd->gadget.is_otg = 0;
+	} else pcd->gadget.is_otg = 1;
+	pcd->driver = 0;
+
+	/* Register the gadget device */
+	retval = device_register(&pcd->gadget.dev);
+
+	/* Initialized the Core for Device mode */
+	if (dwc_otg_is_device_mode(GET_CORE_IF(pcd))) {
+		dwc_otg_core_dev_init(GET_CORE_IF(pcd));
+	}
+
+	/* Initialize EP structures */
+	dwc_otg_pcd_reinit(pcd);
+
+	/* Register the PCD Callbacks */
+	dwc_otg_cil_register_pcd_callbacks(otg_dev->core_if, &pcd_callbacks,pcd);
+
+	/* Setup interupt handler */
+	DWC_DEBUGPL(DBG_ANY, "registering handler for irq%d\n",otg_dev->irq);
+	retval = request_irq(otg_dev->irq, dwc_otg_pcd_irq, IRQF_SHARED, pcd->gadget.name, pcd);
+	if (retval != 0) {
+		DWC_ERROR("request of irq%d failed\n", otg_dev->irq);
+		kfree(pcd);
+		return -EBUSY;
+	}
+
+	/* Initialize the DMA buffer for SETUP packets */
+	if (GET_CORE_IF(pcd)->dma_enable) {
+		pcd->setup_pkt = dma_alloc_coherent(_dev, sizeof(*pcd->setup_pkt)*5, &pcd->setup_pkt_dma_handle, 0);
+		pcd->status_buf = dma_alloc_coherent(_dev, sizeof(uint16_t), &pcd->status_buf_dma_handle, 0);
+	} else {
+		pcd->setup_pkt =  kmalloc(sizeof(*pcd->setup_pkt) * 5, GFP_KERNEL);
+		pcd->status_buf = kmalloc(sizeof(uint16_t), GFP_KERNEL);
+	}
+	if (pcd->setup_pkt == 0) {
+		kfree(pcd);
+		return -ENOMEM;
+	}
+
+    /* Initialize tasklet */
+    start_xfer_tasklet.data = (unsigned long)pcd;
+	pcd->start_xfer_tasklet = &start_xfer_tasklet;
+	return 0;
+}
+
+/* Cleanup the PCD */
+void dwc_otg_pcd_remove(struct device *_dev) {
+	dwc_otg_device_t * otg_dev = dev_get_drvdata(_dev);
+	dwc_otg_pcd_t * pcd = otg_dev->pcd;
+	DWC_DEBUGPL(DBG_PCDV, "%s(%p)\n", __func__, _dev);
+
+	/* Free the IRQ */
+	free_irq(otg_dev->irq, pcd);
+
+	/* start with the driver above us */
+	if (pcd->driver) {
+		/* should have been done already by driver model core */
+		DWC_WARN("driver '%s' is still registered\n",pcd->driver->driver.name);
+		usb_gadget_unregister_driver(pcd->driver);
+	}
+	device_unregister(&pcd->gadget.dev);
+	if (GET_CORE_IF(pcd)->dma_enable) {
+		dma_free_coherent(NULL, sizeof(*pcd->setup_pkt) * 5, pcd->setup_pkt, pcd->setup_pkt_dma_handle);
+		dma_free_coherent(NULL, sizeof(uint16_t), pcd->status_buf, pcd->status_buf_dma_handle);
+	} else {
+		kfree(pcd->setup_pkt);
+		kfree(pcd->status_buf);
+	}
+	kfree(pcd);
+	otg_dev->pcd = 0;
+}
+
+/**
+ * This function registers a gadget driver with the PCD.
+ *
+ * When a driver is successfully registered, it will receive control
+ * requests including set_configuration(), which enables non-control
+ * requests.  then usb traffic follows until a disconnect is reported.
+ * then a host may connect again, or the driver might get unbound.
+ *
+ * @param driver The driver being registered
+ */
+int usb_gadget_register_driver(struct usb_gadget_driver *driver) {
+	int retval;
+	dctl_data_t dctl;
+    uint32_t *addr = NULL;
+
+	DWC_DEBUGPL(DBG_PCD, "registering gadget driver '%s'\n", driver->driver.name);
+	if (!driver || driver->max_speed == USB_SPEED_UNKNOWN || !driver->bind || !driver->disconnect || !driver->setup) {
+		DWC_DEBUGPL(DBG_PCDV, "EINVAL\n");
+		printk("driver=0x%p speed=0x%x bind=0x%p unbind=0x%p disconnect=0x%p setup=0x%p\n", driver,  driver->max_speed, driver->bind, driver->unbind, driver->disconnect,  driver->setup);
+		return -EINVAL;
+	}
+	if (s_pcd == 0) {
+		DWC_DEBUGPL(DBG_PCDV, "ENODEV\n");
+		return -ENODEV;
+	}
+	if (s_pcd->driver != 0) {
+		DWC_DEBUGPL(DBG_PCDV, "EBUSY (%p)\n", s_pcd->driver);
+		return -EBUSY;
+	}
+
+	/* hook up the driver */
+	s_pcd->driver = driver;
+	s_pcd->gadget.dev.driver = &driver->driver;
+	{
+		dwc_otg_core_if_t *_core_if = s_pcd->otg_dev->core_if;
+		if(_core_if) {
+			dwc_otg_disable_global_interrupts(_core_if);
+			dwc_otg_core_init(_core_if);
+			dwc_otg_pcd_reinit(s_pcd);  
+			dwc_otg_enable_global_interrupts(_core_if);
+			if (_core_if->pcd_cb) dwc_otg_pcd_start_cb(_core_if->pcd_cb->p);
+		}
+
+	}
+	DWC_DEBUGPL(DBG_PCD, "bind to driver %s\n", driver->driver.name);
+	retval = driver->bind(&s_pcd->gadget, driver);
+	if (retval) {
+		DWC_ERROR("bind to driver %s --> error %d\n", driver->driver.name, retval);
+		s_pcd->driver = 0;
+		s_pcd->gadget.dev.driver = 0;
+		return retval;
+	}
+	DWC_DEBUGPL(DBG_ANY, "registered gadget driver '%s'\n", driver->driver.name);
+
+	/* do soft-disconnect */
+	addr = (uint32_t *)&(GET_CORE_IF(s_pcd)->dev_if->dev_global_regs->dctl);
+	dctl.d32 = dwc_read_reg32(addr);
+	dctl.b.sftdiscon = 1;
+	dwc_write_reg32(addr, dctl.d32);
+	msleep(2000);
+	dctl.b.sftdiscon = 0;
+	dwc_write_reg32(addr, dctl.d32);
+
+	return 0;
+}
+EXPORT_SYMBOL(usb_gadget_register_driver);
+
+/* Unregisters a gadget driver, @param driver The driver being unregistered */
+int usb_gadget_unregister_driver(struct usb_gadget_driver *driver) {
+    //DWC_DEBUGPL(DBG_PCDV,"%s(%p)\n", __func__, driver);
+	if (s_pcd == 0) {
+		DWC_DEBUGPL(DBG_ANY, "%s Return(%d): s_pcd==0\n", __func__,-ENODEV);
+		return -ENODEV;
+	}
+	if (driver == 0 || driver != s_pcd->driver) {
+		DWC_DEBUGPL(DBG_ANY, "%s Return(%d): driver?\n", __func__,-EINVAL);
+		return -EINVAL;
+	}
+	driver->unbind(&s_pcd->gadget);
+	s_pcd->driver = 0;
+	DWC_DEBUGPL(DBG_ANY, "unregistered driver '%s'\n", driver->driver.name);
+	return 0;
+}
+EXPORT_SYMBOL(usb_gadget_unregister_driver);
+
+#endif	/* DWC_HOST_ONLY */
diff -Naur a/drivers/usb/dwc_otg/dwc_otg_pcd.h b/drivers/usb/dwc_otg/dwc_otg_pcd.h
--- a/drivers/usb/dwc_otg/dwc_otg_pcd.h	1970-01-01 00:00:00.000000000 +0000
+++ b/drivers/usb/dwc_otg/dwc_otg_pcd.h	2016-01-31 16:10:52.000000000 +0000
@@ -0,0 +1,209 @@
+/* ==========================================================================
+ * $File: //dwh/usb_iip/dev/software/otg_ipmate/linux/drivers/dwc_otg_pcd.h $
+ * $Revision: #6 $
+ * $Date: 2007/02/07 $
+ * $Change: 791271 $
+ *
+ * Synopsys HS OTG Linux Software Driver and documentation (hereinafter,
+ * "Software") is an Unsupported proprietary work of Synopsys, Inc. unless
+ * otherwise expressly agreed to in writing between Synopsys and you.
+ *
+ * The Software IS NOT an item of Licensed Software or Licensed Product under
+ * any End User Software License Agreement or Agreement for Licensed Product
+ * with Synopsys or any supplement thereto. You are permitted to use and
+ * redistribute this Software in source and binary forms, with or without
+ * modification, provided that redistributions of source code must retain this
+ * notice. You may not view, use, disclose, copy or distribute this file or
+ * any information contained herein except pursuant to this license grant from
+ * Synopsys. If you do not agree with this notice, including the disclaimer
+ * below, then you are not authorized to use the Software.
+ *
+ * THIS SOFTWARE IS BEING DISTRIBUTED BY SYNOPSYS SOLELY ON AN "AS IS" BASIS
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE HEREBY DISCLAIMED. IN NO EVENT SHALL SYNOPSYS BE LIABLE FOR ANY DIRECT,
+ * INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+ * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+ * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+ * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
+ * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
+ * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH
+ * DAMAGE.
+ * ========================================================================== */
+#ifndef CONFIG_DWC_HOST_ONLY
+#if !defined(__DWC_PCD_H__)
+#define __DWC_PCD_H__
+
+#include <linux/types.h>
+#include <linux/list.h>
+#include <linux/errno.h>
+#include <linux/device.h>
+#include <linux/usb/ch9.h>
+#include <linux/usb/gadget.h>
+#include <linux/interrupt.h>
+#include <linux/dma-mapping.h>
+
+struct lm_device;
+struct dwc_otg_device;
+
+#include "dwc_otg_cil.h"
+
+/**
+ * @file
+ *
+ * This file contains the structures, constants, and interfaces for
+ * the Perpherial Contoller Driver (PCD).
+ *
+ * The Peripheral Controller Driver (PCD) for Linux will implement the
+ * Gadget API, so that the existing Gadget drivers can be used.	 For
+ * the Mass Storage Function driver the File-backed USB Storage Gadget
+ * (FBS) driver will be used.  The FBS driver supports the
+ * Control-Bulk (CB), Control-Bulk-Interrupt (CBI), and Bulk-Only
+ * transports.
+ *
+ */
+
+/** Invalid DMA Address */
+#define DMA_ADDR_INVALID	(~(dma_addr_t)0)
+/** Maxpacket size for EP0 */
+#define MAX_EP0_SIZE	64
+/** Maxpacket size for any EP */
+#define MAX_PACKET_SIZE 1024
+
+/**
+ * Get the pointer to the core_if from the pcd pointer.
+ */
+#define GET_CORE_IF( _pcd ) (_pcd->otg_dev->core_if)
+
+/**
+ * States of EP0.
+ */
+typedef enum ep0_state {
+	EP0_DISCONNECT = 0,		/* no host */
+	EP0_IDLE = 1,
+	EP0_IN_DATA_PHASE = 2,
+	EP0_OUT_DATA_PHASE = 3,
+	EP0_STATUS = 4,
+	EP0_STALL = 5,
+} ep0state_e;
+
+/** Fordward declaration.*/
+struct dwc_otg_pcd;
+
+/**	  PCD EP structure.
+ * This structure describes an EP, there is an array of EPs in the PCD
+ * structure.
+ */
+typedef struct dwc_otg_pcd_ep {
+	/** USB EP data */
+	struct usb_ep		ep;
+	/** USB EP Descriptor */
+	const struct usb_endpoint_descriptor	*desc;
+
+	/** queue of dwc_otg_pcd_requests. */
+	struct list_head	queue;
+	unsigned stopped : 1;
+	unsigned disabling : 1;
+	unsigned dma : 1;
+	unsigned queue_sof : 1;
+
+	/** DWC_otg ep data. */
+	dwc_ep_t dwc_ep;
+
+	/** Pointer to PCD */
+	struct dwc_otg_pcd *pcd;
+}dwc_otg_pcd_ep_t;
+
+
+
+/** DWC_otg PCD Structure.
+ * This structure encapsulates the data for the dwc_otg PCD.
+ */
+typedef struct dwc_otg_pcd {
+	/** USB gadget */
+	struct usb_gadget gadget;
+	/** USB gadget driver pointer*/
+	struct usb_gadget_driver *driver;
+	/** The DWC otg device pointer. */
+	struct dwc_otg_device *otg_dev;
+
+	/** State of EP0 */
+	ep0state_e	ep0state;
+	/** EP0 Request is pending */
+	unsigned	ep0_pending : 1;
+	/** Indicates when SET CONFIGURATION Request is in process */
+	unsigned	request_config : 1;
+	/** The state of the Remote Wakeup Enable. */
+	unsigned	remote_wakeup_enable : 1;
+	/** The state of the B-Device HNP Enable. */
+	unsigned	b_hnp_enable : 1;
+	/** The state of A-Device HNP Support. */
+	unsigned	a_hnp_support : 1;
+	/** The state of the A-Device Alt HNP support. */
+	unsigned	a_alt_hnp_support : 1;
+	/** Count of pending Requests */
+	unsigned	request_pending;
+
+	/** SETUP packet for EP0
+	 * This structure is allocated as a DMA buffer on PCD initialization
+	 * with enough space for up to 3 setup packets.
+	 */
+    union {
+			struct usb_ctrlrequest	req;
+			uint32_t	d32[2];
+	} *setup_pkt;
+
+	dma_addr_t setup_pkt_dma_handle;
+
+	/** 2-byte dma buffer used to return status from GET_STATUS */
+	uint16_t *status_buf;
+	dma_addr_t status_buf_dma_handle;
+
+	/** Array of EPs. */
+	dwc_otg_pcd_ep_t ep0;
+	/** Array of IN EPs. */
+	dwc_otg_pcd_ep_t in_ep[ MAX_EPS_CHANNELS - 1];
+	/** Array of OUT EPs. */
+	dwc_otg_pcd_ep_t out_ep[ MAX_EPS_CHANNELS - 1];
+	/** number of valid EPs in the above array. */
+//	  unsigned	num_eps : 4;
+	spinlock_t	lock;
+	/** Timer for SRP.	If it expires before SRP is successful
+	 * clear the SRP. */
+	struct timer_list srp_timer;
+
+	/** Tasklet to defer starting of TEST mode transmissions until
+	 *	Status Phase has been completed.
+	 */
+	struct tasklet_struct test_mode_tasklet;
+
+	/** Tasklet to delay starting of xfer in DMA mode */
+	struct tasklet_struct *start_xfer_tasklet;
+
+	/** The test mode to enter when the tasklet is executed. */
+	unsigned test_mode;
+
+} dwc_otg_pcd_t;
+
+
+/** DWC_otg request structure.
+ * This structure is a list of requests.
+ */
+typedef struct dwc_otg_pcd_request {
+	struct usb_request	req; /**< USB Request. */
+	struct list_head	queue;	/**< queue of these requests. */
+	unsigned mapped:1;
+} dwc_otg_pcd_request_t;
+
+
+extern int  __init dwc_otg_pcd_init(struct device *_dev);
+
+extern void dwc_otg_pcd_remove( struct device *_dev );
+extern int32_t dwc_otg_pcd_handle_intr( dwc_otg_pcd_t *_pcd );
+extern void dwc_otg_pcd_start_srp_timer(dwc_otg_pcd_t *_pcd );
+
+extern void dwc_otg_pcd_initiate_srp(dwc_otg_pcd_t *_pcd);
+extern void dwc_otg_pcd_remote_wakeup(dwc_otg_pcd_t *_pcd, int set);
+
+#endif
+#endif /* DWC_HOST_ONLY */
diff -Naur a/drivers/usb/dwc_otg/dwc_otg_pcd_intr.c b/drivers/usb/dwc_otg/dwc_otg_pcd_intr.c
--- a/drivers/usb/dwc_otg/dwc_otg_pcd_intr.c	1970-01-01 00:00:00.000000000 +0000
+++ b/drivers/usb/dwc_otg/dwc_otg_pcd_intr.c	2016-01-31 16:10:52.000000000 +0000
@@ -0,0 +1,2519 @@
+/* ==========================================================================
+ * $File: //dwh/usb_iip/dev/software/otg_ipmate/linux/drivers/dwc_otg_pcd_intr.c $
+ * $Revision: #18 $
+ * $Date: 2007/02/07 $
+ * $Change: 791271 $
+ *
+ * Synopsys HS OTG Linux Software Driver and documentation (hereinafter,
+ * "Software") is an Unsupported proprietary work of Synopsys, Inc. unless
+ * otherwise expressly agreed to in writing between Synopsys and you.
+ *
+ * The Software IS NOT an item of Licensed Software or Licensed Product under
+ * any End User Software License Agreement or Agreement for Licensed Product
+ * with Synopsys or any supplement thereto. You are permitted to use and
+ * redistribute this Software in source and binary forms, with or without
+ * modification, provided that redistributions of source code must retain this
+ * notice. You may not view, use, disclose, copy or distribute this file or
+ * any information contained herein except pursuant to this license grant from
+ * Synopsys. If you do not agree with this notice, including the disclaimer
+ * below, then you are not authorized to use the Software.
+ *
+ * THIS SOFTWARE IS BEING DISTRIBUTED BY SYNOPSYS SOLELY ON AN "AS IS" BASIS
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE HEREBY DISCLAIMED. IN NO EVENT SHALL SYNOPSYS BE LIABLE FOR ANY DIRECT,
+ * INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+ * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+ * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+ * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
+ * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
+ * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH
+ * DAMAGE.
+ * ========================================================================== */
+
+#ifndef CONFIG_DWC_HOST_ONLY
+#include <linux/interrupt.h>
+#include <linux/dma-mapping.h>
+
+#include "dwc_otg_driver.h"
+#include "dwc_otg_pcd.h"
+
+//#define VERBOSE
+#define DEBUG_EP0
+
+/* request functions defined in "dwc_otg_pcd.c" */
+extern void request_done(dwc_otg_pcd_ep_t * _ep, dwc_otg_pcd_request_t * _req,
+			 int _status);
+extern void request_nuke(dwc_otg_pcd_ep_t * _ep);
+extern void dwc_otg_pcd_update_otg(dwc_otg_pcd_t * _pcd,
+				    const unsigned _reset);
+
+/** @file
+ * This file contains the implementation of the PCD Interrupt handlers.
+ *
+ * The PCD handles the device interrupts.  Many conditions can cause a
+ * device interrupt. When an interrupt occurs, the device interrupt
+ * service routine determines the cause of the interrupt and
+ * dispatches handling to the appropriate function. These interrupt
+ * handling functions are described below.
+ * All interrupt registers are processed from LSB to MSB.
+ */
+
+/**
+ * This function prints the ep0 state for debug purposes.
+ */
+static inline void print_ep0_state(dwc_otg_pcd_t * _pcd)
+{
+#ifdef CONFIG_DWC_DEBUG
+	char str[40];
+	switch (_pcd->ep0state) {
+	case EP0_DISCONNECT:
+		strcpy(str, "EP0_DISCONNECT");
+		break;
+	case EP0_IDLE:
+		strcpy(str, "EP0_IDLE");
+		break;
+	case EP0_IN_DATA_PHASE:
+		strcpy(str, "EP0_IN_DATA_PHASE");
+		break;
+	case EP0_OUT_DATA_PHASE:
+		strcpy(str, "EP0_OUT_DATA_PHASE");
+		break;
+	case EP0_STATUS:
+		strcpy(str, "EP0_STATUS");
+		break;
+	case EP0_STALL:
+		strcpy(str, "EP0_STALL");
+		break;
+	default:
+		strcpy(str, "EP0_INVALID");
+	}
+	DWC_DEBUGPL(DBG_ANY, "%s(%d)\n", str, _pcd->ep0state);
+#endif	/*  */
+}
+
+/**
+ * This function returns pointer to in ep struct with number ep_num
+ */
+static inline dwc_otg_pcd_ep_t *get_in_ep(dwc_otg_pcd_t * _pcd,
+					  uint32_t ep_num)
+{
+	int i;
+	int num_in_eps = GET_CORE_IF(_pcd)->dev_if->num_in_eps;
+	if (ep_num == 0) {
+		return &_pcd->ep0;
+	} else {
+		for (i = 0; i < num_in_eps; ++i) {
+			if (_pcd->in_ep[i].dwc_ep.num == ep_num)
+				return &_pcd->in_ep[i];
+			}
+		return 0;
+	}
+
+}
+
+/**
+ * This function returns pointer to out ep struct with number ep_num
+ */
+static inline dwc_otg_pcd_ep_t *get_out_ep(dwc_otg_pcd_t * _pcd,
+					   uint32_t ep_num)
+{
+	int i;
+	int num_out_eps = GET_CORE_IF(_pcd)->dev_if->num_out_eps;
+	if (ep_num == 0) {
+		return &_pcd->ep0;
+	} else {
+		for (i = 0; i < num_out_eps; ++i) {
+			if (_pcd->out_ep[i].dwc_ep.num == ep_num)
+				return &_pcd->out_ep[i];
+		}
+	return 0;
+	}
+
+}
+
+/**
+ * This functions gets a pointer to an EP from the wIndex address
+ * value of the control request.
+ */
+static dwc_otg_pcd_ep_t *get_ep_by_addr(dwc_otg_pcd_t * _pcd, u16 _wIndex)
+{
+	dwc_otg_pcd_ep_t * ep;
+	if ((_wIndex & USB_ENDPOINT_NUMBER_MASK) == 0)
+		return &_pcd->ep0;
+	list_for_each_entry(ep, &_pcd->gadget.ep_list, ep.ep_list) {
+		u8 bEndpointAddress;
+		if (!ep->desc)
+			continue;
+		bEndpointAddress = ep->desc->bEndpointAddress;
+		if ((_wIndex ^ bEndpointAddress) & USB_DIR_IN)
+			continue;
+		if ((_wIndex & 0x0f) == (bEndpointAddress & 0x0f))
+			return ep;
+	}
+	return NULL;
+}
+
+
+/**
+ * This function checks the EP request queue, if the queue is not
+ * empty the next request is started.
+ */
+void start_next_request(dwc_otg_pcd_ep_t * _ep)
+{
+	dwc_otg_pcd_request_t * req = 0;
+	if (!list_empty(&_ep->queue)) {
+		req = list_entry(_ep->queue.next, dwc_otg_pcd_request_t, queue);
+
+		/* Setup and start the Transfer */
+		_ep->dwc_ep.start_xfer_buff = req->req.buf;
+		_ep->dwc_ep.xfer_buff = req->req.buf;
+		_ep->dwc_ep.xfer_len = req->req.length;
+		_ep->dwc_ep.xfer_count = 0;
+		_ep->dwc_ep.dma_addr = req->req.dma;
+		_ep->dwc_ep.sent_zlp = 0;
+		_ep->dwc_ep.total_len = _ep->dwc_ep.xfer_len;
+
+		//DWC_ERROR(" -> starting transfer (start_next_req) %s %s\n",
+		//_ep->ep.name, _ep->dwc_ep.is_in?"IN":"OUT");
+#ifdef CONFIG_405EZ
+		/*
+		 * Added-sr: 2007-07-26
+		 *
+		 * When a new transfer will be started, mark this
+		 * endpoint as active. This way it will be blocked
+		 * for further transfers, until the current transfer
+		 * is finished.
+		 */
+		_ep->dwc_ep.active = 1;
+#endif
+		dwc_otg_ep_start_transfer(GET_CORE_IF(_ep->pcd), &_ep->dwc_ep);
+	}
+}
+
+/**
+ * This function handles the SOF Interrupts. At this time the SOF
+ * Interrupt is disabled.
+ */
+int32_t dwc_otg_pcd_handle_sof_intr(dwc_otg_pcd_t * _pcd)
+{
+	dwc_otg_core_if_t * core_if = GET_CORE_IF(_pcd);
+	gintsts_data_t gintsts;
+
+	//DWC_DEBUGPL(DBG_PCD, "SOF\n");
+
+	/* Clear interrupt */
+	gintsts.d32 = 0;
+	gintsts.b.sofintr = 1;
+	dwc_write_reg32(&core_if->core_global_regs->gintsts, gintsts.d32);
+	return 1;
+}
+
+/**
+ * This function handles the Rx Status Queue Level Interrupt, which
+ * indicates that there is a least one packet in the Rx FIFO.  The
+ * packets are moved from the FIFO to memory, where they will be
+ * processed when the Endpoint Interrupt Register indicates Transfer
+ * Complete or SETUP Phase Done.
+ *
+ * Repeat the following until the Rx Status Queue is empty:
+ *	 -# Read the Receive Status Pop Register (GRXSTSP) to get Packet
+ *		info
+ *	 -# If Receive FIFO is empty then skip to step Clear the interrupt
+ *		and exit
+ *	 -# If SETUP Packet call dwc_otg_read_setup_packet to copy the
+ *		SETUP data to the buffer
+ *	 -# If OUT Data Packet call dwc_otg_read_packet to copy the data
+ *		to the destination buffer
+ */
+int32_t dwc_otg_pcd_handle_rx_status_q_level_intr(dwc_otg_pcd_t * _pcd)
+{
+	dwc_otg_core_if_t * core_if = GET_CORE_IF(_pcd);
+	dwc_otg_core_global_regs_t * global_regs = core_if->core_global_regs;
+	gintmsk_data_t gintmask = {.d32 = 0};
+	device_grxsts_data_t status;
+	dwc_otg_pcd_ep_t * ep;
+#ifndef CONFIG_OTG_PLB_DMA_TASKLET
+	gintsts_data_t gintsts;
+#endif
+
+#ifdef CONFIG_DWC_DEBUG
+	static char *dpid_str[] = { "D0", "D2", "D1", "MDATA" };
+
+#endif	/*  */
+	DWC_DEBUGPL(DBG_PCDV, "%s(%p)\n", __func__, _pcd);
+
+	/* Disable the Rx Status Queue Level interrupt */
+	gintmask.b.rxstsqlvl = 1;
+	dwc_modify_reg32(&global_regs->gintmsk, gintmask.d32, 0);
+
+	/* Get the Status from the top of the FIFO */
+	status.d32 = dwc_read_reg32(&global_regs->grxstsp);
+	DWC_DEBUGPL(DBG_PCD, "EP:%d BCnt:%d DPID:%s "
+		      "pktsts:%x Frame:%d(0x%0x)\n", status.b.epnum,
+		      status.b.bcnt, dpid_str[status.b.dpid], status.b.pktsts,
+		      status.b.fn, status.b.fn);
+
+	/* Get pointer to EP structure */
+	ep = get_out_ep(_pcd, status.b.epnum);
+
+//        ep = &_pcd->out_ep[ status.b.epnum - 1];
+	switch (status.b.pktsts) {
+	case DWC_DSTS_GOUT_NAK:
+		DWC_DEBUGPL(DBG_PCDV, "Global OUT NAK\n");
+		break;
+	case DWC_STS_DATA_UPDT:
+		DWC_DEBUGPL(DBG_PCDV, "OUT Data Packet\n");
+		if (status.b.bcnt && ep->dwc_ep.xfer_buff) {
+#ifdef CONFIG_OTG_PLB_DMA_TASKLET
+            /* Enable the Rx Status Queue Level interrupt */
+            dwc_modify_reg32(&global_regs->gintmsk, 0, gintmask.d32);
+#endif
+			/** @todo NGS Check for buffer overflow? */
+		    dwc_otg_read_packet(core_if, ep->dwc_ep.xfer_buff,
+						status.b.bcnt);
+			ep->dwc_ep.xfer_count += status.b.bcnt;
+			ep->dwc_ep.xfer_buff += status.b.bcnt;
+		}
+		break;
+	case DWC_STS_XFER_COMP:
+		DWC_DEBUGPL(DBG_PCDV, "OUT Complete\n");
+		break;
+	case DWC_DSTS_SETUP_COMP:
+#ifdef DEBUG_EP0
+		DWC_DEBUGPL(DBG_PCDV, "Setup Complete\n");
+#endif	/*  */
+		break;
+	case DWC_DSTS_SETUP_UPDT:
+		dwc_otg_read_setup_packet(core_if, _pcd->setup_pkt->d32);
+#ifdef DEBUG_EP0
+		DWC_DEBUGPL(DBG_PCD,
+				"SETUP PKT: %02x.%02x v%04x i%04x l%04x\n",
+				_pcd->setup_pkt->req.bRequestType,
+				_pcd->setup_pkt->req.bRequest,
+				__le16_to_cpu(_pcd->setup_pkt->req.wValue),
+				__le16_to_cpu(_pcd->setup_pkt->req.wIndex),
+				__le16_to_cpu(_pcd->setup_pkt->req.wLength));
+
+#endif	/*  */
+
+		ep->dwc_ep.xfer_count += status.b.bcnt;
+		break;
+	default:
+		DWC_DEBUGPL(DBG_PCDV, "Invalid Packet Status (0x%0x)\n",
+			     status.b.pktsts);
+		break;
+	}
+#ifdef CONFIG_OTG_PLB_DMA_TASKLET  /* Can't access registers */
+    if (!atomic_read(&release_later))
+#endif
+	/* Enable the Rx Status Queue Level interrupt */
+	dwc_modify_reg32(&global_regs->gintmsk, 0, gintmask.d32);
+#ifndef CONFIG_OTG_PLB_DMA_TASKLET     /* why do this? */
+	/* Clear interrupt */
+	gintsts.d32 = 0;
+	gintsts.b.rxstsqlvl = 1;
+	dwc_write_reg32(&global_regs->gintsts, gintsts.d32);
+#endif
+	//DWC_DEBUGPL(DBG_PCDV, "EXIT: %s\n", __func__);
+	return 1;
+}
+
+/**
+ * This function examines the Device IN Token Learning Queue to
+ * determine the EP number of the last IN token received.  This
+ * implementation is for the Mass Storage device where there are only
+ * 2 IN EPs (Control-IN and BULK-IN).
+ *
+ * The EP numbers for the first six IN Tokens are in DTKNQR1 and there
+ * are 8 EP Numbers in each of the other possible DTKNQ Registers.
+ *
+ * @param _core_if Programming view of DWC_otg controller.
+ *
+ */
+static inline int get_ep_of_last_in_token(dwc_otg_core_if_t * _core_if)
+{
+	dwc_otg_device_global_regs_t * dev_global_regs =
+	    _core_if->dev_if->dev_global_regs;
+	const uint32_t TOKEN_Q_DEPTH = _core_if->hwcfg2.b.dev_token_q_depth;
+
+	/* Number of Token Queue Registers */
+	const int DTKNQ_REG_CNT = (TOKEN_Q_DEPTH + 7) / 8;
+	dtknq1_data_t dtknqr1;
+	uint32_t in_tkn_epnums[4];
+	int ndx = 0;
+	int i = 0;
+	volatile uint32_t *addr = &dev_global_regs->dtknqr1;
+	int epnum = 0;
+
+	//DWC_DEBUGPL(DBG_PCD,"dev_token_q_depth=%d\n",TOKEN_Q_DEPTH);
+
+	/* Read the DTKNQ Registers */
+	for (i = 0; i <= DTKNQ_REG_CNT; i++) {
+		in_tkn_epnums[i] = dwc_read_reg32(addr);
+		DWC_DEBUGPL(DBG_PCDV, "DTKNQR%d=0x%08x\n", i + 1,
+			     in_tkn_epnums[i]);
+		if (addr == &dev_global_regs->dvbusdis) {
+			addr = &dev_global_regs->dtknqr3_dthrctl;
+		} else {
+			++addr;
+		}
+	}
+
+	/* Copy the DTKNQR1 data to the bit field. */
+	dtknqr1.d32 = in_tkn_epnums[0];
+
+	/* Get the EP numbers */
+	in_tkn_epnums[0] = dtknqr1.b.epnums0_5;
+	ndx = dtknqr1.b.intknwptr - 1;
+
+	//DWC_DEBUGPL(DBG_PCDV,"ndx=%d\n",ndx);
+	if (ndx == -1) {
+		/** @todo Find a simpler way to calculate the max
+		 * queue position.*/
+		int cnt = TOKEN_Q_DEPTH;
+		if (TOKEN_Q_DEPTH <= 6) {
+			cnt = TOKEN_Q_DEPTH - 1;
+		} else if (TOKEN_Q_DEPTH <= 14) {
+			cnt = TOKEN_Q_DEPTH - 7;
+		} else if (TOKEN_Q_DEPTH <= 22) {
+			cnt = TOKEN_Q_DEPTH - 15;
+		} else {
+			cnt = TOKEN_Q_DEPTH - 23;
+		}
+		epnum = (in_tkn_epnums[DTKNQ_REG_CNT - 1] >> (cnt * 4)) & 0xF;
+	} else {
+		if (ndx <= 5) {
+			epnum = (in_tkn_epnums[0] >> (ndx * 4)) & 0xF;
+		} else if (ndx <= 13) {
+			ndx -= 6;
+			epnum = (in_tkn_epnums[1] >> (ndx * 4)) & 0xF;
+		} else if (ndx <= 21) {
+			ndx -= 14;
+			epnum = (in_tkn_epnums[2] >> (ndx * 4)) & 0xF;
+		} else if (ndx <= 29) {
+			ndx -= 22;
+			epnum = (in_tkn_epnums[3] >> (ndx * 4)) & 0xF;
+		}
+	}
+    //DWC_DEBUGPL(DBG_PCD,"epnum=%d\n",epnum);
+    return epnum;
+}
+
+/**
+ * This interrupt occurs when the non-periodic Tx FIFO is half-empty.
+ * The active request is checked for the next packet to be loaded into
+ * the non-periodic Tx FIFO.
+ */
+int32_t dwc_otg_pcd_handle_np_tx_fifo_empty_intr(dwc_otg_pcd_t * _pcd)
+{
+	dwc_otg_core_if_t * core_if = GET_CORE_IF(_pcd);
+	dwc_otg_core_global_regs_t * global_regs = core_if->core_global_regs;
+	dwc_otg_dev_in_ep_regs_t * ep_regs;
+	volatile gnptxsts_data_t txstatus = {.d32 = 0 };
+#ifndef CONFIG_OTG_PLB_DMA
+	gintsts_data_t gintsts;
+#endif
+	int epnum = 0;
+	dwc_otg_pcd_ep_t * ep = 0;
+	uint32_t len = 0;
+	int dwords;
+
+	/* Get the epnum from the IN Token Learning Queue. */
+	epnum = get_ep_of_last_in_token(core_if);
+	ep = get_in_ep(_pcd, epnum);
+
+/*
+	if(epnum != 0)
+		ep = &_pcd->in_ep[epnum-1];
+	else
+		ep = &_pcd->ep0;
+*/
+	DWC_DEBUGPL(DBG_PCD, "NP TxFifo Empty: %s(%d) \n", ep->ep.name,epnum);
+	ep_regs = core_if->dev_if->in_ep_regs[epnum];
+	len = ep->dwc_ep.xfer_len - ep->dwc_ep.xfer_count;
+	if (len > ep->dwc_ep.maxpacket) {
+		len = ep->dwc_ep.maxpacket;
+	}
+	dwords = (len + 3) / 4;
+
+	/* While there is space in the queue and space in the FIFO and
+	 * More data to tranfer, Write packets to the Tx FIFO
+	 */
+	txstatus.d32 = dwc_read_reg32(&global_regs->gnptxsts);
+	DWC_DEBUGPL(DBG_PCDV, "b4 GNPTXSTS=0x%08x\n", txstatus.d32);
+	while (txstatus.b.nptxqspcavail > 0
+		&& txstatus.b.nptxfspcavail > dwords
+		&& ep->dwc_ep.xfer_count < ep->dwc_ep.xfer_len) {
+
+		/* Write the FIFO */
+#ifdef CONFIG_405EZ
+		/*
+		 * Added-sr: 2007-07-26
+		 *
+		 * When a new transfer will be started, mark this
+		 * endpoint as active. This way it will be blocked
+		 * for further transfers, until the current transfer
+		 * is finished.
+		 */
+		ep->dwc_ep.active = 1;
+#endif
+		dwc_otg_ep_write_packet(core_if, &ep->dwc_ep, 0);
+		len = ep->dwc_ep.xfer_len - ep->dwc_ep.xfer_count;
+		if (len > ep->dwc_ep.maxpacket) {
+			len = ep->dwc_ep.maxpacket;
+		}
+#ifdef CONFIG_OTG_PLB_DMA_TASKLET
+		if (atomic_read(&release_later)) {
+			break;
+		}
+#endif
+		dwords = (len + 3) / 4;
+		txstatus.d32 = dwc_read_reg32(&global_regs->gnptxsts);
+		DWC_DEBUGPL(DBG_PCDV, "GNPTXSTS=0x%08x\n", txstatus.d32);
+	}
+	DWC_DEBUGPL(DBG_PCDV, "GNPTXSTS=0x%08x\n",
+		      dwc_read_reg32(&global_regs->gnptxsts));
+#ifndef CONFIG_OTG_PLB_DMA		/* why do this? */
+	/* Clear interrupt */
+	gintsts.d32 = 0;
+	gintsts.b.nptxfempty = 1;
+	dwc_write_reg32(&global_regs->gintsts, gintsts.d32);
+
+	/*
+	 * Re-enable tx-fifo empty interrupt, if packets are still
+	 * pending
+	 */
+	if (len)
+		dwc_modify_reg32(&global_regs->gintmsk, 0, gintsts.d32);
+#endif
+
+	return 1;
+}
+
+/**
+ * This function is called when dedicated Tx FIFO Empty interrupt occurs.
+ * The active request is checked for the next packet to be loaded into
+ * apropriate Tx FIFO.
+ */
+static int32_t write_empty_tx_fifo(dwc_otg_pcd_t * _pcd, uint32_t epnum)
+{
+	dwc_otg_core_if_t * core_if = GET_CORE_IF(_pcd);
+	dwc_otg_dev_if_t * dev_if = core_if->dev_if;
+	dwc_otg_dev_in_ep_regs_t * ep_regs;
+	dtxfsts_data_t txstatus = {.d32 = 0};
+	dwc_otg_pcd_ep_t * ep = 0;
+	uint32_t len = 0;
+	int dwords;
+	ep = get_in_ep(_pcd, epnum);
+
+/*
+	if(epnum != 0)
+		ep = &_pcd->in_ep[epnum-1];
+	else
+		ep = &_pcd->ep0;
+*/
+	DWC_DEBUGPL(DBG_PCD, "Dedicated TxFifo Empty: %s(%d) \n",ep->ep.name, epnum);
+	ep_regs = core_if->dev_if->in_ep_regs[epnum];
+	len = ep->dwc_ep.xfer_len - ep->dwc_ep.xfer_count;
+	if (len > ep->dwc_ep.maxpacket) {
+		len = ep->dwc_ep.maxpacket;
+	}
+	dwords = (len + 3) / 4;
+
+	/* While there is space in the queue and space in the FIFO and
+	 * More data to tranfer, Write packets to the Tx FIFO */
+	txstatus.d32 = dwc_read_reg32(&dev_if->in_ep_regs[epnum]->dtxfsts);
+	DWC_DEBUGPL(DBG_PCDV, "b4 dtxfsts[%d]=0x%08x\n", epnum, txstatus.d32);
+	while (txstatus.b.txfspcavail > dwords
+		 && ep->dwc_ep.xfer_count < ep->dwc_ep.xfer_len
+		 && ep->dwc_ep.xfer_len != 0) {
+
+		/* Write the FIFO */
+		dwc_otg_ep_write_packet(core_if, &ep->dwc_ep, 0);
+		len = ep->dwc_ep.xfer_len - ep->dwc_ep.xfer_count;
+		if (len > ep->dwc_ep.maxpacket) {
+			len = ep->dwc_ep.maxpacket;
+		}
+		dwords = (len + 3) / 4;
+		txstatus.d32 = dwc_read_reg32(&dev_if->in_ep_regs[epnum]->dtxfsts);
+		DWC_DEBUGPL(DBG_PCDV, "dtxfsts[%d]=0x%08x\n", epnum,
+			     txstatus.d32);
+	}
+	DWC_DEBUGPL(DBG_PCDV, "b4 dtxfsts[%d]=0x%08x\n", epnum,
+		      dwc_read_reg32(&dev_if->in_ep_regs[epnum]->dtxfsts));
+	return 1;
+}
+
+/**
+ * This function is called when the Device is disconnected.	 It stops
+ * any active requests and informs the Gadget driver of the
+ * disconnect.
+ */
+void dwc_otg_pcd_stop(dwc_otg_pcd_t * _pcd)
+{
+	int i, num_in_eps, num_out_eps;
+	dwc_otg_pcd_ep_t * ep;
+	gintmsk_data_t intr_mask = {.d32 = 0};
+	num_in_eps = GET_CORE_IF(_pcd)->dev_if->num_in_eps;
+	num_out_eps = GET_CORE_IF(_pcd)->dev_if->num_out_eps;
+	DWC_DEBUGPL(DBG_PCDV, "%s() \n", __func__);
+
+	/* don't disconnect drivers more than once */
+	if (_pcd->ep0state == EP0_DISCONNECT) {
+		DWC_DEBUGPL(DBG_ANY, "%s() Already Disconnected\n", __func__);
+		return;
+	}
+	_pcd->ep0state = EP0_DISCONNECT;
+
+	/* Reset the OTG state. */
+	dwc_otg_pcd_update_otg(_pcd, 1);
+
+	/* Disable the NP Tx Fifo Empty Interrupt. */
+	intr_mask.b.nptxfempty = 1;
+	dwc_modify_reg32(&GET_CORE_IF(_pcd)->core_global_regs->gintmsk,
+			  intr_mask.d32, 0);
+
+	/* Flush the FIFOs */
+	/**@todo NGS Flush Periodic FIFOs */
+	dwc_otg_flush_tx_fifo(GET_CORE_IF(_pcd), 0);
+	dwc_otg_flush_rx_fifo(GET_CORE_IF(_pcd));
+
+	/* prevent new request submissions, kill any outstanding requests  */
+	ep = &_pcd->ep0;
+	request_nuke(ep);
+
+	/* prevent new request submissions, kill any outstanding requests  */
+	for (i = 0; i < num_in_eps; i++) {
+		dwc_otg_pcd_ep_t * ep = &_pcd->in_ep[i];
+		request_nuke(ep);
+	}
+
+	/* prevent new request submissions, kill any outstanding requests  */
+	for (i = 0; i < num_out_eps; i++) {
+		dwc_otg_pcd_ep_t * ep = &_pcd->out_ep[i];
+		request_nuke(ep);
+	}
+
+	/* report disconnect; the driver is already quiesced */
+	if (_pcd->driver && _pcd->driver->disconnect) {
+		SPIN_UNLOCK(&_pcd->lock);
+		_pcd->driver->disconnect(&_pcd->gadget);
+		SPIN_LOCK(&_pcd->lock);
+	}
+}
+
+/**
+ * This interrupt indicates that ...
+ */
+int32_t dwc_otg_pcd_handle_i2c_intr(dwc_otg_pcd_t * _pcd)
+{
+	gintmsk_data_t intr_mask = {.d32 = 0};
+	gintsts_data_t gintsts;
+	DWC_PRINT("INTERRUPT Handler not implemented for %s\n", "i2cintr");
+	intr_mask.b.i2cintr = 1;
+	dwc_modify_reg32(&GET_CORE_IF(_pcd)->core_global_regs->gintmsk,
+			  intr_mask.d32, 0);
+
+	/* Clear interrupt */
+	gintsts.d32 = 0;
+	gintsts.b.i2cintr = 1;
+	dwc_write_reg32(&GET_CORE_IF(_pcd)->core_global_regs->gintsts,
+			 gintsts.d32);
+	return 1;
+}
+
+/**
+ * This interrupt indicates that ...
+ */
+int32_t dwc_otg_pcd_handle_early_suspend_intr(dwc_otg_pcd_t * _pcd)
+{
+	gintsts_data_t gintsts;
+
+#if defined(VERBOSE)
+	DWC_PRINT("Early Suspend Detected\n");
+#endif	/*  */
+	/* Clear interrupt */
+	gintsts.d32 = 0;
+	gintsts.b.erlysuspend = 1;
+	dwc_write_reg32(&GET_CORE_IF(_pcd)->core_global_regs->gintsts,
+			 gintsts.d32);
+	return 1;
+}
+
+/**
+ * This function configures EPO to receive SETUP packets.
+ *
+ * @todo NGS: Update the comments from the HW FS.
+ *
+ *	-# Program the following fields in the endpoint specific registers
+ *	for Control OUT EP 0, in order to receive a setup packet
+ *	- DOEPTSIZ0.Packet Count = 3 (To receive up to 3 back to back
+ *	  setup packets)
+ *	- DOEPTSIZE0.Transfer Size = 24 Bytes (To receive up to 3 back
+ *	  to back setup packets)
+ *		- In DMA mode, DOEPDMA0 Register with a memory address to
+ *		  store any setup packets received
+ *
+ * @param _core_if Programming view of DWC_otg controller.
+ * @param _pcd	  Programming view of the PCD.
+ */
+static inline void ep0_out_start(dwc_otg_core_if_t * _core_if,
+				 dwc_otg_pcd_t * _pcd)
+{
+	dwc_otg_dev_if_t * dev_if = _core_if->dev_if;
+	deptsiz0_data_t doeptsize0 = {.d32 = 0};
+
+#ifdef VERBOSE
+	    DWC_DEBUGPL(DBG_PCDV, "%s() doepctl0=%0x\n", __func__,
+			dwc_read_reg32(&dev_if->out_ep_regs[0]->doepctl));
+
+#endif	/*  */
+	doeptsize0.b.supcnt = 3;
+	doeptsize0.b.pktcnt = 1;
+	doeptsize0.b.xfersize = 8 * 3;
+	dwc_write_reg32(&dev_if->out_ep_regs[0]->doeptsiz, doeptsize0.d32);
+	if (_core_if->dma_enable) {
+		depctl_data_t doepctl = {.d32 = 0};
+
+		/** @todo dma needs to handle multiple setup packets (up to 3) */
+		dwc_write_reg32(&dev_if->out_ep_regs[0]->doepdma,
+				    _pcd->setup_pkt_dma_handle);
+
+		// EP enable
+		doepctl.d32 =
+		dwc_read_reg32(&dev_if->out_ep_regs[0]->doepctl);
+		doepctl.b.epena = 1;
+		doepctl.d32 = 0x80008000;
+		dwc_write_reg32(&dev_if->out_ep_regs[0]->doepctl,
+				 doepctl.d32);
+	}
+
+#ifdef VERBOSE
+	DWC_DEBUGPL(DBG_PCDV, "doepctl0=%0x\n",
+			dwc_read_reg32(&dev_if->out_ep_regs[0]->doepctl));
+	DWC_DEBUGPL(DBG_PCDV, "diepctl0=%0x\n",
+		     dwc_read_reg32(&dev_if->in_ep_regs[0]->diepctl));
+#endif	/*  */
+}
+
+/**
+ * This interrupt occurs when a USB Reset is detected.	When the USB
+ * Reset Interrupt occurs the device state is set to DEFAULT and the
+ * EP0 state is set to IDLE.
+ *	-#	Set the NAK bit for all OUT endpoints (DOEPCTLn.SNAK = 1)
+ *	-#	Unmask the following interrupt bits
+ *		- DAINTMSK.INEP0 = 1 (Control 0 IN endpoint)
+ *	- DAINTMSK.OUTEP0 = 1 (Control 0 OUT endpoint)
+ *	- DOEPMSK.SETUP = 1
+ *	- DOEPMSK.XferCompl = 1
+ *	- DIEPMSK.XferCompl = 1
+ *	- DIEPMSK.TimeOut = 1
+ *	-# Program the following fields in the endpoint specific registers
+ *	for Control OUT EP 0, in order to receive a setup packet
+ *	- DOEPTSIZ0.Packet Count = 3 (To receive up to 3 back to back
+ *	  setup packets)
+ *	- DOEPTSIZE0.Transfer Size = 24 Bytes (To receive up to 3 back
+ *	  to back setup packets)
+ *		- In DMA mode, DOEPDMA0 Register with a memory address to
+ *		  store any setup packets received
+ * At this point, all the required initialization, except for enabling
+ * the control 0 OUT endpoint is done, for receiving SETUP packets.
+ */
+int32_t dwc_otg_pcd_handle_usb_reset_intr(dwc_otg_pcd_t * _pcd)
+{
+	dwc_otg_core_if_t * core_if = GET_CORE_IF(_pcd);
+	dwc_otg_dev_if_t * dev_if = core_if->dev_if;
+	depctl_data_t doepctl = {.d32 = 0};
+	daint_data_t daintmsk = {.d32 = 0};
+	doepmsk_data_t doepmsk = {.d32 = 0};
+	diepmsk_data_t diepmsk = {.d32 = 0};
+	dcfg_data_t dcfg = {.d32 = 0};
+	grstctl_t resetctl = {.d32 = 0};
+	dctl_data_t dctl = {.d32 = 0};
+	int i = 0;
+	volatile gintsts_data_t gintsts = {.d32 = 0 };
+	DWC_PRINT("USB RESET\n");
+
+	/* reset the HNP settings */
+	dwc_otg_pcd_update_otg(_pcd, 1);
+
+	/* Clear the Remote Wakeup Signalling */
+	dctl.b.rmtwkupsig = 1;
+	dwc_modify_reg32(&core_if->dev_if->dev_global_regs->dctl, dctl.d32,0);
+
+	/* Set NAK for all OUT EPs */
+	doepctl.b.snak = 1;
+	for (i = 0; i <= dev_if->num_out_eps; i++) {
+		dwc_write_reg32(&dev_if->out_ep_regs[i]->doepctl,
+				 doepctl.d32);
+	}
+
+	/* Flush the NP Tx FIFO */
+	dwc_otg_flush_tx_fifo(core_if, 0);
+
+	/* Flush the Learning Queue */
+	resetctl.b.intknqflsh = 1;
+	dwc_write_reg32(&core_if->core_global_regs->grstctl, resetctl.d32);
+	daintmsk.b.inep0 = 1;
+	daintmsk.b.outep0 = 1;
+	dwc_write_reg32(&dev_if->dev_global_regs->daintmsk, daintmsk.d32);
+	doepmsk.b.setup = 1;
+	doepmsk.b.xfercompl = 1;
+	doepmsk.b.ahberr = 1;
+	doepmsk.b.epdisabled = 1;
+	dwc_write_reg32(&dev_if->dev_global_regs->doepmsk, doepmsk.d32);
+	diepmsk.b.xfercompl = 1;
+	diepmsk.b.timeout = 1;
+	diepmsk.b.epdisabled = 1;
+	diepmsk.b.ahberr = 1;
+	diepmsk.b.intknepmis = 1;
+	dwc_write_reg32(&dev_if->dev_global_regs->diepmsk, diepmsk.d32);
+
+	/* Reset Device Address */
+	dcfg.d32 = dwc_read_reg32(&dev_if->dev_global_regs->dcfg);
+	dcfg.b.devaddr = 0;
+	dwc_write_reg32(&dev_if->dev_global_regs->dcfg, dcfg.d32);
+
+	/* setup EP0 to receive SETUP packets */
+	ep0_out_start(core_if, _pcd);
+
+	/* Clear interrupt */
+	gintsts.d32 = 0;
+	gintsts.b.usbreset = 1;
+	dwc_write_reg32(&core_if->core_global_regs->gintsts, gintsts.d32);
+	return 1;
+}
+
+/**
+ * Get the device speed from the device status register and convert it
+ * to USB speed constant.
+ *
+ * @param _core_if Programming view of DWC_otg controller.
+ */
+static int get_device_speed(dwc_otg_core_if_t * _core_if)
+{
+	dsts_data_t dsts;
+	enum usb_device_speed speed = USB_SPEED_UNKNOWN;
+	dsts.d32 = dwc_read_reg32(&_core_if->dev_if->dev_global_regs->dsts);
+	switch (dsts.b.enumspd) {
+	case DWC_DSTS_ENUMSPD_HS_PHY_30MHZ_OR_60MHZ:
+		speed = USB_SPEED_HIGH;
+		break;
+	case DWC_DSTS_ENUMSPD_FS_PHY_30MHZ_OR_60MHZ:
+	case DWC_DSTS_ENUMSPD_FS_PHY_48MHZ:
+		speed = USB_SPEED_FULL;
+		break;
+	case DWC_DSTS_ENUMSPD_LS_PHY_6MHZ:
+		speed = USB_SPEED_LOW;
+		break;
+	}
+	return speed;
+}
+
+/**
+ * Read the device status register and set the device speed in the
+ * data structure.
+ * Set up EP0 to receive SETUP packets by calling dwc_ep0_activate.
+ */
+int32_t dwc_otg_pcd_handle_enum_done_intr(dwc_otg_pcd_t * _pcd)
+{
+	dwc_otg_pcd_ep_t * ep0 = &_pcd->ep0;
+	gintsts_data_t gintsts;
+	gusbcfg_data_t gusbcfg;
+	dwc_otg_core_global_regs_t * global_regs =
+	    GET_CORE_IF(_pcd)->core_global_regs;
+	uint32_t gsnpsid = global_regs->gsnpsid;
+	uint8_t utmi16b, utmi8b;
+	DWC_DEBUGPL(DBG_PCD, "SPEED ENUM\n");
+	if (gsnpsid >= (uint32_t) 0x4f54260a) {
+		utmi16b = 5;
+		utmi8b = 9;
+	} else {
+		utmi16b = 4;
+		utmi8b = 8;
+	}
+	dwc_otg_ep0_activate(GET_CORE_IF(_pcd), &ep0->dwc_ep);
+
+#ifdef DEBUG_EP0
+	print_ep0_state(_pcd);
+#endif	/*  */
+	_pcd->ep0state = EP0_IDLE;
+	ep0->stopped = 0;
+	_pcd->gadget.speed = get_device_speed(GET_CORE_IF(_pcd));
+
+	/* Set USB turnaround time based on device speed and PHY interface. */
+	gusbcfg.d32 = dwc_read_reg32(&global_regs->gusbcfg);
+	if (_pcd->gadget.speed == USB_SPEED_HIGH) {
+		if (GET_CORE_IF(_pcd)->hwcfg2.b.hs_phy_type ==
+			DWC_HWCFG2_HS_PHY_TYPE_ULPI) {
+
+		    /* ULPI interface */
+		    gusbcfg.b.usbtrdtim = 9;
+		}
+		if (GET_CORE_IF(_pcd)->hwcfg2.b.hs_phy_type ==
+		     DWC_HWCFG2_HS_PHY_TYPE_UTMI) {
+
+/////
+			/* UTMI+ interface */
+			if (GET_CORE_IF(_pcd)->hwcfg4.b.
+				utmi_phy_data_width == 0) {
+				gusbcfg.b.usbtrdtim = utmi8b;
+			} else if (GET_CORE_IF(_pcd)->hwcfg4.b.
+				    utmi_phy_data_width == 1) {
+				gusbcfg.b.usbtrdtim = utmi16b;
+			} else if (GET_CORE_IF(_pcd)->core_params->
+				    phy_utmi_width == 8) {
+				gusbcfg.b.usbtrdtim = utmi8b;
+			} else {
+				gusbcfg.b.usbtrdtim = utmi16b;
+			}
+		}
+		if (GET_CORE_IF(_pcd)->hwcfg2.b.hs_phy_type ==
+			DWC_HWCFG2_HS_PHY_TYPE_UTMI_ULPI) {
+			/* UTMI+  OR  ULPI interface */
+			if (gusbcfg.b.ulpi_utmi_sel == 1) {
+			    /* ULPI interface */
+			    gusbcfg.b.usbtrdtim = 9;
+			} else {
+			    /* UTMI+ interface */
+			    if (GET_CORE_IF(_pcd)->core_params->
+					phy_utmi_width == 16) {
+					gusbcfg.b.usbtrdtim = utmi16b;
+				} else {
+					gusbcfg.b.usbtrdtim = utmi8b;
+				}
+			}
+		}
+	} else {
+		/* Full or low speed */
+		gusbcfg.b.usbtrdtim = 9;
+	}
+	dwc_write_reg32(&global_regs->gusbcfg, gusbcfg.d32);
+
+    /* Clear interrupt */
+    gintsts.d32 = 0;
+	gintsts.b.enumdone = 1;
+	dwc_write_reg32(&GET_CORE_IF(_pcd)->core_global_regs->gintsts,
+			 gintsts.d32);
+	return 1;
+}
+
+/**
+ * This interrupt indicates that the ISO OUT Packet was dropped due to
+ * Rx FIFO full or Rx Status Queue Full.  If this interrupt occurs
+ * read all the data from the Rx FIFO.
+ */
+int32_t dwc_otg_pcd_handle_isoc_out_packet_dropped_intr(dwc_otg_pcd_t *
+							    _pcd)
+{
+	gintmsk_data_t intr_mask = {.d32 = 0};
+	gintsts_data_t gintsts;
+	DWC_PRINT("INTERRUPT Handler not implemented for %s\n",
+		    "ISOC Out Dropped");
+	intr_mask.b.isooutdrop = 1;
+	dwc_modify_reg32(&GET_CORE_IF(_pcd)->core_global_regs->gintmsk,
+			  intr_mask.d32, 0);
+
+	/* Clear interrupt */
+	gintsts.d32 = 0;
+	gintsts.b.isooutdrop = 1;
+	dwc_write_reg32(&GET_CORE_IF(_pcd)->core_global_regs->gintsts,
+			 gintsts.d32);
+	return 1;
+}
+
+/**
+ * This interrupt indicates the end of the portion of the micro-frame
+ * for periodic transactions.  If there is a periodic transaction for
+ * the next frame, load the packets into the EP periodic Tx FIFO.
+ */
+int32_t dwc_otg_pcd_handle_end_periodic_frame_intr(dwc_otg_pcd_t * _pcd)
+{
+	gintmsk_data_t intr_mask = {.d32 = 0};
+	gintsts_data_t gintsts;
+	DWC_PRINT("INTERRUPT Handler not implemented for %s\n",
+		   "End of Periodic Portion of Micro-Frame Interrupt");
+	intr_mask.b.eopframe = 1;
+	dwc_modify_reg32(&GET_CORE_IF(_pcd)->core_global_regs->gintmsk,
+			  intr_mask.d32, 0);
+
+	/* Clear interrupt */
+	gintsts.d32 = 0;
+	gintsts.b.eopframe = 1;
+	dwc_write_reg32(&GET_CORE_IF(_pcd)->core_global_regs->gintsts,
+			 gintsts.d32);
+	return 1;
+}
+
+/**
+ * This interrupt indicates that EP of the packet on the top of the
+ * non-periodic Tx FIFO does not match EP of the IN Token received.
+ *
+ * The "Device IN Token Queue" Registers are read to determine the
+ * order the IN Tokens have been received.	The non-periodic Tx FIFO
+ * is flushed, so it can be reloaded in the order seen in the IN Token
+ * Queue.
+ */
+int32_t dwc_otg_pcd_handle_ep_mismatch_intr(dwc_otg_core_if_t * _core_if)
+{
+	gintsts_data_t gintsts;
+	DWC_DEBUGPL(DBG_PCDV, "%s(%p)\n", __func__, _core_if);
+
+	/* Clear interrupt */
+	gintsts.d32 = 0;
+	gintsts.b.epmismatch = 1;
+	dwc_write_reg32(&_core_if->core_global_regs->gintsts, gintsts.d32);
+	return 1;
+}
+
+/**
+ * This funcion stalls EP0.
+ */
+static inline void ep0_do_stall(dwc_otg_pcd_t * _pcd, const int err_val)
+{
+	dwc_otg_pcd_ep_t * ep0 = &_pcd->ep0;
+	struct usb_ctrlrequest *ctrl = &_pcd->setup_pkt->req;
+	DWC_WARN("req %02x.%02x protocol STALL; err %d\n", ctrl->bRequestType,
+		  ctrl->bRequest, err_val);
+	ep0->dwc_ep.is_in = 1;
+	dwc_otg_ep_set_stall(_pcd->otg_dev->core_if, &ep0->dwc_ep);
+	_pcd->ep0.stopped = 1;
+	_pcd->ep0state = EP0_IDLE;
+	ep0_out_start(GET_CORE_IF(_pcd), _pcd);
+}
+
+/**
+ * This functions delegates the setup command to the gadget driver.
+ */
+static inline void do_gadget_setup(dwc_otg_pcd_t * _pcd,
+				   struct usb_ctrlrequest *_ctrl)
+{
+	int ret = 0;
+	if (_pcd->driver && _pcd->driver->setup) {
+		SPIN_UNLOCK(&_pcd->lock);
+		ret = _pcd->driver->setup(&_pcd->gadget, _ctrl);
+		SPIN_LOCK(&_pcd->lock);
+		if (ret < 0) {
+			ep0_do_stall(_pcd, ret);
+		}
+
+		/** @todo This is a g_file_storage gadget driver specific
+		 * workaround: a DELAYED_STATUS result from the fsg_setup
+		 * routine will result in the gadget queueing a EP0 IN status
+		 * phase for a two-stage control transfer.	Exactly the same as
+		 * a SET_CONFIGURATION/SET_INTERFACE except that this is a class
+		 * specific request.  Need a generic way to know when the gadget
+		 * driver will queue the status phase.	Can we assume when we
+		 * call the gadget driver setup() function that it will always
+		 * queue and require the following flag?  Need to look into
+		 * this.
+		 */
+		if (ret == 256 + 999) {
+			_pcd->request_config = 1;
+		}
+	}
+}
+
+/**
+ * This function starts the Zero-Length Packet for the IN status phase
+ * of a 2 stage control transfer.
+ */
+static inline void do_setup_in_status_phase(dwc_otg_pcd_t * _pcd)
+{
+	dwc_otg_pcd_ep_t * ep0 = &_pcd->ep0;
+	if (_pcd->ep0state == EP0_STALL) {
+		return;
+	}
+	_pcd->ep0state = EP0_STATUS;
+
+	/* Prepare for more SETUP Packets */
+	DWC_DEBUGPL(DBG_PCD, "EP0 IN ZLP\n");
+	ep0->dwc_ep.xfer_len = 0;
+	ep0->dwc_ep.xfer_count = 0;
+	ep0->dwc_ep.is_in = 1;
+	ep0->dwc_ep.dma_addr = _pcd->setup_pkt_dma_handle;
+	dwc_otg_ep0_start_transfer(GET_CORE_IF(_pcd), &ep0->dwc_ep);
+
+	/* Prepare for more SETUP Packets */
+	ep0_out_start(GET_CORE_IF(_pcd), _pcd);
+}
+
+/**
+ * This function starts the Zero-Length Packet for the OUT status phase
+ * of a 2 stage control transfer.
+ */
+static inline void do_setup_out_status_phase(dwc_otg_pcd_t * _pcd)
+{
+	dwc_otg_pcd_ep_t * ep0 = &_pcd->ep0;
+	if (_pcd->ep0state == EP0_STALL) {
+		DWC_DEBUGPL(DBG_PCD, "EP0 STALLED\n");
+		return;
+	}
+	_pcd->ep0state = EP0_STATUS;
+
+	/* Prepare for more SETUP Packets */
+	//ep0_out_start( GET_CORE_IF(_pcd), _pcd );
+	DWC_DEBUGPL(DBG_PCD, "EP0 OUT ZLP\n");
+	ep0->dwc_ep.xfer_len = 0;
+	ep0->dwc_ep.xfer_count = 0;
+	ep0->dwc_ep.is_in = 0;
+
+	//ep0->dwc_ep.dma_addr = 0xffffffff;
+	ep0->dwc_ep.dma_addr = _pcd->setup_pkt_dma_handle;
+	dwc_otg_ep0_start_transfer(GET_CORE_IF(_pcd), &ep0->dwc_ep);
+
+	/* Prepare for more SETUP Packets */
+	ep0_out_start(GET_CORE_IF(_pcd), _pcd);
+}
+
+/**
+ * Clear the EP halt (STALL) and if pending requests start the
+ * transfer.
+ */
+static inline void pcd_clear_halt(dwc_otg_pcd_t * _pcd,
+				  dwc_otg_pcd_ep_t * _ep)
+{
+	if (_ep->dwc_ep.stall_clear_flag == 0)
+		dwc_otg_ep_clear_stall(GET_CORE_IF(_pcd), &_ep->dwc_ep);
+
+	/* Reactive the EP */
+	dwc_otg_ep_activate(GET_CORE_IF(_pcd), &_ep->dwc_ep);
+	if (_ep->stopped) {
+		_ep->stopped = 0;
+
+		/* If there is a request in the EP queue start it */
+
+		/** @todo FIXME: this causes an EP mismatch in DMA mode.
+		 * epmismatch not yet implemented. */
+
+		/*
+		 * Above fixme is solved by implmenting a tasklet to call the
+		 * start_next_request(), outside of interrupt context at some
+		 * time after the current time, after a clear-halt setup packet.
+		 * Still need to implement ep mismatch in the future if a gadget
+		 * ever uses more than one endpoint at once
+		 */
+		if (GET_CORE_IF(_pcd)->dma_enable) {
+			_ep->queue_sof = 1;
+			tasklet_schedule(_pcd->start_xfer_tasklet);
+		} else {
+#ifdef CONFIG_405EZ
+			/*
+			 * Added-sr: 2007-07-26
+			 *
+			 * To re-enable this endpoint it's important to
+			 * set this next_ep number. Otherwise the endpoint
+			 * will not get active again after stalling.
+			 */
+//test-only			_ep->pcd->next_ep = _ep->dwc_ep.num;
+			start_next_request( _ep );
+#endif
+#if 0
+			    _ep->queue_sof = 1;
+			DWC_ERROR("tasklet schedule\n");
+			tasklet_schedule(_pcd->start_xfer_tasklet);
+			if (GET_CORE_IF(_pcd)->core_params->opt)
+				 {
+				start_next_request(_ep);
+				}
+
+#endif	/*  */
+		}
+	}
+
+	/* Start Control Status Phase */
+	do_setup_in_status_phase(_pcd);
+}
+
+/**
+ * This function is called when the SET_FEATURE TEST_MODE Setup packet
+ * is sent from the host.  The Device Control register is written with
+ * the Test Mode bits set to the specified Test Mode.  This is done as
+ * a tasklet so that the "Status" phase of the control transfer
+ * completes before transmitting the TEST packets.
+ *
+ * @todo This has not been tested since the tasklet struct was put
+ * into the PCD struct!
+ *
+ */
+static void do_test_mode(unsigned long _data)
+{
+	dctl_data_t dctl;
+	dwc_otg_pcd_t * pcd = (dwc_otg_pcd_t *) _data;
+	dwc_otg_core_if_t * core_if = GET_CORE_IF(pcd);
+	int test_mode = pcd->test_mode;
+
+//        DWC_WARN("%s() has not been tested since being rewritten!\n", __func__);
+	dctl.d32 = dwc_read_reg32(&core_if->dev_if->dev_global_regs->dctl);
+	switch (test_mode) {
+	case 1:		// TEST_J
+		dctl.b.tstctl = 1;
+		break;
+	case 2:		// TEST_K
+		dctl.b.tstctl = 2;
+		break;
+	case 3:		// TEST_SE0_NAK
+		dctl.b.tstctl = 3;
+		break;
+	case 4:		// TEST_PACKET
+		dctl.b.tstctl = 4;
+		break;
+	case 5:		// TEST_FORCE_ENABLE
+		dctl.b.tstctl = 5;
+		break;
+	}
+	dwc_write_reg32(&core_if->dev_if->dev_global_regs->dctl, dctl.d32);
+}
+
+/**
+ * This function process the SET_FEATURE Setup Commands.
+ */
+static inline void do_set_feature(dwc_otg_pcd_t * _pcd)
+{
+	dwc_otg_core_if_t * core_if = GET_CORE_IF(_pcd);
+	dwc_otg_core_global_regs_t * global_regs = core_if->core_global_regs;
+	struct usb_ctrlrequest ctrl = _pcd->setup_pkt->req;
+	dwc_otg_pcd_ep_t * ep = 0;
+	int32_t otg_cap_param = core_if->core_params->otg_cap;
+	gotgctl_data_t gotgctl = {.d32 = 0};
+	DWC_DEBUGPL(DBG_PCD, "SET_FEATURE:%02x.%02x v%04x i%04x l%04x\n",
+		      ctrl.bRequestType, ctrl.bRequest,
+              __le16_to_cpu(ctrl.wValue), __le16_to_cpu(ctrl.wIndex),
+              __le16_to_cpu(ctrl.wLength));
+
+	DWC_DEBUGPL(DBG_PCD, "otg_cap=%d\n", otg_cap_param);
+	switch (ctrl.bRequestType & USB_RECIP_MASK) {
+	case USB_RECIP_DEVICE:
+        switch (__le16_to_cpu(ctrl.wValue)) {
+		case USB_DEVICE_REMOTE_WAKEUP:
+			_pcd->remote_wakeup_enable = 1;
+			break;
+		case USB_DEVICE_TEST_MODE:
+
+			/* Setup the Test Mode tasklet to do the Test
+			 * Packet generation after the SETUP Status
+			 * phase has completed. */
+
+			/** @todo This has not been tested since the
+			 * tasklet struct was put into the PCD
+			 * struct! */
+			_pcd->test_mode_tasklet.next = 0;
+			_pcd->test_mode_tasklet.state = 0;
+			atomic_set(&_pcd->test_mode_tasklet.count, 0);
+			_pcd->test_mode_tasklet.func = do_test_mode;
+			_pcd->test_mode_tasklet.data = (unsigned long)_pcd;
+			_pcd->test_mode = __le16_to_cpu(ctrl.wIndex) >> 8;
+			tasklet_schedule(&_pcd->test_mode_tasklet);
+			break;
+		case USB_DEVICE_B_HNP_ENABLE:
+			DWC_DEBUGPL(DBG_PCDV,
+				     "SET_FEATURE: USB_DEVICE_B_HNP_ENABLE\n");
+
+			/* dev may initiate HNP */
+			if (otg_cap_param == DWC_OTG_CAP_PARAM_HNP_SRP_CAPABLE) {
+				_pcd->b_hnp_enable = 1;
+				dwc_otg_pcd_update_otg(_pcd, 0);
+				DWC_DEBUGPL(DBG_PCD, "Request B HNP\n");
+
+				/**@todo Is the gotgctl.devhnpen cleared
+				 * by a USB Reset? */
+				gotgctl.b.devhnpen = 1;
+				gotgctl.b.hnpreq = 1;
+				dwc_write_reg32(&global_regs->gotgctl,gotgctl.d32);
+			} else {
+				ep0_do_stall(_pcd, -EOPNOTSUPP);
+			}
+			break;
+		case USB_DEVICE_A_HNP_SUPPORT:
+			/* RH port supports HNP */
+			DWC_DEBUGPL(DBG_PCDV,
+					"SET_FEATURE: USB_DEVICE_A_HNP_SUPPORT\n");
+			if (otg_cap_param == DWC_OTG_CAP_PARAM_HNP_SRP_CAPABLE) {
+				_pcd->a_hnp_support = 1;
+				dwc_otg_pcd_update_otg(_pcd, 0);
+			} else {
+				ep0_do_stall(_pcd, -EOPNOTSUPP);
+			}
+			break;
+		case USB_DEVICE_A_ALT_HNP_SUPPORT:
+			/* other RH port does */
+			DWC_DEBUGPL(DBG_PCDV,
+					"SET_FEATURE: USB_DEVICE_A_ALT_HNP_SUPPORT\n");
+			if (otg_cap_param == DWC_OTG_CAP_PARAM_HNP_SRP_CAPABLE) {
+				_pcd->a_alt_hnp_support = 1;
+				dwc_otg_pcd_update_otg(_pcd, 0);
+			} else {
+				ep0_do_stall(_pcd, -EOPNOTSUPP);
+			}
+			break;
+		}
+		do_setup_in_status_phase(_pcd);
+		break;
+	case USB_RECIP_INTERFACE:
+		do_gadget_setup(_pcd, &ctrl);
+		break;
+	case USB_RECIP_ENDPOINT:
+		if (__le16_to_cpu(ctrl.wValue) == USB_ENDPOINT_HALT) {
+			ep = get_ep_by_addr(_pcd, __le16_to_cpu(ctrl.wIndex));
+			if (ep == 0) {
+				ep0_do_stall(_pcd, -EOPNOTSUPP);
+				return;
+			}
+			ep->stopped = 1;
+			dwc_otg_ep_set_stall(core_if, &ep->dwc_ep);
+		}
+		do_setup_in_status_phase(_pcd);
+		break;
+	}
+}
+
+/**
+ * This function process the CLEAR_FEATURE Setup Commands.
+ */
+static inline void do_clear_feature(dwc_otg_pcd_t * _pcd)
+{
+	struct usb_ctrlrequest ctrl = _pcd->setup_pkt->req;
+	dwc_otg_pcd_ep_t * ep = 0;
+	DWC_DEBUGPL(DBG_PCD, "CLEAR_FEATURE:%02x.%02x v%04x i%04x l%04x\n",
+		       ctrl.bRequestType, ctrl.bRequest,
+			   __le16_to_cpu(ctrl.wValue), __le16_to_cpu(ctrl.wIndex),
+               __le16_to_cpu(ctrl.wLength));
+
+	switch (ctrl.bRequestType & USB_RECIP_MASK) {
+	case USB_RECIP_DEVICE:
+		switch (__le16_to_cpu(ctrl.wValue)) {
+		case USB_DEVICE_REMOTE_WAKEUP:
+			_pcd->remote_wakeup_enable = 0;
+			break;
+		case USB_DEVICE_TEST_MODE:
+			/** @todo Add CLEAR_FEATURE for TEST modes. */
+			break;
+		}
+		do_setup_in_status_phase(_pcd);
+		break;
+	case USB_RECIP_ENDPOINT:
+		ep = get_ep_by_addr(_pcd,__le16_to_cpu(ctrl.wIndex));
+		if (ep == 0) {
+			ep0_do_stall(_pcd, -EOPNOTSUPP);
+			return;
+		}
+		pcd_clear_halt(_pcd, ep);
+		DWC_DEBUGPL(DBG_PCD, "%s halt cleared by host\n",
+			      ep->ep.name);
+		break;
+	}
+}
+
+/**
+ *	This function processes SETUP commands.	 In Linux, the USB Command
+ *	processing is done in two places - the first being the PCD and the
+ *	second in the Gadget Driver (for example, the File-Backed Storage
+ *	Gadget Driver).
+ *
+ * <table>
+ * <tr><td>Command	</td><td>Driver </td><td>Description</td></tr>
+ *
+ * <tr><td>GET_STATUS </td><td>PCD </td><td>Command is processed as
+ * defined in chapter 9 of the USB 2.0 Specification chapter 9
+ * </td></tr>
+ *
+ * <tr><td>CLEAR_FEATURE </td><td>PCD </td><td>The Device and Endpoint
+ * requests are the ENDPOINT_HALT feature is procesed, all others the
+ * interface requests are ignored.</td></tr>
+ *
+ * <tr><td>SET_FEATURE </td><td>PCD </td><td>The Device and Endpoint
+ * requests are processed by the PCD.  Interface requests are passed
+ * to the Gadget Driver.</td></tr>
+ *
+ * <tr><td>SET_ADDRESS </td><td>PCD </td><td>Program the DCFG reg,
+ * with device address received </td></tr>
+ *
+ * <tr><td>GET_DESCRIPTOR </td><td>Gadget Driver </td><td>Return the
+ * requested descriptor</td></tr>
+ *
+ * <tr><td>SET_DESCRIPTOR </td><td>Gadget Driver </td><td>Optional -
+ * not implemented by any of the existing Gadget Drivers.</td></tr>
+ *
+ * <tr><td>SET_CONFIGURATION </td><td>Gadget Driver </td><td>Disable
+ * all EPs and enable EPs for new configuration.</td></tr>
+ *
+ * <tr><td>GET_CONFIGURATION </td><td>Gadget Driver </td><td>Return
+ * the current configuration</td></tr>
+ *
+ * <tr><td>SET_INTERFACE </td><td>Gadget Driver </td><td>Disable all
+ * EPs and enable EPs for new configuration.</td></tr>
+ *
+ * <tr><td>GET_INTERFACE </td><td>Gadget Driver </td><td>Return the
+ * current interface.</td></tr>
+ *
+ * <tr><td>SYNC_FRAME </td><td>PCD </td><td>Display debug
+ * message.</td></tr>
+ * </table>
+ *
+ * When the SETUP Phase Done interrupt occurs, the PCD SETUP commands are
+ * processed by pcd_setup. Calling the Function Driver's setup function from
+ * pcd_setup processes the gadget SETUP commands.
+ */
+static inline void pcd_setup(dwc_otg_pcd_t * _pcd)
+{
+	dwc_otg_core_if_t * core_if = GET_CORE_IF(_pcd);
+	dwc_otg_dev_if_t * dev_if = core_if->dev_if;
+	struct usb_ctrlrequest ctrl = _pcd->setup_pkt->req;
+	dwc_otg_pcd_ep_t * ep;
+	dwc_otg_pcd_ep_t * ep0 = &_pcd->ep0;
+	uint16_t * status = _pcd->status_buf;
+	deptsiz0_data_t doeptsize0 = {.d32 = 0};
+
+#ifdef DEBUG_EP0
+	DWC_DEBUGPL(DBG_PCD, "SETUP %02x.%02x v%04x i%04x l%04x\n",
+			ctrl.bRequestType, ctrl.bRequest, __le16_to_cpu(ctrl.wValue),
+			__le16_to_cpu(ctrl.wIndex), __le16_to_cpu(ctrl.wLength));
+
+#endif	/*  */
+	doeptsize0.d32 = dwc_read_reg32(&dev_if->out_ep_regs[0]->doeptsiz);
+
+	/** @todo handle > 1 setup packet , assert error for now */
+	if (core_if->dma_enable && (doeptsize0.b.supcnt < 2)) {
+		DWC_ERROR("\n\n	 CANNOT handle > 1 setup packet in DMA mode\n\n");
+	}
+
+	/* Clean up the request queue */
+	request_nuke(ep0);
+	ep0->stopped = 0;
+	if (ctrl.bRequestType & USB_DIR_IN) {
+		ep0->dwc_ep.is_in = 1;
+		_pcd->ep0state = EP0_IN_DATA_PHASE;
+	} else {
+		ep0->dwc_ep.is_in = 0;
+		_pcd->ep0state = EP0_OUT_DATA_PHASE;
+	}
+	if ((ctrl.bRequestType & USB_TYPE_MASK) != USB_TYPE_STANDARD) {
+	    /* handle non-standard (class/vendor) requests in the gadget driver */
+	    do_gadget_setup(_pcd, &ctrl);
+		return;
+	}
+
+	/** @todo NGS: Handle bad setup packet? */
+	switch (ctrl.bRequest) {
+	case USB_REQ_GET_STATUS:
+#ifdef DEBUG_EP0
+		    DWC_DEBUGPL(DBG_PCD,
+				"GET_STATUS %02x.%02x v%04x i%04x l%04x\n",
+				ctrl.bRequestType, ctrl.bRequest, __le16_to_cpu( ctrl.wValue),
+				__le16_to_cpu(ctrl.wIndex), __le16_to_cpu(ctrl.wLength));
+
+#endif	/*  */
+		switch (ctrl.bRequestType & USB_RECIP_MASK) {
+		case USB_RECIP_DEVICE:
+			*status = 0x1;	/* Self powered */
+			*status |= _pcd->remote_wakeup_enable << 1;
+			break;
+		case USB_RECIP_INTERFACE:
+			*status = 0;
+			break;
+		case USB_RECIP_ENDPOINT:
+			ep = get_ep_by_addr(_pcd, __le16_to_cpu(ctrl.wIndex));
+			if (ep == 0 || __le16_to_cpu(ctrl.wLength) > 2) {
+				ep0_do_stall(_pcd, -EOPNOTSUPP);
+				return;
+			}
+			/** @todo check for EP stall */
+			*status = ep->stopped;
+			break;
+		}
+		*status = __cpu_to_le16(*status);
+		_pcd->ep0_pending = 1;
+		ep0->dwc_ep.start_xfer_buff = (uint8_t *) status;
+		ep0->dwc_ep.xfer_buff = (uint8_t *) status;
+		ep0->dwc_ep.dma_addr = _pcd->status_buf_dma_handle;
+		ep0->dwc_ep.xfer_len = 2;
+		ep0->dwc_ep.xfer_count = 0;
+		ep0->dwc_ep.total_len = ep0->dwc_ep.xfer_len;
+		dwc_otg_ep0_start_transfer(GET_CORE_IF(_pcd), &ep0->dwc_ep);
+		break;
+	case USB_REQ_CLEAR_FEATURE:
+		do_clear_feature(_pcd);
+		break;
+	case USB_REQ_SET_FEATURE:
+		do_set_feature(_pcd);
+		break;
+	case USB_REQ_SET_ADDRESS:
+		if (ctrl.bRequestType == USB_RECIP_DEVICE) {
+			dcfg_data_t dcfg = {
+			.d32 = 0};
+
+#ifdef DEBUG_EP0
+			DWC_DEBUGPL(DBG_PCDV, "SET_ADDRESS:%d\n",
+					__le16_to_cpu(ctrl.wValue));
+
+#endif	/*  */
+			dcfg.b.devaddr = __le16_to_cpu(ctrl.wValue);
+			dwc_modify_reg32(&dev_if->dev_global_regs->dcfg, 0,
+					  dcfg.d32);
+#ifdef DEBUG_EP0
+
+            DWC_DEBUGPL(DBG_PCDV, "dcfg(after updating address :0x%x, dcfg.b.devaddr:%d\n",
+                     dwc_read_reg32(&dev_if->dev_global_regs->dcfg), dcfg.b.devaddr);
+#endif
+
+			do_setup_in_status_phase(_pcd);
+			return;
+		}
+		break;
+	case USB_REQ_SET_INTERFACE:
+	case USB_REQ_SET_CONFIGURATION:
+
+		//DWC_DEBUGPL(DBG_PCD, "SET_CONFIGURATION\n");
+		_pcd->request_config = 1;	/* Configuration changed */
+		do_gadget_setup(_pcd, &ctrl);
+		break;
+	case USB_REQ_SYNCH_FRAME:
+		do_gadget_setup(_pcd, &ctrl);
+		break;
+	default:
+		/* Call the Gadget Driver's setup functions */
+		do_gadget_setup(_pcd, &ctrl);
+		break;
+	}
+}
+
+/**
+ * This function completes the ep0 control transfer.
+ */
+static int32_t ep0_complete_request( dwc_otg_pcd_ep_t *_ep )
+{
+        dwc_otg_core_if_t *core_if = GET_CORE_IF(_ep->pcd);
+        dwc_otg_dev_if_t *dev_if = core_if->dev_if;
+        dwc_otg_dev_in_ep_regs_t *in_ep_regs =
+                dev_if->in_ep_regs[_ep->dwc_ep.num];
+#ifdef DEBUG_EP0
+        dwc_otg_dev_out_ep_regs_t *out_ep_regs =
+                dev_if->out_ep_regs[_ep->dwc_ep.num];
+#endif
+        deptsiz0_data_t deptsiz;
+        dwc_otg_pcd_request_t *req;
+        int is_last = 0;
+        dwc_otg_pcd_t *pcd = _ep->pcd;
+	static int counter =  0;  /*DFX added*/
+	counter++;
+        DWC_DEBUGPL(DBG_PCDV, "%s() %s\n", __func__, _ep->ep.name);
+	/*
+	if ( in_set_config == 1 )  {
+		printk(KERN_ERR "DFX ep0_complete_request in_set_config. ep0 pending: %d  list empty:"
+				" %d ep.is_in: %d ep0State: %d counter: %d\n",
+		       pcd->ep0_pending, list_empty(&_ep->queue), _ep->dwc_ep.is_in,
+		       pcd->ep0state, counter);
+	}
+	if ( in_set_config == 2 )  {
+		printk(KERN_ERR "DFX ep0_complete_request in_set_ADDRESS. ep0 pending: %d  list empty:"
+				" %d ep.is_in: %d ep0State: %d counter: %d\n",
+		       pcd->ep0_pending, list_empty(&_ep->queue), _ep->dwc_ep.is_in,
+		       pcd->ep0state, counter);
+	}
+	*/
+        if ((pcd->ep0_pending && list_empty(&_ep->queue)) /*|| counter == 1*/) {
+                if (_ep->dwc_ep.is_in) {
+#ifdef DEBUG_EP0
+                        DWC_DEBUGPL(DBG_PCDV, "Do setup OUT status phase\n");
+#endif
+                        do_setup_out_status_phase(pcd);
+                } else {
+#ifdef DEBUG_EP0
+                        DWC_DEBUGPL(DBG_PCDV, "Do setup IN status phase\n");
+#endif
+                        do_setup_in_status_phase(pcd);
+                }
+                pcd->ep0_pending = 0;
+                pcd->ep0state = EP0_STATUS;
+                return 1;
+        }
+
+
+	if (list_empty(&_ep->queue)) {
+		return 0;
+        }
+        req = list_entry(_ep->queue.next, dwc_otg_pcd_request_t, queue);
+	//printk(KERN_ERR "DFX compelete request req.zero: %d\n", req->req.zero);
+
+        if (pcd->ep0state == EP0_STATUS) {
+                is_last = 1;
+        }
+	/* DFX TODO Gadget zero sets req.zero to true when the data it is sending
+	 * to the host is shorter than the length specified by the host.  In this
+	 * case, if we also send a ZLP, we also somehow need to come back and
+	 * do_setup_out_status_phase()  Which apparently is not done.
+	 */
+	/* else if (req->req.zero) {
+		req->req.actual = _ep->dwc_ep.xfer_count;
+		//do_setup_in_status_phase (pcd);
+		req->req.zero = 0;
+		_ep->dwc_ep.xfer_len = 0;
+		_ep->dwc_ep.xfer_count = 0;
+		_ep->dwc_ep.sent_zlp = 1;
+		dwc_otg_ep0_start_transfer( GET_CORE_IF(pcd), &_ep->dwc_ep );
+		return 1;
+	}*/
+	else if (_ep->dwc_ep.is_in) {
+        	//printk(KERN_ERR "DFX complete request counter: %d\n", counter);
+                deptsiz.d32 = dwc_read_reg32( &in_ep_regs->dieptsiz);
+#ifdef DEBUG_EP0
+                DWC_DEBUGPL(DBG_PCDV, "%s len=%d  xfersize=%d pktcnt=%d\n",
+                            _ep->ep.name, _ep->dwc_ep.xfer_len,
+                            deptsiz.b.xfersize, deptsiz.b.pktcnt);
+#endif
+                if (deptsiz.b.xfersize == 0) {
+                        req->req.actual = _ep->dwc_ep.xfer_count;
+                        /* Is a Zero Len Packet needed? */
+                        //if (req->req.zero) {
+#ifdef DEBUG_EP0
+                                DWC_DEBUGPL(DBG_PCD, "Setup Rx ZLP\n");
+#endif
+				do_setup_out_status_phase(pcd);
+                }
+        } else {
+                /* ep0-OUT */
+#ifdef DEBUG_EP0
+                deptsiz.d32 = dwc_read_reg32( &out_ep_regs->doeptsiz);
+                DWC_DEBUGPL(DBG_PCDV, "%s len=%d xsize=%d pktcnt=%d\n",
+                            _ep->ep.name, _ep->dwc_ep.xfer_len,
+                            deptsiz.b.xfersize,
+                            deptsiz.b.pktcnt);
+#endif
+		req->req.actual = _ep->dwc_ep.xfer_count;
+
+                /* Is a Zero Len Packet needed? */
+                //if (req->req.zero) {
+#ifdef DEBUG_EP0
+                        DWC_DEBUGPL(DBG_PCDV, "Setup Tx ZLP\n");
+#endif
+                        do_setup_in_status_phase(pcd);
+        }
+
+        /* Complete the request */
+        if (is_last) {
+                request_done(_ep, req, 0);
+                _ep->dwc_ep.start_xfer_buff = 0;
+                _ep->dwc_ep.xfer_buff = 0;
+                _ep->dwc_ep.xfer_len = 0;
+                return 1;
+        }
+        return 0;
+}
+
+/**
+ * This function completes the request for the EP.	If there are
+ * additional requests for the EP in the queue they will be started.
+ */
+static void complete_ep(dwc_otg_pcd_ep_t * _ep)
+{
+	dwc_otg_core_if_t * core_if = GET_CORE_IF(_ep->pcd);
+	dwc_otg_dev_if_t * dev_if = core_if->dev_if;
+	dwc_otg_dev_in_ep_regs_t * in_ep_regs =
+	    dev_if->in_ep_regs[_ep->dwc_ep.num];
+	deptsiz_data_t deptsiz;
+	dwc_otg_pcd_request_t * req = 0;
+	int is_last = 0;
+	DWC_DEBUGPL(DBG_PCDV, "%s() %s-%s\n", __func__, _ep->ep.name,
+		      (_ep->dwc_ep.is_in ? "IN" : "OUT"));
+
+	/* Get any pending requests */
+	if (!list_empty(&_ep->queue)) {
+		req = list_entry(_ep->queue.next, dwc_otg_pcd_request_t, queue);
+	}
+	DWC_DEBUGPL(DBG_PCD, "Requests %d\n", _ep->pcd->request_pending);
+	if (_ep->dwc_ep.is_in) {
+		deptsiz.d32 = dwc_read_reg32(&in_ep_regs->dieptsiz);
+		if (core_if->dma_enable) {
+			if (deptsiz.b.xfersize == 0)
+				_ep->dwc_ep.xfer_count = _ep->dwc_ep.xfer_len;
+		}
+		DWC_DEBUGPL(DBG_PCDV, "%s len=%d  xfersize=%d pktcnt=%d\n",
+			      _ep->ep.name, _ep->dwc_ep.xfer_len,
+			      deptsiz.b.xfersize, deptsiz.b.pktcnt);
+		if (deptsiz.b.xfersize == 0 && deptsiz.b.pktcnt == 0
+		      && _ep->dwc_ep.xfer_count == _ep->dwc_ep.xfer_len) {
+			is_last = 1;
+		} else {
+			DWC_WARN("Incomplete transfer (%s-%s [siz=%d pkt=%d])\n",
+			     _ep->ep.name, (_ep->dwc_ep.is_in ? "IN" : "OUT"),
+			     deptsiz.b.xfersize, deptsiz.b.pktcnt);
+		}
+	} else {
+		dwc_otg_dev_out_ep_regs_t * out_ep_regs =
+		    dev_if->out_ep_regs[_ep->dwc_ep.num];
+		deptsiz.d32 = 0;
+		deptsiz.d32 = dwc_read_reg32(&out_ep_regs->doeptsiz);
+#ifdef CONFIG_DEBUG
+		    DWC_DEBUGPL(DBG_PCDV,
+				 "addr %p,	 %s len=%d cnt=%d xsize=%d pktcnt=%d\n",
+				 &out_ep_regs->doeptsiz, _ep->ep.name,
+				 _ep->dwc_ep.xfer_len,
+				 _ep->dwc_ep.xfer_count,
+				 deptsiz.b.xfersize, deptsiz.b.pktcnt);
+
+#endif	/*  */
+		    is_last = 1;
+	}
+
+	/* Complete the request */
+	if (is_last) {
+#ifdef CONFIG_405EZ
+		/*
+		 * Added-sr: 2007-07-26
+		 *
+		 * Since the 405EZ (Ultra) only support 2047 bytes as
+		 * max transfer size, we have to split up bigger transfers
+		 * into multiple transfers of 1024 bytes sized messages.
+		 * I happens often, that transfers of 4096 bytes are
+		 * required (zero-gadget, file_storage-gadget).
+		 */
+		if (_ep->dwc_ep.bytes_pending) {
+			dwc_otg_dev_in_ep_regs_t *in_regs =
+				core_if->dev_if->in_ep_regs[_ep->dwc_ep.num];
+			gintmsk_data_t intr_mask = { .d32 = 0};
+
+			_ep->dwc_ep.xfer_len = _ep->dwc_ep.bytes_pending;
+			if (_ep->dwc_ep.xfer_len > MAX_XFER_LEN) {
+				_ep->dwc_ep.bytes_pending = _ep->dwc_ep.xfer_len -
+					MAX_XFER_LEN;
+				_ep->dwc_ep.xfer_len = MAX_XFER_LEN;
+			} else {
+				_ep->dwc_ep.bytes_pending = 0;
+			}
+
+			/*
+			 * Restart the current transfer with the next "chunk"
+			 * of data.
+			 */
+			_ep->dwc_ep.xfer_count = 0;
+			deptsiz.d32 = dwc_read_reg32(&(in_regs->dieptsiz));
+                        deptsiz.b.xfersize = _ep->dwc_ep.xfer_len;
+                        deptsiz.b.pktcnt = (_ep->dwc_ep.xfer_len - 1 +
+					    _ep->dwc_ep.maxpacket) / _ep->dwc_ep.maxpacket;
+			dwc_write_reg32(&in_regs->dieptsiz, deptsiz.d32);
+
+                        intr_mask.b.nptxfempty = 1;
+                        dwc_modify_reg32( &core_if->core_global_regs->gintsts,
+                                          intr_mask.d32, 0);
+                        dwc_modify_reg32( &core_if->core_global_regs->gintmsk,
+                                          intr_mask.d32, intr_mask.d32);
+
+			/*
+			 * Just return here if message was not completely
+			 * transferred.
+			 */
+			return;
+		}
+#endif
+		if (core_if->dma_enable) {
+			req->req.actual =
+			    _ep->dwc_ep.xfer_len - deptsiz.b.xfersize;
+		} else {
+			req->req.actual = _ep->dwc_ep.xfer_count;
+		}
+		request_done(_ep, req, 0);
+		_ep->dwc_ep.start_xfer_buff = 0;
+		_ep->dwc_ep.xfer_buff = 0;
+		_ep->dwc_ep.xfer_len = 0;
+
+		/* If there is a request in the queue start it. */
+		start_next_request(_ep);
+	}
+}
+
+/**
+ * This function handles EP0 Control transfers.
+ *
+ * The state of the control tranfers are tracked in
+ * <code>ep0state</code>.
+ */
+static void handle_ep0(dwc_otg_pcd_t * _pcd)
+{
+	dwc_otg_core_if_t * core_if = GET_CORE_IF(_pcd);
+	dwc_otg_pcd_ep_t * ep0 = &_pcd->ep0;
+
+#ifdef DEBUG_EP0
+	DWC_DEBUGPL(DBG_PCDV, "%s()\n", __func__);
+	print_ep0_state(_pcd);
+
+#endif	/*  */
+	switch (_pcd->ep0state) {
+	case EP0_DISCONNECT:
+		break;
+	case EP0_IDLE:
+		_pcd->request_config = 0;
+		pcd_setup(_pcd);
+		break;
+	case EP0_IN_DATA_PHASE:
+
+#ifdef DEBUG_EP0
+		DWC_DEBUGPL(DBG_PCD, "DATA_IN EP%d-%s: type=%d, mps=%d\n",
+				ep0->dwc_ep.num,
+				(ep0->dwc_ep.is_in ? "IN" : "OUT"),
+				ep0->dwc_ep.type, ep0->dwc_ep.maxpacket);
+
+#endif	/*  */
+		if (core_if->dma_enable) {
+	    	/*
+	    	 * For EP0 we can only program 1 packet at a time so we
+	    	 * need to do the make calculations after each complete.
+	    	 * Call write_packet to make the calculations, as in
+	    	 * slave mode, and use those values to determine if we
+	    	 * can complete.
+	    	 */
+	    	dwc_otg_ep_write_packet(core_if, &ep0->dwc_ep, 1);
+		}
+#ifdef CONFIG_DWC_SLAVE
+        else {
+            dwc_otg_ep_write_packet(core_if, &ep0->dwc_ep, 0);
+        }
+#endif
+
+		if (ep0->dwc_ep.xfer_count < ep0->dwc_ep.total_len) {
+			dwc_otg_ep0_continue_transfer(GET_CORE_IF(_pcd),
+						       &ep0->dwc_ep);
+			DWC_DEBUGPL(DBG_PCD, "CONTINUE TRANSFER\n");
+		} else {
+			ep0_complete_request(ep0);
+			DWC_DEBUGPL(DBG_PCD, "COMPLETE TRANSFER\n");
+		}
+		break;
+	case EP0_OUT_DATA_PHASE:
+#ifdef DEBUG_EP0
+	    DWC_DEBUGPL(DBG_PCD, "DATA_OUT EP%d-%s: type=%d, mps=%d\n",
+				ep0->dwc_ep.num,
+				(ep0->dwc_ep.is_in ? "IN" : "OUT"),
+				ep0->dwc_ep.type, ep0->dwc_ep.maxpacket);
+
+#endif	/*  */
+		ep0_complete_request(ep0);
+		break;
+	case EP0_STATUS:
+		DWC_DEBUGPL(DBG_PCD, "CASE: EP0_STATUS\n");
+		ep0_complete_request(ep0);
+		_pcd->ep0state = EP0_IDLE;
+		ep0->stopped = 1;
+		ep0->dwc_ep.is_in = 0;	/* OUT for next SETUP */
+
+		/* Prepare for more SETUP Packets */
+		if (core_if->dma_enable) {
+			ep0_out_start(core_if, _pcd);
+		}
+		if (!GET_CORE_IF(_pcd)->dma_enable) {
+			int i;
+			depctl_data_t diepctl;
+			diepctl.d32 =dwc_read_reg32(&core_if->dev_if->in_ep_regs[0]->diepctl);
+			if (_pcd->ep0.queue_sof) {
+				_pcd->ep0.queue_sof = 0;
+				start_next_request(&_pcd->ep0);
+			}
+			diepctl.d32 =dwc_read_reg32(&core_if->dev_if->in_ep_regs[0]->diepctl);
+			if (_pcd->ep0.queue_sof) {
+				_pcd->ep0.queue_sof = 0;
+				start_next_request(&_pcd->ep0);
+			}
+			for (i = 0; i < core_if->dev_if->num_in_eps; i++) {
+				diepctl.d32 = dwc_read_reg32(&core_if->dev_if->in_ep_regs[i + 1]->diepctl);
+				if (_pcd->in_ep[i].queue_sof) {
+					_pcd->in_ep[i].queue_sof = 0;
+					start_next_request(&_pcd->in_ep[i]);
+				}
+			}
+		}
+		break;
+	case EP0_STALL:
+		DWC_ERROR("EP0 STALLed, should not get here pcd_setup()\n");
+		break;
+	}
+
+#ifdef DEBUG_EP0
+	    print_ep0_state(_pcd);
+#endif	/*  */
+}
+
+/**
+ * Restart transfer
+ */
+static void restart_transfer(dwc_otg_pcd_t * _pcd, const uint32_t _epnum)
+{
+	dwc_otg_core_if_t * core_if = GET_CORE_IF(_pcd);
+	dwc_otg_dev_if_t * dev_if = core_if->dev_if;
+	deptsiz_data_t dieptsiz = {.d32 = 0};
+
+	//depctl_data_t diepctl = {.d32=0};
+	dwc_otg_pcd_ep_t * ep;
+	dieptsiz.d32 = dwc_read_reg32(&dev_if->in_ep_regs[_epnum]->dieptsiz);
+	ep = get_in_ep(_pcd, _epnum);
+
+/*
+	if(_epnum != 0)
+		ep = &_pcd->in_ep[ _epnum - 1];
+	else
+		ep = &_pcd->ep0;
+*/
+	DWC_DEBUGPL(DBG_PCD, "xfer_buff=%p xfer_count=%0x xfer_len=%0x"
+			" stopped=%d\n", ep->dwc_ep.xfer_buff,
+			ep->dwc_ep.xfer_count, ep->dwc_ep.xfer_len,
+			ep->stopped);
+
+	/*
+	 * If xfersize is 0 and pktcnt in not 0, resend the last packet.
+	 */
+	if (dieptsiz.b.pktcnt && dieptsiz.b.xfersize == 0
+		&& ep->dwc_ep.start_xfer_buff != 0) {
+		if (ep->dwc_ep.xfer_len <= ep->dwc_ep.maxpacket) {
+			ep->dwc_ep.xfer_count = 0;
+			ep->dwc_ep.xfer_buff = ep->dwc_ep.start_xfer_buff;
+		} else {
+			ep->dwc_ep.xfer_count -= ep->dwc_ep.maxpacket;
+
+			/* convert packet size to dwords. */
+			ep->dwc_ep.xfer_buff -= ep->dwc_ep.maxpacket;
+		}
+		ep->stopped = 0;
+		DWC_DEBUGPL(DBG_PCD, "xfer_buff=%p xfer_count=%0x "
+			     "xfer_len=%0x stopped=%d\n", ep->dwc_ep.xfer_buff,
+			     ep->dwc_ep.xfer_count, ep->dwc_ep.xfer_len,
+			     ep->stopped );
+		if (_epnum == 0) {
+			dwc_otg_ep0_start_transfer(core_if, &ep->dwc_ep);
+		} else {
+			dwc_otg_ep_start_transfer(core_if, &ep->dwc_ep);
+		}
+	}
+}
+
+/**
+ * handle the IN EP disable interrupt.
+ */
+static inline void handle_in_ep_disable_intr(dwc_otg_pcd_t * _pcd,
+					     const uint32_t _epnum)
+{
+	dwc_otg_core_if_t * core_if = GET_CORE_IF(_pcd);
+	dwc_otg_dev_if_t * dev_if = core_if->dev_if;
+	deptsiz_data_t dieptsiz = {.d32 = 0};
+	dctl_data_t dctl = {.d32 = 0};
+	dwc_otg_pcd_ep_t * ep;
+	dwc_ep_t * dwc_ep;
+	ep = get_in_ep(_pcd, _epnum);
+	dwc_ep = &ep->dwc_ep;
+/*
+	if(_epnum != 0)
+	{
+		ep = &_pcd->in_ep[ _epnum - 1];
+		dwc_ep = &_pcd->in_ep[ _epnum - 1].dwc_ep;
+	}
+	else
+	{
+		ep = &_pcd->ep0;
+		dwc_ep = &_pcd->ep0.dwc_ep;
+	}
+*/
+	DWC_DEBUGPL(DBG_PCD, "diepctl%d=%0x\n", _epnum,
+			dwc_read_reg32(&dev_if->in_ep_regs[_epnum]->diepctl));
+	dieptsiz.d32 = dwc_read_reg32(&dev_if->in_ep_regs[_epnum]->dieptsiz);
+	DWC_DEBUGPL(DBG_ANY, "pktcnt=%d size=%d\n", dieptsiz.b.pktcnt,
+		      dieptsiz.b.xfersize);
+	if (ep->stopped) {
+
+		/* Flush the Tx FIFO */
+		/** @todo NGS: This is not the correct FIFO */
+		dwc_otg_flush_tx_fifo(core_if, 0);
+
+		/* Clear the Global IN NP NAK */
+		dctl.d32 = 0;
+		dctl.b.cgnpinnak = 1;
+		dwc_modify_reg32(&dev_if->dev_global_regs->dctl, dctl.d32, 0);
+
+		/* Restart the transaction */
+		if (dieptsiz.b.pktcnt != 0 || dieptsiz.b.xfersize != 0) {
+			restart_transfer(_pcd, _epnum);
+		}
+	} else {
+
+		/* Restart the transaction */
+		if (dieptsiz.b.pktcnt != 0 || dieptsiz.b.xfersize != 0) {
+			restart_transfer(_pcd, _epnum);
+		}
+		DWC_DEBUGPL(DBG_ANY, "STOPPED!!!\n");
+	}
+}
+
+/**
+ * Handler for the IN EP timeout handshake interrupt.
+ */
+static inline void handle_in_ep_timeout_intr(dwc_otg_pcd_t * _pcd,
+					     const uint32_t _epnum)
+{
+	dwc_otg_core_if_t * core_if = GET_CORE_IF(_pcd);
+	dwc_otg_dev_if_t * dev_if = core_if->dev_if;
+
+#ifdef CONFIG_DWC_DEBUG
+	deptsiz_data_t dieptsiz = {.d32 = 0};
+	uint32_t epnum = 0;
+
+#endif	/*  */
+	dctl_data_t dctl = {
+	.d32 = 0};
+	dwc_otg_pcd_ep_t * ep;
+	gintmsk_data_t intr_mask = {.d32 = 0};
+	ep = get_in_ep(_pcd, _epnum);
+
+/*
+	if(_epnum != 0)
+		ep = &_pcd->in_ep[ _epnum - 1];
+	else
+		ep = &_pcd->ep0;
+*/
+
+	/* Disable the NP Tx Fifo Empty Interrrupt */
+	if (!core_if->dma_enable) {
+		intr_mask.b.nptxfempty = 1;
+		dwc_modify_reg32(&core_if->core_global_regs->gintmsk,
+				  intr_mask.d32, 0);
+	}
+
+	/** @todo NGS Check EP type.
+	 * Implement for Periodic EPs */
+	    /*
+	     * Non-periodic EP
+	     */
+	/* Enable the Global IN NAK Effective Interrupt */
+	intr_mask.d32 = 0;			/* Bug fixed - clear mask b4 reusing */
+	intr_mask.b.ginnakeff = 1;
+	dwc_modify_reg32(&core_if->core_global_regs->gintmsk, 0,
+			  intr_mask.d32);
+
+	/* Set Global IN NAK */
+	dctl.b.sgnpinnak = 1;
+	dwc_modify_reg32(&dev_if->dev_global_regs->dctl, dctl.d32, dctl.d32);
+	ep->stopped = 1;
+
+#ifdef CONFIG_DWC_DEBUG
+	dieptsiz.d32 = dwc_read_reg32(&dev_if->in_ep_regs[epnum]->dieptsiz);
+	DWC_DEBUGPL(DBG_ANY, "pktcnt=%d size=%d\n", dieptsiz.b.pktcnt,
+		     dieptsiz.b.xfersize);
+
+#endif	/*  */
+
+#ifdef DISABLE_PERIODIC_EP
+	/*
+	 * Set the NAK bit for this EP to
+	 * start the disable process.
+	 */
+	diepctl.d32 = 0;
+	diepctl.b.snak = 1;
+	dwc_modify_reg32(&dev_if->in_ep_regs[epnum]->diepctl, diepctl.d32,
+			  diepctl.d32);
+	ep->disabling = 1;
+	ep->stopped = 1;
+
+#endif	/*  */
+}
+
+/**
+ * This interrupt indicates that an IN EP has a pending Interrupt.
+ * The sequence for handling the IN EP interrupt is shown below:
+ * -#	Read the Device All Endpoint Interrupt register
+ * -#	Repeat the following for each IN EP interrupt bit set (from
+ *		LSB to MSB).
+ * -#	Read the Device Endpoint Interrupt (DIEPINTn) register
+ * -#	If "Transfer Complete" call the request complete function
+ * -#	If "Endpoint Disabled" complete the EP disable procedure.
+ * -#	If "AHB Error Interrupt" log error
+ * -#	If "Time-out Handshake" log error
+ * -#	If "IN Token Received when TxFIFO Empty" write packet to Tx
+ *		FIFO.
+ * -#	If "IN Token EP Mismatch" (disable, this is handled by EP
+ *		Mismatch Interrupt)
+ */
+static int32_t dwc_otg_pcd_handle_in_ep_intr(dwc_otg_pcd_t * _pcd)
+{
+
+#define CLEAR_IN_EP_INTR(__core_if,__epnum,__intr) \
+	    do { \
+		diepint_data_t diepint = {.d32 = 0}; \
+		diepint.b.__intr = 1; \
+		dwc_write_reg32(&__core_if->dev_if->in_ep_regs[__epnum]->diepint, \
+		diepint.d32); \
+	} while (0)
+
+	dwc_otg_core_if_t * core_if = GET_CORE_IF(_pcd);
+	dwc_otg_dev_if_t * dev_if = core_if->dev_if;
+	diepint_data_t diepint = {.d32 = 0};
+	depctl_data_t diepctl = {.d32 = 0};
+	uint32_t ep_intr;
+	uint32_t epnum = 0;
+	dwc_otg_pcd_ep_t * ep;
+	dwc_ep_t * dwc_ep;
+	uint32_t _empty_msk, _diepctl;
+	gintmsk_data_t intr_mask = {.d32 = 0};
+	DWC_DEBUGPL(DBG_PCDV, "%s(%p)\n", __func__, _pcd);
+
+	/* Read in the device interrupt bits */
+	ep_intr = dwc_otg_read_dev_all_in_ep_intr(core_if);
+
+	/* Service the Device IN interrupts for each endpoint */
+	while (ep_intr) {
+		if (ep_intr & 0x1) {
+		    /* Get EP pointer */
+		    ep = get_in_ep(_pcd, epnum);
+			dwc_ep = &ep->dwc_ep;
+			_diepctl = dwc_read_reg32(&dev_if->in_ep_regs[epnum]->diepctl);
+			_empty_msk = dwc_read_reg32(&dev_if->dev_global_regs->dtknqr4_fifoemptymsk);
+			DWC_DEBUGPL(DBG_PCDV,
+				      "IN EP INTERRUPT - %d\nepmty_msk - %8x  diepctl - %8x\n",
+				      epnum, _empty_msk, _diepctl);
+			DWC_DEBUGPL(DBG_PCD, "EP%d-%s: type=%d, mps=%d\n",
+				      dwc_ep->num,(dwc_ep->is_in ? "IN" : "OUT"),
+				      dwc_ep->type, dwc_ep->maxpacket);
+			diepint.d32 = dwc_otg_read_dev_in_ep_intr(core_if, dwc_ep);
+			DWC_DEBUGPL(DBG_PCDV, "EP %d Interrupt Register - 0x%x\n",
+				      epnum, diepint.d32);
+
+		    /* Transfer complete */
+		    if (diepint.b.xfercompl) {
+				DWC_DEBUGPL(DBG_PCD,
+					      "EP%d IN Xfer Complete\n", epnum);
+
+				/* Disable the NP Tx FIFO Empty
+				 * Interrrupt */
+				if (core_if->en_multiple_tx_fifo == 0) {
+					intr_mask.b.nptxfempty = 1;
+					dwc_modify_reg32(&core_if->core_global_regs->gintmsk,
+							  intr_mask.d32, 0);
+				} else {
+					/* Disable the Tx FIFO Empty Interrupt for this EP */
+					uint32_t fifoemptymsk = 0x1 << dwc_ep->num;
+					dwc_modify_reg32(&core_if->dev_if->dev_global_regs->
+							  dtknqr4_fifoemptymsk,fifoemptymsk, 0);
+				}
+
+				/* Clear the bit in DIEPINTn for this interrupt */
+				CLEAR_IN_EP_INTR(core_if, epnum, xfercompl);
+
+				/* Complete the transfer */
+				if (epnum == 0) {
+					handle_ep0(_pcd);
+				} else {
+					complete_ep(ep);
+				}
+			}
+
+			/* Endpoint disable      */
+			if (diepint.b.epdisabled) {
+				DWC_DEBUGPL(DBG_ANY, "EP%d IN disabled\n", epnum);
+				handle_in_ep_disable_intr(_pcd, epnum);
+
+				/* Clear the bit in DIEPINTn for this interrupt */
+				CLEAR_IN_EP_INTR(core_if, epnum, epdisabled);
+			}
+
+			/* AHB Error */
+			if (diepint.b.ahberr) {
+				DWC_DEBUGPL(DBG_ANY, "EP%d IN AHB Error\n", epnum);
+
+				/* Clear the bit in DIEPINTn for this interrupt */
+				CLEAR_IN_EP_INTR(core_if, epnum, ahberr);
+			}
+
+			/* TimeOUT Handshake (non-ISOC IN EPs) */
+			if (diepint.b.timeout) {
+				DWC_DEBUGPL(DBG_ANY, "EP%d IN Time-out\n", epnum);
+				handle_in_ep_timeout_intr(_pcd, epnum);
+				CLEAR_IN_EP_INTR(core_if, epnum, timeout);
+			}
+
+			/** IN Token received with TxF Empty */
+			if (diepint.b.intktxfemp) {
+				DWC_DEBUGPL(DBG_ANY,"EP%d IN TKN TxFifo Empty\n",epnum);
+				if (!ep->stopped && epnum != 0) {
+					diepmsk_data_t diepmsk = {.d32 = 0};
+					diepmsk.b.intktxfemp = 1;
+					dwc_modify_reg32(&dev_if-> dev_global_regs->
+							  diepmsk, diepmsk.d32, 0);
+#ifdef CONFIG_405EZ
+					/*
+					 * Added-sr: 2007-07-26
+					 *
+					 * Only start the next transfer, when currently
+					 * no other transfer is active on this endpoint.
+					 */
+					if (dwc_ep->active == 0)
+						start_next_request(ep);
+#else
+					start_next_request(ep);
+#endif
+				}
+				CLEAR_IN_EP_INTR(core_if, epnum, intktxfemp);
+			}
+
+			/** IN Token Received with EP mismatch */
+			if (diepint.b.intknepmis) {
+				DWC_DEBUGPL(DBG_ANY,"EP%d IN TKN EP Mismatch\n",
+					     epnum);
+				CLEAR_IN_EP_INTR(core_if, epnum, intknepmis);
+			}
+
+			/** IN Endpoint NAK Effective */
+			if (diepint.b.inepnakeff) {
+				DWC_DEBUGPL(DBG_ANY, "EP%d IN EP NAK Effective\n",epnum);
+
+				/* Periodic EP */
+				if (ep->disabling) {
+					diepctl.d32 = 0;
+					diepctl.b.snak = 1;
+					diepctl.b.epdis = 1;
+					dwc_modify_reg32(&dev_if->in_ep_regs[epnum]->
+							  diepctl, diepctl.d32,diepctl.d32);
+				}
+				CLEAR_IN_EP_INTR(core_if, epnum, inepnakeff);
+			}
+
+			/** IN EP Tx FIFO Empty Intr */
+			if (diepint.b.emptyintr) {
+			DWC_DEBUGPL(DBG_ANY,"EP%d Tx FIFO Empty Intr \n",epnum);
+				write_empty_tx_fifo(_pcd, epnum);
+				/* VJ updated based on v2.65a */
+			//	CLEAR_IN_EP_INTR(core_if, epnum, emptyintr);
+			}
+		}
+		epnum++;
+		ep_intr >>= 1;
+	}
+	return 1;
+#undef CLEAR_IN_EP_INTR
+}
+
+/**
+ * This interrupt indicates that an OUT EP has a pending Interrupt.
+ * The sequence for handling the OUT EP interrupt is shown below:
+ * -#	Read the Device All Endpoint Interrupt register
+ * -#	Repeat the following for each OUT EP interrupt bit set (from
+ *		LSB to MSB).
+ * -#	Read the Device Endpoint Interrupt (DOEPINTn) register
+ * -#	If "Transfer Complete" call the request complete function
+ * -#	If "Endpoint Disabled" complete the EP disable procedure.
+ * -#	If "AHB Error Interrupt" log error
+ * -#	If "Setup Phase Done" process Setup Packet (See Standard USB
+ *		Command Processing)
+ */
+static int32_t dwc_otg_pcd_handle_out_ep_intr(dwc_otg_pcd_t * _pcd)
+{
+
+#define CLEAR_OUT_EP_INTR(__core_if,__epnum,__intr) \
+	    do { \
+		doepint_data_t doepint = { .d32 = 0}; \
+		doepint.b.__intr = 1; \
+		dwc_write_reg32(&__core_if->dev_if->out_ep_regs[__epnum]->doepint, \
+		doepint.d32); \
+	} while (0)
+
+	dwc_otg_core_if_t * core_if = GET_CORE_IF(_pcd);
+	uint32_t ep_intr;
+	doepint_data_t doepint = {.d32 = 0};
+	uint32_t epnum = 0;
+	dwc_ep_t * dwc_ep;
+	DWC_DEBUGPL(DBG_PCDV, "%s()\n", __func__);
+
+	/* Read in the device interrupt bits */
+	ep_intr = dwc_otg_read_dev_all_out_ep_intr(core_if);
+	while (ep_intr) {
+		if (ep_intr & 0x1) {
+		    /* Get EP pointer */
+		    dwc_ep = &((get_out_ep(_pcd, epnum))->dwc_ep);
+//                        dwc_ep = &_pcd->out_ep[ epnum - 1].dwc_ep;
+#ifdef VERBOSE
+			DWC_DEBUGPL(DBG_PCDV, "EP%d-%s: type=%d, mps=%d\n",
+					dwc_ep->num,
+					(dwc_ep->is_in ? "IN" : "OUT"),
+					dwc_ep->type, dwc_ep->maxpacket);
+
+#endif	/*  */
+			doepint.d32 = dwc_otg_read_dev_out_ep_intr(core_if, dwc_ep);
+
+		    /* Transfer complete */
+		    if (doepint.b.xfercompl) {
+				DWC_DEBUGPL(DBG_PCD,"EP%d OUT Xfer Complete\n",epnum);
+
+			    /* Clear the bit in DOEPINTn for this interrupt */
+			    CLEAR_OUT_EP_INTR(core_if, epnum,xfercompl);
+				if (epnum == 0) {
+					handle_ep0(_pcd);
+				} else {
+					complete_ep(get_out_ep(_pcd, epnum));
+					// complete_ep( &_pcd->out_ep[ epnum - 1] );
+				}
+			}
+
+		    /* Endpoint disable      */
+		    if (doepint.b.epdisabled) {
+				DWC_DEBUGPL(DBG_PCD, "EP%d OUT disabled\n",epnum);
+
+			    /* Clear the bit in DOEPINTn for this interrupt */
+			    CLEAR_OUT_EP_INTR(core_if, epnum,epdisabled);
+			}
+
+		    /* AHB Error */
+		    if (doepint.b.ahberr) {
+				DWC_DEBUGPL(DBG_PCD, "EP%d OUT AHB Error\n",
+					     epnum);
+				DWC_DEBUGPL(DBG_PCD, "EP DMA REG	 %d \n",
+					     core_if->dev_if->out_ep_regs[epnum]->doepdma);
+				CLEAR_OUT_EP_INTR(core_if, epnum, ahberr);
+			}
+
+		    /* Setup Phase Done (contorl EPs) */
+		    if (doepint.b.setup) {
+#ifdef DEBUG_EP0
+			    DWC_DEBUGPL(DBG_PCD, "EP%d SETUP Done\n",epnum);
+
+#endif	/*  */
+				handle_ep0(_pcd);
+				CLEAR_OUT_EP_INTR(core_if, epnum, setup);
+			}
+		}
+		epnum++;
+		ep_intr >>= 1;
+	}
+	return 1;
+
+#undef CLEAR_OUT_EP_INTR
+}
+
+/**
+ * Incomplete ISO IN Transfer Interrupt.
+ * This interrupt indicates one of the following conditions occurred
+ * while transmitting an ISOC transaction.
+ * - Corrupted IN Token for ISOC EP.
+ * - Packet not complete in FIFO.
+ * The follow actions will be taken:
+ *	-#	Determine the EP
+ *	-#	Set incomplete flag in dwc_ep structure
+ *	-#	Disable EP; when "Endpoint Disabled" interrupt is received
+ *		Flush FIFO
+ */
+int32_t dwc_otg_pcd_handle_incomplete_isoc_in_intr(dwc_otg_pcd_t * _pcd)
+{
+	gintmsk_data_t intr_mask = {.d32 = 0};
+	gintsts_data_t gintsts;
+	DWC_PRINT("INTERRUPT Handler not implemented for %s\n",
+		   "IN ISOC Incomplete");
+	intr_mask.b.incomplisoin = 1;
+	dwc_modify_reg32(&GET_CORE_IF(_pcd)->core_global_regs->gintmsk,
+			  intr_mask.d32, 0);
+
+	/* Clear interrupt */
+	gintsts.d32 = 0;
+	gintsts.b.incomplisoin = 1;
+	dwc_write_reg32(&GET_CORE_IF(_pcd)->core_global_regs->gintsts,
+			 gintsts.d32);
+	return 1;
+}
+
+/**
+ * Incomplete ISO OUT Transfer Interrupt.
+ *
+ * This interrupt indicates that the core has dropped an ISO OUT
+ * packet.	The following conditions can be the cause:
+ * - FIFO Full, the entire packet would not fit in the FIFO.
+ * - CRC Error
+ * - Corrupted Token
+ * The follow actions will be taken:
+ *	-#	Determine the EP
+ *	-#	Set incomplete flag in dwc_ep structure
+ *	-#	Read any data from the FIFO
+ *	-#	Disable EP.	 when "Endpoint Disabled" interrupt is received
+ *		re-enable EP.
+ */
+int32_t dwc_otg_pcd_handle_incomplete_isoc_out_intr(dwc_otg_pcd_t * _pcd)
+{
+
+	/** @todo implement ISR */
+	gintmsk_data_t intr_mask = {.d32 = 0};
+	gintsts_data_t gintsts;
+	DWC_PRINT("INTERRUPT Handler not implemented for %s\n",
+		   "OUT ISOC Incomplete");
+	intr_mask.b.incomplisoout = 1;
+	dwc_modify_reg32(&GET_CORE_IF(_pcd)->core_global_regs->gintmsk,
+			  intr_mask.d32, 0);
+
+	/* Clear interrupt */
+	gintsts.d32 = 0;
+	gintsts.b.incomplisoout = 1;
+	dwc_write_reg32(&GET_CORE_IF(_pcd)->core_global_regs->gintsts,
+			 gintsts.d32);
+	return 1;
+}
+
+/**
+ * This function handles the Global IN NAK Effective interrupt.
+ *
+ */
+int32_t dwc_otg_pcd_handle_in_nak_effective(dwc_otg_pcd_t * _pcd)
+{
+	dwc_otg_dev_if_t * dev_if = GET_CORE_IF(_pcd)->dev_if;
+	depctl_data_t diepctl = {.d32 = 0};
+	depctl_data_t diepctl_rd = {.d32 = 0};
+	gintmsk_data_t intr_mask = {.d32 = 0};
+	gintsts_data_t gintsts;
+	int i;
+	DWC_DEBUGPL(DBG_PCD, "Global IN NAK Effective\n");
+
+	/* Disable all active IN EPs */
+	diepctl.b.epdis = 1;
+	diepctl.b.snak = 1;
+	for (i = 0; i <= dev_if->num_in_eps; i++) {
+		diepctl_rd.d32 = dwc_read_reg32(&dev_if->in_ep_regs[i]->diepctl);
+		if (diepctl_rd.b.epena) {
+			dwc_write_reg32(&dev_if->in_ep_regs[i]->diepctl, diepctl.d32);
+		}
+	}
+
+	/* Disable the Global IN NAK Effective Interrupt */
+	intr_mask.b.ginnakeff = 1;
+	dwc_modify_reg32(&GET_CORE_IF(_pcd)->core_global_regs->gintmsk,
+			  intr_mask.d32, 0);
+
+	/* Clear interrupt */
+	gintsts.d32 = 0;
+	gintsts.b.ginnakeff = 1;
+	dwc_write_reg32(&GET_CORE_IF(_pcd)->core_global_regs->gintsts,
+			 gintsts.d32);
+	return 1;
+}
+
+/**
+ * OUT NAK Effective.
+ *
+ */
+int32_t dwc_otg_pcd_handle_out_nak_effective(dwc_otg_pcd_t * _pcd)
+{
+	gintmsk_data_t intr_mask = {.d32 = 0};
+	gintsts_data_t gintsts;
+	DWC_PRINT("INTERRUPT Handler not implemented for %s\n",
+		    "Global IN NAK Effective\n");
+
+	/* Disable the Global IN NAK Effective Interrupt */
+	intr_mask.b.goutnakeff = 1;
+	dwc_modify_reg32(&GET_CORE_IF(_pcd)->core_global_regs->gintmsk,
+			  intr_mask.d32, 0);
+
+	/* Clear interrupt */
+	gintsts.d32 = 0;
+	gintsts.b.goutnakeff = 1;
+	dwc_write_reg32(&GET_CORE_IF(_pcd)->core_global_regs->gintsts,
+			 gintsts.d32);
+	return 1;
+}
+
+/**
+ * PCD interrupt handler.
+ *
+ * The PCD handles the device interrupts.  Many conditions can cause a
+ * device interrupt. When an interrupt occurs, the device interrupt
+ * service routine determines the cause of the interrupt and
+ * dispatches handling to the appropriate function. These interrupt
+ * handling functions are described below.
+ *
+ * All interrupt registers are processed from LSB to MSB.
+ *
+ */
+int32_t dwc_otg_pcd_handle_intr(dwc_otg_pcd_t * _pcd)
+{
+	dwc_otg_core_if_t * core_if = GET_CORE_IF(_pcd);
+
+#ifdef VERBOSE
+	dwc_otg_core_global_regs_t * global_regs =
+		core_if->core_global_regs;
+#endif	/*  */
+	gintsts_data_t gintr_status;
+	int32_t retval = 0;
+
+	if (dwc_otg_is_device_mode(core_if)) {
+		SPIN_LOCK(&_pcd->lock);
+
+#ifdef VERBOSE
+	    DWC_DEBUGPL(DBG_PCDV, "%s() gintsts=%08x  gintmsk=%08x\n",
+				__func__,
+				dwc_read_reg32(&global_regs->gintsts),
+				dwc_read_reg32(&global_regs->gintmsk));
+
+#endif	/*  */
+	    gintr_status.d32 = dwc_otg_read_core_intr(core_if);
+		if (!gintr_status.d32) {
+			return 0;
+		}
+		DWC_DEBUGPL(DBG_PCDV, "%s: gintsts&gintmsk=%08x\n", __func__,
+			     gintr_status.d32);
+		if (gintr_status.b.sofintr) {
+			retval |= dwc_otg_pcd_handle_sof_intr(_pcd);
+		}
+#ifndef CONFIG_OTG_PLB_DMA_TASKLET
+		if (gintr_status.b.rxstsqlvl) {
+			retval |= dwc_otg_pcd_handle_rx_status_q_level_intr(_pcd);
+		}
+		if (gintr_status.b.nptxfempty) {
+			retval |= dwc_otg_pcd_handle_np_tx_fifo_empty_intr(_pcd);
+		}
+#endif
+		if (gintr_status.b.ginnakeff) {
+			retval |= dwc_otg_pcd_handle_in_nak_effective(_pcd);
+		}
+		if (gintr_status.b.goutnakeff) {
+			retval |= dwc_otg_pcd_handle_out_nak_effective(_pcd);
+		}
+		if (gintr_status.b.i2cintr) {
+			retval |= dwc_otg_pcd_handle_i2c_intr(_pcd);
+		}
+		if (gintr_status.b.erlysuspend) {
+			retval |= dwc_otg_pcd_handle_early_suspend_intr(_pcd);
+		}
+		if (gintr_status.b.usbreset) {
+			retval |= dwc_otg_pcd_handle_usb_reset_intr(_pcd);
+		}
+		if (gintr_status.b.enumdone) {
+			retval |= dwc_otg_pcd_handle_enum_done_intr(_pcd);
+		}
+		if (gintr_status.b.isooutdrop) {
+			retval |= dwc_otg_pcd_handle_isoc_out_packet_dropped_intr(_pcd);
+		}
+		if (gintr_status.b.eopframe) {
+			retval |= dwc_otg_pcd_handle_end_periodic_frame_intr(_pcd);
+		}
+		if (gintr_status.b.epmismatch) {
+			retval |= dwc_otg_pcd_handle_ep_mismatch_intr(core_if);
+		}
+		if (gintr_status.b.inepint) {
+			retval |= dwc_otg_pcd_handle_in_ep_intr(_pcd);
+		}
+		if (gintr_status.b.outepintr) {
+			retval |= dwc_otg_pcd_handle_out_ep_intr(_pcd);
+		}
+		if (gintr_status.b.incomplisoin) {
+			retval |= dwc_otg_pcd_handle_incomplete_isoc_in_intr(_pcd);
+		}
+		if (gintr_status.b.incomplisoout) {
+			retval |= dwc_otg_pcd_handle_incomplete_isoc_out_intr(_pcd);
+		}
+#ifdef VERBOSE
+	    DWC_DEBUGPL(DBG_PCDV, "%s() gintsts=%0x\n", __func__,
+				dwc_read_reg32(&global_regs->gintsts));
+
+#endif	/*  */
+#ifdef CONFIG_OTG_PLB_DMA_TASKLET
+		if (gintr_status.b.rxstsqlvl) {
+			retval |= dwc_otg_pcd_handle_rx_status_q_level_intr(_pcd);
+		}
+		if (!atomic_read(&release_later) &&  gintr_status.b.nptxfempty) {
+			retval |= dwc_otg_pcd_handle_np_tx_fifo_empty_intr(_pcd);
+		}
+#endif
+	    SPIN_UNLOCK(&_pcd->lock);
+	}
+	return retval;
+}
+
+
+#endif	/* DWC_HOST_ONLY */
diff -Naur a/drivers/usb/dwc_otg/dwc_otg_plat.h b/drivers/usb/dwc_otg/dwc_otg_plat.h
--- a/drivers/usb/dwc_otg/dwc_otg_plat.h	1970-01-01 00:00:00.000000000 +0000
+++ b/drivers/usb/dwc_otg/dwc_otg_plat.h	2017-06-22 17:45:15.318472014 +0000
@@ -0,0 +1,180 @@
+/* ==========================================================================
+ * $File: //dwh/usb_iip/dev/software/otg_ipmate/linux/platform/dwc_otg_plat.h $
+ * $Revision: #1 $
+ * $Date: 2005/07/07 $
+ * $Change: 510301 $
+ *
+ * Synopsys HS OTG Linux Software Driver and documentation (hereinafter,
+ * "Software") is an Unsupported proprietary work of Synopsys, Inc. unless
+ * otherwise expressly agreed to in writing between Synopsys and you.
+ *
+ * The Software IS NOT an item of Licensed Software or Licensed Product under
+ * any End User Software License Agreement or Agreement for Licensed Product
+ * with Synopsys or any supplement thereto. You are permitted to use and
+ * redistribute this Software in source and binary forms, with or without
+ * modification, provided that redistributions of source code must retain this
+ * notice. You may not view, use, disclose, copy or distribute this file or
+ * any information contained herein except pursuant to this license grant from
+ * Synopsys. If you do not agree with this notice, including the disclaimer
+ * below, then you are not authorized to use the Software.
+ *
+ * THIS SOFTWARE IS BEING DISTRIBUTED BY SYNOPSYS SOLELY ON AN "AS IS" BASIS
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE HEREBY DISCLAIMED. IN NO EVENT SHALL SYNOPSYS BE LIABLE FOR ANY DIRECT,
+ * INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+ * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+ * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+ * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
+ * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
+ * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH
+ * DAMAGE.
+ * ========================================================================== */
+
+#if !defined(__DWC_OTG_PLAT_H__)
+#define __DWC_OTG_PLAT_H__
+
+#include <linux/types.h>
+#include <linux/slab.h>
+#include <linux/list.h>
+#include <linux/delay.h>
+#include <asm/io.h>
+
+/* This file contains the Platform Specific constants, interfaces for Linux */
+#if !defined(CONFIG_4xx)
+#error "The contents of this file are AMCC 44x processor specific!!!"
+#endif
+
+#if defined(CONFIG_405EX) || defined(CONFIG_460EX) || \
+	defined(CONFIG_APM82181)
+#define CONFIG_DWC_OTG_REG_LE
+#endif
+
+#if defined(CONFIG_405EZ)
+#define CONFIG_DWC_OTG_FIFO_LE
+#endif
+
+#define SZ_256K  0x00040000
+/* Reads the content of a register
+ * Usage: uint32_t dev_ctl = dwc_read_reg32(&dev_regs->dctl); */
+static __always_inline uint32_t dwc_read_reg32( volatile uint32_t *_reg){
+#ifdef CONFIG_DWC_OTG_REG_LE
+	return in_le32(_reg);
+#else
+	return in_be32(_reg);
+#endif
+};
+
+/* Writes a register with a 32 bit value.
+ * Usage: dwc_write_reg32(&dev_regs->dctl, 0); */
+static __always_inline void dwc_write_reg32(volatile uint32_t *reg, const uint32_t value) {
+#ifdef CONFIG_DWC_OTG_REG_LE
+	out_le32(reg, value);
+#else
+	out_be32(reg, value);
+#endif
+};
+
+/* This function modifies bit values in a register.  Using the algorithm:
+ * (reg_contents & ~clear_mask) | set_mask.
+ * Usage: Clear the SOF Interrupt Mask bit and set the OTG Interrupt mask bit
+ *    dwc_modify_reg32(&dev_regs->gintmsk, DWC_SOF_INT, DWC_OTG_INT); */
+static __always_inline void dwc_modify_reg32(volatile uint32_t *reg,
+	const uint32_t clear_mask, const uint32_t set_mask) {
+#ifdef CONFIG_DWC_OTG_REG_LE
+	out_le32(reg, (in_le32(reg) & ~clear_mask) | set_mask );
+#else
+	out_be32(reg, (in_be32(reg) & ~clear_mask) | set_mask );
+#endif
+};
+
+static __always_inline void dwc_write_datafifo32(volatile uint32_t *reg, const uint32_t value){
+#ifdef CONFIG_DWC_OTG_FIFO_LE
+	out_le32(reg, value);
+#else
+	out_be32(reg, value);
+#endif
+};
+
+static __always_inline uint32_t dwc_read_datafifo32(volatile uint32_t *reg){
+#ifdef CONFIG_DWC_OTG_FIFO_LE
+	return in_le32(reg);
+#else
+	return in_be32(reg);
+#endif
+};
+
+/* Wrapper for the OS micro-second delay function */
+static __always_inline void UDELAY(const uint32_t usecs){ udelay(usecs); }
+
+/* Wrapper for the OS milli-second delay function */
+static __always_inline void MDELAY(const uint32_t msecs){ mdelay(msecs); }
+
+/* Wrapper for Linux spin_lock.  On ARM (Integrator) spin_lock() is a nop */
+static __always_inline void SPIN_LOCK(spinlock_t *lock) { spin_lock(lock); }
+
+/* Wrapper for Linux spin_unlock.  On  ARM (Integrator) spin_lock() is a nop */
+static __always_inline void SPIN_UNLOCK(spinlock_t *lock) {	spin_unlock(lock); }
+
+/* Wrapper (macro) for Linux spin_lock_irqsave.  On ARM (Integrator) spin_lock() is a nop */
+#define SPIN_LOCK_IRQSAVE(l,f) spin_lock_irqsave(l,f);
+
+/* Wrapper (macro) for Linux spin_unlock_irqrestore.  On ARM(Integrator) spin_lock() is a nop */
+#define SPIN_UNLOCK_IRQRESTORE(l,f)	spin_unlock_irqrestore(l,f);
+
+/* Debugging support vanishes in non-debug builds */
+/* The Debug Level bit-mask variable */
+extern uint32_t g_dbg_lvl;
+/* Set the Debug Level variable */
+static __always_inline uint32_t SET_DEBUG_LEVEL(const uint32_t new){
+	uint32_t old = g_dbg_lvl;
+	g_dbg_lvl = new;
+	return old;
+}
+
+/** When debug level has the DBG_CIL bit set, display CIL Debug messages. */
+#define DBG_CIL		(0x2)
+/** When debug level has the DBG_CILV bit set, display CIL Verbose debug messages */
+#define DBG_CILV	(0x20)
+/**  When debug level has the DBG_PCD bit set, display PCD (Device) debug messages */
+#define DBG_PCD		(0x4)
+/** When debug level has the DBG_PCDV set, display PCD (Device) Verbose debug messages */
+#define DBG_PCDV	(0x40)
+/** When debug level has the DBG_HCD bit set, display Host debug messages */
+#define DBG_HCD		(0x8)
+/** When debug level has the DBG_HCDV bit set, display Verbose Host debug messages */
+#define DBG_HCDV	(0x80)
+/** When debug level has the DBG_HCD_URB bit set, display enqueued URBs in host mode. */
+#define DBG_HCD_URB	(0x800)
+#define DBG_SP		(0x400)
+/* When debug level has any bit set, display debug messages */
+#define DBG_ANY		(0xFF)
+/* All debug messages off */
+#define DBG_OFF		0
+
+/* Prefix string for DWC_DEBUG print macros. */
+#define USB_DWC "dwc_otg: "
+
+/* Print a debug message when the Global debug level variable contains the bit defined in lvl
+ * Example: DWC_DEBUGPL( DBG_ANY, "%s(%p)\n", __func__, _reg_base_addr);
+ * usb-DWC_otg: dwc_otg_cil_init(ca867000) */
+#ifdef CONFIG_DWC_DEBUG
+# define DWC_DEBUGPL(lvl, x...) do{ if ((lvl)&g_dbg_lvl)printk( KERN_ERR USB_DWC x ); }while(0)
+# define DWC_DEBUGP(x...)	DWC_DEBUGPL(DBG_ANY, x )
+# define CHK_DEBUG_LEVEL(level) ((level) & g_dbg_lvl)
+#else
+# define DWC_DEBUGPL(lvl, x...) do{}while(0)
+# define DWC_DEBUGP(x...)
+# define CHK_DEBUG_LEVEL(level) (0)
+#endif /*DEBUG*/
+
+/* Print an Error message */
+#define DWC_ERROR(x...) printk( KERN_ERR USB_DWC x )
+/* Print a Warning message */
+#define DWC_WARN(x...) printk( KERN_WARNING USB_DWC x )
+/* Print a notice (normal but significant message) */
+#define DWC_NOTICE(x...) printk( KERN_NOTICE USB_DWC x )
+/* Basic message printing */
+#define DWC_PRINT(x...) printk( KERN_INFO USB_DWC x )
+
+#endif
diff -Naur a/drivers/usb/dwc_otg/dwc_otg_regs.h b/drivers/usb/dwc_otg/dwc_otg_regs.h
--- a/drivers/usb/dwc_otg/dwc_otg_regs.h	1970-01-01 00:00:00.000000000 +0000
+++ b/drivers/usb/dwc_otg/dwc_otg_regs.h	2016-01-31 16:10:52.000000000 +0000
@@ -0,0 +1,3606 @@
+/* ==========================================================================
+ * $File: //dwh/usb_iip/dev/software/otg_ipmate/linux/drivers/dwc_otg_regs.h $
+ * $Revision: #8 $
+ * $Date: 2007/02/07 $
+ * $Change: 791271 $
+ *
+ * Synopsys HS OTG Linux Software Driver and documentation (hereinafter,
+ * "Software") is an Unsupported proprietary work of Synopsys, Inc. unless
+ * otherwise expressly agreed to in writing between Synopsys and you.
+ *
+ * The Software IS NOT an item of Licensed Software or Licensed Product under
+ * any End User Software License Agreement or Agreement for Licensed Product
+ * with Synopsys or any supplement thereto. You are permitted to use and
+ * redistribute this Software in source and binary forms, with or without
+ * modification, provided that redistributions of source code must retain this
+ * notice. You may not view, use, disclose, copy or distribute this file or
+ * any information contained herein except pursuant to this license grant from
+ * Synopsys. If you do not agree with this notice, including the disclaimer
+ * below, then you are not authorized to use the Software.
+ *
+ * THIS SOFTWARE IS BEING DISTRIBUTED BY SYNOPSYS SOLELY ON AN "AS IS" BASIS
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE HEREBY DISCLAIMED. IN NO EVENT SHALL SYNOPSYS BE LIABLE FOR ANY DIRECT,
+ * INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+ * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+ * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+ * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
+ * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
+ * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH
+ * DAMAGE.
+ * ========================================================================== */
+
+#ifndef __DWC_OTG_REGS_H__
+#define __DWC_OTG_REGS_H__
+
+/**
+ * @file
+ *
+ * This file contains the data structures for accessing the DWC_otg core registers.
+ *
+ * The application interfaces with the HS OTG core by reading from and
+ * writing to the Control and Status Register (CSR) space through the
+ * AHB Slave interface. These registers are 32 bits wide, and the
+ * addresses are 32-bit-block aligned.
+ * CSRs are classified as follows:
+ * - Core Global Registers
+ * - Device Mode Registers
+ * - Device Global Registers
+ * - Device Endpoint Specific Registers
+ * - Host Mode Registers
+ * - Host Global Registers
+ * - Host Port CSRs
+ * - Host Channel Specific Registers
+ *
+ * Only the Core Global registers can be accessed in both Device and
+ * Host modes. When the HS OTG core is operating in one mode, either
+ * Device or Host, the application must not access registers from the
+ * other mode. When the core switches from one mode to another, the
+ * registers in the new mode of operation must be reprogrammed as they
+ * would be after a power-on reset.
+ */
+
+/****************************************************************************/
+/** DWC_otg Core registers .
+ * The dwc_otg_core_global_regs structure defines the size
+ * and relative field offsets for the Core Global registers.
+ */
+typedef struct dwc_otg_core_global_regs
+{
+	/** OTG Control and Status Register.  <i>Offset: 000h</i> */
+	volatile uint32_t gotgctl;
+	/** OTG Interrupt Register.	 <i>Offset: 004h</i> */
+	volatile uint32_t gotgint;
+	/**Core AHB Configuration Register.	 <i>Offset: 008h</i> */
+	volatile uint32_t gahbcfg;
+
+#define DWC_GLBINTRMASK		0x0001
+#define DWC_DMAENABLE		0x0020
+#define DWC_NPTXEMPTYLVL_EMPTY	0x0080
+#define DWC_NPTXEMPTYLVL_HALFEMPTY	0x0000
+#define DWC_PTXEMPTYLVL_EMPTY	0x0100
+#define DWC_PTXEMPTYLVL_HALFEMPTY	0x0000
+
+	/**Core USB Configuration Register.	 <i>Offset: 00Ch</i> */
+	volatile uint32_t gusbcfg;
+	/**Core Reset Register.	 <i>Offset: 010h</i> */
+	volatile uint32_t grstctl;
+	/**Core Interrupt Register.	 <i>Offset: 014h</i> */
+	volatile uint32_t gintsts;
+	/**Core Interrupt Mask Register.  <i>Offset: 018h</i> */
+	volatile uint32_t gintmsk;
+	/**Receive Status Queue Read Register (Read Only).	<i>Offset: 01Ch</i> */
+	volatile uint32_t grxstsr;
+	/**Receive Status Queue Read & POP Register (Read Only).  <i>Offset: 020h</i>*/
+	volatile uint32_t grxstsp;
+	/**Receive FIFO Size Register.	<i>Offset: 024h</i> */
+	volatile uint32_t grxfsiz;
+	/**Non Periodic Transmit FIFO Size Register.  <i>Offset: 028h</i> */
+	volatile uint32_t gnptxfsiz;
+	/**Non Periodic Transmit FIFO/Queue Status Register (Read
+	 * Only). <i>Offset: 02Ch</i> */
+	volatile uint32_t gnptxsts;
+	/**I2C Access Register.	 <i>Offset: 030h</i> */
+	volatile uint32_t gi2cctl;
+	/**PHY Vendor Control Register.	 <i>Offset: 034h</i> */
+	volatile uint32_t gpvndctl;
+	/**General Purpose Input/Output Register.  <i>Offset: 038h</i> */
+	volatile uint32_t ggpio;
+	/**User ID Register.  <i>Offset: 03Ch</i> */
+	volatile uint32_t guid;
+	/**Synopsys ID Register (Read Only).  <i>Offset: 040h</i> */
+	volatile uint32_t gsnpsid;
+	/**User HW Config1 Register (Read Only).  <i>Offset: 044h</i> */
+	volatile uint32_t ghwcfg1;
+	/**User HW Config2 Register (Read Only).  <i>Offset: 048h</i> */
+	volatile uint32_t ghwcfg2;
+#define DWC_SLAVE_ONLY_ARCH 0
+#define DWC_EXT_DMA_ARCH 1
+#define DWC_INT_DMA_ARCH 2
+
+#define DWC_MODE_HNP_SRP_CAPABLE	0
+#define DWC_MODE_SRP_ONLY_CAPABLE	1
+#define DWC_MODE_NO_HNP_SRP_CAPABLE		2
+#define DWC_MODE_SRP_CAPABLE_DEVICE		3
+#define DWC_MODE_NO_SRP_CAPABLE_DEVICE	4
+#define DWC_MODE_SRP_CAPABLE_HOST	5
+#define DWC_MODE_NO_SRP_CAPABLE_HOST	6
+
+	/**User HW Config3 Register (Read Only).  <i>Offset: 04Ch</i> */
+	volatile uint32_t ghwcfg3;
+	/**User HW Config4 Register (Read Only).  <i>Offset: 050h</i>*/
+	volatile uint32_t ghwcfg4;
+	/** Reserved  <i>Offset: 054h-0FFh</i> */
+	uint32_t reserved[43];
+	/** Host Periodic Transmit FIFO Size Register. <i>Offset: 100h</i> */
+	volatile uint32_t hptxfsiz;
+	/** Device Periodic Transmit FIFO#n Register if dedicated fifos are disabled,
+		otherwise Device Transmit FIFO#n Register.
+	 * <i>Offset: 104h + (FIFO_Number-1)*04h, 1 <= FIFO Number <= 15 (1<=n<=15).</i> */
+	volatile uint32_t dptxfsiz_dieptxf[15];
+} dwc_otg_core_global_regs_t;
+
+
+#if defined(CONFIG_4xx)
+/**
+ * This union represents the bit fields of the Core OTG Control
+ * and Status Register (GOTGCTL).  Set the bits using the bit
+ * fields then write the <i>d32</i> value to the register.
+ */
+typedef union gotgctl_data                  //*
+{
+	/** raw register data */
+	uint32_t d32;
+	/** register bits */
+	struct
+	{
+		unsigned reserved31_21 : 11;
+		unsigned currmod : 1;
+		unsigned bsesvld : 1;
+		unsigned asesvld : 1;
+		unsigned reserved17 : 1;
+		unsigned conidsts : 1;
+		unsigned reserved1_12 : 4;
+		unsigned devhnpen : 1;
+		unsigned hstsethnpen : 1;
+		unsigned hnpreq : 1;
+		unsigned hstnegscs : 1;
+		unsigned reserved07_02 : 6;
+		unsigned sesreq : 1;
+		unsigned sesreqscs : 1;
+	} b;
+} gotgctl_data_t;
+
+/**
+ * This union represents the bit fields of the Core OTG Interrupt Register
+ * (GOTGINT).  Set/clear the bits using the bit fields then write the <i>d32</i>
+ * value to the register.
+ */
+typedef union gotgint_data                  //*
+{
+	/** raw register data */
+	uint32_t d32;
+	/** register bits */
+	struct
+	{
+		/** Current Mode */
+		unsigned reserved31_20 : 12;
+		/** Debounce Done */
+		unsigned debdone : 1;
+		/** A-Device Timeout Change */
+		unsigned adevtoutchng : 1;
+		/** Host Negotiation Detected */
+		unsigned hstnegdet : 1;
+		unsigned reserver16_10 : 7;
+		/** Host Negotiation Success Status Change */
+		unsigned hstnegsucstschng : 1;
+		/** Session Request Success Status Change */
+		unsigned sesreqsucstschng : 1;
+		unsigned reserved3_7 : 5;
+		/** Session End Detected */
+		unsigned sesenddet : 1;
+		unsigned reserved01_00 : 2;
+	} b;
+} gotgint_data_t;
+
+
+/**
+ * This union represents the bit fields of the Core AHB Configuration
+ * Register (GAHBCFG).  Set/clear the bits using the bit fields then
+ * write the <i>d32</i> value to the register.
+ */
+typedef union gahbcfg_data                  //*
+{
+	/** raw register data */
+	uint32_t d32;
+	/** register bits */
+	struct
+	{
+		unsigned reserved9_31 : 23;
+		unsigned ptxfemplvl : 1;
+#define DWC_GAHBCFG_TXFEMPTYLVL_EMPTY 		1
+#define DWC_GAHBCFG_TXFEMPTYLVL_HALFEMPTY	0
+		unsigned nptxfemplvl_txfemplvl : 1;		/*fscz*/
+        unsigned reserved : 1;
+
+		unsigned dmaenable : 1;
+#define DWC_GAHBCFG_DMAENABLE   		1
+
+		unsigned hburstlen : 4;
+#define DWC_GAHBCFG_INT_DMA_BURST_SINGLE 	0
+#define DWC_GAHBCFG_INT_DMA_BURST_INCR 		1
+#define DWC_GAHBCFG_INT_DMA_BURST_INCR4 	3
+#define DWC_GAHBCFG_INT_DMA_BURST_INCR8 	5
+#define DWC_GAHBCFG_INT_DMA_BURST_INCR16 	7
+
+		unsigned glblintrmsk : 1;
+#define DWC_GAHBCFG_GLBINT_ENABLE 		1
+	} b;
+} gahbcfg_data_t;
+
+/**
+ * This union represents the bit fields of the Core USB Configuration
+ * Register (GUSBCFG).  Set the bits using the bit fields then write
+ * the <i>d32</i> value to the register.
+ */
+typedef union gusbcfg_data                  //*
+{
+        /** raw register data */
+        uint32_t d32;
+        /** register bits */
+        struct
+        {
+		unsigned corrupt_tx_packet: 1;		/*fscz*/
+		unsigned force_device_mode: 1;
+		unsigned force_host_mode: 1;
+		unsigned reserved23_28 : 6;
+		unsigned term_sel_dl_pulse : 1;
+		unsigned ulpi_int_vbus_indicator : 1;
+		unsigned ulpi_ext_vbus_drv : 1;
+		unsigned ulpi_clk_sus_m : 1;
+		unsigned ulpi_auto_res : 1;
+		unsigned ulpi_fsls : 1;
+
+		unsigned otgutmifssel : 1;
+		unsigned phylpwrclksel : 1;
+		unsigned nptxfrwnden : 1;
+		unsigned usbtrdtim : 4;
+		unsigned hnpcap : 1;
+		unsigned srpcap : 1;
+		unsigned ddrsel : 1;
+		unsigned physel : 1;
+		unsigned fsintf : 1;
+		unsigned ulpi_utmi_sel : 1;
+		unsigned phyif : 1;
+		unsigned toutcal : 3;
+        } b;
+} gusbcfg_data_t;
+
+/**
+ * This union represents the bit fields of the Core Reset Register
+ * (GRSTCTL).  Set/clear the bits using the bit fields then write the
+ * <i>d32</i> value to the register.
+ */
+typedef union grstctl_data                  //*
+{
+        /** raw register data */
+        uint32_t d32;
+        /** register bits */
+        struct
+        {
+		/** AHB Master Idle.  Indicates the AHB Master State
+		 * Machine is in IDLE condition. */
+		unsigned ahbidle : 1;
+
+		/** DMA Request Signal.  Indicated DMA request is in
+		 * probress.  Used for debug purpose. */
+		unsigned dmareq : 1;
+
+		/** Reserved */
+		unsigned reserved29_11 : 19;
+
+		/** TxFIFO Number (TxFNum) (Device and Host).
+		 *
+		 * This is the FIFO number which needs to be flushed,
+		 * using the TxFIFO Flush bit. This field should not
+		 * be changed until the TxFIFO Flush bit is cleared by
+		 * the core.
+		 *   - 0x0 : Non Periodic TxFIFO Flush
+		 *   - 0x1 : Periodic TxFIFO #1 Flush in device mode
+		 *     or Periodic TxFIFO in host mode
+		 *   - 0x2 : Periodic TxFIFO #2 Flush in device mode.
+		 *   - ...
+		 *   - 0xF : Periodic TxFIFO #15 Flush in device mode
+		 *   - 0x10: Flush all the Transmit NonPeriodic and
+		 *     Transmit Periodic FIFOs in the core
+		 */
+		unsigned txfnum : 5;
+
+		/** TxFIFO Flush (TxFFlsh) (Device and Host).
+		 *
+		 * This bit is used to selectively flush a single or
+		 * all transmit FIFOs.  The application must first
+		 * ensure that the core is not in the middle of a
+		 * transaction.  <p>The application should write into
+		 * this bit, only after making sure that neither the
+		 * DMA engine is writing into the TxFIFO nor the MAC
+		 * is reading the data out of the FIFO.  <p>The
+		 * application should wait until the core clears this
+		 * bit, before performing any operations. This bit
+		 * will takes 8 clocks (slowest of PHY or AHB clock)
+		 * to clear.
+		 */
+		unsigned txfflsh : 1;
+
+		/** RxFIFO Flush (RxFFlsh) (Device and Host)
+		 *
+		 * The application can flush the entire Receive FIFO
+		 * using this bit.  <p>The application must first
+		 * ensure that the core is not in the middle of a
+		 * transaction.  <p>The application should write into
+		 * this bit, only after making sure that neither the
+		 * DMA engine is reading from the RxFIFO nor the MAC
+		 * is writing the data in to the FIFO.  <p>The
+		 * application should wait until the bit is cleared
+		 * before performing any other operations. This bit
+		 * will takes 8 clocks (slowest of PHY or AHB clock)
+		 * to clear.
+		 */
+		unsigned rxfflsh : 1;
+
+		/** In Token Sequence Learning Queue Flush
+		 * (INTknQFlsh) (Device Only)
+		 */
+		unsigned intknqflsh : 1;
+
+		/** Host Frame Counter Reset (Host Only)<br>
+		 *
+		 * The application can reset the (micro)frame number
+		 * counter inside the core, using this bit. When the
+		 * (micro)frame counter is reset, the subsequent SOF
+		 * sent out by the core, will have a (micro)frame
+		 * number of 0.
+		 */
+		unsigned hstfrm : 1;
+
+		/** Hclk Soft Reset
+		 *
+		 * The application uses this bit to reset the control logic in
+		 * the AHB clock domain. Only AHB clock domain pipelines are
+		 * reset.
+		 */
+		unsigned hsftrst : 1;
+
+		/** Core Soft Reset (CSftRst) (Device and Host)
+		 *
+		 * The application can flush the control logic in the
+		 * entire core using this bit. This bit resets the
+		 * pipelines in the AHB Clock domain as well as the
+		 * PHY Clock domain.
+		 *
+		 * The state machines are reset to an IDLE state, the
+		 * control bits in the CSRs are cleared, all the
+		 * transmit FIFOs and the receive FIFO are flushed.
+		 *
+		 * The status mask bits that control the generation of
+		 * the interrupt, are cleared, to clear the
+		 * interrupt. The interrupt status bits are not
+		 * cleared, so the application can get the status of
+		 * any events that occurred in the core after it has
+		 * set this bit.
+		 *
+		 * Any transactions on the AHB are terminated as soon
+		 * as possible following the protocol. Any
+		 * transactions on the USB are terminated immediately.
+		 *
+		 * The configuration settings in the CSRs are
+		 * unchanged, so the software doesn't have to
+		 * reprogram these registers (Device
+		 * Configuration/Host Configuration/Core System
+		 * Configuration/Core PHY Configuration).
+		 *
+		 * The application can write to this bit, any time it
+		 * wants to reset the core. This is a self clearing
+		 * bit and the core clears this bit after all the
+		 * necessary logic is reset in the core, which may
+		 * take several clocks, depending on the current state
+		 * of the core.
+		 */
+		unsigned csftrst : 1;
+        } b;
+} grstctl_t;
+
+/**
+ * This union represents the bit fields of the Core Interrupt Mask
+ * Register (GINTMSK).  Set/clear the bits using the bit fields then
+ * write the <i>d32</i> value to the register.
+ */
+typedef union gintmsk_data                  //*
+{
+        /** raw register data */
+        uint32_t d32;
+        /** register bits */
+        struct
+        {
+                unsigned wkupintr : 1;
+                unsigned sessreqintr : 1;
+                unsigned disconnect : 1;
+                unsigned conidstschng : 1;
+                unsigned reserved27 : 1;
+                unsigned ptxfempty : 1;
+                unsigned hcintr : 1;
+                unsigned portintr : 1;
+                unsigned reserved22_23 : 2;
+                unsigned incomplisoout : 1;
+                unsigned incomplisoin : 1;
+                unsigned outepintr : 1;
+                unsigned inepintr : 1;
+                unsigned epmismatch : 1;
+                unsigned reserved16 : 1;
+                unsigned eopframe : 1;
+                unsigned isooutdrop : 1;
+                unsigned enumdone : 1;
+                unsigned usbreset : 1;
+                unsigned usbsuspend : 1;
+                unsigned erlysuspend : 1;
+                unsigned i2cintr : 1;
+                unsigned reserved08 : 1;
+                unsigned goutnakeff : 1;
+                unsigned ginnakeff : 1;
+                unsigned nptxfempty : 1;
+                unsigned rxstsqlvl : 1;
+                unsigned sofintr : 1;
+                unsigned otgintr : 1;
+                unsigned modemismatch : 1;
+                unsigned reserved00 : 1;
+        } b;
+} gintmsk_data_t;
+/**
+ * This union represents the bit fields of the Core Interrupt Register
+ * (GINTSTS).  Set/clear the bits using the bit fields then write the
+ * <i>d32</i> value to the register.
+ */
+typedef union gintsts_data                  //*
+{
+	/** raw register data */
+	uint32_t d32;
+#define DWC_SOF_INTR_MASK 0x0008
+	/** register bits */
+	struct
+	{
+#define DWC_HOST_MODE 1
+		unsigned wkupintr : 1;
+		unsigned sessreqintr : 1;
+		unsigned disconnect : 1;
+		unsigned conidstschng : 1;
+		unsigned reserved27 : 1;
+		unsigned ptxfempty : 1;
+		unsigned hcintr : 1;
+		unsigned portintr : 1;
+		unsigned reserved22_23 : 2;
+		unsigned incomplisoout : 1;
+		unsigned incomplisoin : 1;
+		unsigned outepintr : 1;
+		unsigned inepint: 1;
+		unsigned epmismatch : 1;
+		unsigned intokenrx : 1;
+		unsigned eopframe : 1;
+		unsigned isooutdrop : 1;
+		unsigned enumdone : 1;
+		unsigned usbreset : 1;
+		unsigned usbsuspend : 1;
+		unsigned erlysuspend : 1;
+		unsigned i2cintr : 1;
+		unsigned reserved8 : 1;
+		unsigned goutnakeff : 1;
+		unsigned ginnakeff : 1;
+		unsigned nptxfempty : 1;
+		unsigned rxstsqlvl : 1;
+		unsigned sofintr : 1;
+		unsigned otgintr : 1;
+		unsigned modemismatch : 1;
+		unsigned curmode : 1;
+	} b;
+} gintsts_data_t;
+
+
+/**
+ * This union represents the bit fields in the Device Receive Status Read and
+ * Pop Registers (GRXSTSR, GRXSTSP) Read the register into the <i>d32</i>
+ * element then read out the bits using the <i>b</i>it elements.
+ */
+typedef union device_grxsts_data {          //*
+	/** raw register data */
+	uint32_t d32;
+	/** register bits */
+	struct {
+		unsigned reserved : 7;
+		unsigned fn : 4;
+		unsigned pktsts : 4;
+#define DWC_STS_DATA_UPDT   	0x2               // OUT Data Packet
+#define DWC_STS_XFER_COMP   	0x3               // OUT Data Transfer Complete
+
+#define DWC_DSTS_GOUT_NAK   	0x1               // Global OUT NAK
+#define DWC_DSTS_SETUP_COMP 	0x4               // Setup Phase Complete
+#define DWC_DSTS_SETUP_UPDT	0x6               // SETUP Packet
+
+		unsigned dpid : 2;
+		unsigned bcnt : 11;
+		unsigned epnum : 4;
+	} b;
+} device_grxsts_data_t;
+
+/**
+ * This union represents the bit fields in the Host Receive Status Read and
+ * Pop Registers (GRXSTSR, GRXSTSP) Read the register into the <i>d32</i>
+ * element then read out the bits using the <i>b</i>it elements.
+ */
+typedef union host_grxsts_data {            //*
+	/** raw register data */
+	uint32_t d32;
+	/** register bits */
+	struct {
+		unsigned reserved31_21 : 11;
+		unsigned pktsts : 4;
+#define DWC_GRXSTS_PKTSTS_IN              0x2
+#define DWC_GRXSTS_PKTSTS_IN_XFER_COMP    0x3
+#define DWC_GRXSTS_PKTSTS_DATA_TOGGLE_ERR 0x5
+#define DWC_GRXSTS_PKTSTS_CH_HALTED       0x7
+
+		unsigned dpid : 2;
+		unsigned bcnt : 11;
+	 	unsigned chnum : 4;
+	} b;
+} host_grxsts_data_t;
+
+/**
+ * This union represents the bit fields in the FIFO Size Registers (HPTXFSIZ,
+ * GNPTXFSIZ, DPTXFSIZn). Read the register into the <i>d32</i> element then
+ * read out the bits using the <i>b</i>it elements.
+ */
+typedef union fifosize_data {               //*
+	/** raw register data */
+	uint32_t d32;
+	/** register bits */
+	struct {
+		unsigned depth : 16;
+		unsigned startaddr : 16;
+	} b;
+} fifosize_data_t;
+
+/**
+ * This union represents the bit fields in the Non-Periodic Transmit
+ * FIFO/Queue Status Register (GNPTXSTS). Read the register into the
+ * <i>d32</i> element then read out the bits using the <i>b</i>it
+ * elements.
+ */
+typedef union gnptxsts_data {               //*
+	/** raw register data */
+	uint32_t d32;
+	/** register bits */
+	struct {
+	unsigned reserved : 1;
+		/** Top of the Non-Periodic Transmit Request Queue
+		 *  - bits 30:27 - Channel/EP Number
+		 *  - bits 26:25 - Token Type
+		 *    - 2'b00 - IN/OUT
+		 *    - 2'b01 - Zero Length OUT
+		 *    - 2'b10 - PING/Complete Split
+		 *    - 2'b11 - Channel Halt
+		 *  - bit 24 - Terminate (Last entry for the selected
+		 *    channel/EP)
+		 */
+		unsigned nptxqtop_chnep : 4;
+		unsigned nptxqtop_token : 2;
+		unsigned nptxqtop_terminate : 1;
+		unsigned nptxqspcavail : 8;
+		unsigned nptxfspcavail : 16;
+        } b;
+} gnptxsts_data_t;
+
+/**
+ * This union represents the bit fields in the Transmit
+ * FIFO Status Register (DTXFSTS). Read the register into the
+ * <i>d32</i> element then read out the bits using the <i>b</i>it
+ * elements.
+ */
+typedef union dtxfsts_data 	/* fscz */	 //*
+{
+	/** raw register data */
+	uint32_t d32;
+	/** register bits */
+	struct {
+		unsigned reserved : 16;
+		unsigned txfspcavail : 16;
+	} b;
+} dtxfsts_data_t;
+
+
+/**
+ * This union represents the bit fields in the I2C Control Register
+ * (I2CCTL). Read the register into the <i>d32</i> element then read out the
+ * bits using the <i>b</i>it elements.
+ */
+typedef union gi2cctl_data {                //*
+	/** raw register data */
+	uint32_t d32;
+	/** register bits */
+	struct {
+		unsigned bsydne : 1;
+		unsigned rw : 1;
+		unsigned reserved : 2;
+		unsigned i2cdevaddr : 2;
+		unsigned i2csuspctl : 1;
+		unsigned ack : 1;
+		unsigned i2cen : 1;
+		unsigned addr : 7;
+		unsigned regaddr : 8;
+		unsigned rwdata : 8;
+	} b;
+} gi2cctl_data_t;
+
+/**
+ * This union represents the bit fields in the User HW Config1
+ * Register.  Read the register into the <i>d32</i> element then read
+ * out the bits using the <i>b</i>it elements.
+ */
+typedef union hwcfg1_data {                 //*
+	/** raw register data */
+	uint32_t d32;
+	/** register bits */
+	struct {
+		unsigned ep_dir15 : 2;
+		unsigned ep_dir14 : 2;
+		unsigned ep_dir13 : 2;
+		unsigned ep_dir12 : 2;
+		unsigned ep_dir11 : 2;
+		unsigned ep_dir10 : 2;
+		unsigned ep_dir9  : 2;
+		unsigned ep_dir8  : 2;
+		unsigned ep_dir7  : 2;
+		unsigned ep_dir6  : 2;
+		unsigned ep_dir5  : 2;
+		unsigned ep_dir4  : 2;
+		unsigned ep_dir3  : 2;
+		unsigned ep_dir2  : 2;
+		unsigned ep_dir1  : 2;
+		unsigned ep_dir0  : 2;
+        } b;
+} hwcfg1_data_t;
+
+/**
+ * This union represents the bit fields in the User HW Config2
+ * Register.  Read the register into the <i>d32</i> element then read
+ * out the bits using the <i>b</i>it elements.
+ */
+typedef union hwcfg2_data                   //*
+{
+	/** raw register data */
+	uint32_t d32;
+	/** register bits */
+	struct {
+		/* GHWCFG2 */
+		unsigned reserved31 : 1;
+		unsigned dev_token_q_depth : 5;
+		unsigned host_perio_tx_q_depth : 2;
+		unsigned nonperio_tx_q_depth : 2;
+		unsigned rx_status_q_depth : 2;
+		unsigned dynamic_fifo : 1;
+		unsigned perio_ep_supported : 1;
+		unsigned num_host_chan : 4;
+		unsigned num_dev_ep : 4;
+		unsigned fs_phy_type : 2;
+		unsigned hs_phy_type : 2;
+#define DWC_HWCFG2_HS_PHY_TYPE_NOT_SUPPORTED 0
+#define DWC_HWCFG2_HS_PHY_TYPE_UTMI 1
+#define DWC_HWCFG2_HS_PHY_TYPE_ULPI 2
+#define DWC_HWCFG2_HS_PHY_TYPE_UTMI_ULPI 3
+
+		unsigned point2point : 1;
+		unsigned architecture : 2;
+		unsigned op_mode : 3;
+#define DWC_HWCFG2_OP_MODE_HNP_SRP_CAPABLE_OTG 0
+#define DWC_HWCFG2_OP_MODE_SRP_ONLY_CAPABLE_OTG 1
+#define DWC_HWCFG2_OP_MODE_NO_HNP_SRP_CAPABLE_OTG 2
+#define DWC_HWCFG2_OP_MODE_SRP_CAPABLE_DEVICE 3
+#define DWC_HWCFG2_OP_MODE_NO_SRP_CAPABLE_DEVICE 4
+#define DWC_HWCFG2_OP_MODE_SRP_CAPABLE_HOST 5
+#define DWC_HWCFG2_OP_MODE_NO_SRP_CAPABLE_HOST 6
+        } b;
+} hwcfg2_data_t;
+
+/**
+ * This union represents the bit fields in the User HW Config3
+ * Register.  Read the register into the <i>d32</i> element then read
+ * out the bits using the <i>b</i>it elements.
+ */
+typedef union hwcfg3_data                   //*
+{
+	/** raw register data */
+	uint32_t d32;
+	/** register bits */
+	struct {
+		/* GHWCFG3 */
+		unsigned dfifo_depth : 16;
+		unsigned reserved15_13 : 3;
+		unsigned ahb_phy_clock_synch : 1;
+		unsigned synch_reset_type : 1;
+		unsigned optional_features : 1;
+		unsigned vendor_ctrl_if : 1;
+		unsigned i2c : 1;
+		unsigned otg_func : 1;
+		unsigned packet_size_cntr_width : 3;
+		unsigned xfer_size_cntr_width : 4;
+        } b;
+} hwcfg3_data_t;
+
+/**
+ * This union represents the bit fields in the User HW Config4
+ * Register.  Read the register into the <i>d32</i> element then read
+ * out the bits using the <i>b</i>it elements.
+ */
+typedef union hwcfg4_data                   //*
+{
+        /** raw register data */
+        uint32_t d32;
+        /** register bits */
+        struct {
+
+		unsigned reserved31_30 : 2;	/* fscz */
+		unsigned num_in_eps : 4;
+		unsigned ded_fifo_en : 1;
+
+		unsigned session_end_filt_en : 1;
+		unsigned b_valid_filt_en : 1;
+		unsigned a_valid_filt_en : 1;
+		unsigned vbus_valid_filt_en : 1;
+		unsigned iddig_filt_en : 1;
+		unsigned num_dev_mode_ctrl_ep : 4;
+		unsigned utmi_phy_data_width : 2;
+		unsigned min_ahb_freq : 9;
+		unsigned power_optimiz : 1;
+		unsigned num_dev_perio_in_ep : 4;
+        } b;
+} hwcfg4_data_t;
+
+
+////////////////////////////////////////////
+// Device Registers
+/**
+ * Device Global Registers. <i>Offsets 800h-BFFh</i>
+ *
+ * The following structures define the size and relative field offsets
+ * for the Device Mode Registers.
+ *
+ * <i>These registers are visible only in Device mode and must not be
+ * accessed in Host mode, as the results are unknown.</i>
+ */
+typedef struct dwc_otg_dev_global_regs
+{
+        /** Device Configuration Register. <i>Offset 800h</i> */
+        volatile uint32_t dcfg;
+        /** Device Control Register. <i>Offset: 804h</i> */
+        volatile uint32_t dctl;
+        /** Device Status Register (Read Only). <i>Offset: 808h</i> */
+        volatile uint32_t dsts;
+        /** Reserved. <i>Offset: 80Ch</i> */
+        uint32_t unused;
+        /** Device IN Endpoint Common Interrupt Mask
+         * Register. <i>Offset: 810h</i> */
+        volatile uint32_t diepmsk;
+        /** Device OUT Endpoint Common Interrupt Mask
+         * Register. <i>Offset: 814h</i> */
+        volatile uint32_t doepmsk;
+        /** Device All Endpoints Interrupt Register.  <i>Offset: 818h</i> */
+        volatile uint32_t daint;
+        /** Device All Endpoints Interrupt Mask Register.  <i>Offset:
+         * 81Ch</i> */
+        volatile uint32_t daintmsk;
+        /** Device IN Token Queue Read Register-1 (Read Only).
+         * <i>Offset: 820h</i> */
+        volatile uint32_t dtknqr1;
+        /** Device IN Token Queue Read Register-2 (Read Only).
+         * <i>Offset: 824h</i> */
+        volatile uint32_t dtknqr2;
+        /** Device VBUS  discharge Register.  <i>Offset: 828h</i> */
+        volatile uint32_t dvbusdis;
+        /** Device VBUS Pulse Register.  <i>Offset: 82Ch</i> */
+        volatile uint32_t dvbuspulse;
+        /** Device IN Token Queue Read Register-3 (Read Only).
+         * <i>Offset: 830h</i> */
+		/*fscz*/
+	    /** Device IN Token Queue Read Register-3 (Read Only). /
+    	 *  Device Thresholding control register (Read/Write)
+	     * <i>Offset: 830h</i> */
+	    volatile uint32_t dtknqr3_dthrctl;
+    	/** Device IN Token Queue Read Register-4 (Read Only). /
+	     *  Device IN EPs empty Inr. Mask Register (Read/Write)
+    	 * <i>Offset: 834h</i> */
+	    volatile uint32_t dtknqr4_fifoemptymsk;
+} dwc_otg_device_global_regs_t;
+
+/**
+ * This union represents the bit fields in the Device Configuration
+ * Register.  Read the register into the <i>d32</i> member then
+ * set/clear the bits using the <i>b</i>it elements.  Write the
+ * <i>d32</i> member to the dcfg register.
+ */
+typedef union dcfg_data                     //*
+{
+	/** raw register data */
+	uint32_t d32;
+	/** register bits */
+	struct {
+		unsigned reserved0_8	: 9;	/*fsczzzz correct*/
+		unsigned epmscnt : 5;
+		/** In Endpoint Mis-match count */
+		unsigned reserved17_13 : 5;
+		/** Periodic Frame Interval */
+		unsigned perfrint : 2;
+#define DWC_DCFG_FRAME_INTERVAL_80 0
+#define DWC_DCFG_FRAME_INTERVAL_85 1
+#define DWC_DCFG_FRAME_INTERVAL_90 2
+#define DWC_DCFG_FRAME_INTERVAL_95 3
+
+		/** Device Addresses */
+		unsigned devaddr : 7;
+		unsigned reserved3 : 1;
+		/** Non Zero Length Status OUT Handshake */
+		unsigned nzstsouthshk : 1;
+#define DWC_DCFG_SEND_STALL 1
+
+		/** Device Speed */
+		unsigned devspd : 2;
+        } b;
+} dcfg_data_t;
+
+/**
+ * This union represents the bit fields in the Device Control
+ * Register.  Read the register into the <i>d32</i> member then
+ * set/clear the bits using the <i>b</i>it elements.
+ */
+typedef union dctl_data                     //*
+{
+	/** raw register data */
+	uint32_t d32;
+	/** register bits */
+	struct {
+		unsigned reserved31_12 : 21;
+		/** Clear Global OUT NAK */
+		unsigned cgoutnak : 1;
+		/** Set Global OUT NAK */
+		unsigned sgoutnak : 1;
+		/** Clear Global Non-Periodic IN NAK */
+		unsigned cgnpinnak : 1;
+		/** Set Global Non-Periodic IN NAK */
+		unsigned sgnpinnak : 1;
+		/** Test Control */
+		unsigned tstctl : 3;
+		/** Global OUT NAK Status */
+		unsigned goutnaksts : 1;
+		/** Global Non-Periodic IN NAK Status */
+		unsigned gnpinnaksts : 1;
+		/** Soft Disconnect */
+		unsigned sftdiscon : 1;
+		/** Remote Wakeup */
+		unsigned rmtwkupsig : 1;
+	} b;
+} dctl_data_t;
+
+/**
+ * This union represents the bit fields in the Device Status
+ * Register.  Read the register into the <i>d32</i> member then
+ * set/clear the bits using the <i>b</i>it elements.
+ */
+typedef union dsts_data                     //*
+{
+	/** raw register data */
+	uint32_t d32;
+	/** register bits */
+	struct {
+		unsigned reserved31_22 : 10;
+		/** Frame or Microframe Number of the received SOF */
+		unsigned soffn : 14;
+		unsigned reserved07_04 : 4;
+		/** Erratic Error */
+		unsigned errticerr : 1;
+		/** Enumerated Speed */
+		unsigned enumspd : 2;
+#define DWC_DSTS_ENUMSPD_HS_PHY_30MHZ_OR_60MHZ 0
+#define DWC_DSTS_ENUMSPD_FS_PHY_30MHZ_OR_60MHZ 1
+#define DWC_DSTS_ENUMSPD_LS_PHY_6MHZ           2
+#define DWC_DSTS_ENUMSPD_FS_PHY_48MHZ          3
+		/** Suspend Status */
+		unsigned suspsts : 1;
+        } b;
+} dsts_data_t;
+
+
+/**
+ * This union represents the bit fields in the Device IN EP Interrupt
+ * Register and the Device IN EP Common Mask Register.
+ *
+ * - Read the register into the <i>d32</i> member then set/clear the
+ *   bits using the <i>b</i>it elements.
+ */
+typedef union diepint_data                  //*
+{
+	/** raw register data */
+	uint32_t d32;
+	/** register bits */
+	struct {
+		unsigned reserved31_08 : 23;
+		unsigned txfifoundrn : 1;
+        /** IN Endpoint HAK Effective mask */
+        unsigned emptyintr : 1;
+		/** IN Endpoint NAK Effective mask */
+		unsigned inepnakeff : 1;
+		/** IN Token Received with EP mismatch mask */
+		unsigned intknepmis : 1;
+		/** IN Token received with TxF Empty mask */
+		unsigned intktxfemp : 1;
+		/** TimeOUT Handshake mask (non-ISOC EPs) */
+		unsigned timeout : 1;
+		/** AHB Error mask */
+		unsigned ahberr : 1;
+		/** Endpoint disable mask */
+		unsigned epdisabled : 1;
+		/** Transfer complete mask */
+		unsigned xfercompl : 1;
+        } b;
+} diepint_data_t;
+/**
+ * This union represents the bit fields in the Device IN EP Common
+ * Interrupt Mask Register.
+ */
+typedef union diepint_data diepmsk_data_t;  //*-*
+
+/**
+ * This union represents the bit fields in the Device OUT EP
+ * Interrupt Register and Device OUT EP Common Interrupt Mask
+ * Register.
+ *
+ * - Read the register into the <i>d32</i> member then set/clear the
+ *   bits using the <i>b</i>it elements.
+ */
+typedef union doepint_data                  //*
+{
+	/** raw register data */
+	uint32_t d32;
+	/** register bits */
+	struct {
+		unsigned reserved31_04 : 28;    // Docs say reserved is 27 bits
+
+		// There is 1 bit missing here, not used?
+
+		/** Setup Phase Done (control EPs) */
+		unsigned setup : 1;
+		/** AHB Error */
+		unsigned ahberr : 1;
+		/** Endpoint disable  */
+		unsigned epdisabled : 1;
+		/** Transfer complete */
+		unsigned xfercompl : 1;
+        } b;
+} doepint_data_t;
+/**
+ * This union represents the bit fields in the Device OUT EP Common
+ * Interrupt Mask Register.
+ */
+typedef union doepint_data doepmsk_data_t;  //*-*
+
+
+/**
+ * This union represents the bit fields in the Device All EP Interrupt
+ * and Mask Registers.
+ * - Read the register into the <i>d32</i> member then set/clear the
+ *   bits using the <i>b</i>it elements.
+ */
+typedef union daint_data                    //*
+{
+	/** raw register data */
+	uint32_t d32;
+	/** register bits */
+	struct {
+		/** OUT Endpoint bits */
+		unsigned out : 16;
+		/** IN Endpoint bits */
+		unsigned in : 16;
+        } ep;
+	struct {
+		/** OUT Endpoint bits */
+		unsigned outep15 : 1;
+		unsigned outep14 : 1;
+		unsigned outep13 : 1;
+		unsigned outep12 : 1;
+		unsigned outep11 : 1;
+		unsigned outep10 : 1;
+		unsigned outep9  : 1;
+		unsigned outep8  : 1;
+		unsigned outep7  : 1;
+		unsigned outep6  : 1;
+		unsigned outep5  : 1;
+		unsigned outep4  : 1;
+		unsigned outep3  : 1;
+		unsigned outep2  : 1;
+		unsigned outep1  : 1;
+		unsigned outep0  : 1;
+		/** IN Endpoint bits */
+		unsigned inep15 : 1;
+		unsigned inep14 : 1;
+		unsigned inep13 : 1;
+		unsigned inep12 : 1;
+		unsigned inep11 : 1;
+		unsigned inep10 : 1;
+		unsigned inep9  : 1;
+		unsigned inep8  : 1;
+		unsigned inep7  : 1;
+		unsigned inep6  : 1;
+		unsigned inep5  : 1;
+		unsigned inep4  : 1;
+		unsigned inep3  : 1;
+		unsigned inep2  : 1;
+		unsigned inep1  : 1;
+		unsigned inep0  : 1;
+        } b;
+} daint_data_t;
+
+/**
+ * This union represents the bit fields in the Device IN Token Queue
+ * Read Registers.
+ * - Read the register into the <i>d32</i> member.
+ * - READ-ONLY Register
+ */
+typedef union dtknq1_data                   //*
+{
+        /** raw register data */
+        uint32_t d32;
+        /** register bits */
+        struct {
+		/** EP Numbers of IN Tokens 0 ... 4 */
+		unsigned epnums0_5 : 24;
+		/** write pointer has wrapped. */
+		unsigned wrap_bit : 1;
+		/** Reserved */
+		unsigned reserved05_06 : 2;
+		/** In Token Queue Write Pointer */
+		unsigned intknwptr : 5;
+        }b;
+} dtknq1_data_t;
+
+/**
+ * This union represents Threshold control Register
+ * - Read and write the register into the <i>d32</i> member.
+ * - READ-WRITABLE Register
+ */
+typedef union dthrctl_data			//* /*fscz */
+{
+    /** raw register data */
+    uint32_t d32;
+    /** register bits */
+    struct {
+        /** Reserved */
+        unsigned reserved26_31 : 6;
+        /** Rx Thr. Length */
+        unsigned rx_thr_len : 9;
+        /** Rx Thr. Enable */
+        unsigned rx_thr_en : 1;
+        /** Reserved */
+        unsigned reserved11_15 : 5;
+        /** Tx Thr. Length */
+        unsigned tx_thr_len : 9;
+        /** ISO Tx Thr. Enable */
+        unsigned iso_thr_en : 1;
+        /** non ISO Tx Thr. Enable */
+        unsigned non_iso_thr_en : 1;
+
+    }b;
+} dthrctl_data_t;
+
+
+/**
+ * Device Logical IN Endpoint-Specific Registers. <i>Offsets
+ * 900h-AFCh</i>
+ *
+ * There will be one set of endpoint registers per logical endpoint
+ * implemented.
+ *
+ * <i>These registers are visible only in Device mode and must not be
+ * accessed in Host mode, as the results are unknown.</i>
+ */
+typedef struct dwc_otg_dev_in_ep_regs
+{
+        /** Device IN Endpoint Control Register. <i>Offset:900h +
+         * (ep_num * 20h) + 00h</i> */
+        volatile uint32_t diepctl;
+        /** Reserved. <i>Offset:900h + (ep_num * 20h) + 04h</i> */
+        uint32_t reserved04;
+        /** Device IN Endpoint Interrupt Register. <i>Offset:900h +
+         * (ep_num * 20h) + 08h</i> */
+        volatile uint32_t diepint;
+        /** Reserved. <i>Offset:900h + (ep_num * 20h) + 0Ch</i> */
+        uint32_t reserved0C;
+        /** Device IN Endpoint Transfer Size
+         * Register. <i>Offset:900h + (ep_num * 20h) + 10h</i> */
+        volatile uint32_t dieptsiz;
+        /** Device IN Endpoint DMA Address Register. <i>Offset:900h +
+         * (ep_num * 20h) + 14h</i> */
+        volatile uint32_t diepdma;
+        /** Reserved. <i>Offset:900h + (ep_num * 20h) + 18h - 900h +
+         * (ep_num * 20h) + 1Ch</i>*/
+	    volatile uint32_t dtxfsts;
+    	/** Reserved. <i>Offset:900h + (ep_num * 20h) + 1Ch - 900h +
+	     * (ep_num * 20h) + 1Ch</i>*/
+    	uint32_t reserved18;
+} dwc_otg_dev_in_ep_regs_t;
+
+/**
+ * Device Logical OUT Endpoint-Specific Registers. <i>Offsets:
+ * B00h-CFCh</i>
+ *
+ * There will be one set of endpoint registers per logical endpoint
+ * implemented.
+ *
+ * <i>These registers are visible only in Device mode and must not be
+ * accessed in Host mode, as the results are unknown.</i>
+ */
+typedef struct dwc_otg_dev_out_ep_regs
+{
+        /** Device OUT Endpoint Control Register. <i>Offset:B00h +
+         * (ep_num * 20h) + 00h</i> */
+        volatile uint32_t doepctl;
+        /** Device OUT Endpoint Frame number Register.  <i>Offset:
+         * B00h + (ep_num * 20h) + 04h</i> */
+        volatile uint32_t doepfn;
+        /** Device OUT Endpoint Interrupt Register. <i>Offset:B00h +
+         * (ep_num * 20h) + 08h</i> */
+        volatile uint32_t doepint;
+        /** Reserved. <i>Offset:B00h + (ep_num * 20h) + 0Ch</i> */
+        uint32_t reserved0C;
+        /** Device OUT Endpoint Transfer Size Register. <i>Offset:
+         * B00h + (ep_num * 20h) + 10h</i> */
+        volatile uint32_t doeptsiz;
+        /** Device OUT Endpoint DMA Address Register. <i>Offset:B00h
+         * + (ep_num * 20h) + 14h</i> */
+        volatile uint32_t doepdma;
+        /** Reserved. <i>Offset:B00h + (ep_num * 20h) + 18h - B00h +
+         * (ep_num * 20h) + 1Ch</i> */
+        uint32_t unused[2];
+} dwc_otg_dev_out_ep_regs_t;
+
+/**
+ * This union represents the bit fields in the Device EP Control
+ * Register.  Read the register into the <i>d32</i> member then
+ * set/clear the bits using the <i>b</i>it elements.
+ */
+typedef union depctl_data                   //*
+{
+        /** raw register data */
+        uint32_t d32;
+        /** register bits */
+        struct {
+		/** Endpoint Enable */
+		unsigned epena : 1;
+		/** Endpoint Disable */
+		unsigned epdis : 1;
+
+		/** Set DATA1 PID (INTR/Bulk IN and OUT endpoints)
+		 * Writing to this field sets the Endpoint DPID (DPID)
+		 * field in this register to DATA1 Set Odd
+		 * (micro)frame (SetOddFr) (ISO IN and OUT Endpoints)
+		 * Writing to this field sets the Even/Odd
+		 * (micro)frame (EO_FrNum) field to odd (micro) frame.
+		 */
+		unsigned setd1pid : 1;
+		/** Set DATA0 PID (INTR/Bulk IN and OUT endpoints)
+		 * Writing to this field sets the Endpoint DPID (DPID)
+		 * field in this register to DATA0. Set Even
+		 * (micro)frame (SetEvenFr) (ISO IN and OUT Endpoints)
+		 * Writing to this field sets the Even/Odd
+		 * (micro)frame (EO_FrNum) field to even (micro)
+		 * frame.
+		 */
+		unsigned setd0pid : 1;
+
+		/** Set NAK */
+		unsigned snak : 1;
+		/** Clear NAK */
+		unsigned cnak : 1;
+
+		/** Tx Fifo Number
+		 * IN EPn/IN EP0
+		 * OUT EPn/OUT EP0 - reserved */
+		unsigned txfnum : 4;
+
+		/** Stall Handshake */
+		unsigned stall : 1;
+
+		/** Snoop Mode
+		 * OUT EPn/OUT EP0
+		 * IN EPn/IN EP0 - reserved */
+		unsigned snp : 1;
+
+		/** Endpoint Type
+		 *  2'b00: Control
+		 *  2'b01: Isochronous
+		 *  2'b10: Bulk
+		 *  2'b11: Interrupt */
+		unsigned eptype : 2;
+
+		/** NAK Status */
+		unsigned naksts : 1;
+
+		/** Endpoint DPID (INTR/Bulk IN and OUT endpoints)
+                 * This field contains the PID of the packet going to
+                 * be received or transmitted on this endpoint. The
+                 * application should program the PID of the first
+                 * packet going to be received or transmitted on this
+                 * endpoint , after the endpoint is
+                 * activated. Application use the SetD1PID and
+                 * SetD0PID fields of this register to program either
+                 * D0 or D1 PID.
+                 *
+                 * The encoding for this field is
+                 *   - 0: D0
+                 *   - 1: D1
+                 */
+		unsigned dpid : 1;
+
+		/** USB Active Endpoint */
+		unsigned usbactep : 1;
+
+		/** Next Endpoint
+		 * IN EPn/IN EP0
+		 * OUT EPn/OUT EP0 - reserved */
+		unsigned nextep : 4;
+
+		 /** Maximum Packet Size
+		 * IN/OUT EPn
+		 * IN/OUT EP0 - 2 bits
+		 *   2'b00: 64 Bytes
+		 *   2'b01: 32
+		 *   2'b10: 16
+		 *   2'b11: 8 */
+		unsigned mps : 11;
+#define DWC_DEP0CTL_MPS_64   0
+#define DWC_DEP0CTL_MPS_32   1
+#define DWC_DEP0CTL_MPS_16   2
+#define DWC_DEP0CTL_MPS_8    3
+        } b;
+} depctl_data_t;
+
+/**
+ * This union represents the bit fields in the Device EP Transfer
+ * Size Register.  Read the register into the <i>d32</i> member then
+ * set/clear the bits using the <i>b</i>it elements.
+ */
+typedef union deptsiz_data                  //*
+{
+        /** raw register data */
+        uint32_t d32;
+
+	/*
+	 * Added-sr: 2007-07-26
+	 *
+	 * Correct ther register layout for the 405EZ Ultra
+	 * USB device implementation.
+	 */
+#ifdef CONFIG_405EZ
+        /** register bits */
+        struct {
+		unsigned reserved : 1;
+		/** Multi Count - Periodic IN endpoints */
+		unsigned mc : 2;
+		unsigned reserved1 : 5;
+		/** Packet Count */
+		unsigned pktcnt : 5;
+		unsigned reserved2 : 8;
+		 /** Transfer size */
+		unsigned xfersize : 11;
+        } b;
+#else
+        /** register bits */
+        struct {
+		unsigned reserved : 1;
+		/** Multi Count - Periodic IN endpoints */
+		unsigned mc : 2;
+		/** Packet Count */
+		unsigned pktcnt : 10;
+		 /** Transfer size */
+		unsigned xfersize : 19;
+        } b;
+#endif
+} deptsiz_data_t;
+
+/**
+ * This union represents the bit fields in the Device EP 0 Transfer
+ * Size Register.  Read the register into the <i>d32</i> member then
+ * set/clear the bits using the <i>b</i>it elements.
+ */
+typedef union deptsiz0_data                 //*
+{
+        /** raw register data */
+        uint32_t d32;
+        /** register bits */
+        struct {
+		unsigned reserved31 : 1; /*fsczzzz device*/
+		/**Setup Packet Count (DOEPTSIZ0 Only) */
+		unsigned supcnt : 2;
+		/** Reserved */
+		unsigned reserved28_20 : 9;
+		/** Packet Count */
+		unsigned pktcnt : 1;
+		/** Reserved */
+		unsigned reserved18_7 : 12;
+		/** Transfer size */
+		unsigned xfersize : 7;
+        } b;
+} deptsiz0_data_t;
+
+
+/** Maximum number of Periodic FIFOs */
+#define MAX_PERIO_FIFOS 15
+/** Maximum number of Periodic FIFOs */
+#define MAX_TX_FIFOS 15
+
+/** Maximum number of Endpoints/HostChannels */
+#if defined(CONFIG_460EX) || defined(CONFIG_APM82181)
+#define MAX_EPS_CHANNELS 12
+#else
+#define MAX_EPS_CHANNELS 4
+#endif
+
+/**
+ * The dwc_otg_dev_if structure contains information needed to manage
+ * the DWC_otg controller acting in device mode. It represents the
+ * programming view of the device-specific aspects of the controller.
+ */
+typedef struct dwc_otg_dev_if {
+        /** Pointer to device Global registers.
+         * Device Global Registers starting at offset 800h
+         */
+        dwc_otg_device_global_regs_t *dev_global_regs;
+#define DWC_DEV_GLOBAL_REG_OFFSET 0x800
+
+        /**
+         * Device Logical IN Endpoint-Specific Registers 900h-AFCh
+         */
+        dwc_otg_dev_in_ep_regs_t     *in_ep_regs[MAX_EPS_CHANNELS];	/*fscz divide 2 */
+#define DWC_DEV_IN_EP_REG_OFFSET 0x900
+#define DWC_EP_REG_OFFSET 0x20
+
+        /** Device Logical OUT Endpoint-Specific Registers B00h-CFCh */
+        dwc_otg_dev_out_ep_regs_t    *out_ep_regs[MAX_EPS_CHANNELS]; /*fscz divide 2 */
+#define DWC_DEV_OUT_EP_REG_OFFSET 0xB00
+
+        /* Device configuration information*/
+        uint8_t  speed;              /**< Device Speed  0: Unknown, 1: LS, 2:FS, 3: HS */
+	/*fscz */
+    uint8_t  num_in_eps;         /**< Number # of Tx EP range: 0-15 exept ep0 */
+    uint8_t  num_out_eps;        /**< Number # of Rx EP range: 0-15 exept ep 0*/
+
+
+        /** Size of periodic FIFOs (Bytes) */
+        uint16_t perio_tx_fifo_size[MAX_PERIO_FIFOS];
+
+		/*fscz */
+	    /** Size of Tx FIFOs (Bytes) */
+    	uint16_t tx_fifo_size[MAX_TX_FIFOS];
+
+	    /** Thresholding enable flags and length varaiables **/
+    	uint16_t rx_thr_en;
+	    uint16_t iso_tx_thr_en;
+   		uint16_t non_iso_tx_thr_en;
+
+	    uint16_t rx_thr_length;
+    	uint16_t tx_thr_length;
+} dwc_otg_dev_if_t;
+
+/**
+ * This union represents the bit fields in the Power and Clock Gating Control
+ * Register. Read the register into the <i>d32</i> member then set/clear the
+ * bits using the <i>b</i>it elements.
+ */
+typedef union pcgcctl_data		/*fsczzzz */
+{
+	/** raw register data */
+	uint32_t d32;
+
+	/** register bits */
+	struct {
+		unsigned reserved31_05 : 27;
+		/** PHY Suspended */
+		unsigned physuspended : 1;
+		/** Reset Power Down Modules */
+		unsigned rstpdwnmodule : 1;
+		/** Power Clamp */
+		unsigned pwrclmp : 1;
+		/** Gate Hclk */
+		unsigned gatehclk : 1;
+		/** Stop Pclk */
+		unsigned stoppclk : 1;
+	} b;
+} pcgcctl_data_t;
+
+/////////////////////////////////////////////////
+// Host Mode Register Structures
+//
+/**
+ * The Host Global Registers structure defines the size and relative
+ * field offsets for the Host Mode Global Registers.  Host Global
+ * Registers offsets 400h-7FFh.
+*/
+typedef struct dwc_otg_host_global_regs
+{
+        /** Host Configuration Register.   <i>Offset: 400h</i> */
+        volatile uint32_t hcfg;
+        /** Host Frame Interval Register.   <i>Offset: 404h</i> */
+        volatile uint32_t hfir;
+        /** Host Frame Number / Frame Remaining Register. <i>Offset: 408h</i> */
+        volatile uint32_t hfnum;
+        /** Reserved.   <i>Offset: 40Ch</i> */
+        uint32_t reserved40C;
+        /** Host Periodic Transmit FIFO/ Queue Status Register. <i>Offset: 410h</i> */
+        volatile uint32_t hptxsts;
+        /** Host All Channels Interrupt Register. <i>Offset: 414h</i> */
+        volatile uint32_t haint;
+        /** Host All Channels Interrupt Mask Register. <i>Offset: 418h</i> */
+        volatile uint32_t haintmsk;
+} dwc_otg_host_global_regs_t;
+
+/**
+ * This union represents the bit fields in the Host Configuration Register.
+ * Read the register into the <i>d32</i> member then set/clear the bits using
+ * the <i>b</i>it elements. Write the <i>d32</i> member to the hcfg register.
+ */
+typedef union hcfg_data			//*
+{
+        /** raw register data */
+        uint32_t d32;
+
+        /** register bits */
+        struct {
+
+#define DWC_HCFG_30_60_MHZ 0
+#define DWC_HCFG_48_MHZ    1
+#define DWC_HCFG_6_MHZ     2
+		/** FS/LS Only Support */
+		unsigned fslssupp : 1;
+		/** FS/LS Phy Clock Select */
+		unsigned fslspclksel : 2;
+        } b;
+} hcfg_data_t;
+
+/**
+ * This union represents the bit fields in the Host Frame Remaing/Number
+ * Register.
+ */
+typedef union hfir_data			//*
+{
+        /** raw register data */
+        uint32_t d32;
+
+        /** register bits */
+        struct {
+		unsigned reserved : 16;
+		unsigned frint : 16;
+        } b;
+} hfir_data_t;
+
+/**
+ * This union represents the bit fields in the Host Frame Remaing/Number
+ * Register.
+ */
+typedef union hfnum_data	//*
+{
+        /** raw register data */
+        uint32_t d32;
+
+        /** register bits */
+        struct {
+#define DWC_HFNUM_MAX_FRNUM 0x3FFF
+		unsigned frrem : 16;
+		unsigned frnum : 16;
+        } b;
+} hfnum_data_t;
+
+typedef union hptxsts_data	//*
+{
+	/** raw register data */
+	uint32_t d32;
+
+	/** register bits */
+	struct {
+		unsigned ptxqtop_odd : 1;
+		unsigned ptxqtop_chnum : 4;
+		unsigned ptxqtop_token : 2;
+		unsigned ptxqtop_terminate : 1;
+		unsigned ptxqspcavail : 8;
+		unsigned ptxfspcavail : 16;
+		/** Top of the Periodic Transmit Request Queue
+		 *  - bit 24 - Terminate (last entry for the selected channel)
+		 *  - bits 26:25 - Token Type
+		 *    - 2'b00 - Zero length
+		 *    - 2'b01 - Ping
+		 *    - 2'b10 - Disable
+		 *  - bits 30:27 - Channel Number
+		 *  - bit 31 - Odd/even microframe
+		 */
+	} b;
+} hptxsts_data_t;
+
+/**
+ * This union represents the bit fields in the Host Port Control and Status
+ * Register. Read the register into the <i>d32</i> member then set/clear the
+ * bits using the <i>b</i>it elements. Write the <i>d32</i> member to the
+ * hprt0 register.
+ */
+typedef union hprt0_data	//*
+{
+        /** raw register data */
+        uint32_t d32;
+        /** register bits */
+        struct {
+
+#define DWC_HPRT0_PRTSPD_HIGH_SPEED 0
+#define DWC_HPRT0_PRTSPD_FULL_SPEED 1
+#define DWC_HPRT0_PRTSPD_LOW_SPEED  2
+		unsigned reserved19_31 : 13;
+		unsigned prtspd : 2;
+		unsigned prttstctl : 4;
+		unsigned prtpwr : 1;
+		unsigned prtlnsts : 2;
+		unsigned reserved9 : 1;
+		unsigned prtrst : 1;
+		unsigned prtsusp : 1;
+		unsigned prtres : 1;
+		unsigned prtovrcurrchng : 1;
+		unsigned prtovrcurract : 1;
+		unsigned prtenchng : 1;
+		unsigned prtena : 1;
+		unsigned prtconndet : 1;
+		unsigned prtconnsts : 1;
+        } b;
+} hprt0_data_t;
+
+/**
+ * This union represents the bit fields in the Host All Interrupt
+ * Register.
+ */
+typedef union haint_data	//*
+{
+        /** raw register data */
+        uint32_t d32;
+        /** register bits */
+        struct {
+		unsigned reserved : 16;
+		unsigned ch15 : 1;
+		unsigned ch14 : 1;
+		unsigned ch13 : 1;
+		unsigned ch12 : 1;
+		unsigned ch11 : 1;
+		unsigned ch10 : 1;
+		unsigned ch9 : 1;
+		unsigned ch8 : 1;
+		unsigned ch7 : 1;
+		unsigned ch6 : 1;
+		unsigned ch5 : 1;
+		unsigned ch4 : 1;
+		unsigned ch3 : 1;
+		unsigned ch2 : 1;
+		unsigned ch1 : 1;
+		unsigned ch0 : 1;
+	} b;
+        struct {
+		unsigned reserved : 16;
+		unsigned chint : 16;
+	} b2;
+} haint_data_t;
+
+/**
+ * This union represents the bit fields in the Host All Interrupt
+ * Register.
+ */
+typedef union haintmsk_data		//*
+{
+        /** raw register data */
+        uint32_t d32;
+        /** register bits */
+        struct {
+		unsigned reserved : 16;
+		unsigned ch15 : 1;
+		unsigned ch14 : 1;
+		unsigned ch13 : 1;
+		unsigned ch12 : 1;
+		unsigned ch11 : 1;
+		unsigned ch10 : 1;
+		unsigned ch9 : 1;
+		unsigned ch8 : 1;
+		unsigned ch7 : 1;
+		unsigned ch6 : 1;
+		unsigned ch5 : 1;
+		unsigned ch4 : 1;
+		unsigned ch3 : 1;
+		unsigned ch2 : 1;
+		unsigned ch1 : 1;
+		unsigned ch0 : 1;
+	} b;
+        struct {
+		unsigned reserved : 16;
+		unsigned chint : 16;
+	} b2;
+} haintmsk_data_t;
+
+/**
+ * Host Channel Specific Registers. <i>500h-5FCh</i>
+ */
+typedef struct dwc_otg_hc_regs
+{
+        /** Host Channel 0 Characteristic Register. <i>Offset: 500h + (chan_num * 20h) + 00h</i> */
+        volatile uint32_t hcchar;
+        /** Host Channel 0 Split Control Register. <i>Offset: 500h + (chan_num * 20h) + 04h</i> */
+        volatile uint32_t hcsplt;
+        /** Host Channel 0 Interrupt Register. <i>Offset: 500h + (chan_num * 20h) + 08h</i> */
+        volatile uint32_t hcint;
+        /** Host Channel 0 Interrupt Mask Register. <i>Offset: 500h + (chan_num * 20h) + 0Ch</i> */
+        volatile uint32_t hcintmsk;
+        /** Host Channel 0 Transfer Size Register. <i>Offset: 500h + (chan_num * 20h) + 10h</i> */
+        volatile uint32_t hctsiz;
+        /** Host Channel 0 DMA Address Register. <i>Offset: 500h + (chan_num * 20h) + 14h</i> */
+        volatile uint32_t hcdma;
+        /** Reserved.  <i>Offset: 500h + (chan_num * 20h) + 18h - 500h + (chan_num * 20h) + 1Ch</i> */
+        uint32_t reserved[2];
+} dwc_otg_hc_regs_t;
+
+/**
+ * This union represents the bit fields in the Host Channel Characteristics
+ * Register. Read the register into the <i>d32</i> member then set/clear the
+ * bits using the <i>b</i>it elements. Write the <i>d32</i> member to the
+ * hcchar register.
+ */
+typedef union hcchar_data		//*
+{
+        /** raw register data */
+        uint32_t d32;
+
+        /** register bits */
+        struct {
+		/** Channel enable */
+		unsigned chen : 1;
+
+		/** Channel disable */
+		unsigned chdis : 1;
+
+		/**
+		 * Frame to transmit periodic transaction.
+		 * 0: even, 1: odd
+		 */
+		unsigned oddfrm : 1;
+
+		/** Device address */
+		unsigned devaddr : 7;
+
+		/** Packets per frame for periodic transfers. 0 is reserved. */
+		unsigned multicnt : 2;
+
+		/** 0: Control, 1: Isoc, 2: Bulk, 3: Intr */
+		unsigned eptype : 2;
+
+		/** 0: Full/high speed device, 1: Low speed device */
+		unsigned lspddev : 1;
+
+		unsigned reserved : 1;
+
+		/** 0: OUT, 1: IN */
+		unsigned epdir : 1;
+
+		/** Endpoint number */
+		unsigned epnum : 4;
+
+		/** Maximum packet size in bytes */
+		unsigned mps : 11;
+        } b;
+} hcchar_data_t;
+
+typedef union hcsplt_data	//*
+{
+        /** raw register data */
+        uint32_t d32;
+
+        /** register bits */
+        struct {
+		/** Split Enble */
+		unsigned spltena : 1;
+
+		/** Reserved */
+		unsigned reserved : 14;
+
+		/** Do Complete Split */
+		unsigned compsplt : 1;
+
+
+		/** Transaction Position */
+		unsigned xactpos : 2;
+#define DWC_HCSPLIT_XACTPOS_MID 0
+#define DWC_HCSPLIT_XACTPOS_END 1
+#define DWC_HCSPLIT_XACTPOS_BEGIN 2
+#define DWC_HCSPLIT_XACTPOS_ALL 3
+
+		/** Hub Address */
+		unsigned hubaddr : 7;
+
+		/** Port Address */
+		unsigned prtaddr : 7;
+
+	} b;
+} hcsplt_data_t;
+
+
+/**
+ * This union represents the bit fields in the Host All Interrupt
+ * Register.
+ */
+typedef union hcint_data	//*
+{
+        /** raw register data */
+        uint32_t d32;
+        /** register bits */
+        struct {
+		/** Reserved */
+		unsigned reserved : 21;
+		/** Data Toggle Error */
+		unsigned datatglerr : 1;
+		/** Frame Overrun */
+		unsigned frmovrun : 1;
+		/** Babble Error */
+		unsigned bblerr : 1;
+		/** Transaction Err */
+		unsigned xacterr : 1;
+		/** NYET Response Received */
+		unsigned nyet : 1;
+		/** ACK Response Received */
+		unsigned ack : 1;
+		/** NAK Response Received */
+		unsigned nak : 1;
+		/** STALL Response Received */
+		unsigned stall : 1;
+		/** AHB Error */
+		unsigned ahberr : 1;
+		/** Channel Halted */
+		unsigned chhltd : 1;
+		/** Transfer Complete */
+		unsigned xfercomp : 1;
+	} b;
+} hcint_data_t;
+
+/**
+ * This union represents the bit fields in the Host Channel Transfer Size
+ * Register. Read the register into the <i>d32</i> member then set/clear the
+ * bits using the <i>b</i>it elements. Write the <i>d32</i> member to the
+ * hcchar register.
+ */
+typedef union hctsiz_data	//*
+{
+        /** raw register data */
+        uint32_t d32;
+
+        /** register bits */
+        struct {
+#define DWC_HCTSIZ_DATA0 0
+#define DWC_HCTSIZ_DATA1 2
+#define DWC_HCTSIZ_DATA2 1
+#define DWC_HCTSIZ_MDATA 3
+#define DWC_HCTSIZ_SETUP 3
+
+		/** Do PING protocol when 1 */
+		unsigned dopng : 1;
+
+		/**
+		 * Packet ID for next data packet
+		 * 0: DATA0
+		 * 1: DATA2
+		 * 2: DATA1
+		 * 3: MDATA (non-Control), SETUP (Control)
+		 */
+		unsigned pid : 2;
+
+		/** Data packets to transfer */
+		unsigned pktcnt : 10;
+
+		/** Total transfer size in bytes */
+		unsigned xfersize : 19;
+        } b;
+} hctsiz_data_t;
+
+/**
+ * This union represents the bit fields in the Host Channel Interrupt Mask
+ * Register. Read the register into the <i>d32</i> member then set/clear the
+ * bits using the <i>b</i>it elements. Write the <i>d32</i> member to the
+ * hcintmsk register.
+ */
+typedef union hcintmsk_data		//*
+{
+        /** raw register data */
+        uint32_t d32;
+
+        /** register bits */
+        struct {
+		unsigned reserved : 21;
+		unsigned datatglerr : 1;
+		unsigned frmovrun : 1;
+		unsigned bblerr : 1;
+		unsigned xacterr : 1;
+		unsigned nyet : 1;
+		unsigned ack : 1;
+		unsigned nak : 1;
+		unsigned stall : 1;
+		unsigned ahberr : 1;
+		unsigned chhltd : 1;
+		unsigned xfercompl : 1;
+        } b;
+} hcintmsk_data_t;
+
+/** OTG Host Interface Structure.
+ *
+ * The OTG Host Interface Structure structure contains information
+ * needed to manage the DWC_otg controller acting in host mode. It
+ * represents the programming view of the host-specific aspects of the
+ * controller.
+ */
+typedef struct dwc_otg_host_if {
+        /** Host Global Registers starting at offset 400h.*/
+        dwc_otg_host_global_regs_t *host_global_regs;
+#define DWC_OTG_HOST_GLOBAL_REG_OFFSET 0x400
+
+        /** Host Port 0 Control and Status Register */
+        volatile uint32_t *hprt0;
+#define DWC_OTG_HOST_PORT_REGS_OFFSET 0x440
+
+
+        /** Host Channel Specific Registers at offsets 500h-5FCh. */
+        dwc_otg_hc_regs_t *hc_regs[MAX_EPS_CHANNELS];
+#define DWC_OTG_HOST_CHAN_REGS_OFFSET 0x500
+#define DWC_OTG_CHAN_REGS_OFFSET 0x20
+
+
+        /* Host configuration information */
+        /** Number of Host Channels (range: 1-16) */
+        uint8_t  num_host_channels;
+        /** Periodic EPs supported (0: no, 1: yes) */
+        uint8_t  perio_eps_supported;
+        /** Periodic Tx FIFO Size (Only 1 host periodic Tx FIFO) */
+        uint16_t perio_tx_fifo_size;
+
+} dwc_otg_host_if_t;
+
+
+#else  /* CONFIG_4xx not defined */
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+/**
+ * This union represents the bit fields of the Core OTG Control
+ * and Status Register (GOTGCTL).  Set the bits using the bit
+ * fields then write the <i>d32</i> value to the register.
+ */
+typedef union gotgctl_data
+{
+	/** raw register data */
+	uint32_t d32;
+	/** register bits */
+	struct {
+		unsigned sesreqscs : 1;
+		unsigned sesreq : 1;
+		unsigned reserved2_7 : 6;
+		unsigned hstnegscs : 1;
+		unsigned hnpreq : 1;
+		unsigned hstsethnpen : 1;
+		unsigned devhnpen : 1;
+		unsigned reserved12_15 : 4;
+		unsigned conidsts : 1;
+		unsigned reserved17 : 1;
+		unsigned asesvld : 1;
+		unsigned bsesvld : 1;
+		unsigned currmod : 1;
+		unsigned reserved21_31 : 11;
+	} b;
+} gotgctl_data_t;
+
+/**
+ * This union represents the bit fields of the Core OTG Interrupt Register
+ * (GOTGINT).  Set/clear the bits using the bit fields then write the <i>d32</i>
+ * value to the register.
+ */
+typedef union gotgint_data
+{
+	/** raw register data */
+	uint32_t d32;
+	/** register bits */
+	struct {
+		/** Current Mode */
+		unsigned reserved0_1 : 2;
+
+		/** Session End Detected */
+		unsigned sesenddet : 1;
+
+		unsigned reserved3_7 : 5;
+
+		/** Session Request Success Status Change */
+		unsigned sesreqsucstschng : 1;
+		/** Host Negotiation Success Status Change */
+		unsigned hstnegsucstschng : 1;
+
+		unsigned reserver10_16 : 7;
+
+		/** Host Negotiation Detected */
+		unsigned hstnegdet : 1;
+		/** A-Device Timeout Change */
+		unsigned adevtoutchng : 1;
+		/** Debounce Done */
+		unsigned debdone : 1;
+
+		unsigned reserved31_20 : 12;
+
+	} b;
+} gotgint_data_t;
+
+
+/**
+ * This union represents the bit fields of the Core AHB Configuration
+ * Register (GAHBCFG).	Set/clear the bits using the bit fields then
+ * write the <i>d32</i> value to the register.
+ */
+typedef union gahbcfg_data
+{
+	/** raw register data */
+	uint32_t d32;
+	/** register bits */
+	struct {
+		unsigned glblintrmsk : 1;
+#define DWC_GAHBCFG_GLBINT_ENABLE		1
+
+		unsigned hburstlen : 4;
+#define DWC_GAHBCFG_INT_DMA_BURST_SINGLE	0
+#define DWC_GAHBCFG_INT_DMA_BURST_INCR		1
+#define DWC_GAHBCFG_INT_DMA_BURST_INCR4		3
+#define DWC_GAHBCFG_INT_DMA_BURST_INCR8		5
+#define DWC_GAHBCFG_INT_DMA_BURST_INCR16	7
+
+		unsigned dmaenable : 1;
+#define DWC_GAHBCFG_DMAENABLE			1
+		unsigned reserved : 1;
+		unsigned nptxfemplvl_txfemplvl : 1;
+		unsigned ptxfemplvl : 1;
+#define DWC_GAHBCFG_TXFEMPTYLVL_EMPTY		1
+#define DWC_GAHBCFG_TXFEMPTYLVL_HALFEMPTY	0
+		unsigned reserved9_31 : 23;
+	} b;
+} gahbcfg_data_t;
+
+/**
+ * This union represents the bit fields of the Core USB Configuration
+ * Register (GUSBCFG).	Set the bits using the bit fields then write
+ * the <i>d32</i> value to the register.
+ */
+typedef union gusbcfg_data
+{
+	/** raw register data */
+	uint32_t d32;
+	/** register bits */
+	struct {
+		unsigned toutcal : 3;
+		unsigned phyif : 1;
+		unsigned ulpi_utmi_sel : 1;
+		unsigned fsintf : 1;
+		unsigned physel : 1;
+		unsigned ddrsel : 1;
+		unsigned srpcap : 1;
+		unsigned hnpcap : 1;
+		unsigned usbtrdtim : 4;
+		unsigned nptxfrwnden : 1;
+		unsigned phylpwrclksel : 1;
+		unsigned otgutmifssel : 1;
+		unsigned ulpi_fsls : 1;
+		unsigned ulpi_auto_res : 1;
+		unsigned ulpi_clk_sus_m : 1;
+		unsigned ulpi_ext_vbus_drv : 1;
+		unsigned ulpi_int_vbus_indicator : 1;
+		unsigned term_sel_dl_pulse : 1;
+		unsigned reserved23_28 : 6;
+		unsigned force_host_mode: 1;
+		unsigned force_device_mode: 1;
+		unsigned corrupt_tx_packet: 1;
+	} b;
+} gusbcfg_data_t;
+
+/**
+ * This union represents the bit fields of the Core Reset Register
+ * (GRSTCTL).  Set/clear the bits using the bit fields then write the
+ * <i>d32</i> value to the register.
+ */
+typedef union grstctl_data
+{
+	/** raw register data */
+	uint32_t d32;
+	/** register bits */
+	struct {
+		/** Core Soft Reset (CSftRst) (Device and Host)
+		 *
+		 * The application can flush the control logic in the
+		 * entire core using this bit. This bit resets the
+		 * pipelines in the AHB Clock domain as well as the
+		 * PHY Clock domain.
+		 *
+		 * The state machines are reset to an IDLE state, the
+		 * control bits in the CSRs are cleared, all the
+		 * transmit FIFOs and the receive FIFO are flushed.
+		 *
+		 * The status mask bits that control the generation of
+		 * the interrupt, are cleared, to clear the
+		 * interrupt. The interrupt status bits are not
+		 * cleared, so the application can get the status of
+		 * any events that occurred in the core after it has
+		 * set this bit.
+		 *
+		 * Any transactions on the AHB are terminated as soon
+		 * as possible following the protocol. Any
+		 * transactions on the USB are terminated immediately.
+		 *
+		 * The configuration settings in the CSRs are
+		 * unchanged, so the software doesn't have to
+		 * reprogram these registers (Device
+		 * Configuration/Host Configuration/Core System
+		 * Configuration/Core PHY Configuration).
+		 *
+		 * The application can write to this bit, any time it
+		 * wants to reset the core. This is a self clearing
+		 * bit and the core clears this bit after all the
+		 * necessary logic is reset in the core, which may
+		 * take several clocks, depending on the current state
+		 * of the core.
+		 */
+		unsigned csftrst : 1;
+		/** Hclk Soft Reset
+		 *
+		 * The application uses this bit to reset the control logic in
+		 * the AHB clock domain. Only AHB clock domain pipelines are
+		 * reset.
+		 */
+		unsigned hsftrst : 1;
+		/** Host Frame Counter Reset (Host Only)<br>
+		 *
+		 * The application can reset the (micro)frame number
+		 * counter inside the core, using this bit. When the
+		 * (micro)frame counter is reset, the subsequent SOF
+		 * sent out by the core, will have a (micro)frame
+		 * number of 0.
+		 */
+		unsigned hstfrm : 1;
+		/** In Token Sequence Learning Queue Flush
+		 * (INTknQFlsh) (Device Only)
+		 */
+		unsigned intknqflsh : 1;
+		/** RxFIFO Flush (RxFFlsh) (Device and Host)
+		 *
+		 * The application can flush the entire Receive FIFO
+		 * using this bit.	<p>The application must first
+		 * ensure that the core is not in the middle of a
+		 * transaction.	 <p>The application should write into
+		 * this bit, only after making sure that neither the
+		 * DMA engine is reading from the RxFIFO nor the MAC
+		 * is writing the data in to the FIFO.	<p>The
+		 * application should wait until the bit is cleared
+		 * before performing any other operations. This bit
+		 * will takes 8 clocks (slowest of PHY or AHB clock)
+		 * to clear.
+		 */
+		unsigned rxfflsh : 1;
+		/** TxFIFO Flush (TxFFlsh) (Device and Host).
+		 *
+		 * This bit is used to selectively flush a single or
+		 * all transmit FIFOs.	The application must first
+		 * ensure that the core is not in the middle of a
+		 * transaction.	 <p>The application should write into
+		 * this bit, only after making sure that neither the
+		 * DMA engine is writing into the TxFIFO nor the MAC
+		 * is reading the data out of the FIFO.	 <p>The
+		 * application should wait until the core clears this
+		 * bit, before performing any operations. This bit
+		 * will takes 8 clocks (slowest of PHY or AHB clock)
+		 * to clear.
+		 */
+		unsigned txfflsh : 1;
+
+		/** TxFIFO Number (TxFNum) (Device and Host).
+		 *
+		 * This is the FIFO number which needs to be flushed,
+		 * using the TxFIFO Flush bit. This field should not
+		 * be changed until the TxFIFO Flush bit is cleared by
+		 * the core.
+		 *	 - 0x0 : Non Periodic TxFIFO Flush
+		 *	 - 0x1 : Periodic TxFIFO #1 Flush in device mode
+		 *	   or Periodic TxFIFO in host mode
+		 *	 - 0x2 : Periodic TxFIFO #2 Flush in device mode.
+		 *	 - ...
+		 *	 - 0xF : Periodic TxFIFO #15 Flush in device mode
+		 *	 - 0x10: Flush all the Transmit NonPeriodic and
+		 *	   Transmit Periodic FIFOs in the core
+		 */
+		unsigned txfnum : 5;
+		/** Reserved */
+		unsigned reserved11_29 : 19;
+		/** DMA Request Signal.	 Indicated DMA request is in
+		 * probress.  Used for debug purpose. */
+		unsigned dmareq : 1;
+		/** AHB Master Idle.  Indicates the AHB Master State
+		 * Machine is in IDLE condition. */
+		unsigned ahbidle : 1;
+	} b;
+} grstctl_t;
+
+
+/**
+ * This union represents the bit fields of the Core Interrupt Mask
+ * Register (GINTMSK).	Set/clear the bits using the bit fields then
+ * write the <i>d32</i> value to the register.
+ */
+typedef union gintmsk_data
+{
+	/** raw register data */
+	uint32_t d32;
+	/** register bits */
+	struct {
+		unsigned reserved0 : 1;
+		unsigned modemismatch : 1;
+		unsigned otgintr : 1;
+		unsigned sofintr : 1;
+		unsigned rxstsqlvl : 1;
+		unsigned nptxfempty : 1;
+		unsigned ginnakeff : 1;
+		unsigned goutnakeff : 1;
+		unsigned reserved8 : 1;
+		unsigned i2cintr : 1;
+		unsigned erlysuspend : 1;
+		unsigned usbsuspend : 1;
+		unsigned usbreset : 1;
+		unsigned enumdone : 1;
+		unsigned isooutdrop : 1;
+		unsigned eopframe : 1;
+		unsigned reserved16 : 1;
+		unsigned epmismatch : 1;
+		unsigned inepintr : 1;
+		unsigned outepintr : 1;
+		unsigned incomplisoin : 1;
+		unsigned incomplisoout : 1;
+		unsigned reserved22_23 : 2;
+		unsigned portintr : 1;
+		unsigned hcintr : 1;
+		unsigned ptxfempty : 1;
+		unsigned reserved27 : 1;
+		unsigned conidstschng : 1;
+		unsigned disconnect : 1;
+		unsigned sessreqintr : 1;
+		unsigned wkupintr : 1;
+	} b;
+} gintmsk_data_t;
+/**
+ * This union represents the bit fields of the Core Interrupt Register
+ * (GINTSTS).  Set/clear the bits using the bit fields then write the
+ * <i>d32</i> value to the register.
+ */
+typedef union gintsts_data
+{
+	/** raw register data */
+	uint32_t d32;
+#define DWC_SOF_INTR_MASK 0x0008
+	/** register bits */
+	struct {
+#define DWC_HOST_MODE 1
+		unsigned curmode : 1;
+		unsigned modemismatch : 1;
+		unsigned otgintr : 1;
+		unsigned sofintr : 1;
+		unsigned rxstsqlvl : 1;
+		unsigned nptxfempty : 1;
+		unsigned ginnakeff : 1;
+		unsigned goutnakeff : 1;
+		unsigned reserved8 : 1;
+		unsigned i2cintr : 1;
+		unsigned erlysuspend : 1;
+		unsigned usbsuspend : 1;
+		unsigned usbreset : 1;
+		unsigned enumdone : 1;
+		unsigned isooutdrop : 1;
+		unsigned eopframe : 1;
+		unsigned intokenrx : 1;
+		unsigned epmismatch : 1;
+		unsigned inepint: 1;
+		unsigned outepintr : 1;
+		unsigned incomplisoin : 1;
+		unsigned incomplisoout : 1;
+		unsigned reserved22_23 : 2;
+		unsigned portintr : 1;
+		unsigned hcintr : 1;
+		unsigned ptxfempty : 1;
+		unsigned reserved27 : 1;
+		unsigned conidstschng : 1;
+		unsigned disconnect : 1;
+		unsigned sessreqintr : 1;
+		unsigned wkupintr : 1;
+	} b;
+} gintsts_data_t;
+
+
+/**
+ * This union represents the bit fields in the Device Receive Status Read and
+ * Pop Registers (GRXSTSR, GRXSTSP) Read the register into the <i>d32</i>
+ * element then read out the bits using the <i>b</i>it elements.
+ */
+typedef union device_grxsts_data
+{
+	/** raw register data */
+	uint32_t d32;
+	/** register bits */
+	struct {
+		unsigned epnum : 4;
+		unsigned bcnt : 11;
+		unsigned dpid : 2;
+
+#define DWC_STS_DATA_UPDT		0x2				  // OUT Data Packet
+#define DWC_STS_XFER_COMP		0x3				  // OUT Data Transfer Complete
+
+#define DWC_DSTS_GOUT_NAK		0x1				  // Global OUT NAK
+#define DWC_DSTS_SETUP_COMP		0x4				  // Setup Phase Complete
+#define DWC_DSTS_SETUP_UPDT 0x6				  // SETUP Packet
+		unsigned pktsts : 4;
+		unsigned fn : 4;
+		unsigned reserved : 7;
+	} b;
+} device_grxsts_data_t;
+
+/**
+ * This union represents the bit fields in the Host Receive Status Read and
+ * Pop Registers (GRXSTSR, GRXSTSP) Read the register into the <i>d32</i>
+ * element then read out the bits using the <i>b</i>it elements.
+ */
+typedef union host_grxsts_data
+{
+	/** raw register data */
+	uint32_t d32;
+	/** register bits */
+	struct {
+		unsigned chnum : 4;
+		unsigned bcnt : 11;
+		unsigned dpid : 2;
+
+		unsigned pktsts : 4;
+#define DWC_GRXSTS_PKTSTS_IN			  0x2
+#define DWC_GRXSTS_PKTSTS_IN_XFER_COMP	  0x3
+#define DWC_GRXSTS_PKTSTS_DATA_TOGGLE_ERR 0x5
+#define DWC_GRXSTS_PKTSTS_CH_HALTED		  0x7
+
+		unsigned reserved : 11;
+	} b;
+} host_grxsts_data_t;
+
+/**
+ * This union represents the bit fields in the FIFO Size Registers (HPTXFSIZ,
+ * GNPTXFSIZ, DPTXFSIZn, DIEPTXFn). Read the register into the <i>d32</i> element then
+ * read out the bits using the <i>b</i>it elements.
+ */
+typedef union fifosize_data
+{
+	/** raw register data */
+	uint32_t d32;
+	/** register bits */
+	struct {
+		unsigned startaddr : 16;
+		unsigned depth : 16;
+	} b;
+} fifosize_data_t;
+
+/**
+ * This union represents the bit fields in the Non-Periodic Transmit
+ * FIFO/Queue Status Register (GNPTXSTS). Read the register into the
+ * <i>d32</i> element then read out the bits using the <i>b</i>it
+ * elements.
+ */
+typedef union gnptxsts_data
+{
+	/** raw register data */
+	uint32_t d32;
+	/** register bits */
+	struct {
+		unsigned nptxfspcavail : 16;
+		unsigned nptxqspcavail : 8;
+		/** Top of the Non-Periodic Transmit Request Queue
+		 *	- bit 24 - Terminate (Last entry for the selected
+		 *	  channel/EP)
+		 *	- bits 26:25 - Token Type
+		 *	  - 2'b00 - IN/OUT
+		 *	  - 2'b01 - Zero Length OUT
+		 *	  - 2'b10 - PING/Complete Split
+		 *	  - 2'b11 - Channel Halt
+		 *	- bits 30:27 - Channel/EP Number
+		 */
+		unsigned nptxqtop_terminate : 1;
+		unsigned nptxqtop_token : 2;
+		unsigned nptxqtop_chnep : 4;
+		unsigned reserved : 1;
+	} b;
+} gnptxsts_data_t;
+
+/**
+ * This union represents the bit fields in the Transmit
+ * FIFO Status Register (DTXFSTS). Read the register into the
+ * <i>d32</i> element then read out the bits using the <i>b</i>it
+ * elements.
+ */
+typedef union dtxfsts_data
+{
+	/** raw register data */
+	uint32_t d32;
+	/** register bits */
+	struct {
+		unsigned txfspcavail : 16;
+		unsigned reserved : 16;
+	} b;
+} dtxfsts_data_t;
+
+/**
+ * This union represents the bit fields in the I2C Control Register
+ * (I2CCTL). Read the register into the <i>d32</i> element then read out the
+ * bits using the <i>b</i>it elements.
+ */
+typedef union gi2cctl_data
+{
+	/** raw register data */
+	uint32_t d32;
+	/** register bits */
+	struct {
+		unsigned rwdata : 8;
+		unsigned regaddr : 8;
+		unsigned addr : 7;
+		unsigned i2cen : 1;
+		unsigned ack : 1;
+		unsigned i2csuspctl : 1;
+		unsigned i2cdevaddr : 2;
+		unsigned reserved : 2;
+		unsigned rw : 1;
+		unsigned bsydne : 1;
+	} b;
+} gi2cctl_data_t;
+
+/**
+ * This union represents the bit fields in the User HW Config1
+ * Register.  Read the register into the <i>d32</i> element then read
+ * out the bits using the <i>b</i>it elements.
+ */
+typedef union hwcfg1_data
+{
+	/** raw register data */
+	uint32_t d32;
+	/** register bits */
+	struct {
+		unsigned ep_dir0 : 2;
+		unsigned ep_dir1 : 2;
+		unsigned ep_dir2 : 2;
+		unsigned ep_dir3 : 2;
+		unsigned ep_dir4 : 2;
+		unsigned ep_dir5 : 2;
+		unsigned ep_dir6 : 2;
+		unsigned ep_dir7 : 2;
+		unsigned ep_dir8 : 2;
+		unsigned ep_dir9 : 2;
+		unsigned ep_dir10 : 2;
+		unsigned ep_dir11 : 2;
+		unsigned ep_dir12 : 2;
+		unsigned ep_dir13 : 2;
+		unsigned ep_dir14 : 2;
+		unsigned ep_dir15 : 2;
+	} b;
+} hwcfg1_data_t;
+
+/**
+ * This union represents the bit fields in the User HW Config2
+ * Register.  Read the register into the <i>d32</i> element then read
+ * out the bits using the <i>b</i>it elements.
+ */
+typedef union hwcfg2_data
+{
+	/** raw register data */
+	uint32_t d32;
+	/** register bits */
+	struct {
+		/* GHWCFG2 */
+		unsigned op_mode : 3;
+#define DWC_HWCFG2_OP_MODE_HNP_SRP_CAPABLE_OTG 0
+#define DWC_HWCFG2_OP_MODE_SRP_ONLY_CAPABLE_OTG 1
+#define DWC_HWCFG2_OP_MODE_NO_HNP_SRP_CAPABLE_OTG 2
+#define DWC_HWCFG2_OP_MODE_SRP_CAPABLE_DEVICE 3
+#define DWC_HWCFG2_OP_MODE_NO_SRP_CAPABLE_DEVICE 4
+#define DWC_HWCFG2_OP_MODE_SRP_CAPABLE_HOST 5
+#define DWC_HWCFG2_OP_MODE_NO_SRP_CAPABLE_HOST 6
+
+		unsigned architecture : 2;
+		unsigned point2point : 1;
+		unsigned hs_phy_type : 2;
+#define DWC_HWCFG2_HS_PHY_TYPE_NOT_SUPPORTED 0
+#define DWC_HWCFG2_HS_PHY_TYPE_UTMI 1
+#define DWC_HWCFG2_HS_PHY_TYPE_ULPI 2
+#define DWC_HWCFG2_HS_PHY_TYPE_UTMI_ULPI 3
+
+		unsigned fs_phy_type : 2;
+		unsigned num_dev_ep : 4;
+		unsigned num_host_chan : 4;
+		unsigned perio_ep_supported : 1;
+		unsigned dynamic_fifo : 1;
+		unsigned rx_status_q_depth : 2;
+		unsigned nonperio_tx_q_depth : 2;
+		unsigned host_perio_tx_q_depth : 2;
+		unsigned dev_token_q_depth : 5;
+		unsigned reserved31 : 1;
+	} b;
+} hwcfg2_data_t;
+
+/**
+ * This union represents the bit fields in the User HW Config3
+ * Register.  Read the register into the <i>d32</i> element then read
+ * out the bits using the <i>b</i>it elements.
+ */
+typedef union hwcfg3_data
+{
+	/** raw register data */
+	uint32_t d32;
+	/** register bits */
+	struct {
+		/* GHWCFG3 */
+		unsigned xfer_size_cntr_width : 4;
+		unsigned packet_size_cntr_width : 3;
+		unsigned otg_func : 1;
+		unsigned i2c : 1;
+		unsigned vendor_ctrl_if : 1;
+		unsigned optional_features : 1;
+		unsigned synch_reset_type : 1;
+		unsigned reserved15_12 : 4;
+		unsigned dfifo_depth : 16;
+	} b;
+} hwcfg3_data_t;
+
+/**
+ * This union represents the bit fields in the User HW Config4
+ * Register.  Read the register into the <i>d32</i> element then read
+ * out the bits using the <i>b</i>it elements.
+ */
+typedef union hwcfg4_data
+{
+	/** raw register data */
+	uint32_t d32;
+	/** register bits */
+	struct {
+		unsigned num_dev_perio_in_ep : 4;
+		unsigned power_optimiz : 1;
+		unsigned min_ahb_freq : 9;
+		unsigned utmi_phy_data_width : 2;
+		unsigned num_dev_mode_ctrl_ep : 4;
+		unsigned iddig_filt_en : 1;
+		unsigned vbus_valid_filt_en : 1;
+		unsigned a_valid_filt_en : 1;
+		unsigned b_valid_filt_en : 1;
+		unsigned session_end_filt_en : 1;
+		unsigned ded_fifo_en : 1;
+		unsigned num_in_eps : 4;
+		unsigned reserved31_30 : 2;
+	} b;
+} hwcfg4_data_t;
+
+////////////////////////////////////////////
+// Device Registers
+/**
+ * Device Global Registers. <i>Offsets 800h-BFFh</i>
+ *
+ * The following structures define the size and relative field offsets
+ * for the Device Mode Registers.
+ *
+ * <i>These registers are visible only in Device mode and must not be
+ * accessed in Host mode, as the results are unknown.</i>
+ */
+typedef struct dwc_otg_dev_global_regs
+{
+	/** Device Configuration Register. <i>Offset 800h</i> */
+	volatile uint32_t dcfg;
+	/** Device Control Register. <i>Offset: 804h</i> */
+	volatile uint32_t dctl;
+	/** Device Status Register (Read Only). <i>Offset: 808h</i> */
+	volatile uint32_t dsts;
+	/** Reserved. <i>Offset: 80Ch</i> */
+	uint32_t unused;
+	/** Device IN Endpoint Common Interrupt Mask
+	 * Register. <i>Offset: 810h</i> */
+	volatile uint32_t diepmsk;
+	/** Device OUT Endpoint Common Interrupt Mask
+	 * Register. <i>Offset: 814h</i> */
+	volatile uint32_t doepmsk;
+	/** Device All Endpoints Interrupt Register.  <i>Offset: 818h</i> */
+	volatile uint32_t daint;
+	/** Device All Endpoints Interrupt Mask Register.  <i>Offset:
+	 * 81Ch</i> */
+	volatile uint32_t daintmsk;
+	/** Device IN Token Queue Read Register-1 (Read Only).
+	 * <i>Offset: 820h</i> */
+	volatile uint32_t dtknqr1;
+	/** Device IN Token Queue Read Register-2 (Read Only).
+	 * <i>Offset: 824h</i> */
+	volatile uint32_t dtknqr2;
+	/** Device VBUS	 discharge Register.  <i>Offset: 828h</i> */
+	volatile uint32_t dvbusdis;
+	/** Device VBUS Pulse Register.	 <i>Offset: 82Ch</i> */
+	volatile uint32_t dvbuspulse;
+	/** Device IN Token Queue Read Register-3 (Read Only). /
+	 *	Device Thresholding control register (Read/Write)
+	 * <i>Offset: 830h</i> */
+	volatile uint32_t dtknqr3_dthrctl;
+	/** Device IN Token Queue Read Register-4 (Read Only). /
+	 *	Device IN EPs empty Inr. Mask Register (Read/Write)
+	 * <i>Offset: 834h</i> */
+	volatile uint32_t dtknqr4_fifoemptymsk;
+} dwc_otg_device_global_regs_t;
+
+/**
+ * This union represents the bit fields in the Device Configuration
+ * Register.  Read the register into the <i>d32</i> member then
+ * set/clear the bits using the <i>b</i>it elements.  Write the
+ * <i>d32</i> member to the dcfg register.
+ */
+typedef union dcfg_data
+{
+	/** raw register data */
+	uint32_t d32;
+	/** register bits */
+	struct {
+		/** Device Speed */
+		unsigned devspd : 2;
+		/** Non Zero Length Status OUT Handshake */
+		unsigned nzstsouthshk : 1;
+#define DWC_DCFG_SEND_STALL 1
+
+		unsigned reserved3 : 1;
+		/** Device Addresses */
+		unsigned devaddr : 7;
+		/** Periodic Frame Interval */
+		unsigned perfrint : 2;
+#define DWC_DCFG_FRAME_INTERVAL_80 0
+#define DWC_DCFG_FRAME_INTERVAL_85 1
+#define DWC_DCFG_FRAME_INTERVAL_90 2
+#define DWC_DCFG_FRAME_INTERVAL_95 3
+
+		unsigned reserved13_17 : 5;
+		/** In Endpoint Mis-match count */
+		unsigned epmscnt : 4;
+	} b;
+} dcfg_data_t;
+
+/**
+ * This union represents the bit fields in the Device Control
+ * Register.  Read the register into the <i>d32</i> member then
+ * set/clear the bits using the <i>b</i>it elements.
+ */
+typedef union dctl_data
+{
+	/** raw register data */
+	uint32_t d32;
+	/** register bits */
+	struct {
+		/** Remote Wakeup */
+		unsigned rmtwkupsig : 1;
+		/** Soft Disconnect */
+		unsigned sftdiscon : 1;
+		/** Global Non-Periodic IN NAK Status */
+		unsigned gnpinnaksts : 1;
+		/** Global OUT NAK Status */
+		unsigned goutnaksts : 1;
+		/** Test Control */
+		unsigned tstctl : 3;
+		/** Set Global Non-Periodic IN NAK */
+		unsigned sgnpinnak : 1;
+		/** Clear Global Non-Periodic IN NAK */
+		unsigned cgnpinnak : 1;
+		/** Set Global OUT NAK */
+		unsigned sgoutnak : 1;
+		/** Clear Global OUT NAK */
+		unsigned cgoutnak : 1;
+
+		unsigned reserved : 21;
+	} b;
+} dctl_data_t;
+
+/**
+ * This union represents the bit fields in the Device Status
+ * Register.  Read the register into the <i>d32</i> member then
+ * set/clear the bits using the <i>b</i>it elements.
+ */
+typedef union dsts_data
+{
+	/** raw register data */
+	uint32_t d32;
+	/** register bits */
+	struct {
+		/** Suspend Status */
+		unsigned suspsts : 1;
+		/** Enumerated Speed */
+		unsigned enumspd : 2;
+#define DWC_DSTS_ENUMSPD_HS_PHY_30MHZ_OR_60MHZ 0
+#define DWC_DSTS_ENUMSPD_FS_PHY_30MHZ_OR_60MHZ 1
+#define DWC_DSTS_ENUMSPD_LS_PHY_6MHZ		   2
+#define DWC_DSTS_ENUMSPD_FS_PHY_48MHZ		   3
+		/** Erratic Error */
+		unsigned errticerr : 1;
+		unsigned reserved4_7: 4;
+		/** Frame or Microframe Number of the received SOF */
+		unsigned soffn : 14;
+		unsigned reserved22_31 : 10;
+	} b;
+} dsts_data_t;
+
+
+/**
+ * This union represents the bit fields in the Device IN EP Interrupt
+ * Register and the Device IN EP Common Mask Register.
+ *
+ * - Read the register into the <i>d32</i> member then set/clear the
+ *	 bits using the <i>b</i>it elements.
+ */
+typedef union diepint_data
+{
+	/** raw register data */
+	uint32_t d32;
+	/** register bits */
+	struct {
+		/** Transfer complete mask */
+		unsigned xfercompl : 1;
+		/** Endpoint disable mask */
+		unsigned epdisabled : 1;
+		/** AHB Error mask */
+		unsigned ahberr : 1;
+		/** TimeOUT Handshake mask (non-ISOC EPs) */
+		unsigned timeout : 1;
+		/** IN Token received with TxF Empty mask */
+		unsigned intktxfemp : 1;
+		/** IN Token Received with EP mismatch mask */
+		unsigned intknepmis : 1;
+		/** IN Endpoint HAK Effective mask */
+		unsigned inepnakeff : 1;
+		/** IN Endpoint HAK Effective mask */
+		unsigned emptyintr : 1;
+
+		unsigned txfifoundrn : 1;
+
+		unsigned reserved08_31 : 23;
+		} b;
+} diepint_data_t;
+/**
+ * This union represents the bit fields in the Device IN EP Common
+ * Interrupt Mask Register.
+ */
+typedef union diepint_data diepmsk_data_t;
+
+/**
+ * This union represents the bit fields in the Device OUT EP Interrupt
+ * Registerand Device OUT EP Common Interrupt Mask Register.
+ *
+ * - Read the register into the <i>d32</i> member then set/clear the
+ *	 bits using the <i>b</i>it elements.
+ */
+typedef union doepint_data
+{
+	/** raw register data */
+	uint32_t d32;
+	/** register bits */
+	struct {
+		/** Transfer complete */
+		unsigned xfercompl : 1;
+		/** Endpoint disable  */
+		unsigned epdisabled : 1;
+		/** AHB Error */
+		unsigned ahberr : 1;
+		/** Setup Phase Done (contorl EPs) */
+		unsigned setup : 1;
+		unsigned reserved04_31 : 28;
+	} b;
+} doepint_data_t;
+/**
+ * This union represents the bit fields in the Device OUT EP Common
+ * Interrupt Mask Register.
+ */
+typedef union doepint_data doepmsk_data_t;
+
+
+/**
+ * This union represents the bit fields in the Device All EP Interrupt
+ * and Mask Registers.
+ * - Read the register into the <i>d32</i> member then set/clear the
+ *	 bits using the <i>b</i>it elements.
+ */
+typedef union daint_data
+{
+	/** raw register data */
+	uint32_t d32;
+	/** register bits */
+	struct {
+		/** IN Endpoint bits */
+		unsigned in : 16;
+		/** OUT Endpoint bits */
+		unsigned out : 16;
+	} ep;
+	struct {
+		/** IN Endpoint bits */
+		unsigned inep0	: 1;
+		unsigned inep1	: 1;
+		unsigned inep2	: 1;
+		unsigned inep3	: 1;
+		unsigned inep4	: 1;
+		unsigned inep5	: 1;
+		unsigned inep6	: 1;
+		unsigned inep7	: 1;
+		unsigned inep8	: 1;
+		unsigned inep9	: 1;
+		unsigned inep10 : 1;
+		unsigned inep11 : 1;
+		unsigned inep12 : 1;
+		unsigned inep13 : 1;
+		unsigned inep14 : 1;
+		unsigned inep15 : 1;
+		/** OUT Endpoint bits */
+		unsigned outep0	 : 1;
+		unsigned outep1	 : 1;
+		unsigned outep2	 : 1;
+		unsigned outep3	 : 1;
+		unsigned outep4	 : 1;
+		unsigned outep5	 : 1;
+		unsigned outep6	 : 1;
+		unsigned outep7	 : 1;
+		unsigned outep8	 : 1;
+		unsigned outep9	 : 1;
+		unsigned outep10 : 1;
+		unsigned outep11 : 1;
+		unsigned outep12 : 1;
+		unsigned outep13 : 1;
+		unsigned outep14 : 1;
+		unsigned outep15 : 1;
+	} b;
+} daint_data_t;
+
+/**
+ * This union represents the bit fields in the Device IN Token Queue
+ * Read Registers.
+ * - Read the register into the <i>d32</i> member.
+ * - READ-ONLY Register
+ */
+typedef union dtknq1_data
+{
+	/** raw register data */
+	uint32_t d32;
+	/** register bits */
+	struct {
+		/** In Token Queue Write Pointer */
+		unsigned intknwptr : 5;
+		/** Reserved */
+		unsigned reserved05_06 : 2;
+		/** write pointer has wrapped. */
+		unsigned wrap_bit : 1;
+		/** EP Numbers of IN Tokens 0 ... 4 */
+		unsigned epnums0_5 : 24;
+	}b;
+} dtknq1_data_t;
+
+/**
+ * This union represents Threshold control Register
+ * - Read and write the register into the <i>d32</i> member.
+ * - READ-WRITABLE Register
+ */
+typedef union dthrctl_data
+{
+	/** raw register data */
+	uint32_t d32;
+	/** register bits */
+	struct {
+		/** non ISO Tx Thr. Enable */
+		unsigned non_iso_thr_en : 1;
+		/** ISO Tx Thr. Enable */
+		unsigned iso_thr_en : 1;
+		/** Tx Thr. Length */
+		unsigned tx_thr_len : 9;
+		/** Reserved */
+		unsigned reserved11_15 : 5;
+		/** Rx Thr. Enable */
+		unsigned rx_thr_en : 1;
+		/** Rx Thr. Length */
+		unsigned rx_thr_len : 9;
+		/** Reserved */
+		unsigned reserved26_31 : 6;
+	}b;
+} dthrctl_data_t;
+
+
+/**
+ * Device Logical IN Endpoint-Specific Registers. <i>Offsets
+ * 900h-AFCh</i>
+ *
+ * There will be one set of endpoint registers per logical endpoint
+ * implemented.
+ *
+ * <i>These registers are visible only in Device mode and must not be
+ * accessed in Host mode, as the results are unknown.</i>
+ */
+typedef struct dwc_otg_dev_in_ep_regs
+{
+	/** Device IN Endpoint Control Register. <i>Offset:900h +
+	 * (ep_num * 20h) + 00h</i> */
+	volatile uint32_t diepctl;
+	/** Reserved. <i>Offset:900h + (ep_num * 20h) + 04h</i> */
+	uint32_t reserved04;
+	/** Device IN Endpoint Interrupt Register. <i>Offset:900h +
+	 * (ep_num * 20h) + 08h</i> */
+	volatile uint32_t diepint;
+	/** Reserved. <i>Offset:900h + (ep_num * 20h) + 0Ch</i> */
+	uint32_t reserved0C;
+	/** Device IN Endpoint Transfer Size
+	 * Register. <i>Offset:900h + (ep_num * 20h) + 10h</i> */
+	volatile uint32_t dieptsiz;
+	/** Device IN Endpoint DMA Address Register. <i>Offset:900h +
+	 * (ep_num * 20h) + 14h</i> */
+	volatile uint32_t diepdma;
+	/** Device IN Endpoint Transmit FIFO Status Register. <i>Offset:900h +
+	 * (ep_num * 20h) + 18h</i> */
+	volatile uint32_t dtxfsts;
+	/** Reserved. <i>Offset:900h + (ep_num * 20h) + 1Ch - 900h +
+	 * (ep_num * 20h) + 1Ch</i>*/
+	uint32_t reserved18;
+} dwc_otg_dev_in_ep_regs_t;
+
+/**
+ * Device Logical OUT Endpoint-Specific Registers. <i>Offsets:
+ * B00h-CFCh</i>
+ *
+ * There will be one set of endpoint registers per logical endpoint
+ * implemented.
+ *
+ * <i>These registers are visible only in Device mode and must not be
+ * accessed in Host mode, as the results are unknown.</i>
+ */
+typedef struct dwc_otg_dev_out_ep_regs
+{
+	/** Device OUT Endpoint Control Register. <i>Offset:B00h +
+	 * (ep_num * 20h) + 00h</i> */
+	volatile uint32_t doepctl;
+	/** Device OUT Endpoint Frame number Register.	<i>Offset:
+	 * B00h + (ep_num * 20h) + 04h</i> */
+	volatile uint32_t doepfn;
+	/** Device OUT Endpoint Interrupt Register. <i>Offset:B00h +
+	 * (ep_num * 20h) + 08h</i> */
+	volatile uint32_t doepint;
+	/** Reserved. <i>Offset:B00h + (ep_num * 20h) + 0Ch</i> */
+	uint32_t reserved0C;
+	/** Device OUT Endpoint Transfer Size Register. <i>Offset:
+	 * B00h + (ep_num * 20h) + 10h</i> */
+	volatile uint32_t doeptsiz;
+	/** Device OUT Endpoint DMA Address Register. <i>Offset:B00h
+	 * + (ep_num * 20h) + 14h</i> */
+	volatile uint32_t doepdma;
+	/** Reserved. <i>Offset:B00h + (ep_num * 20h) + 18h - B00h +
+	 * (ep_num * 20h) + 1Ch</i> */
+	uint32_t unused[2];
+} dwc_otg_dev_out_ep_regs_t;
+
+/**
+ * This union represents the bit fields in the Device EP Control
+ * Register.  Read the register into the <i>d32</i> member then
+ * set/clear the bits using the <i>b</i>it elements.
+ */
+typedef union depctl_data
+{
+	/** raw register data */
+	uint32_t d32;
+	/** register bits */
+	struct {
+		/** Maximum Packet Size
+		 * IN/OUT EPn
+		 * IN/OUT EP0 - 2 bits
+		 *	 2'b00: 64 Bytes
+		 *	 2'b01: 32
+		 *	 2'b10: 16
+		 *	 2'b11: 8 */
+		unsigned mps : 11;
+#define DWC_DEP0CTL_MPS_64	 0
+#define DWC_DEP0CTL_MPS_32	 1
+#define DWC_DEP0CTL_MPS_16	 2
+#define DWC_DEP0CTL_MPS_8	 3
+
+		/** Next Endpoint
+		 * IN EPn/IN EP0
+		 * OUT EPn/OUT EP0 - reserved */
+		unsigned nextep : 4;
+
+		/** USB Active Endpoint */
+		unsigned usbactep : 1;
+
+		/** Endpoint DPID (INTR/Bulk IN and OUT endpoints)
+		 * This field contains the PID of the packet going to
+		 * be received or transmitted on this endpoint. The
+		 * application should program the PID of the first
+		 * packet going to be received or transmitted on this
+		 * endpoint , after the endpoint is
+		 * activated. Application use the SetD1PID and
+		 * SetD0PID fields of this register to program either
+		 * D0 or D1 PID.
+		 *
+		 * The encoding for this field is
+		 *	 - 0: D0
+		 *	 - 1: D1
+		 */
+		unsigned dpid : 1;
+
+		/** NAK Status */
+		unsigned naksts : 1;
+
+		/** Endpoint Type
+		 *	2'b00: Control
+		 *	2'b01: Isochronous
+		 *	2'b10: Bulk
+		 *	2'b11: Interrupt */
+		unsigned eptype : 2;
+
+		/** Snoop Mode
+		 * OUT EPn/OUT EP0
+		 * IN EPn/IN EP0 - reserved */
+		unsigned snp : 1;
+
+		/** Stall Handshake */
+		unsigned stall : 1;
+
+		/** Tx Fifo Number
+		 * IN EPn/IN EP0
+		 * OUT EPn/OUT EP0 - reserved */
+		unsigned txfnum : 4;
+
+		/** Clear NAK */
+		unsigned cnak : 1;
+		/** Set NAK */
+		unsigned snak : 1;
+		/** Set DATA0 PID (INTR/Bulk IN and OUT endpoints)
+		 * Writing to this field sets the Endpoint DPID (DPID)
+		 * field in this register to DATA0. Set Even
+		 * (micro)frame (SetEvenFr) (ISO IN and OUT Endpoints)
+		 * Writing to this field sets the Even/Odd
+		 * (micro)frame (EO_FrNum) field to even (micro)
+		 * frame.
+		 */
+		unsigned setd0pid : 1;
+		/** Set DATA1 PID (INTR/Bulk IN and OUT endpoints)
+		 * Writing to this field sets the Endpoint DPID (DPID)
+		 * field in this register to DATA1 Set Odd
+		 * (micro)frame (SetOddFr) (ISO IN and OUT Endpoints)
+		 * Writing to this field sets the Even/Odd
+		 * (micro)frame (EO_FrNum) field to odd (micro) frame.
+		 */
+		unsigned setd1pid : 1;
+
+		/** Endpoint Disable */
+		unsigned epdis : 1;
+		/** Endpoint Enable */
+		unsigned epena : 1;
+		} b;
+} depctl_data_t;
+
+/**
+ * This union represents the bit fields in the Device EP Transfer
+ * Size Register.  Read the register into the <i>d32</i> member then
+ * set/clear the bits using the <i>b</i>it elements.
+ */
+typedef union deptsiz_data
+{
+		/** raw register data */
+		uint32_t d32;
+		/** register bits */
+		struct {
+		/** Transfer size */
+		unsigned xfersize : 19;
+		/** Packet Count */
+		unsigned pktcnt : 10;
+		/** Multi Count - Periodic IN endpoints */
+		unsigned mc : 2;
+		unsigned reserved : 1;
+		} b;
+} deptsiz_data_t;
+
+/**
+ * This union represents the bit fields in the Device EP 0 Transfer
+ * Size Register.  Read the register into the <i>d32</i> member then
+ * set/clear the bits using the <i>b</i>it elements.
+ */
+typedef union deptsiz0_data
+{
+		/** raw register data */
+		uint32_t d32;
+		/** register bits */
+		struct {
+		/** Transfer size */
+		unsigned xfersize : 7;
+				/** Reserved */
+				unsigned reserved7_18 : 12;
+		/** Packet Count */
+		unsigned pktcnt : 2;
+				/** Reserved */
+		unsigned reserved21_28 : 9;
+				/**Setup Packet Count (DOEPTSIZ0 Only) */
+				unsigned supcnt : 2;
+				unsigned reserved31;
+		} b;
+} deptsiz0_data_t;
+
+
+/** Maximum number of Periodic FIFOs */
+#define MAX_PERIO_FIFOS 15
+/** Maximum number of Periodic FIFOs */
+#define MAX_TX_FIFOS 15
+
+/** Maximum number of Endpoints/HostChannels */
+#define MAX_EPS_CHANNELS 4
+
+/**
+ * The dwc_otg_dev_if structure contains information needed to manage
+ * the DWC_otg controller acting in device mode. It represents the
+ * programming view of the device-specific aspects of the controller.
+ */
+typedef struct dwc_otg_dev_if
+{
+	/** Pointer to device Global registers.
+	 * Device Global Registers starting at offset 800h
+	 */
+	dwc_otg_device_global_regs_t *dev_global_regs;
+#define DWC_DEV_GLOBAL_REG_OFFSET 0x800
+
+	/**
+	 * Device Logical IN Endpoint-Specific Registers 900h-AFCh
+	 */
+	dwc_otg_dev_in_ep_regs_t	 *in_ep_regs[MAX_EPS_CHANNELS/2];
+#define DWC_DEV_IN_EP_REG_OFFSET 0x900
+#define DWC_EP_REG_OFFSET 0x20
+
+	/** Device Logical OUT Endpoint-Specific Registers B00h-CFCh */
+	dwc_otg_dev_out_ep_regs_t	 *out_ep_regs[MAX_EPS_CHANNELS/2];
+#define DWC_DEV_OUT_EP_REG_OFFSET 0xB00
+
+	/* Device configuration information*/
+	uint8_t	 speed;				 /**< Device Speed	0: Unknown, 1: LS, 2:FS, 3: HS */
+	uint8_t	 num_in_eps;		 /**< Number # of Tx EP range: 0-15 exept ep0 */
+	uint8_t	 num_out_eps;		 /**< Number # of Rx EP range: 0-15 exept ep 0*/
+
+	/** Size of periodic FIFOs (Bytes) */
+	uint16_t perio_tx_fifo_size[MAX_PERIO_FIFOS];
+
+	/** Size of Tx FIFOs (Bytes) */
+	uint16_t tx_fifo_size[MAX_TX_FIFOS];
+
+	/** Thresholding enable flags and length varaiables **/
+	uint16_t rx_thr_en;
+	uint16_t iso_tx_thr_en;
+	uint16_t non_iso_tx_thr_en;
+
+	uint16_t rx_thr_length;
+	uint16_t tx_thr_length;
+
+} dwc_otg_dev_if_t;
+
+
+/////////////////////////////////////////////////
+// Host Mode Register Structures
+//
+/**
+ * The Host Global Registers structure defines the size and relative
+ * field offsets for the Host Mode Global Registers.  Host Global
+ * Registers offsets 400h-7FFh.
+*/
+typedef struct dwc_otg_host_global_regs
+{
+	/** Host Configuration Register.   <i>Offset: 400h</i> */
+	volatile uint32_t hcfg;
+	/** Host Frame Interval Register.	<i>Offset: 404h</i> */
+	volatile uint32_t hfir;
+	/** Host Frame Number / Frame Remaining Register. <i>Offset: 408h</i> */
+	volatile uint32_t hfnum;
+	/** Reserved.	<i>Offset: 40Ch</i> */
+	uint32_t reserved40C;
+	/** Host Periodic Transmit FIFO/ Queue Status Register. <i>Offset: 410h</i> */
+	volatile uint32_t hptxsts;
+	/** Host All Channels Interrupt Register. <i>Offset: 414h</i> */
+	volatile uint32_t haint;
+	/** Host All Channels Interrupt Mask Register. <i>Offset: 418h</i> */
+	volatile uint32_t haintmsk;
+} dwc_otg_host_global_regs_t;
+
+/**
+ * This union represents the bit fields in the Host Configuration Register.
+ * Read the register into the <i>d32</i> member then set/clear the bits using
+ * the <i>b</i>it elements. Write the <i>d32</i> member to the hcfg register.
+ */
+typedef union hcfg_data
+{
+	/** raw register data */
+	uint32_t d32;
+
+	/** register bits */
+	struct {
+		/** FS/LS Phy Clock Select */
+		unsigned fslspclksel : 2;
+#define DWC_HCFG_30_60_MHZ 0
+#define DWC_HCFG_48_MHZ	   1
+#define DWC_HCFG_6_MHZ	   2
+
+		/** FS/LS Only Support */
+		unsigned fslssupp : 1;
+		} b;
+} hcfg_data_t;
+
+/**
+ * This union represents the bit fields in the Host Frame Remaing/Number
+ * Register.
+ */
+typedef union hfir_data
+{
+	/** raw register data */
+	uint32_t d32;
+
+	/** register bits */
+	struct {
+		unsigned frint : 16;
+		unsigned reserved : 16;
+	} b;
+} hfir_data_t;
+
+/**
+ * This union represents the bit fields in the Host Frame Remaing/Number
+ * Register.
+ */
+typedef union hfnum_data
+{
+	/** raw register data */
+	uint32_t d32;
+
+	/** register bits */
+	struct {
+		unsigned frnum : 16;
+#define DWC_HFNUM_MAX_FRNUM 0x3FFF
+		unsigned frrem : 16;
+	} b;
+} hfnum_data_t;
+
+typedef union hptxsts_data
+{
+	/** raw register data */
+	uint32_t d32;
+
+	/** register bits */
+	struct {
+		unsigned ptxfspcavail : 16;
+		unsigned ptxqspcavail : 8;
+		/** Top of the Periodic Transmit Request Queue
+		 *	- bit 24 - Terminate (last entry for the selected channel)
+		 *	- bits 26:25 - Token Type
+		 *	  - 2'b00 - Zero length
+		 *	  - 2'b01 - Ping
+		 *	  - 2'b10 - Disable
+		 *	- bits 30:27 - Channel Number
+		 *	- bit 31 - Odd/even microframe
+		 */
+		unsigned ptxqtop_terminate : 1;
+		unsigned ptxqtop_token : 2;
+		unsigned ptxqtop_chnum : 4;
+		unsigned ptxqtop_odd : 1;
+	} b;
+} hptxsts_data_t;
+
+/**
+ * This union represents the bit fields in the Host Port Control and Status
+ * Register. Read the register into the <i>d32</i> member then set/clear the
+ * bits using the <i>b</i>it elements. Write the <i>d32</i> member to the
+ * hprt0 register.
+ */
+typedef union hprt0_data
+{
+	/** raw register data */
+	uint32_t d32;
+	/** register bits */
+	struct {
+		unsigned prtconnsts : 1;
+		unsigned prtconndet : 1;
+		unsigned prtena : 1;
+		unsigned prtenchng : 1;
+		unsigned prtovrcurract : 1;
+		unsigned prtovrcurrchng : 1;
+		unsigned prtres : 1;
+		unsigned prtsusp : 1;
+		unsigned prtrst : 1;
+		unsigned reserved9 : 1;
+		unsigned prtlnsts : 2;
+		unsigned prtpwr : 1;
+		unsigned prttstctl : 4;
+		unsigned prtspd : 2;
+#define DWC_HPRT0_PRTSPD_HIGH_SPEED 0
+#define DWC_HPRT0_PRTSPD_FULL_SPEED 1
+#define DWC_HPRT0_PRTSPD_LOW_SPEED	2
+		unsigned reserved19_31 : 13;
+	} b;
+} hprt0_data_t;
+
+/**
+ * This union represents the bit fields in the Host All Interrupt
+ * Register.
+ */
+typedef union haint_data
+{
+	/** raw register data */
+	uint32_t d32;
+	/** register bits */
+	struct {
+		unsigned ch0 : 1;
+		unsigned ch1 : 1;
+		unsigned ch2 : 1;
+		unsigned ch3 : 1;
+		unsigned ch4 : 1;
+		unsigned ch5 : 1;
+		unsigned ch6 : 1;
+		unsigned ch7 : 1;
+		unsigned ch8 : 1;
+		unsigned ch9 : 1;
+		unsigned ch10 : 1;
+		unsigned ch11 : 1;
+		unsigned ch12 : 1;
+		unsigned ch13 : 1;
+		unsigned ch14 : 1;
+		unsigned ch15 : 1;
+		unsigned reserved : 16;
+	} b;
+
+	struct {
+		unsigned chint : 16;
+		unsigned reserved : 16;
+	} b2;
+} haint_data_t;
+
+/**
+ * This union represents the bit fields in the Host All Interrupt
+ * Register.
+ */
+typedef union haintmsk_data
+{
+	/** raw register data */
+	uint32_t d32;
+	/** register bits */
+	struct {
+		unsigned ch0 : 1;
+		unsigned ch1 : 1;
+		unsigned ch2 : 1;
+		unsigned ch3 : 1;
+		unsigned ch4 : 1;
+		unsigned ch5 : 1;
+		unsigned ch6 : 1;
+		unsigned ch7 : 1;
+		unsigned ch8 : 1;
+		unsigned ch9 : 1;
+		unsigned ch10 : 1;
+		unsigned ch11 : 1;
+		unsigned ch12 : 1;
+		unsigned ch13 : 1;
+		unsigned ch14 : 1;
+		unsigned ch15 : 1;
+		unsigned reserved : 16;
+	} b;
+
+	struct {
+		unsigned chint : 16;
+		unsigned reserved : 16;
+	} b2;
+} haintmsk_data_t;
+
+/**
+ * Host Channel Specific Registers. <i>500h-5FCh</i>
+ */
+typedef struct dwc_otg_hc_regs
+{
+	/** Host Channel 0 Characteristic Register. <i>Offset: 500h + (chan_num * 20h) + 00h</i> */
+	volatile uint32_t hcchar;
+	/** Host Channel 0 Split Control Register. <i>Offset: 500h + (chan_num * 20h) + 04h</i> */
+	volatile uint32_t hcsplt;
+	/** Host Channel 0 Interrupt Register. <i>Offset: 500h + (chan_num * 20h) + 08h</i> */
+	volatile uint32_t hcint;
+	/** Host Channel 0 Interrupt Mask Register. <i>Offset: 500h + (chan_num * 20h) + 0Ch</i> */
+	volatile uint32_t hcintmsk;
+	/** Host Channel 0 Transfer Size Register. <i>Offset: 500h + (chan_num * 20h) + 10h</i> */
+	volatile uint32_t hctsiz;
+	/** Host Channel 0 DMA Address Register. <i>Offset: 500h + (chan_num * 20h) + 14h</i> */
+	volatile uint32_t hcdma;
+	/** Reserved.  <i>Offset: 500h + (chan_num * 20h) + 18h - 500h + (chan_num * 20h) + 1Ch</i> */
+	uint32_t reserved[2];
+} dwc_otg_hc_regs_t;
+
+/**
+ * This union represents the bit fields in the Host Channel Characteristics
+ * Register. Read the register into the <i>d32</i> member then set/clear the
+ * bits using the <i>b</i>it elements. Write the <i>d32</i> member to the
+ * hcchar register.
+ */
+typedef union hcchar_data
+{
+	/** raw register data */
+	uint32_t d32;
+
+	/** register bits */
+	struct {
+		/** Maximum packet size in bytes */
+		unsigned mps : 11;
+
+		/** Endpoint number */
+		unsigned epnum : 4;
+
+		/** 0: OUT, 1: IN */
+		unsigned epdir : 1;
+
+		unsigned reserved : 1;
+
+		/** 0: Full/high speed device, 1: Low speed device */
+		unsigned lspddev : 1;
+
+		/** 0: Control, 1: Isoc, 2: Bulk, 3: Intr */
+		unsigned eptype : 2;
+
+		/** Packets per frame for periodic transfers. 0 is reserved. */
+		unsigned multicnt : 2;
+
+		/** Device address */
+		unsigned devaddr : 7;
+
+		/**
+		 * Frame to transmit periodic transaction.
+		 * 0: even, 1: odd
+		 */
+		unsigned oddfrm : 1;
+
+		/** Channel disable */
+		unsigned chdis : 1;
+
+		/** Channel enable */
+		unsigned chen : 1;
+	} b;
+} hcchar_data_t;
+
+typedef union hcsplt_data
+{
+	/** raw register data */
+	uint32_t d32;
+
+	/** register bits */
+	struct {
+		/** Port Address */
+		unsigned prtaddr : 7;
+
+		/** Hub Address */
+		unsigned hubaddr : 7;
+
+		/** Transaction Position */
+		unsigned xactpos : 2;
+#define DWC_HCSPLIT_XACTPOS_MID 0
+#define DWC_HCSPLIT_XACTPOS_END 1
+#define DWC_HCSPLIT_XACTPOS_BEGIN 2
+#define DWC_HCSPLIT_XACTPOS_ALL 3
+
+		/** Do Complete Split */
+		unsigned compsplt : 1;
+
+		/** Reserved */
+		unsigned reserved : 14;
+
+		/** Split Enble */
+		unsigned spltena : 1;
+	} b;
+} hcsplt_data_t;
+
+
+/**
+ * This union represents the bit fields in the Host All Interrupt
+ * Register.
+ */
+typedef union hcint_data
+{
+	/** raw register data */
+	uint32_t d32;
+	/** register bits */
+	struct {
+		/** Transfer Complete */
+		unsigned xfercomp : 1;
+		/** Channel Halted */
+		unsigned chhltd : 1;
+		/** AHB Error */
+		unsigned ahberr : 1;
+		/** STALL Response Received */
+		unsigned stall : 1;
+		/** NAK Response Received */
+		unsigned nak : 1;
+		/** ACK Response Received */
+		unsigned ack : 1;
+		/** NYET Response Received */
+		unsigned nyet : 1;
+		/** Transaction Err */
+		unsigned xacterr : 1;
+		/** Babble Error */
+		unsigned bblerr : 1;
+		/** Frame Overrun */
+		unsigned frmovrun : 1;
+		/** Data Toggle Error */
+		unsigned datatglerr : 1;
+		/** Reserved */
+		unsigned reserved : 21;
+	} b;
+} hcint_data_t;
+
+/**
+ * This union represents the bit fields in the Host Channel Transfer Size
+ * Register. Read the register into the <i>d32</i> member then set/clear the
+ * bits using the <i>b</i>it elements. Write the <i>d32</i> member to the
+ * hcchar register.
+ */
+typedef union hctsiz_data
+{
+	/** raw register data */
+	uint32_t d32;
+
+	/** register bits */
+	struct {
+		/** Total transfer size in bytes */
+		unsigned xfersize : 19;
+
+		/** Data packets to transfer */
+		unsigned pktcnt : 10;
+
+		/**
+		 * Packet ID for next data packet
+		 * 0: DATA0
+		 * 1: DATA2
+		 * 2: DATA1
+		 * 3: MDATA (non-Control), SETUP (Control)
+		 */
+		unsigned pid : 2;
+#define DWC_HCTSIZ_DATA0 0
+#define DWC_HCTSIZ_DATA1 2
+#define DWC_HCTSIZ_DATA2 1
+#define DWC_HCTSIZ_MDATA 3
+#define DWC_HCTSIZ_SETUP 3
+
+		/** Do PING protocol when 1 */
+		unsigned dopng : 1;
+	} b;
+} hctsiz_data_t;
+
+/**
+ * This union represents the bit fields in the Host Channel Interrupt Mask
+ * Register. Read the register into the <i>d32</i> member then set/clear the
+ * bits using the <i>b</i>it elements. Write the <i>d32</i> member to the
+ * hcintmsk register.
+ */
+typedef union hcintmsk_data
+{
+	/** raw register data */
+	uint32_t d32;
+
+	/** register bits */
+	struct {
+		unsigned xfercompl : 1;
+		unsigned chhltd : 1;
+		unsigned ahberr : 1;
+		unsigned stall : 1;
+		unsigned nak : 1;
+		unsigned ack : 1;
+		unsigned nyet : 1;
+		unsigned xacterr : 1;
+		unsigned bblerr : 1;
+		unsigned frmovrun : 1;
+		unsigned datatglerr : 1;
+		unsigned reserved : 21;
+	} b;
+} hcintmsk_data_t;
+
+/** OTG Host Interface Structure.
+ *
+ * The OTG Host Interface Structure structure contains information
+ * needed to manage the DWC_otg controller acting in host mode. It
+ * represents the programming view of the host-specific aspects of the
+ * controller.
+ */
+typedef struct dwc_otg_host_if
+{
+	/** Host Global Registers starting at offset 400h.*/
+	dwc_otg_host_global_regs_t *host_global_regs;
+#define DWC_OTG_HOST_GLOBAL_REG_OFFSET 0x400
+
+	/** Host Port 0 Control and Status Register */
+	volatile uint32_t *hprt0;
+#define DWC_OTG_HOST_PORT_REGS_OFFSET 0x440
+
+
+	/** Host Channel Specific Registers at offsets 500h-5FCh. */
+	dwc_otg_hc_regs_t *hc_regs[MAX_EPS_CHANNELS];
+#define DWC_OTG_HOST_CHAN_REGS_OFFSET 0x500
+#define DWC_OTG_CHAN_REGS_OFFSET 0x20
+
+
+	/* Host configuration information */
+	/** Number of Host Channels (range: 1-16) */
+	uint8_t	 num_host_channels;
+	/** Periodic EPs supported (0: no, 1: yes) */
+	uint8_t	 perio_eps_supported;
+	/** Periodic Tx FIFO Size (Only 1 host periodic Tx FIFO) */
+	uint16_t perio_tx_fifo_size;
+
+} dwc_otg_host_if_t;
+
+/**
+ * This union represents the bit fields in the Power and Clock Gating Control
+ * Register. Read the register into the <i>d32</i> member then set/clear the
+ * bits using the <i>b</i>it elements.
+ */
+typedef union pcgcctl_data
+{
+	/** raw register data */
+	uint32_t d32;
+
+	/** register bits */
+	struct {
+		/** Stop Pclk */
+		unsigned stoppclk : 1;
+		/** Gate Hclk */
+		unsigned gatehclk : 1;
+		/** Power Clamp */
+		unsigned pwrclmp : 1;
+		/** Reset Power Down Modules */
+		unsigned rstpdwnmodule : 1;
+		/** PHY Suspended */
+		unsigned physuspended : 1;
+
+		unsigned reserved : 27;
+	} b;
+} pcgcctl_data_t;
+
+#endif /* CONFIG_4xx */
+#endif
diff -Naur a/drivers/usb/dwc_otg/ppc4xx_dma.c b/drivers/usb/dwc_otg/ppc4xx_dma.c
--- a/drivers/usb/dwc_otg/ppc4xx_dma.c	1970-01-01 00:00:00.000000000 +0000
+++ b/drivers/usb/dwc_otg/ppc4xx_dma.c	2016-01-31 16:10:52.000000000 +0000
@@ -0,0 +1,735 @@
+/*
+ * IBM PPC4xx DMA engine core library
+ *
+ * Copyright 2000-2004 MontaVista Software Inc.
+ *
+ * Cleaned up and converted to new DCR access
+ * Matt Porter <mporter@kernel.crashing.org>
+ *
+ * Original code by Armin Kuster <akuster@mvista.com>
+ * and Pete Popov <ppopov@mvista.com>
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General  Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ *
+ * You should have received a copy of the  GNU General Public License along
+ * with this program; if not, write  to the Free Software Foundation, Inc.,
+ * 675 Mass Ave, Cambridge, MA 02139, USA.
+ */
+
+#include <linux/kernel.h>
+#include <linux/mm.h>
+#include <linux/miscdevice.h>
+#include <linux/init.h>
+#include <linux/module.h>
+
+#include <asm/system.h>
+#include <asm/io.h>
+#include <asm/dma.h>
+#include <asm/dcr.h>
+#include "ppc4xx_dma.h"
+
+ppc_dma_ch_t dma_channels[MAX_PPC4xx_DMA_CHANNELS];
+
+int
+ppc4xx_get_dma_status(void)
+{
+	return (mfdcr(DCRN_DMASR));
+}
+
+void
+ppc4xx_set_src_addr(int dmanr, phys_addr_t src_addr)
+{
+	if (dmanr >= MAX_PPC4xx_DMA_CHANNELS) {
+		printk("set_src_addr: bad channel: %d\n", dmanr);
+		return;
+	}
+
+#ifdef PPC4xx_DMA_64BIT
+	mtdcr(DCRN_DMASAH0 + dmanr*8, src_addr >> 32);
+#endif
+	mtdcr(DCRN_DMASA0 + dmanr*8, (u32)src_addr);
+}
+
+void
+ppc4xx_set_dst_addr(int dmanr, phys_addr_t dst_addr)
+{
+	if (dmanr >= MAX_PPC4xx_DMA_CHANNELS) {
+		printk("set_dst_addr: bad channel: %d\n", dmanr);
+		return;
+	}
+
+#ifdef PPC4xx_DMA_64BIT
+	mtdcr(DCRN_DMADAH0 + dmanr*8, dst_addr >> 32);
+#endif
+	mtdcr(DCRN_DMADA0 + dmanr*8, (u32)dst_addr);
+}
+
+void
+ppc4xx_enable_dma(unsigned int dmanr)
+{
+	unsigned int control;
+	ppc_dma_ch_t *p_dma_ch = &dma_channels[dmanr];
+	unsigned int status_bits[] = { DMA_CS0 | DMA_TS0 | DMA_CH0_ERR,
+				       DMA_CS1 | DMA_TS1 | DMA_CH1_ERR,
+				       DMA_CS2 | DMA_TS2 | DMA_CH2_ERR,
+				       DMA_CS3 | DMA_TS3 | DMA_CH3_ERR};
+
+	if (p_dma_ch->in_use) {
+		printk("enable_dma: channel %d in use\n", dmanr);
+		return;
+	}
+
+	if (dmanr >= MAX_PPC4xx_DMA_CHANNELS) {
+		printk("enable_dma: bad channel: %d\n", dmanr);
+		return;
+	}
+
+	if (p_dma_ch->mode == DMA_MODE_READ) {
+		/* peripheral to memory */
+		ppc4xx_set_src_addr(dmanr, 0);
+		ppc4xx_set_dst_addr(dmanr, p_dma_ch->addr);
+	} else if (p_dma_ch->mode == DMA_MODE_WRITE) {
+		/* memory to peripheral */
+		ppc4xx_set_src_addr(dmanr, p_dma_ch->addr);
+		ppc4xx_set_dst_addr(dmanr, 0);
+	}
+
+	/* for other xfer modes, the addresses are already set */
+	control = mfdcr(DCRN_DMACR0 + (dmanr * 0x8));
+
+	control &= ~(DMA_TM_MASK | DMA_TD);	/* clear all mode bits */
+	if (p_dma_ch->mode == DMA_MODE_MM) {
+		/* software initiated memory to memory */
+		control |= DMA_ETD_OUTPUT | DMA_TCE_ENABLE;
+#if defined(CONFIG_405EX) || defined(CONFIG_405EXr) || \
+	 defined(CONFIG_APM82181)
+		control |= DMA_MODE_MM;
+		if (p_dma_ch->dai) {
+			control |= DMA_DAI;
+		}
+		if (p_dma_ch->sai) {
+			control |= DMA_SAI;
+		}
+
+#endif
+#if defined(CONFIG_460EX) || defined(CONFIG_460GT) || \
+	defined(CONFIG_APM82181)
+		control |= DMA_MODE_MM | DMA_DAI | DMA_SAI;
+#endif
+	}
+
+	mtdcr(DCRN_DMACR0 + (dmanr * 0x8), control);
+
+	/*
+	 * Clear the CS, TS, RI bits for the channel from DMASR.  This
+	 * has been observed to happen correctly only after the mode and
+	 * ETD/DCE bits in DMACRx are set above.  Must do this before
+	 * enabling the channel.
+	 */
+
+	mtdcr(DCRN_DMASR, status_bits[dmanr]);
+
+	/*
+	 * For device-paced transfers, Terminal Count Enable apparently
+	 * must be on, and this must be turned on after the mode, etc.
+	 * bits are cleared above (at least on Redwood-6).
+	 */
+
+	if ((p_dma_ch->mode == DMA_MODE_MM_DEVATDST) ||
+	    (p_dma_ch->mode == DMA_MODE_MM_DEVATSRC))
+		control |= DMA_TCE_ENABLE;
+
+	/*
+	 * Now enable the channel.
+	 */
+
+	control |= (p_dma_ch->mode | DMA_CE_ENABLE);
+	mtdcr(DCRN_DMACR0 + (dmanr * 0x8), control);
+
+	p_dma_ch->in_use = 1;
+}
+
+void
+ppc4xx_disable_dma(unsigned int dmanr)
+{
+	unsigned int control;
+	ppc_dma_ch_t *p_dma_ch = &dma_channels[dmanr];
+
+	if (!p_dma_ch->in_use) {
+		printk("disable_dma: channel %d not in use\n", dmanr);
+		return;
+	}
+
+	if (dmanr >= MAX_PPC4xx_DMA_CHANNELS) {
+		printk("disable_dma: bad channel: %d\n", dmanr);
+		return;
+	}
+
+	control = mfdcr(DCRN_DMACR0 + (dmanr * 0x8));
+	control &= ~DMA_CE_ENABLE;
+	mtdcr(DCRN_DMACR0 + (dmanr * 0x8), control);
+
+	p_dma_ch->in_use = 0;
+}
+
+/*
+ * Sets the dma mode for single DMA transfers only.
+ * For scatter/gather transfers, the mode is passed to the
+ * alloc_dma_handle() function as one of the parameters.
+ *
+ * The mode is simply saved and used later.  This allows
+ * the driver to call set_dma_mode() and set_dma_addr() in
+ * any order.
+ *
+ * Valid mode values are:
+ *
+ * DMA_MODE_READ          peripheral to memory
+ * DMA_MODE_WRITE         memory to peripheral
+ * DMA_MODE_MM            memory to memory
+ * DMA_MODE_MM_DEVATSRC   device-paced memory to memory, device at src
+ * DMA_MODE_MM_DEVATDST   device-paced memory to memory, device at dst
+ */
+int
+ppc4xx_set_dma_mode(unsigned int dmanr, unsigned int mode)
+{
+	ppc_dma_ch_t *p_dma_ch = &dma_channels[dmanr];
+
+	if (dmanr >= MAX_PPC4xx_DMA_CHANNELS) {
+		printk("set_dma_mode: bad channel 0x%x\n", dmanr);
+		return DMA_STATUS_BAD_CHANNEL;
+	}
+
+	p_dma_ch->mode = mode;
+
+	return DMA_STATUS_GOOD;
+}
+
+/*
+ * Sets the DMA Count register. Note that 'count' is in bytes.
+ * However, the DMA Count register counts the number of "transfers",
+ * where each transfer is equal to the bus width.  Thus, count
+ * MUST be a multiple of the bus width.
+ */
+void
+ppc4xx_set_dma_count(unsigned int dmanr, unsigned int count)
+{
+	ppc_dma_ch_t *p_dma_ch = &dma_channels[dmanr];
+
+#ifdef DEBUG_4xxDMA
+	{
+		int error = 0;
+		switch (p_dma_ch->pwidth) {
+		case PW_8:
+			break;
+		case PW_16:
+			if (count & 0x1)
+				error = 1;
+			break;
+		case PW_32:
+			if (count & 0x3)
+				error = 1;
+			break;
+		case PW_64:
+			if (count & 0x7)
+				error = 1;
+			break;
+		default:
+			printk("set_dma_count: invalid bus width: 0x%x\n",
+			       p_dma_ch->pwidth);
+			return;
+		}
+		if (error)
+			printk
+			    ("Warning: set_dma_count count 0x%x bus width %d\n",
+			     count, p_dma_ch->pwidth);
+	}
+#endif
+
+	count = count >> p_dma_ch->shift;
+
+	mtdcr(DCRN_DMACT0 + (dmanr * 0x8), count);
+}
+
+/*
+ *   Returns the number of bytes left to be transfered.
+ *   After a DMA transfer, this should return zero.
+ *   Reading this while a DMA transfer is still in progress will return
+ *   unpredictable results.
+ */
+int
+ppc4xx_get_dma_residue(unsigned int dmanr)
+{
+	unsigned int count;
+	ppc_dma_ch_t *p_dma_ch = &dma_channels[dmanr];
+
+	if (dmanr >= MAX_PPC4xx_DMA_CHANNELS) {
+		printk("ppc4xx_get_dma_residue: bad channel 0x%x\n", dmanr);
+		return DMA_STATUS_BAD_CHANNEL;
+	}
+
+	count = mfdcr(DCRN_DMACT0 + (dmanr * 0x8));
+#if defined(CONFIG_405EX) || defined(CONFIG_405EXr) || \
+    defined(CONFIG_460EX) || defined(CONFIG_460GT) || \
+	defined(CONFIG_APM82181)
+	count &= DMA_CTC_TC_MASK;
+#endif
+
+	return (count << p_dma_ch->shift);
+}
+
+/*
+ * Sets the DMA address for a memory to peripheral or peripheral
+ * to memory transfer.  The address is just saved in the channel
+ * structure for now and used later in enable_dma().
+ */
+void
+ppc4xx_set_dma_addr(unsigned int dmanr, phys_addr_t addr)
+{
+	ppc_dma_ch_t *p_dma_ch = &dma_channels[dmanr];
+
+	if (dmanr >= MAX_PPC4xx_DMA_CHANNELS) {
+		printk("ppc4xx_set_dma_addr: bad channel: %d\n", dmanr);
+		return;
+	}
+
+#ifdef DEBUG_4xxDMA
+	{
+		int error = 0;
+		switch (p_dma_ch->pwidth) {
+		case PW_8:
+			break;
+		case PW_16:
+			if ((unsigned) addr & 0x1)
+				error = 1;
+			break;
+		case PW_32:
+			if ((unsigned) addr & 0x3)
+				error = 1;
+			break;
+		case PW_64:
+			if ((unsigned) addr & 0x7)
+				error = 1;
+			break;
+		default:
+			printk("ppc4xx_set_dma_addr: invalid bus width: 0x%x\n",
+			       p_dma_ch->pwidth);
+			return;
+		}
+		if (error)
+			printk("Warning: ppc4xx_set_dma_addr addr 0x%x bus width %d\n",
+			       addr, p_dma_ch->pwidth);
+	}
+#endif
+
+	/* save dma address and program it later after we know the xfer mode */
+	p_dma_ch->addr = addr;
+}
+
+/*
+ * Sets both DMA addresses for a memory to memory transfer.
+ * For memory to peripheral or peripheral to memory transfers
+ * the function set_dma_addr() should be used instead.
+ */
+void
+ppc4xx_set_dma_addr2(unsigned int dmanr, phys_addr_t src_dma_addr,
+		     phys_addr_t dst_dma_addr)
+{
+	if (dmanr >= MAX_PPC4xx_DMA_CHANNELS) {
+		printk("ppc4xx_set_dma_addr2: bad channel: %d\n", dmanr);
+		return;
+	}
+
+#ifdef DEBUG_4xxDMA
+	{
+		ppc_dma_ch_t *p_dma_ch = &dma_channels[dmanr];
+		int error = 0;
+		switch (p_dma_ch->pwidth) {
+			case PW_8:
+				break;
+			case PW_16:
+				if (((unsigned) src_dma_addr & 0x1) ||
+						((unsigned) dst_dma_addr & 0x1)
+				   )
+					error = 1;
+				break;
+			case PW_32:
+				if (((unsigned) src_dma_addr & 0x3) ||
+						((unsigned) dst_dma_addr & 0x3)
+				   )
+					error = 1;
+				break;
+			case PW_64:
+				if (((unsigned) src_dma_addr & 0x7) ||
+						((unsigned) dst_dma_addr & 0x7)
+				   )
+					error = 1;
+				break;
+			default:
+				printk("ppc4xx_set_dma_addr2: invalid bus width: 0x%x\n",
+						p_dma_ch->pwidth);
+				return;
+		}
+		if (error)
+			printk
+				("Warning: ppc4xx_set_dma_addr2 src 0x%x dst 0x%x bus width %d\n",
+				 src_dma_addr, dst_dma_addr, p_dma_ch->pwidth);
+	}
+#endif
+
+	ppc4xx_set_src_addr(dmanr, src_dma_addr);
+	ppc4xx_set_dst_addr(dmanr, dst_dma_addr);
+}
+
+/*
+ * Enables the channel interrupt.
+ *
+ * If performing a scatter/gatter transfer, this function
+ * MUST be called before calling alloc_dma_handle() and building
+ * the sgl list.  Otherwise, interrupts will not be enabled, if
+ * they were previously disabled.
+ */
+int
+ppc4xx_enable_dma_interrupt(unsigned int dmanr)
+{
+	unsigned int control;
+	ppc_dma_ch_t *p_dma_ch = &dma_channels[dmanr];
+
+	if (dmanr >= MAX_PPC4xx_DMA_CHANNELS) {
+		printk("ppc4xx_enable_dma_interrupt: bad channel: %d\n", dmanr);
+		return DMA_STATUS_BAD_CHANNEL;
+	}
+
+	p_dma_ch->int_enable = 1;
+
+#if defined(CONFIG_405EX) || defined (CONFIG_405EXr) || \
+    defined(CONFIG_460EX) || defined (CONFIG_460GT) || \
+	defined(CONFIG_APM82181)
+	control = mfdcr(DCRN_DMACT0 + (dmanr * 0x8));
+	control |= DMA_CTC_TCIE | DMA_CTC_ETIE | DMA_CTC_EIE;
+	mtdcr(DCRN_DMACT0 + (dmanr * 0x8), control);
+#endif
+
+	control = mfdcr(DCRN_DMACR0 + (dmanr * 0x8));
+	control |= DMA_CIE_ENABLE;	/* Channel Interrupt Enable */
+	mtdcr(DCRN_DMACR0 + (dmanr * 0x8), control);
+
+	return DMA_STATUS_GOOD;
+}
+
+/*
+ * Disables the channel interrupt.
+ *
+ * If performing a scatter/gatter transfer, this function
+ * MUST be called before calling alloc_dma_handle() and building
+ * the sgl list.  Otherwise, interrupts will not be disabled, if
+ * they were previously enabled.
+ */
+int
+ppc4xx_disable_dma_interrupt(unsigned int dmanr)
+{
+	unsigned int control;
+	ppc_dma_ch_t *p_dma_ch = &dma_channels[dmanr];
+
+	if (dmanr >= MAX_PPC4xx_DMA_CHANNELS) {
+		printk("ppc4xx_disable_dma_interrupt: bad channel: %d\n", dmanr);
+		return DMA_STATUS_BAD_CHANNEL;
+	}
+
+	p_dma_ch->int_enable = 0;
+
+	control = mfdcr(DCRN_DMACR0 + (dmanr * 0x8));
+	control &= ~DMA_CIE_ENABLE;	/* Channel Interrupt Enable */
+	mtdcr(DCRN_DMACR0 + (dmanr * 0x8), control);
+
+	return DMA_STATUS_GOOD;
+}
+
+/*
+ * Configures a DMA channel, including the peripheral bus width, if a
+ * peripheral is attached to the channel, the polarity of the DMAReq and
+ * DMAAck signals, etc.  This information should really be setup by the boot
+ * code, since most likely the configuration won't change dynamically.
+ * If the kernel has to call this function, it's recommended that it's
+ * called from platform specific init code.  The driver should not need to
+ * call this function.
+ */
+int
+ppc4xx_init_dma_channel(unsigned int dmanr, ppc_dma_ch_t * p_init)
+{
+	unsigned int polarity;
+	uint32_t control = 0;
+	ppc_dma_ch_t *p_dma_ch = &dma_channels[dmanr];
+
+	DMA_MODE_READ = (unsigned long) DMA_TD;	/* Peripheral to Memory */
+	DMA_MODE_WRITE = 0;	/* Memory to Peripheral */
+
+	if (!p_init) {
+		printk("ppc4xx_init_dma_channel: NULL p_init\n");
+		return DMA_STATUS_NULL_POINTER;
+	}
+
+	if (dmanr >= MAX_PPC4xx_DMA_CHANNELS) {
+		printk("ppc4xx_init_dma_channel: bad channel %d\n", dmanr);
+		return DMA_STATUS_BAD_CHANNEL;
+	}
+
+#if DCRN_POL > 0
+	polarity = mfdcr(DCRN_POL);
+#else
+	polarity = 0;
+#endif
+
+	/* Setup the control register based on the values passed to
+	 * us in p_init.  Then, over-write the control register with this
+	 * new value.
+	 */
+	control |= SET_DMA_CONTROL;
+
+	/* clear all polarity signals and then "or" in new signal levels */
+	polarity &= ~GET_DMA_POLARITY(dmanr);
+	polarity |= p_init->polarity;
+#if DCRN_POL > 0
+	mtdcr(DCRN_POL, polarity);
+#endif
+	mtdcr(DCRN_DMACR0 + (dmanr * 0x8), control);
+
+	/* save these values in our dma channel structure */
+	memcpy(p_dma_ch, p_init, sizeof (ppc_dma_ch_t));
+
+	/*
+	 * The peripheral width values written in the control register are:
+	 *   PW_8                 0
+	 *   PW_16                1
+	 *   PW_32                2
+	 *   PW_64                3
+	 *
+	 *   Since the DMA count register takes the number of "transfers",
+	 *   we need to divide the count sent to us in certain
+	 *   functions by the appropriate number.  It so happens that our
+	 *   right shift value is equal to the peripheral width value.
+	 */
+	p_dma_ch->shift = p_init->pwidth;
+
+	/*
+	 * Save the control word for easy access.
+	 */
+	p_dma_ch->control = control;
+	mtdcr(DCRN_DMASR, 0xffffffff);	/* clear status register */
+	return DMA_STATUS_GOOD;
+}
+
+/*
+ * This function returns the channel configuration.
+ */
+int
+ppc4xx_get_channel_config(unsigned int dmanr, ppc_dma_ch_t * p_dma_ch)
+{
+	unsigned int polarity;
+	unsigned int control;
+
+	if (dmanr >= MAX_PPC4xx_DMA_CHANNELS) {
+		printk("ppc4xx_get_channel_config: bad channel %d\n", dmanr);
+		return DMA_STATUS_BAD_CHANNEL;
+	}
+
+	memcpy(p_dma_ch, &dma_channels[dmanr], sizeof (ppc_dma_ch_t));
+
+#if DCRN_POL > 0
+	polarity = mfdcr(DCRN_POL);
+#else
+	polarity = 0;
+#endif
+
+	p_dma_ch->polarity = polarity & GET_DMA_POLARITY(dmanr);
+	control = mfdcr(DCRN_DMACR0 + (dmanr * 0x8));
+
+	p_dma_ch->cp = GET_DMA_PRIORITY(control);
+	p_dma_ch->pwidth = GET_DMA_PW(control);
+	p_dma_ch->psc = GET_DMA_PSC(control);
+	p_dma_ch->pwc = GET_DMA_PWC(control);
+	p_dma_ch->phc = GET_DMA_PHC(control);
+	p_dma_ch->ce = GET_DMA_CE_ENABLE(control);
+	p_dma_ch->int_enable = GET_DMA_CIE_ENABLE(control);
+	p_dma_ch->shift = GET_DMA_PW(control);
+
+#ifdef CONFIG_PPC4xx_EDMA
+	p_dma_ch->pf = GET_DMA_PREFETCH(control);
+#else
+	p_dma_ch->ch_enable = GET_DMA_CH(control);
+	p_dma_ch->ece_enable = GET_DMA_ECE(control);
+	p_dma_ch->tcd_disable = GET_DMA_TCD(control);
+#endif
+	return DMA_STATUS_GOOD;
+}
+
+/*
+ * Sets the priority for the DMA channel dmanr.
+ * Since this is setup by the hardware init function, this function
+ * can be used to dynamically change the priority of a channel.
+ *
+ * Acceptable priorities:
+ *
+ * PRIORITY_LOW
+ * PRIORITY_MID_LOW
+ * PRIORITY_MID_HIGH
+ * PRIORITY_HIGH
+ *
+ */
+int
+ppc4xx_set_channel_priority(unsigned int dmanr, unsigned int priority)
+{
+	unsigned int control;
+
+	if (dmanr >= MAX_PPC4xx_DMA_CHANNELS) {
+		printk("ppc4xx_set_channel_priority: bad channel %d\n", dmanr);
+		return DMA_STATUS_BAD_CHANNEL;
+	}
+
+	if ((priority != PRIORITY_LOW) &&
+	    (priority != PRIORITY_MID_LOW) &&
+	    (priority != PRIORITY_MID_HIGH) && (priority != PRIORITY_HIGH)) {
+		printk("ppc4xx_set_channel_priority: bad priority: 0x%x\n", priority);
+	}
+
+	control = mfdcr(DCRN_DMACR0 + (dmanr * 0x8));
+	control |= SET_DMA_PRIORITY(priority);
+	mtdcr(DCRN_DMACR0 + (dmanr * 0x8), control);
+
+	return DMA_STATUS_GOOD;
+}
+
+/*
+ * Returns the width of the peripheral attached to this channel. This assumes
+ * that someone who knows the hardware configuration, boot code or some other
+ * init code, already set the width.
+ *
+ * The return value is one of:
+ *   PW_8
+ *   PW_16
+ *   PW_32
+ *   PW_64
+ *
+ *   The function returns 0 on error.
+ */
+unsigned int
+ppc4xx_get_peripheral_width(unsigned int dmanr)
+{
+	unsigned int control;
+
+	if (dmanr >= MAX_PPC4xx_DMA_CHANNELS) {
+		printk("ppc4xx_get_peripheral_width: bad channel %d\n", dmanr);
+		return DMA_STATUS_BAD_CHANNEL;
+	}
+
+	control = mfdcr(DCRN_DMACR0 + (dmanr * 0x8));
+
+	return (GET_DMA_PW(control));
+}
+
+/*
+ * Clears the channel status bits
+ */
+int
+ppc4xx_clr_dma_status(unsigned int dmanr)
+{
+	if (dmanr >= MAX_PPC4xx_DMA_CHANNELS) {
+		printk(KERN_ERR "ppc4xx_clr_dma_status: bad channel: %d\n", dmanr);
+		return DMA_STATUS_BAD_CHANNEL;
+	}
+	mtdcr(DCRN_DMASR, ((u32)DMA_CH0_ERR | (u32)DMA_CS0 | (u32)DMA_TS0) >> dmanr);
+	return DMA_STATUS_GOOD;
+}
+
+#ifdef CONFIG_PPC4xx_EDMA
+/*
+ * Enables the burst on the channel (BTEN bit in the control/count register)
+ * Note:
+ * For scatter/gather dma, this function MUST be called before the
+ * ppc4xx_alloc_dma_handle() func as the chan count register is copied into the
+ * sgl list and used as each sgl element is added.
+ */
+int
+ppc4xx_enable_burst(unsigned int dmanr)
+{
+	unsigned int ctc;
+	if (dmanr >= MAX_PPC4xx_DMA_CHANNELS) {
+		printk(KERN_ERR "ppc4xx_enable_burst: bad channel: %d\n", dmanr);
+		return DMA_STATUS_BAD_CHANNEL;
+	}
+        ctc = mfdcr(DCRN_DMACT0 + (dmanr * 0x8)) | DMA_CTC_BTEN;
+	mtdcr(DCRN_DMACT0 + (dmanr * 0x8), ctc);
+	return DMA_STATUS_GOOD;
+}
+/*
+ * Disables the burst on the channel (BTEN bit in the control/count register)
+ * Note:
+ * For scatter/gather dma, this function MUST be called before the
+ * ppc4xx_alloc_dma_handle() func as the chan count register is copied into the
+ * sgl list and used as each sgl element is added.
+ */
+int
+ppc4xx_disable_burst(unsigned int dmanr)
+{
+	unsigned int ctc;
+	if (dmanr >= MAX_PPC4xx_DMA_CHANNELS) {
+		printk(KERN_ERR "ppc4xx_disable_burst: bad channel: %d\n", dmanr);
+		return DMA_STATUS_BAD_CHANNEL;
+	}
+	ctc = mfdcr(DCRN_DMACT0 + (dmanr * 0x8)) &~ DMA_CTC_BTEN;
+	mtdcr(DCRN_DMACT0 + (dmanr * 0x8), ctc);
+	return DMA_STATUS_GOOD;
+}
+/*
+ * Sets the burst size (number of peripheral widths) for the channel
+ * (BSIZ bits in the control/count register))
+ * must be one of:
+ *    DMA_CTC_BSIZ_2
+ *    DMA_CTC_BSIZ_4
+ *    DMA_CTC_BSIZ_8
+ *    DMA_CTC_BSIZ_16
+ * Note:
+ * For scatter/gather dma, this function MUST be called before the
+ * ppc4xx_alloc_dma_handle() func as the chan count register is copied into the
+ * sgl list and used as each sgl element is added.
+ */
+int
+ppc4xx_set_burst_size(unsigned int dmanr, unsigned int bsize)
+{
+	unsigned int ctc;
+	if (dmanr >= MAX_PPC4xx_DMA_CHANNELS) {
+		printk(KERN_ERR "ppc4xx_set_burst_size: bad channel: %d\n", dmanr);
+		return DMA_STATUS_BAD_CHANNEL;
+	}
+	ctc = mfdcr(DCRN_DMACT0 + (dmanr * 0x8)) &~ DMA_CTC_BSIZ_MSK;
+	ctc |= (bsize & DMA_CTC_BSIZ_MSK);
+	mtdcr(DCRN_DMACT0 + (dmanr * 0x8), ctc);
+	return DMA_STATUS_GOOD;
+}
+
+EXPORT_SYMBOL(ppc4xx_enable_burst);
+EXPORT_SYMBOL(ppc4xx_disable_burst);
+EXPORT_SYMBOL(ppc4xx_set_burst_size);
+#endif /* CONFIG_PPC4xx_EDMA */
+
+EXPORT_SYMBOL(ppc4xx_init_dma_channel);
+EXPORT_SYMBOL(ppc4xx_get_channel_config);
+EXPORT_SYMBOL(ppc4xx_set_channel_priority);
+EXPORT_SYMBOL(ppc4xx_get_peripheral_width);
+EXPORT_SYMBOL(dma_channels);
+EXPORT_SYMBOL(ppc4xx_set_src_addr);
+EXPORT_SYMBOL(ppc4xx_set_dst_addr);
+EXPORT_SYMBOL(ppc4xx_set_dma_addr);
+EXPORT_SYMBOL(ppc4xx_set_dma_addr2);
+EXPORT_SYMBOL(ppc4xx_enable_dma);
+EXPORT_SYMBOL(ppc4xx_disable_dma);
+EXPORT_SYMBOL(ppc4xx_set_dma_mode);
+EXPORT_SYMBOL(ppc4xx_set_dma_count);
+EXPORT_SYMBOL(ppc4xx_get_dma_residue);
+EXPORT_SYMBOL(ppc4xx_enable_dma_interrupt);
+EXPORT_SYMBOL(ppc4xx_disable_dma_interrupt);
+EXPORT_SYMBOL(ppc4xx_get_dma_status);
+EXPORT_SYMBOL(ppc4xx_clr_dma_status);
+
diff -Naur a/drivers/usb/dwc_otg/ppc4xx_dma.h b/drivers/usb/dwc_otg/ppc4xx_dma.h
--- a/drivers/usb/dwc_otg/ppc4xx_dma.h	1970-01-01 00:00:00.000000000 +0000
+++ b/drivers/usb/dwc_otg/ppc4xx_dma.h	2016-01-31 16:10:52.000000000 +0000
@@ -0,0 +1,620 @@
+/*
+ * include/asm-ppc/ppc4xx_dma.h
+ *
+ * IBM PPC4xx DMA engine library
+ *
+ * Copyright 2000-2004 MontaVista Software Inc.
+ *
+ * Cleaned up a bit more, Matt Porter <mporter@kernel.crashing.org>
+ *
+ * Original code by Armin Kuster <akuster@mvista.com>
+ * and Pete Popov <ppopov@mvista.com>
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General  Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ *
+ * You should have received a copy of the  GNU General Public License along
+ * with this program; if not, write  to the Free Software Foundation, Inc.,
+ * 675 Mass Ave, Cambridge, MA 02139, USA.
+ */
+
+#ifdef __KERNEL__
+#ifndef __ASMPPC_PPC4xx_DMA_H
+#define __ASMPPC_PPC4xx_DMA_H
+
+#include <linux/types.h>
+#include <asm/mmu.h>
+
+#ifdef CONFIG_405EX
+#define DCRN_DMA0_BASE               0x100
+#define DCRN_DMASR_BASE              0x120
+#endif
+
+#if defined(CONFIG_460EX) || defined(CONFIG_APM82181)
+#define DCRN_DMA0_BASE               0x200
+#define DCRN_DMASR_BASE              0x220
+#endif
+
+#ifndef DCRN_DMA0_BASE
+#error DMA register not defined for this PPC4xx variant!
+#endif
+
+#define DCRN_DMACR0     (DCRN_DMA0_BASE + 0x0)  /* DMA Channel Control 0 */
+#define DCRN_DMACT0     (DCRN_DMA0_BASE + 0x1)  /* DMA Count 0 */
+#define DCRN_DMASAH0 (DCRN_DMA0_BASE + 0x2)     /* DMA Src Addr High 0 */
+#define DCRN_DMASA0     (DCRN_DMA0_BASE + 0x3)  /* DMA Src Addr Low 0 */
+#define DCRN_DMADAH0 (DCRN_DMA0_BASE + 0x4)     /* DMA Dest Addr High 0 */
+#define DCRN_DMADA0     (DCRN_DMA0_BASE + 0x5)  /* DMA Dest Addr Low 0 */
+#define DCRN_ASGH0      (DCRN_DMA0_BASE + 0x6)  /* DMA SG Desc Addr High 0 */
+#define DCRN_ASG0       (DCRN_DMA0_BASE + 0x7)  /* DMA SG Desc Addr Low 0 */
+
+#define DCRN_DMASR      (DCRN_DMASR_BASE + 0x0) /* DMA Status Register */
+#define DCRN_ASGC       (DCRN_DMASR_BASE + 0x3) /* DMA Scatter/Gather Command */
+#define DCRN_SLP        (DCRN_DMASR_BASE + 0x5) /* DMA Sleep Register */
+#define DCRN_POL        (DCRN_DMASR_BASE + 0x6) /* DMA Polarity Register */
+
+#undef DEBUG_4xxDMA
+
+#define MAX_PPC4xx_DMA_CHANNELS		4
+
+#define DMA_CH0     0
+#define DMA_CH1     1
+#define DMA_CH2     2
+#define DMA_CH3     3
+
+/*
+ * Function return status codes
+ * These values are used to indicate whether or not the function
+ * call was successful, or a bad/invalid parameter was passed.
+ */
+#define DMA_STATUS_GOOD			0
+#define DMA_STATUS_BAD_CHANNEL		1
+#define DMA_STATUS_BAD_HANDLE		2
+#define DMA_STATUS_BAD_MODE		3
+#define DMA_STATUS_NULL_POINTER		4
+#define DMA_STATUS_OUT_OF_MEMORY	5
+#define DMA_STATUS_SGL_LIST_EMPTY	6
+#define DMA_STATUS_GENERAL_ERROR	7
+#define DMA_STATUS_CHANNEL_NOTFREE	8
+
+#define DMA_CHANNEL_BUSY		0x80000000
+
+/*
+ * These indicate status as returned from the DMA Status Register.
+ */
+#define DMA_STATUS_NO_ERROR	0
+#define DMA_STATUS_CS		1	/* Count Status        */
+#define DMA_STATUS_TS		2	/* Transfer Status     */
+#define DMA_STATUS_DMA_ERROR	3	/* DMA Error Occurred  */
+#define DMA_STATUS_DMA_BUSY	4	/* The channel is busy */
+
+
+/*
+ * DMA Channel Control Registers
+ */
+
+/* The 44x devices have 64bit DMA controllers, where the 405EX/r have 32bit */
+#if defined(CONFIG_44x)
+#define	PPC4xx_DMA_64BIT
+#endif
+
+/* The 44x and 405EX/r come up big-endian with last bit reserved */
+#if defined(CONFIG_44x) || defined(CONFIG_405EX) || defined(CONFIG_405EXr)
+#define DMA_CR_OFFSET 1
+#else
+#define DMA_CR_OFFSET 0
+#endif
+
+#define DMA_CE_ENABLE        (1<<31)	/* DMA Channel Enable */
+#define SET_DMA_CE_ENABLE(x) (((x)&0x1)<<31)
+#define GET_DMA_CE_ENABLE(x) (((x)&DMA_CE_ENABLE)>>31)
+
+#define DMA_CIE_ENABLE        (1<<30)	/* DMA Channel Interrupt Enable */
+#define SET_DMA_CIE_ENABLE(x) (((x)&0x1)<<30)
+#define GET_DMA_CIE_ENABLE(x) (((x)&DMA_CIE_ENABLE)>>30)
+
+#define DMA_TD                (1<<29)
+#define SET_DMA_TD(x)         (((x)&0x1)<<29)
+#define GET_DMA_TD(x)         (((x)&DMA_TD)>>29)
+
+#define DMA_PL                (1<<28)	/* Peripheral Location */
+#define SET_DMA_PL(x)         (((x)&0x1)<<28)
+#define GET_DMA_PL(x)         (((x)&DMA_PL)>>28)
+
+#define EXTERNAL_PERIPHERAL    0
+#define INTERNAL_PERIPHERAL    1
+
+#define SET_DMA_PW(x)     (((x)&0x3)<<(26-DMA_CR_OFFSET))	/* Peripheral Width */
+#define DMA_PW_MASK       SET_DMA_PW(3)
+#define   PW_8                 0
+#define   PW_16                1
+#define   PW_32                2
+#define   PW_64                3
+/* FIXME: Add PW_128 support for 440GP DMA block */
+#define GET_DMA_PW(x)     (((x)&DMA_PW_MASK)>>(26-DMA_CR_OFFSET))
+
+#define DMA_DAI           (1<<(25-DMA_CR_OFFSET))	/* Destination Address Increment */
+#define SET_DMA_DAI(x)    (((x)&0x1)<<(25-DMA_CR_OFFSET))
+
+#define DMA_SAI           (1<<(24-DMA_CR_OFFSET))	/* Source Address Increment */
+#define SET_DMA_SAI(x)    (((x)&0x1)<<(24-DMA_CR_OFFSET))
+
+#define DMA_BEN           (1<<(23-DMA_CR_OFFSET))	/* Buffer Enable */
+#define SET_DMA_BEN(x)    (((x)&0x1)<<(23-DMA_CR_OFFSET))
+
+#define SET_DMA_TM(x)     (((x)&0x3)<<(21-DMA_CR_OFFSET))	/* Transfer Mode */
+#define DMA_TM_MASK       SET_DMA_TM(3)
+#define   TM_PERIPHERAL        0	/* Peripheral */
+#define   TM_RESERVED          1	/* Reserved */
+#define   TM_S_MM              2	/* Memory to Memory */
+#define   TM_D_MM              3	/* Device Paced Memory to Memory */
+#define GET_DMA_TM(x)     (((x)&DMA_TM_MASK)>>(21-DMA_CR_OFFSET))
+
+#define SET_DMA_PSC(x)    (((x)&0x3)<<(19-DMA_CR_OFFSET))	/* Peripheral Setup Cycles */
+#define DMA_PSC_MASK      SET_DMA_PSC(3)
+#define GET_DMA_PSC(x)    (((x)&DMA_PSC_MASK)>>(19-DMA_CR_OFFSET))
+
+#define SET_DMA_PWC(x)    (((x)&0x3F)<<(13-DMA_CR_OFFSET))	/* Peripheral Wait Cycles */
+#define DMA_PWC_MASK      SET_DMA_PWC(0x3F)
+#define GET_DMA_PWC(x)    (((x)&DMA_PWC_MASK)>>(13-DMA_CR_OFFSET))
+
+#define SET_DMA_PHC(x)    (((x)&0x7)<<(10-DMA_CR_OFFSET))	/* Peripheral Hold Cycles */
+#define DMA_PHC_MASK      SET_DMA_PHC(0x7)
+#define GET_DMA_PHC(x)    (((x)&DMA_PHC_MASK)>>(10-DMA_CR_OFFSET))
+
+#define DMA_ETD_OUTPUT     (1<<(9-DMA_CR_OFFSET))	/* EOT pin is a TC output */
+#define SET_DMA_ETD(x)     (((x)&0x1)<<(9-DMA_CR_OFFSET))
+
+#define DMA_TCE_ENABLE     (1<<(8-DMA_CR_OFFSET))
+#define SET_DMA_TCE(x)     (((x)&0x1)<<(8-DMA_CR_OFFSET))
+
+#define DMA_DEC            (1<<(2))	/* Address Decrement */
+#define SET_DMA_DEC(x)     (((x)&0x1)<<2)
+#define GET_DMA_DEC(x)     (((x)&DMA_DEC)>>2)
+
+
+/*
+ * Transfer Modes
+ * These modes are defined in a way that makes it possible to
+ * simply "or" in the value in the control register.
+ */
+
+#define DMA_MODE_MM		(SET_DMA_TM(TM_S_MM))	/* memory to memory */
+
+				/* Device-paced memory to memory, */
+				/* device is at source address    */
+#define DMA_MODE_MM_DEVATSRC	(DMA_TD | SET_DMA_TM(TM_D_MM))
+
+				/* Device-paced memory to memory,      */
+				/* device is at destination address    */
+#define DMA_MODE_MM_DEVATDST	(SET_DMA_TM(TM_D_MM))
+
+/* 405gp/440gp */
+#define SET_DMA_PREFETCH(x)   (((x)&0x3)<<(4-DMA_CR_OFFSET))	/* Memory Read Prefetch */
+#define DMA_PREFETCH_MASK      SET_DMA_PREFETCH(3)
+#define   PREFETCH_1           0	/* Prefetch 1 Double Word */
+#define   PREFETCH_2           1
+#define   PREFETCH_4           2
+#define GET_DMA_PREFETCH(x) (((x)&DMA_PREFETCH_MASK)>>(4-DMA_CR_OFFSET))
+
+#define DMA_PCE            (1<<(3-DMA_CR_OFFSET))	/* Parity Check Enable */
+#define SET_DMA_PCE(x)     (((x)&0x1)<<(3-DMA_CR_OFFSET))
+#define GET_DMA_PCE(x)     (((x)&DMA_PCE)>>(3-DMA_CR_OFFSET))
+
+/* stb3x */
+
+#define DMA_ECE_ENABLE (1<<5)
+#define SET_DMA_ECE(x) (((x)&0x1)<<5)
+#define GET_DMA_ECE(x) (((x)&DMA_ECE_ENABLE)>>5)
+
+#define DMA_TCD_DISABLE	(1<<4)
+#define SET_DMA_TCD(x) (((x)&0x1)<<4)
+#define GET_DMA_TCD(x) (((x)&DMA_TCD_DISABLE)>>4)
+
+typedef uint32_t sgl_handle_t;
+
+#ifdef CONFIG_PPC4xx_EDMA
+
+#define SGL_LIST_SIZE 4096
+#define DMA_PPC4xx_SIZE SGL_LIST_SIZE
+
+#define SET_DMA_PRIORITY(x)   (((x)&0x3)<<(6-DMA_CR_OFFSET))	/* DMA Channel Priority */
+#define DMA_PRIORITY_MASK SET_DMA_PRIORITY(3)
+#define PRIORITY_LOW           0
+#define PRIORITY_MID_LOW       1
+#define PRIORITY_MID_HIGH      2
+#define PRIORITY_HIGH          3
+#define GET_DMA_PRIORITY(x) (((x)&DMA_PRIORITY_MASK)>>(6-DMA_CR_OFFSET))
+
+/*
+ * DMA Polarity Configuration Register
+ */
+#define DMAReq_ActiveLow(chan) (1<<(31-(chan*3)))
+#define DMAAck_ActiveLow(chan) (1<<(30-(chan*3)))
+#define EOT_ActiveLow(chan)    (1<<(29-(chan*3)))	/* End of Transfer */
+
+/*
+ * DMA Sleep Mode Register
+ */
+#define SLEEP_MODE_ENABLE (1<<21)
+
+/*
+ * DMA Status Register
+ */
+#define DMA_CS0           (1<<31)	/* Terminal Count has been reached */
+#define DMA_CS1           (1<<30)
+#define DMA_CS2           (1<<29)
+#define DMA_CS3           (1<<28)
+
+#define DMA_TS0           (1<<27)	/* End of Transfer has been requested */
+#define DMA_TS1           (1<<26)
+#define DMA_TS2           (1<<25)
+#define DMA_TS3           (1<<24)
+
+#define DMA_CH0_ERR       (1<<23)	/* DMA Chanel 0 Error */
+#define DMA_CH1_ERR       (1<<22)
+#define DMA_CH2_ERR       (1<<21)
+#define DMA_CH3_ERR       (1<<20)
+
+#define DMA_IN_DMA_REQ0   (1<<19)	/* Internal DMA Request is pending */
+#define DMA_IN_DMA_REQ1   (1<<18)
+#define DMA_IN_DMA_REQ2   (1<<17)
+#define DMA_IN_DMA_REQ3   (1<<16)
+
+#define DMA_EXT_DMA_REQ0  (1<<15)	/* External DMA Request is pending */
+#define DMA_EXT_DMA_REQ1  (1<<14)
+#define DMA_EXT_DMA_REQ2  (1<<13)
+#define DMA_EXT_DMA_REQ3  (1<<12)
+
+#define DMA_CH0_BUSY      (1<<11)	/* DMA Channel 0 Busy */
+#define DMA_CH1_BUSY      (1<<10)
+#define DMA_CH2_BUSY       (1<<9)
+#define DMA_CH3_BUSY       (1<<8)
+
+#define DMA_SG0            (1<<7)	/* DMA Channel 0 Scatter/Gather in progress */
+#define DMA_SG1            (1<<6)
+#define DMA_SG2            (1<<5)
+#define DMA_SG3            (1<<4)
+
+/* DMA Channel Count Register */
+#define DMA_CTC_TCIE	 (1<<29)	/* Terminal Count Interrupt Enable */
+#define DMA_CTC_ETIE     (1<<28)	/* EOT Interupt Enable */
+#define DMA_CTC_EIE		 (1<<27)	/* Error Interrupt Enable */
+#define DMA_CTC_BTEN     (1<<23)    /* Burst Enable/Disable bit */
+#define DMA_CTC_BSIZ_MSK (3<<21)    /* Mask of the Burst size bits */
+#define DMA_CTC_BSIZ_2   (0)
+#define DMA_CTC_BSIZ_4   (1<<21)
+#define DMA_CTC_BSIZ_8   (2<<21)
+#define DMA_CTC_BSIZ_16  (3<<21)
+#define DMA_CTC_TC_MASK  0xFFFFF
+
+/*
+ * DMA SG Command Register
+ */
+#define SSG_ENABLE(chan)   	(1<<(31-chan))	/* Start Scatter Gather */
+#define SSG_MASK_ENABLE(chan)	(1<<(15-chan))	/* Enable writing to SSG0 bit */
+
+/*
+ * DMA Scatter/Gather Descriptor Bit fields
+ */
+#define SG_LINK            (1<<31)	/* Link */
+#define SG_TCI_ENABLE      (1<<29)	/* Enable Terminal Count Interrupt */
+#define SG_ETI_ENABLE      (1<<28)	/* Enable End of Transfer Interrupt */
+#define SG_ERI_ENABLE      (1<<27)	/* Enable Error Interrupt */
+#define SG_COUNT_MASK       0xFFFF	/* Count Field */
+
+#define SET_DMA_CONTROL \
+ 		(SET_DMA_CIE_ENABLE(p_init->int_enable) | /* interrupt enable         */ \
+ 		SET_DMA_BEN(p_init->buffer_enable)     | /* buffer enable            */\
+		SET_DMA_ETD(p_init->etd_output)        | /* end of transfer pin      */ \
+	       	SET_DMA_TCE(p_init->tce_enable)        | /* terminal count enable    */ \
+                SET_DMA_PL(p_init->pl)                 | /* peripheral location      */ \
+                SET_DMA_DAI(p_init->dai)               | /* dest addr increment      */ \
+                SET_DMA_SAI(p_init->sai)               | /* src addr increment       */ \
+                SET_DMA_PRIORITY(p_init->cp)           |  /* channel priority        */ \
+                SET_DMA_PW(p_init->pwidth)             |  /* peripheral/bus width    */ \
+                SET_DMA_PSC(p_init->psc)               |  /* peripheral setup cycles */ \
+                SET_DMA_PWC(p_init->pwc)               |  /* peripheral wait cycles  */ \
+                SET_DMA_PHC(p_init->phc)               |  /* peripheral hold cycles  */ \
+                SET_DMA_PREFETCH(p_init->pf)              /* read prefetch           */)
+
+#define GET_DMA_POLARITY(chan) (DMAReq_ActiveLow(chan) | DMAAck_ActiveLow(chan) | EOT_ActiveLow(chan))
+
+#elif defined(CONFIG_STB03xxx)		/* stb03xxx */
+
+#define DMA_PPC4xx_SIZE	4096
+
+/*
+ * DMA Status Register
+ */
+
+#define SET_DMA_PRIORITY(x)   (((x)&0x00800001))	/* DMA Channel Priority */
+#define DMA_PRIORITY_MASK	0x00800001
+#define   PRIORITY_LOW         	0x00000000
+#define   PRIORITY_MID_LOW     	0x00000001
+#define   PRIORITY_MID_HIGH    	0x00800000
+#define   PRIORITY_HIGH        	0x00800001
+#define GET_DMA_PRIORITY(x) (((((x)&DMA_PRIORITY_MASK) &0x00800000) >> 22 ) | (((x)&DMA_PRIORITY_MASK) &0x00000001))
+
+#define DMA_CS0           (1<<31)	/* Terminal Count has been reached */
+#define DMA_CS1           (1<<30)
+#define DMA_CS2           (1<<29)
+#define DMA_CS3           (1<<28)
+
+#define DMA_TS0           (1<<27)	/* End of Transfer has been requested */
+#define DMA_TS1           (1<<26)
+#define DMA_TS2           (1<<25)
+#define DMA_TS3           (1<<24)
+
+#define DMA_CH0_ERR       (1<<23)	/* DMA Chanel 0 Error */
+#define DMA_CH1_ERR       (1<<22)
+#define DMA_CH2_ERR       (1<<21)
+#define DMA_CH3_ERR       (1<<20)
+
+#define DMA_CT0		  (1<<19)	/* Chained transfere */
+
+#define DMA_IN_DMA_REQ0   (1<<18)	/* Internal DMA Request is pending */
+#define DMA_IN_DMA_REQ1   (1<<17)
+#define DMA_IN_DMA_REQ2   (1<<16)
+#define DMA_IN_DMA_REQ3   (1<<15)
+
+#define DMA_EXT_DMA_REQ0  (1<<14)	/* External DMA Request is pending */
+#define DMA_EXT_DMA_REQ1  (1<<13)
+#define DMA_EXT_DMA_REQ2  (1<<12)
+#define DMA_EXT_DMA_REQ3  (1<<11)
+
+#define DMA_CH0_BUSY      (1<<10)	/* DMA Channel 0 Busy */
+#define DMA_CH1_BUSY      (1<<9)
+#define DMA_CH2_BUSY       (1<<8)
+#define DMA_CH3_BUSY       (1<<7)
+
+#define DMA_CT1            (1<<6)	/* Chained transfere */
+#define DMA_CT2            (1<<5)
+#define DMA_CT3            (1<<4)
+
+#define DMA_CH_ENABLE (1<<7)
+#define SET_DMA_CH(x) (((x)&0x1)<<7)
+#define GET_DMA_CH(x) (((x)&DMA_CH_ENABLE)>>7)
+
+/* STBx25xxx dma unique */
+/* enable device port on a dma channel
+ * example ext 0 on dma 1
+ */
+
+#define	SSP0_RECV	15
+#define	SSP0_XMIT	14
+#define EXT_DMA_0	12
+#define	SC1_XMIT	11
+#define SC1_RECV	10
+#define EXT_DMA_2	9
+#define	EXT_DMA_3	8
+#define SERIAL2_XMIT	7
+#define SERIAL2_RECV	6
+#define SC0_XMIT 	5
+#define	SC0_RECV	4
+#define	SERIAL1_XMIT	3
+#define SERIAL1_RECV	2
+#define	SERIAL0_XMIT	1
+#define SERIAL0_RECV	0
+
+#define DMA_CHAN_0	1
+#define DMA_CHAN_1	2
+#define DMA_CHAN_2	3
+#define DMA_CHAN_3	4
+
+/* end STBx25xx */
+
+/*
+ * Bit 30 must be one for Redwoods, otherwise transfers may receive errors.
+ */
+#define DMA_CR_MB0 0x2
+
+#define SET_DMA_CONTROL \
+       		(SET_DMA_CIE_ENABLE(p_init->int_enable) |  /* interrupt enable         */ \
+		SET_DMA_ETD(p_init->etd_output)        |  /* end of transfer pin      */ \
+		SET_DMA_TCE(p_init->tce_enable)        |  /* terminal count enable    */ \
+		SET_DMA_PL(p_init->pl)                 |  /* peripheral location      */ \
+		SET_DMA_DAI(p_init->dai)               |  /* dest addr increment      */ \
+		SET_DMA_SAI(p_init->sai)               |  /* src addr increment       */ \
+		SET_DMA_PRIORITY(p_init->cp)           |  /* channel priority        */  \
+		SET_DMA_PW(p_init->pwidth)             |  /* peripheral/bus width    */ \
+		SET_DMA_PSC(p_init->psc)               |  /* peripheral setup cycles */ \
+		SET_DMA_PWC(p_init->pwc)               |  /* peripheral wait cycles  */ \
+		SET_DMA_PHC(p_init->phc)               |  /* peripheral hold cycles  */ \
+		SET_DMA_TCD(p_init->tcd_disable)	  |  /* TC chain mode disable   */ \
+		SET_DMA_ECE(p_init->ece_enable)	  |  /* ECE chanin mode enable  */ \
+		SET_DMA_CH(p_init->ch_enable)	|    /* Chain enable 	        */ \
+		DMA_CR_MB0				/* must be one */)
+
+#define GET_DMA_POLARITY(chan) chan
+
+#endif
+
+typedef struct {
+	unsigned short in_use;	/* set when channel is being used, clr when
+				 * available.
+				 */
+	/*
+	 * Valid polarity settings:
+	 *   DMAReq_ActiveLow(n)
+	 *   DMAAck_ActiveLow(n)
+	 *   EOT_ActiveLow(n)
+	 *
+	 *   n is 0 to max dma chans
+	 */
+	unsigned int polarity;
+
+	char buffer_enable;	/* Boolean: buffer enable            */
+	char tce_enable;	/* Boolean: terminal count enable    */
+	char etd_output;	/* Boolean: eot pin is a tc output   */
+	char pce;		/* Boolean: parity check enable      */
+
+	/*
+	 * Peripheral location:
+	 * INTERNAL_PERIPHERAL (UART0 on the 405GP)
+	 * EXTERNAL_PERIPHERAL
+	 */
+	char pl;		/* internal/external peripheral      */
+
+	/*
+	 * Valid pwidth settings:
+	 *   PW_8
+	 *   PW_16
+	 *   PW_32
+	 *   PW_64
+	 */
+	unsigned int pwidth;
+
+	char dai;		/* Boolean: dst address increment   */
+	char sai;		/* Boolean: src address increment   */
+
+	/*
+	 * Valid psc settings: 0-3
+	 */
+	unsigned int psc;	/* Peripheral Setup Cycles         */
+
+	/*
+	 * Valid pwc settings:
+	 * 0-63
+	 */
+	unsigned int pwc;	/* Peripheral Wait Cycles          */
+
+	/*
+	 * Valid phc settings:
+	 * 0-7
+	 */
+	unsigned int phc;	/* Peripheral Hold Cycles          */
+
+	/*
+	 * Valid cp (channel priority) settings:
+	 *   PRIORITY_LOW
+	 *   PRIORITY_MID_LOW
+	 *   PRIORITY_MID_HIGH
+	 *   PRIORITY_HIGH
+	 */
+	unsigned int cp;	/* channel priority                */
+
+	/*
+	 * Valid pf (memory read prefetch) settings:
+	 *
+	 *   PREFETCH_1
+	 *   PREFETCH_2
+	 *   PREFETCH_4
+	 */
+	unsigned int pf;	/* memory read prefetch            */
+
+	/*
+	 * Boolean: channel interrupt enable
+	 * NOTE: for sgl transfers, only the last descriptor will be setup to
+	 * interrupt.
+	 */
+	char int_enable;
+
+	char shift;		/* easy access to byte_count shift, based on */
+	/* the width of the channel                  */
+
+	uint32_t control;	/* channel control word                      */
+
+	/* These variabled are used ONLY in single dma transfers              */
+	unsigned int mode;	/* transfer mode                     */
+	phys_addr_t addr;
+	char ce;		/* channel enable */
+#ifdef CONFIG_STB03xxx
+	char ch_enable;
+	char tcd_disable;
+	char ece_enable;
+	char td;		/* transfer direction */
+#endif
+
+	char int_on_final_sg;/* for scatter/gather - only interrupt on last sg */
+} ppc_dma_ch_t;
+
+/*
+ * PPC44x DMA implementations have a slightly different
+ * descriptor layout.  Probably moved about due to the
+ * change to 64-bit addresses and link pointer. I don't
+ * know why they didn't just leave control_count after
+ * the dst_addr.
+ */
+#ifdef PPC4xx_DMA_64BIT
+typedef struct {
+	uint32_t control;
+	uint32_t control_count;
+	phys_addr_t src_addr;
+	phys_addr_t dst_addr;
+	phys_addr_t next;
+} ppc_sgl_t;
+#else
+typedef struct {
+	uint32_t control;
+	phys_addr_t src_addr;
+	phys_addr_t dst_addr;
+	uint32_t control_count;
+	uint32_t next;
+} ppc_sgl_t;
+#endif
+
+typedef struct {
+	unsigned int dmanr;
+	uint32_t control;	/* channel ctrl word; loaded from each descrptr */
+	uint32_t sgl_control;	/* LK, TCI, ETI, and ERI bits in sgl descriptor */
+	dma_addr_t dma_addr;	/* dma (physical) address of this list          */
+	ppc_sgl_t *phead;
+	dma_addr_t phead_dma;
+	ppc_sgl_t *ptail;
+	dma_addr_t ptail_dma;
+} sgl_list_info_t;
+
+typedef struct {
+	phys_addr_t *src_addr;
+	phys_addr_t *dst_addr;
+	phys_addr_t dma_src_addr;
+	phys_addr_t dma_dst_addr;
+} pci_alloc_desc_t;
+
+extern ppc_dma_ch_t dma_channels[];
+
+/*
+ * The DMA API are in ppc4xx_dma.c and ppc4xx_sgdma.c
+ */
+extern int ppc4xx_init_dma_channel(unsigned int, ppc_dma_ch_t *);
+extern int ppc4xx_get_channel_config(unsigned int, ppc_dma_ch_t *);
+extern int ppc4xx_set_channel_priority(unsigned int, unsigned int);
+extern unsigned int ppc4xx_get_peripheral_width(unsigned int);
+extern void ppc4xx_set_sg_addr(int, phys_addr_t);
+extern int ppc4xx_add_dma_sgl(sgl_handle_t, phys_addr_t, phys_addr_t, unsigned int);
+extern void ppc4xx_enable_dma_sgl(sgl_handle_t);
+extern void ppc4xx_disable_dma_sgl(sgl_handle_t);
+extern int ppc4xx_get_dma_sgl_residue(sgl_handle_t, phys_addr_t *, phys_addr_t *);
+extern int ppc4xx_delete_dma_sgl_element(sgl_handle_t, phys_addr_t *, phys_addr_t *);
+extern int ppc4xx_alloc_dma_handle(sgl_handle_t *, unsigned int, unsigned int);
+extern void ppc4xx_free_dma_handle(sgl_handle_t);
+extern int ppc4xx_get_dma_status(void);
+extern int ppc4xx_enable_burst(unsigned int);
+extern int ppc4xx_disable_burst(unsigned int);
+extern int ppc4xx_set_burst_size(unsigned int, unsigned int);
+extern void ppc4xx_set_src_addr(int dmanr, phys_addr_t src_addr);
+extern void ppc4xx_set_dst_addr(int dmanr, phys_addr_t dst_addr);
+extern void ppc4xx_enable_dma(unsigned int dmanr);
+extern void ppc4xx_disable_dma(unsigned int dmanr);
+extern void ppc4xx_set_dma_count(unsigned int dmanr, unsigned int count);
+extern int ppc4xx_get_dma_residue(unsigned int dmanr);
+extern void ppc4xx_set_dma_addr2(unsigned int dmanr, phys_addr_t src_dma_addr,
+				 phys_addr_t dst_dma_addr);
+extern int ppc4xx_enable_dma_interrupt(unsigned int dmanr);
+extern int ppc4xx_disable_dma_interrupt(unsigned int dmanr);
+extern int ppc4xx_clr_dma_status(unsigned int dmanr);
+extern int ppc4xx_map_dma_port(unsigned int dmanr, unsigned int ocp_dma,short dma_chan);
+extern int ppc4xx_disable_dma_port(unsigned int dmanr, unsigned int ocp_dma,short dma_chan);
+extern int ppc4xx_set_dma_mode(unsigned int dmanr, unsigned int mode);
+
+/* These are in kernel/dma.c: */
+
+/* reserve a DMA channel */
+extern int request_dma(unsigned int dmanr, const char *device_id);
+/* release it again */
+extern void free_dma(unsigned int dmanr);
+#endif
+#endif				/* __KERNEL__ */

--- a/arch/powerpc/platforms/44x/apollo3g-usb.c	2017-06-21 20:25:20.252000000 +0000
+++ b/arch/powerpc/platforms/44x/apollo3g-usb.c	2017-06-19 13:09:20.421238353 +0000
@@ -0,0 +1,113 @@
+/*
+ * AMCC Kilauea USB-OTG wrapper
+ *
+ * Copyright 2008 DENX Software Engineering, Stefan Roese <sr@denx.de>
+ *
+ * Extract the resources (MEM & IRQ) from the dts file and put them
+ * into the platform-device struct for usage in the platform-device
+ * USB-OTG driver.
+ *
+ */
+#include <linux/init.h>
+#include <linux/module.h>
+#include <linux/platform_device.h>
+#include <linux/of_address.h>
+#include <linux/of_irq.h>
+#include <linux/of_platform.h>
+#define U64_TO_U32_LOW(val)     ((u32)((val) & 0x00000000ffffffffULL))
+#define U64_TO_U32_HIGH(val)    ((u32)((val) >> 32))
+
+
+/*
+ * Resource template will be filled dynamically with the values
+ * extracted from the dts file
+ */
+static struct resource usb_otg_resources[] = {
+	[0] = {
+		/* 405EX USB-OTG registers */
+		.flags  = IORESOURCE_MEM,
+	},
+	[1] = {
+		/* 405EX OTG IRQ */
+		.flags  = IORESOURCE_IRQ,
+	},
+	[2] = {
+		/* High-Power workaround IRQ */
+		.flags  = IORESOURCE_IRQ,
+	},
+	[3] = {
+		/* 405EX DMA IRQ */
+		.flags  = IORESOURCE_IRQ,
+	},
+};
+
+static u64 dma_mask = 0xffffffffULL;
+
+static struct platform_device usb_otg_device = {
+//     	.name = "dwc_otg",
+		.name = "dwc2",
+        .id = 0,
+        .num_resources = ARRAY_SIZE(usb_otg_resources),
+        .resource = usb_otg_resources,
+        .dev = {
+			.dma_mask = &dma_mask,
+			.coherent_dma_mask = 0xffffffffULL,
+        }
+};
+
+static struct platform_device *ppc405ex_devs[] = { &usb_otg_device };
+
+static int ppc405ex_usb_otg_probe(struct platform_device *ofdev) {
+	struct device_node *np = ofdev->dev.of_node;
+	struct resource res;
+
+	/*
+	 * Extract register address reange from device tree and put it into
+	 * the platform device structure
+	 */
+	dev_notice(&ofdev->dev, "Apollo3G USB driver\n");
+	if (of_address_to_resource(np, 0, &res)) {
+		printk(KERN_ERR "%s: Can't get USB-OTG register address\n", __func__);
+		return -ENOMEM;
+	}
+	usb_otg_resources[0].start = res.start;
+	usb_otg_resources[0].end = res.end;
+
+	/*
+	 * Extract IRQ number(s) from device tree and put them into
+	 * the platform device structure
+	 */
+	usb_otg_resources[1].start = usb_otg_resources[1].end =
+		irq_of_parse_and_map(np, 0);
+	usb_otg_resources[2].start = usb_otg_resources[2].end =
+		irq_of_parse_and_map(np, 1);
+	usb_otg_resources[3].start = usb_otg_resources[3].end =
+		irq_of_parse_and_map(np, 2);
+	return platform_add_devices(ppc405ex_devs, ARRAY_SIZE(ppc405ex_devs));
+}
+
+static int ppc405ex_usb_otg_remove(struct platform_device *ofdev)
+{
+	/* Nothing to do here */
+	return 0;
+}
+
+static const struct of_device_id ppc405ex_usb_otg_match[] = {
+	{ .compatible = "amcc,usb-otg-405ex", },
+	{}
+};
+
+static struct platform_driver ppc405ex_usb_otg_driver = {
+	.driver = {
+		.name = "amcc,usb-otg-405ex",
+		.of_match_table = ppc405ex_usb_otg_match,
+	},
+	.probe = ppc405ex_usb_otg_probe,
+	.remove = ppc405ex_usb_otg_remove,
+};
+
+static int __init ppc405ex_usb_otg_init(void)
+{
+	return platform_driver_register(&ppc405ex_usb_otg_driver);
+}
+device_initcall(ppc405ex_usb_otg_init);
