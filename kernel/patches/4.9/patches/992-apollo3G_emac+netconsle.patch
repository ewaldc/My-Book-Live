diff -Naur a/drivers/net/ethernet/ibm/emac/Kconfig b/drivers/net/ethernet/ibm/emac/Kconfig
--- a/drivers/net/ethernet/ibm/emac/Kconfig	2019-01-09 16:16:45.000000000 +0100 +0000
+++ b/drivers/net/ethernet/ibm/emac/Kconfig	2019-02-16 18:28:31.991150000 +0000
@@ -39,6 +39,51 @@
 
 	  If unsure, set to 0.
 
+config IBM_EMAC_INTR_COALESCE
+	bool "Hardware Interrupt coalescing"
+	depends on IBM_EMAC && (460EX || 460GT || 405EX || 460SX || APM821xx)
+	default y
+	help
+	  When selected the Ethernet interrupt coalescing is selected.
+
+config IBM_EMAC_TX_COAL_COUNT
+	int "TX Coalescence frame count (packets)"
+	depends on IBM_EMAC_INTR_COALESCE
+	default "16"
+
+config IBM_EMAC_TX_COAL_TIMER
+	int "TX Coalescence timer (clock ticks)"
+	depends on IBM_EMAC_INTR_COALESCE
+	default "1000000"
+
+config IBM_EMAC_RX_COAL_COUNT
+	int "RX Coalescence frame count (packets)"
+	depends on IBM_EMAC_INTR_COALESCE
+	default "1"
+
+config IBM_EMAC_RX_COAL_TIMER
+	int "RX Coalescence timer (clock ticks)"
+	depends on IBM_EMAC_INTR_COALESCE
+	default "1000000"
+	  
+config IBM_EMAC_MASK_CEXT
+	bool "Mask Carrier Extension signals"
+	depends on IBM_EMAC && APM821xx
+	default n
+	help
+	  During normal idle TX, continously send dummy packets to mask 
+	  the Carrier Extension signals. This creates a separate BD 
+	  specifically for this purpose.
+
+	  If unsure, set to N.
+
+config IBM_EMAC_SYSFS
+	bool "Sysfs support for IBM EMAC"
+	depends on IBM_EMAC
+	default n
+	help
+	  Export IBM EMAC parameters via /sys/class/net/eth* interface
+
 config IBM_EMAC_DEBUG
 	bool "Debugging"
 	depends on IBM_EMAC
diff -Naur a/drivers/net/ethernet/ibm/emac/core.c b/drivers/net/ethernet/ibm/emac/core.c
--- a/drivers/net/ethernet/ibm/emac/core.c	2019-01-09 16:16:45.000000000 +0000
+++ b/drivers/net/ethernet/ibm/emac/core.c	2019-02-16 18:28:31.991150000 +0000
@@ -33,6 +33,7 @@
 #include <linux/pci.h>
 #include <linux/etherdevice.h>
 #include <linux/skbuff.h>
+#include <linux/tcp.h>
 #include <linux/crc32.h>
 #include <linux/ethtool.h>
 #include <linux/mii.h>
@@ -42,12 +43,14 @@
 #include <linux/of_address.h>
 #include <linux/of_irq.h>
 #include <linux/of_net.h>
+#include <linux/of_mdio.h>
 #include <linux/slab.h>
 
+#include <net/tcp.h>
 #include <asm/processor.h>
 #include <asm/io.h>
 #include <asm/dma.h>
-#include <asm/uaccess.h>
+#include <linux/uaccess.h>
 #include <asm/dcr.h>
 #include <asm/dcr-regs.h>
 
@@ -75,8 +78,7 @@
 #define DRV_DESC        "PPC 4xx OCP EMAC driver"
 
 MODULE_DESCRIPTION(DRV_DESC);
-MODULE_AUTHOR
-    ("Eugene Surovegin <eugene.surovegin@zultys.com> or <ebs@ebshome.net>");
+MODULE_AUTHOR("Eugene Surovegin <eugene.surovegin@zultys.com> or <ebs@ebshome.net>");
 MODULE_LICENSE("GPL");
 
 /* minimum number of free TX descriptors required to wake up TX process */
@@ -122,39 +124,34 @@
 #define EMAC_PROBE_DEP_TIMEOUT	(HZ * 5)
 
 /* I don't want to litter system log with timeout errors
- * when we have brain-damaged PHY.
- */
-static inline void emac_report_timeout_error(struct emac_instance *dev,
-					     const char *error)
-{
-	if (emac_has_feature(dev, EMAC_FTR_440GX_PHY_CLK_FIX |
-				  EMAC_FTR_460EX_PHY_CLK_FIX |
-				  EMAC_FTR_440EP_PHY_CLK_FIX))
+ * when we have brain-damaged PHY */
+static inline void emac_report_timeout_error(struct emac_instance *dev, const char *error) {
+	if (emac_has_feature(dev, EMAC_FTR_440GX_PHY_CLK_FIX | EMAC_FTR_460EX_PHY_CLK_FIX |
+		EMAC_FTR_APM821XX_PHY_CLK_FIX | EMAC_FTR_440EP_PHY_CLK_FIX))
 		DBG(dev, "%s" NL, error);
 	else if (net_ratelimit())
-		printk(KERN_ERR "%s: %s\n", dev->ofdev->dev.of_node->full_name,
-			error);
+		printk(KERN_ERR "%s: %s\n", dev->ofdev->dev.of_node->full_name, error);
 }
 
 /* EMAC PHY clock workaround:
  * 440EP/440GR has more sane SDR0_MFR register implementation than 440GX,
  * which allows controlling each EMAC clock
  */
-static inline void emac_rx_clk_tx(struct emac_instance *dev)
-{
+static inline void emac_rx_clk_tx(struct emac_instance *dev) {
 #ifdef CONFIG_PPC_DCR_NATIVE
-	if (emac_has_feature(dev, EMAC_FTR_440EP_PHY_CLK_FIX))
-		dcri_clrset(SDR0, SDR0_MFR,
-			    0, SDR0_MFR_ECS >> dev->cell_index);
+	if (emac_has_feature(dev, EMAC_FTR_APM821XX_PHY_CLK_FIX))
+		dcri_clrset(SDR0, SDR0_ETH_CFG, 0, 0x00000100 >> dev->cell_index);
+	else if (emac_has_feature(dev, EMAC_FTR_440EP_PHY_CLK_FIX))
+		dcri_clrset(SDR0, SDR0_MFR, 0, SDR0_MFR_ECS >> dev->cell_index);
 #endif
 }
 
-static inline void emac_rx_clk_default(struct emac_instance *dev)
-{
+static inline void emac_rx_clk_default(struct emac_instance *dev) {
 #ifdef CONFIG_PPC_DCR_NATIVE
-	if (emac_has_feature(dev, EMAC_FTR_440EP_PHY_CLK_FIX))
-		dcri_clrset(SDR0, SDR0_MFR,
-			    SDR0_MFR_ECS >> dev->cell_index, 0);
+	if (emac_has_feature(dev, EMAC_FTR_APM821XX_PHY_CLK_FIX))
+		dcri_clrset(SDR0, SDR0_ETH_CFG, 0x00000100 >> dev->cell_index, 0);
+	else if (emac_has_feature(dev, EMAC_FTR_440EP_PHY_CLK_FIX))
+		dcri_clrset(SDR0, SDR0_MFR, SDR0_MFR_ECS >> dev->cell_index, 0);
 #endif
 }
 
@@ -163,16 +160,13 @@
 #define PHY_POLL_LINK_OFF	(HZ / 5)
 
 /* Graceful stop timeouts in us.
- * We should allow up to 1 frame time (full-duplex, ignoring collisions)
- */
+ * We should allow up to 1 frame time (full-duplex, ignoring collisions) */
 #define STOP_TIMEOUT_10		1230
 #define STOP_TIMEOUT_100	124
 #define STOP_TIMEOUT_1000	13
 #define STOP_TIMEOUT_1000_JUMBO	73
 
-static unsigned char default_mcast_addr[] = {
-	0x01, 0x80, 0xC2, 0x00, 0x00, 0x01
-};
+static unsigned char default_mcast_addr[] = { 0x01, 0x80, 0xC2, 0x00, 0x00, 0x01 };
 
 /* Please, keep in sync with struct ibm_emac_stats/ibm_emac_error_stats */
 static const char emac_stats_keys[EMAC_ETHTOOL_STATS_COUNT][ETH_GSTRING_LEN] = {
@@ -194,39 +188,27 @@
 };
 
 static irqreturn_t emac_irq(int irq, void *dev_instance);
+static irqreturn_t wol_irq(int irq, void *dev_instance);
 static void emac_clean_tx_ring(struct emac_instance *dev);
 static void __emac_set_multicast_list(struct emac_instance *dev);
 
-static inline int emac_phy_supports_gige(int phy_mode)
-{
-	return  phy_mode == PHY_MODE_GMII ||
-		phy_mode == PHY_MODE_RGMII ||
-		phy_mode == PHY_MODE_SGMII ||
-		phy_mode == PHY_MODE_TBI ||
-		phy_mode == PHY_MODE_RTBI;
-}
-
-static inline int emac_phy_gpcs(int phy_mode)
-{
-	return  phy_mode == PHY_MODE_SGMII ||
-		phy_mode == PHY_MODE_TBI ||
-		phy_mode == PHY_MODE_RTBI;
+static inline int emac_phy_supports_gige(int phy_mode) {
+	return phy_mode == PHY_MODE_GMII || phy_mode == PHY_MODE_RGMII ||
+		phy_mode == PHY_MODE_SGMII || phy_mode == PHY_MODE_TBI || phy_mode == PHY_MODE_RTBI;
 }
 
-static inline void emac_tx_enable(struct emac_instance *dev)
-{
-	struct emac_regs __iomem *p = dev->emacp;
-	u32 r;
+static inline int emac_phy_gpcs(int phy_mode) {
+	return  phy_mode == PHY_MODE_SGMII || phy_mode == PHY_MODE_TBI || phy_mode == PHY_MODE_RTBI;
+}
 
+static inline void emac_tx_enable(struct emac_instance *dev) {
+	struct emac_regs __iomem *p = dev->emacp;
+	u32 r = in_be32(&p->mr0);
 	DBG(dev, "tx_enable" NL);
-
-	r = in_be32(&p->mr0);
-	if (!(r & EMAC_MR0_TXE))
-		out_be32(&p->mr0, r | EMAC_MR0_TXE);
+	if (!(r & EMAC_MR0_TXE)) out_be32(&p->mr0, r | EMAC_MR0_TXE);
 }
 
-static void emac_tx_disable(struct emac_instance *dev)
-{
+static void emac_tx_disable(struct emac_instance *dev) {
 	struct emac_regs __iomem *p = dev->emacp;
 	u32 r;
 
@@ -245,57 +227,80 @@
 	}
 }
 
-static void emac_rx_enable(struct emac_instance *dev)
-{
-	struct emac_regs __iomem *p = dev->emacp;
+#ifdef CONFIG_IBM_EMAC_MASK_CEXT
+/* no longer used
+static void emac_spin_delay(unsigned long spin_usecs) {
+	u64 tick_start, tick_end, spin_ticks = spin_usecs*tb_ticks_per_usec;
+	//printk("spin_ticks = %lld\n", spin_ticks);
+	tick_start = get_tb();
+	while(1) {
+		tick_end = get_tb();
+		if((tick_end - tick_start) >= spin_ticks) return;
+	}
+}
+*/
+/* some code duplication here to avoid function calls */
+static inline void emac_start_idlemode(struct emac_instance *dev) {
+	u32 perclk;
+	//printk("ibmnewemac: start_idle\n");
+	DBG(dev, "start_idlemode" NL);
+
+	//emac_spin_delay(TX_FIFO_SYNC_USEC);	/* Wait for TX FIFO to Sync */
+	perclk = mfdcri(SDR0, SDR0_PERCLK);		/* Disable Ethernet Clock */
+	mtdcri(SDR0, SDR0_PERCLK, perclk | 0x88000000);
+	perclk = mfdcri(SDR0, SDR0_PERCLK);		/* Write0 to set rising clock edge next time*/
+	mtdcri(SDR0, SDR0_PERCLK, perclk & 0x7fffffff); 
+	//perclk = mfdcri(SDR0, SDR0_PERCLK);
+	//printk("%s:%d - Ethernet TX Clock Disabled perclk=0x%08lx\n", __FUNCTION__, __LINE__, perclk);
+}
+
+static inline void emac_exit_idlemode(struct emac_instance *dev) {
+	u32 perclk;
+	DBG(dev, "exit_idlemode" NL);
+
+	perclk = mfdcri(SDR0, SDR0_PERCLK);		/* Enable Ethernet Clock */
+	mtdcri(SDR0, SDR0_PERCLK, (perclk & 0xF7ffffff) | 0x80000000);
+	perclk = mfdcri(SDR0, SDR0_PERCLK);
+	mtdcri(SDR0, SDR0_PERCLK, perclk & 0x7fffffff);	/* Write0 to set rising clock edge next time*/
+	//perclk = mfdcri(SDR0, SDR0_PERCLK);
+	//printk("%s:%d - Ethernet TX Clock Enabled perclk=0x%08lx\n", __FUNCTION__, __LINE__, perclk);
+}
+#endif
+
+static inline void emac_rx_enable(struct emac_instance *dev) {
 	u32 r;
 
-	if (unlikely(test_bit(MAL_COMMAC_RX_STOPPED, &dev->commac.flags)))
-		goto out;
+	if (unlikely(test_bit(MAL_COMMAC_RX_STOPPED, &dev->commac.flags))) return;
 
 	DBG(dev, "rx_enable" NL);
-
-	r = in_be32(&p->mr0);
+	r = in_be32(dev->mr0);
 	if (!(r & EMAC_MR0_RXE)) {
-		if (unlikely(!(r & EMAC_MR0_RXI))) {
-			/* Wait if previous async disable is still in progress */
+		if (unlikely(!(r & EMAC_MR0_RXI))) { /* Wait if previous async disable is still in progress */
 			int n = dev->stop_timeout;
-			while (!(r = in_be32(&p->mr0) & EMAC_MR0_RXI) && n) {
-				udelay(1);
-				--n;
-			}
-			if (unlikely(!n))
-				emac_report_timeout_error(dev,
-							  "RX disable timeout");
+			while (!(r = in_be32(dev->mr0) & EMAC_MR0_RXI) && n--) udelay(1);
+			if (unlikely(!n)) emac_report_timeout_error(dev, "RX disable timeout");
 		}
-		out_be32(&p->mr0, r | EMAC_MR0_RXE);
+		out_be32(dev->mr0, r | EMAC_MR0_RXE);
 	}
- out:
-	;
 }
 
-static void emac_rx_disable(struct emac_instance *dev)
-{
+static inline void emac_rx_disable(struct emac_instance *dev) {
 	struct emac_regs __iomem *p = dev->emacp;
-	u32 r;
+	u32 r = in_be32(&p->mr0);
+	//u32 r = in_be32(dev->mr0);
 
 	DBG(dev, "rx_disable" NL);
-
-	r = in_be32(&p->mr0);
 	if (r & EMAC_MR0_RXE) {
 		int n = dev->stop_timeout;
 		out_be32(&p->mr0, r & ~EMAC_MR0_RXE);
-		while (!(in_be32(&p->mr0) & EMAC_MR0_RXI) && n) {
-			udelay(1);
-			--n;
-		}
-		if (unlikely(!n))
-			emac_report_timeout_error(dev, "RX disable timeout");
+		//out_be32(dev->mr0, r & ~EMAC_MR0_RXE);
+		while (!(in_be32(&p->mr0) & EMAC_MR0_RXI) && n--) udelay(1);
+		//while (!(in_be32(dev->mr0) & EMAC_MR0_RXI) && n) { udelay(1);	--n; }
+		if (unlikely(!n)) emac_report_timeout_error(dev, "RX disable timeout");
 	}
 }
 
-static inline void emac_netif_stop(struct emac_instance *dev)
-{
+static inline void emac_netif_stop(struct emac_instance *dev) {
 	netif_tx_lock_bh(dev->ndev);
 	netif_addr_lock(dev->ndev);
 	dev->no_mcast = 1;
@@ -306,8 +311,7 @@
 	netif_tx_disable(dev->ndev);
 }
 
-static inline void emac_netif_start(struct emac_instance *dev)
-{
+static inline void emac_netif_start(struct emac_instance *dev) {
 	netif_tx_lock_bh(dev->ndev);
 	netif_addr_lock(dev->ndev);
 	dev->no_mcast = 0;
@@ -326,20 +330,15 @@
 	mal_poll_enable(dev->mal, &dev->commac);
 }
 
-static inline void emac_rx_disable_async(struct emac_instance *dev)
-{
-	struct emac_regs __iomem *p = dev->emacp;
-	u32 r;
-
+static inline void emac_rx_disable_async(struct emac_instance *dev) {
+	//struct emac_regs __iomem *p = dev->emacp;
+	u32 r = in_be32(dev->mr0);
 	DBG(dev, "rx_disable_async" NL);
 
-	r = in_be32(&p->mr0);
-	if (r & EMAC_MR0_RXE)
-		out_be32(&p->mr0, r & ~EMAC_MR0_RXE);
+	if (r & EMAC_MR0_RXE) out_be32(dev->mr0, r & ~EMAC_MR0_RXE);
 }
 
-static int emac_reset(struct emac_instance *dev)
-{
+static int emac_reset(struct emac_instance *dev) {
 	struct emac_regs __iomem *p = dev->emacp;
 	int n = 20;
 	bool __maybe_unused try_internal_clock = false;
@@ -347,9 +346,14 @@
 	DBG(dev, "reset" NL);
 
 	if (!dev->reset_failed) {
-		/* 40x erratum suggests stopping RX channel before reset,
-		 * we stop TX as well
-		 */
+#ifdef CONFIG_IBM_EMAC_MASK_CEXT
+	if (atomic_read(&dev->mask_cext_enable))
+		if (atomic_read(&dev->idle_mode)) {
+			emac_exit_idlemode(dev);
+			atomic_set(&dev->idle_mode, 0);
+		}
+#endif
+		/* 40x erratum suggests stopping RX channel before reset, we stop TX as well */
 		emac_rx_disable(dev);
 		emac_tx_disable(dev);
 	}
@@ -374,22 +378,18 @@
 	 * the first reset fails.
 	 */
 	if (emac_has_feature(dev, EMAC_FTR_460EX_PHY_CLK_FIX)) {
-		if (try_internal_clock || (dev->phy_address == 0xffffffff &&
-					   dev->phy_map == 0xffffffff)) {
+		if (try_internal_clock || (dev->phy_address == 0xffffffff && dev->phy_map == 0xffffffff))
 			/* No PHY: select internal loop clock before reset */
-			dcri_clrset(SDR0, SDR0_ETH_CFG,
-				    0, SDR0_ETH_CFG_ECS << dev->cell_index);
-		} else {
+			dcri_clrset(SDR0, SDR0_ETH_CFG, 0, SDR0_ETH_CFG_ECS << dev->cell_index);
+		else
 			/* PHY present: select external clock before reset */
-			dcri_clrset(SDR0, SDR0_ETH_CFG,
-				    SDR0_ETH_CFG_ECS << dev->cell_index, 0);
-		}
+			dcri_clrset(SDR0, SDR0_ETH_CFG, SDR0_ETH_CFG_ECS << dev->cell_index, 0);
 	}
 #endif
 
-	out_be32(&p->mr0, EMAC_MR0_SRST);
+	out_be32(&p->mr0, EMAC_MR0_SRST);	// Soft Reset
 	while ((in_be32(&p->mr0) & EMAC_MR0_SRST) && n)
-		--n;
+		--n;	// Poll until 0
 
 #ifdef CONFIG_PPC_DCR_NATIVE
 	if (emac_has_feature(dev, EMAC_FTR_460EX_PHY_CLK_FIX)) {
@@ -400,11 +400,9 @@
 			goto do_retry;
 		}
 
-		if (try_internal_clock || (dev->phy_address == 0xffffffff &&
-					   dev->phy_map == 0xffffffff)) {
+		if (try_internal_clock || (dev->phy_address == 0xffffffff && dev->phy_map == 0xffffffff)) {
 			/* No PHY: restore external clock source after reset */
-			dcri_clrset(SDR0, SDR0_ETH_CFG,
-				    SDR0_ETH_CFG_ECS << dev->cell_index, 0);
+			dcri_clrset(SDR0, SDR0_ETH_CFG, SDR0_ETH_CFG_ECS << dev->cell_index, 0);
 		}
 	}
 #endif
@@ -419,158 +417,108 @@
 	}
 }
 
-static void emac_hash_mc(struct emac_instance *dev)
-{
+static void emac_hash_mc(struct emac_instance *dev) {
 	const int regs = EMAC_XAHT_REGS(dev);
-	u32 *gaht_base = emac_gaht_base(dev);
-	u32 gaht_temp[regs];
+	u32 *gaht_base = emac_gaht_base(dev), gaht_temp[EMAC_XAHT_MAX_REGS];
 	struct netdev_hw_addr *ha;
 	int i;
 
 	DBG(dev, "hash_mc %d" NL, netdev_mc_count(dev->ndev));
-
 	memset(gaht_temp, 0, sizeof (gaht_temp));
-
 	netdev_for_each_mc_addr(ha, dev->ndev) {
-		int slot, reg, mask;
+		int slot, reg;
 		DBG2(dev, "mc %pM" NL, ha->addr);
-
-		slot = EMAC_XAHT_CRC_TO_SLOT(dev,
-					     ether_crc(ETH_ALEN, ha->addr));
+		slot = EMAC_XAHT_CRC_TO_SLOT(dev, ether_crc(ETH_ALEN, ha->addr));
 		reg = EMAC_XAHT_SLOT_TO_REG(dev, slot);
-		mask = EMAC_XAHT_SLOT_TO_MASK(dev, slot);
-
-		gaht_temp[reg] |= mask;
+		gaht_temp[reg] |= EMAC_XAHT_SLOT_TO_MASK(dev, slot);
 	}
-
-	for (i = 0; i < regs; i++)
-		out_be32(gaht_base + i, gaht_temp[i]);
+	for (i = 0; i < regs; i++) out_be32(gaht_base + i, gaht_temp[i]);
 }
 
-static inline u32 emac_iff2rmr(struct net_device *ndev)
-{
+static inline u32 emac_iff2rmr(struct net_device *ndev) {
 	struct emac_instance *dev = netdev_priv(ndev);
 	u32 r;
+	r = EMAC_RMR_SP | EMAC_RMR_SFCS | EMAC_RMR_IAE | EMAC_RMR_BAE;	// EMAC_RMR_RFP  (ECO)
 
-	r = EMAC_RMR_SP | EMAC_RMR_SFCS | EMAC_RMR_IAE | EMAC_RMR_BAE;
+	if (likely(emac_has_feature(dev, EMAC_FTR_EMAC4))) r |= EMAC4_RMR_BASE;
+	else r |= EMAC_RMR_BASE;
 
-	if (emac_has_feature(dev, EMAC_FTR_EMAC4))
-	    r |= EMAC4_RMR_BASE;
-	else
-	    r |= EMAC_RMR_BASE;
-
-	if (ndev->flags & IFF_PROMISC)
-		r |= EMAC_RMR_PME;
-	else if (ndev->flags & IFF_ALLMULTI ||
-			 (netdev_mc_count(ndev) > EMAC_XAHT_SLOTS(dev)))
+	if (ndev->flags & IFF_PROMISC) r |= EMAC_RMR_PME;
+	else if (ndev->flags & IFF_ALLMULTI || (netdev_mc_count(ndev) > EMAC_XAHT_SLOTS(dev)))
 		r |= EMAC_RMR_PMME;
-	else if (!netdev_mc_empty(ndev))
-		r |= EMAC_RMR_MAE;
+	else if (!netdev_mc_empty(ndev)) r |= EMAC_RMR_MAE;
 
-	if (emac_has_feature(dev, EMAC_APM821XX_REQ_JUMBO_FRAME_SIZE)) {
+	/* When Jumbo Frame is not enabled, MJS field has no effect. So setting MJS when Jumbo Frame
+	 * is disabled should not cause any issue */
+	if (emac_has_feature(dev, EMAC_APM821XX_REQ_JUMBO_FRAME_SIZE)) { //ECO
 		r &= ~EMAC4_RMR_MJS_MASK;
 		r |= EMAC4_RMR_MJS(ndev->mtu);
+		DBG(dev, "emac_iff2rmr: EMAC_RMR = 0x%08x" NL, r);
 	}
-
 	return r;
 }
 
-static u32 __emac_calc_base_mr1(struct emac_instance *dev, int tx_size, int rx_size)
-{
+static u32 __emac_calc_base_mr1(struct emac_instance *dev, int tx_size, int rx_size) {
 	u32 ret = EMAC_MR1_VLE | EMAC_MR1_IST | EMAC_MR1_TR0_MULT;
 
 	DBG2(dev, "__emac_calc_base_mr1" NL);
-
 	switch(tx_size) {
-	case 2048:
-		ret |= EMAC_MR1_TFS_2K;
-		break;
-	default:
-		printk(KERN_WARNING "%s: Unknown Tx FIFO size %d\n",
-		       dev->ndev->name, tx_size);
+		case 2048: ret |= EMAC_MR1_TFS_2K; break;
+		default:
+			printk(KERN_WARNING "%s: Unknown Tx FIFO size %d\n", dev->ndev->name, tx_size);
 	}
 
 	switch(rx_size) {
-	case 16384:
-		ret |= EMAC_MR1_RFS_16K;
-		break;
-	case 4096:
-		ret |= EMAC_MR1_RFS_4K;
-		break;
-	default:
-		printk(KERN_WARNING "%s: Unknown Rx FIFO size %d\n",
-		       dev->ndev->name, rx_size);
+		case 16384:	ret |= EMAC_MR1_RFS_16K; break;
+		case 4096:	ret |= EMAC_MR1_RFS_4K; break;
+		default:
+			printk(KERN_WARNING "%s: Unknown Rx FIFO size %d\n", dev->ndev->name, rx_size);
 	}
-
 	return ret;
 }
 
-static u32 __emac4_calc_base_mr1(struct emac_instance *dev, int tx_size, int rx_size)
-{
-	u32 ret = EMAC_MR1_VLE | EMAC_MR1_IST | EMAC4_MR1_TR |
+static u32 __emac4_calc_base_mr1(struct emac_instance *dev, int tx_size, int rx_size) {
+	u32 ret = EMAC_MR1_VLE| EMAC_MR1_IST| EMAC4_MR1_TR| 	// EMAC_MR1_APP |  (ECO)
 		EMAC4_MR1_OBCI(dev->opb_bus_freq / 1000000);
 
 	DBG2(dev, "__emac4_calc_base_mr1" NL);
-
 	switch(tx_size) {
-	case 16384:
-		ret |= EMAC4_MR1_TFS_16K;
-		break;
-	case 4096:
-		ret |= EMAC4_MR1_TFS_4K;
-		break;
-	case 2048:
-		ret |= EMAC4_MR1_TFS_2K;
-		break;
-	default:
-		printk(KERN_WARNING "%s: Unknown Tx FIFO size %d\n",
-		       dev->ndev->name, tx_size);
+		case 16384:	ret |= EMAC4_MR1_TFS_16K; break;
+		case 8192:	ret |= EMAC4_MR1_TFS_8K; break;
+		case 4096:	ret |= EMAC4_MR1_TFS_4K; break;
+		case 2048:	ret |= EMAC4_MR1_TFS_2K; break;
+		default:
+			printk(KERN_WARNING "%s: Unknown Tx FIFO size %d\n", dev->ndev->name, tx_size);
 	}
 
 	switch(rx_size) {
-	case 16384:
-		ret |= EMAC4_MR1_RFS_16K;
-		break;
-	case 4096:
-		ret |= EMAC4_MR1_RFS_4K;
-		break;
-	case 2048:
-		ret |= EMAC4_MR1_RFS_2K;
-		break;
-	default:
-		printk(KERN_WARNING "%s: Unknown Rx FIFO size %d\n",
-		       dev->ndev->name, rx_size);
+		case 16384:	ret |= EMAC4_MR1_RFS_16K; break;
+		case 8192:	ret |= EMAC4_MR1_RFS_8K; break;
+		case 4096:	ret |= EMAC4_MR1_RFS_4K; break;
+		case 2048:	ret |= EMAC4_MR1_RFS_2K; break;
+		default:
+			printk(KERN_WARNING "%s: Unknown Rx FIFO size %d\n", dev->ndev->name, rx_size);
 	}
-
 	return ret;
 }
 
-static u32 emac_calc_base_mr1(struct emac_instance *dev, int tx_size, int rx_size)
-{
+static inline u32 emac_calc_base_mr1(struct emac_instance *dev, int tx_size, int rx_size) {
 	return emac_has_feature(dev, EMAC_FTR_EMAC4) ?
 		__emac4_calc_base_mr1(dev, tx_size, rx_size) :
 		__emac_calc_base_mr1(dev, tx_size, rx_size);
 }
 
-static inline u32 emac_calc_trtr(struct emac_instance *dev, unsigned int size)
-{
-	if (emac_has_feature(dev, EMAC_FTR_EMAC4))
-		return ((size >> 6) - 1) << EMAC_TRTR_SHIFT_EMAC4;
-	else
-		return ((size >> 6) - 1) << EMAC_TRTR_SHIFT;
+static inline u32 emac_calc_trtr(struct emac_instance *dev, unsigned int size) {
+	return (likely(emac_has_feature(dev, EMAC_FTR_EMAC4))) ? 
+		((size >> 6) -1) << EMAC_TRTR_SHIFT_EMAC4 : ((size >> 6) -1) << EMAC_TRTR_SHIFT;
 }
 
-static inline u32 emac_calc_rwmr(struct emac_instance *dev,
-				 unsigned int low, unsigned int high)
-{
-	if (emac_has_feature(dev, EMAC_FTR_EMAC4))
-		return (low << 22) | ( (high & 0x3ff) << 6);
-	else
-		return (low << 23) | ( (high & 0x1ff) << 7);
+static inline u32 emac_calc_rwmr(struct emac_instance *dev, u32 low, u32 high) {
+	return (likely(emac_has_feature(dev, EMAC_FTR_EMAC4))) ? 
+		(low << 22) | ( (high & 0x3ff) << 6) : (low << 23) | ( (high & 0x1ff) << 7);
 }
 
-static int emac_configure(struct emac_instance *dev)
-{
+static int emac_configure(struct emac_instance *dev) {
 	struct emac_regs __iomem *p = dev->emacp;
 	struct net_device *ndev = dev->ndev;
 	int tx_size, rx_size, link = netif_carrier_ok(dev->ndev);
@@ -579,14 +527,11 @@
 	DBG(dev, "configure" NL);
 
 	if (!link) {
-		out_be32(&p->mr1, in_be32(&p->mr1)
-			 | EMAC_MR1_FDE | EMAC_MR1_ILE);
+		out_be32(&p->mr1, in_be32(&p->mr1) | EMAC_MR1_FDE | EMAC_MR1_ILE);
 		udelay(100);
-	} else if (emac_reset(dev) < 0)
-		return -ETIMEDOUT;
+	} else if (emac_reset(dev) < 0)	return -ETIMEDOUT;
 
-	if (emac_has_feature(dev, EMAC_FTR_HAS_TAH))
-		tah_reset(dev->tah_dev);
+	if (emac_has_feature(dev, EMAC_FTR_HAS_TAH)) tah_reset(dev->tah_dev);
 
 	DBG(dev, " link = %d duplex = %d, pause = %d, asym_pause = %d\n",
 	    link, dev->phy.duplex, dev->phy.pause, dev->phy.asym_pause);
@@ -596,12 +541,15 @@
 	rx_size = dev->rx_fifo_size;
 
 	/* No link, force loopback */
-	if (!link)
-		mr1 = EMAC_MR1_FDE | EMAC_MR1_ILE;
+	if (!link) mr1 = EMAC_MR1_FDE | EMAC_MR1_ILE;
 
 	/* Check for full duplex */
 	else if (dev->phy.duplex == DUPLEX_FULL)
+#if !defined(CONFIG_IBM_EMAC_MASK_CEXT)
 		mr1 |= EMAC_MR1_FDE | EMAC_MR1_MWSW_001;
+#else
+		mr1 |= EMAC_MR1_FDE;
+#endif
 
 	/* Adjust fifo sizes, mr1 and timeouts based on link speed */
 	dev->stop_timeout = STOP_TIMEOUT_10;
@@ -624,37 +572,29 @@
 		rx_size = dev->rx_fifo_size_gige;
 
 		if (dev->ndev->mtu > ETH_DATA_LEN) {
-			if (emac_has_feature(dev, EMAC_FTR_EMAC4))
-				mr1 |= EMAC4_MR1_JPSM;
-			else
-				mr1 |= EMAC_MR1_JPSM;
+			if (likely(emac_has_feature(dev, EMAC_FTR_EMAC4))) mr1 |= EMAC4_MR1_JPSM;
+			else mr1 |= EMAC_MR1_JPSM;
 			dev->stop_timeout = STOP_TIMEOUT_1000_JUMBO;
-		} else
-			dev->stop_timeout = STOP_TIMEOUT_1000;
+		} else dev->stop_timeout = STOP_TIMEOUT_1000;
 		break;
 	case SPEED_100:
 		mr1 |= EMAC_MR1_MF_100;
 		dev->stop_timeout = STOP_TIMEOUT_100;
 		break;
-	default: /* make gcc happy */
-		break;
+	default: break;
 	}
 
 	if (emac_has_feature(dev, EMAC_FTR_HAS_RGMII))
-		rgmii_set_speed(dev->rgmii_dev, dev->rgmii_port,
-				dev->phy.speed);
+		rgmii_set_speed(dev->rgmii_dev, dev->rgmii_port, dev->phy.speed);
 	if (emac_has_feature(dev, EMAC_FTR_HAS_ZMII))
 		zmii_set_speed(dev->zmii_dev, dev->zmii_port, dev->phy.speed);
 
 	/* on 40x erratum forces us to NOT use integrated flow control,
-	 * let's hope it works on 44x ;)
-	 */
+	 * let's hope it works on 44x ;) */
 	if (!emac_has_feature(dev, EMAC_FTR_NO_FLOW_CONTROL_40x) &&
 	    dev->phy.duplex == DUPLEX_FULL) {
-		if (dev->phy.pause)
-			mr1 |= EMAC_MR1_EIFC | EMAC_MR1_APP;
-		else if (dev->phy.asym_pause)
-			mr1 |= EMAC_MR1_APP;
+		if (dev->phy.pause)	mr1 |= EMAC_MR1_EIFC | EMAC_MR1_APP;
+		else if (dev->phy.asym_pause) mr1 |= EMAC_MR1_APP;
 	}
 
 	/* Add base settings & fifo sizes & program MR1 */
@@ -663,25 +603,22 @@
 
 	/* Set individual MAC address */
 	out_be32(&p->iahr, (ndev->dev_addr[0] << 8) | ndev->dev_addr[1]);
-	out_be32(&p->ialr, (ndev->dev_addr[2] << 24) |
-		 (ndev->dev_addr[3] << 16) | (ndev->dev_addr[4] << 8) |
-		 ndev->dev_addr[5]);
+	out_be32(&p->ialr, (ndev->dev_addr[2] << 24) | (ndev->dev_addr[3] << 16) |
+		 (ndev->dev_addr[4] << 8) | ndev->dev_addr[5]);
 
 	/* VLAN Tag Protocol ID */
 	out_be32(&p->vtpid, 0x8100);
 
 	/* Receive mode register */
 	r = emac_iff2rmr(ndev);
-	if (r & EMAC_RMR_MAE)
-		emac_hash_mc(dev);
+	if (r & EMAC_RMR_MAE) emac_hash_mc(dev);
 	out_be32(&p->rmr, r);
 
 	/* FIFOs thresholds */
 	if (emac_has_feature(dev, EMAC_FTR_EMAC4))
 		r = EMAC4_TMR1((dev->mal_burst_size / dev->fifo_entry_size) + 1,
 			       tx_size / 2 / dev->fifo_entry_size);
-	else
-		r = EMAC_TMR1((dev->mal_burst_size / dev->fifo_entry_size) + 1,
+	else r = EMAC_TMR1((dev->mal_burst_size / dev->fifo_entry_size) + 1,
 			      tx_size / 2 / dev->fifo_entry_size);
 	out_be32(&p->tmr1, r);
 	out_be32(&p->trtr, emac_calc_trtr(dev, tx_size / 2));
@@ -703,8 +640,7 @@
 	   3187 bytes
 
 	   I chose to set high-water mark to RX_FIFO_SIZE / 4 (1024 bytes)
-	   low-water mark  to RX_FIFO_SIZE / 8 (512 bytes)
-	 */
+	   low-water mark  to RX_FIFO_SIZE / 8 (512 bytes) */
 	r = emac_calc_rwmr(dev, rx_size / 8 / dev->fifo_entry_size,
 			   rx_size / 4 / dev->fifo_entry_size);
 	out_be32(&p->rwmr, r);
@@ -717,23 +653,18 @@
 		EMAC_ISR_ALE | EMAC_ISR_BFCS | EMAC_ISR_PTLE | EMAC_ISR_ORE |
 		EMAC_ISR_IRE | EMAC_ISR_TE;
 	if (emac_has_feature(dev, EMAC_FTR_EMAC4))
-	    r |= EMAC4_ISR_TXPE | EMAC4_ISR_RXPE /* | EMAC4_ISR_TXUE |
-						  EMAC4_ISR_RXOE | */;
+	    r |= EMAC4_ISR_TXPE | EMAC4_ISR_RXPE /* | EMAC4_ISR_TXUE | EMAC4_ISR_RXOE | */;
 	out_be32(&p->iser,  r);
 
 	/* We need to take GPCS PHY out of isolate mode after EMAC reset */
 	if (emac_phy_gpcs(dev->phy.mode)) {
-		if (dev->phy.gpcs_address != 0xffffffff)
-			emac_mii_reset_gpcs(&dev->phy);
-		else
-			emac_mii_reset_phy(&dev->phy);
+		if (dev->phy.gpcs_address != 0xffffffff) emac_mii_reset_gpcs(&dev->phy);
+		else emac_mii_reset_phy(&dev->phy);
 	}
-
 	return 0;
 }
 
-static void emac_reinitialize(struct emac_instance *dev)
-{
+static void emac_reinitialize(struct emac_instance *dev) {
 	DBG(dev, "reinitialize" NL);
 
 	emac_netif_stop(dev);
@@ -744,8 +675,7 @@
 	emac_netif_start(dev);
 }
 
-static void emac_full_tx_reset(struct emac_instance *dev)
-{
+static void emac_full_tx_reset(struct emac_instance *dev) {
 	DBG(dev, "full_tx_reset" NL);
 
 	emac_tx_disable(dev);
@@ -760,12 +690,10 @@
 	emac_rx_enable(dev);
 }
 
-static void emac_reset_work(struct work_struct *work)
-{
+static void emac_reset_work(struct work_struct *work) {
 	struct emac_instance *dev = container_of(work, struct emac_instance, reset_work);
 
 	DBG(dev, "reset_work" NL);
-
 	mutex_lock(&dev->link_lock);
 	if (dev->opened) {
 		emac_netif_stop(dev);
@@ -775,41 +703,29 @@
 	mutex_unlock(&dev->link_lock);
 }
 
-static void emac_tx_timeout(struct net_device *ndev)
-{
+/* Respond to a TX hang */
+static void emac_tx_timeout(struct net_device *ndev) {
 	struct emac_instance *dev = netdev_priv(ndev);
-
 	DBG(dev, "tx_timeout" NL);
-
 	schedule_work(&dev->reset_work);
 }
 
 
-static inline int emac_phy_done(struct emac_instance *dev, u32 stacr)
-{
+static inline int emac_phy_done(struct emac_instance *dev, u32 stacr) {
 	int done = !!(stacr & EMAC_STACR_OC);
-
-	if (emac_has_feature(dev, EMAC_FTR_STACR_OC_INVERT))
-		done = !done;
-
+	if (likely(emac_has_feature(dev, EMAC_FTR_STACR_OC_INVERT))) done = !done;
 	return done;
 };
 
-static int __emac_mdio_read(struct emac_instance *dev, u8 id, u8 reg)
-{
+static inline int __emac_mdio_read(struct emac_instance *dev, u8 id, u8 reg) {
 	struct emac_regs __iomem *p = dev->emacp;
 	u32 r = 0;
 	int n, err = -ETIMEDOUT;
 
 	mutex_lock(&dev->mdio_lock);
-
 	DBG2(dev, "mdio_read(%02x,%02x)" NL, id, reg);
 
-	/* Enable proper MDIO port */
-	if (emac_has_feature(dev, EMAC_FTR_HAS_ZMII))
-		zmii_get_mdio(dev->zmii_dev, dev->zmii_port);
-	if (emac_has_feature(dev, EMAC_FTR_HAS_RGMII))
-		rgmii_get_mdio(dev->rgmii_dev, dev->rgmii_port);
+	MDIO(get, dev);		/* Enable proper MDIO port */
 
 	/* Wait for management interface to become idle */
 	n = 20;
@@ -822,18 +738,13 @@
 	}
 
 	/* Issue read command */
-	if (emac_has_feature(dev, EMAC_FTR_EMAC4))
-		r = EMAC4_STACR_BASE(dev->opb_bus_freq);
-	else
-		r = EMAC_STACR_BASE(dev->opb_bus_freq);
-	if (emac_has_feature(dev, EMAC_FTR_STACR_OC_INVERT))
-		r |= EMAC_STACR_OC;
-	if (emac_has_feature(dev, EMAC_FTR_HAS_NEW_STACR))
-		r |= EMACX_STACR_STAC_READ;
-	else
-		r |= EMAC_STACR_STAC_READ;
-	r |= (reg & EMAC_STACR_PRA_MASK)
-		| ((id & EMAC_STACR_PCDA_MASK) << EMAC_STACR_PCDA_SHIFT);
+	if (likely(emac_has_feature(dev, EMAC_FTR_EMAC4))) r = EMAC4_STACR_BASE(dev->opb_bus_freq);
+	else r = EMAC_STACR_BASE(dev->opb_bus_freq);
+
+	if (likely(emac_has_feature(dev, EMAC_FTR_STACR_OC_INVERT))) r |= EMAC_STACR_OC;
+	if (likely(emac_has_feature(dev, EMAC_FTR_HAS_NEW_STACR))) r |= EMACX_STACR_STAC_READ;
+	else r |= EMAC_STACR_STAC_READ;
+	r |= (reg & EMAC_STACR_PRA_MASK) | ((id & EMAC_STACR_PCDA_MASK) << EMAC_STACR_PCDA_SHIFT);
 	out_be32(&p->stacr, r);
 
 	/* Wait for read to complete */
@@ -857,31 +768,19 @@
 	DBG2(dev, "mdio_read -> %04x" NL, r);
 	err = 0;
  bail:
-	if (emac_has_feature(dev, EMAC_FTR_HAS_RGMII))
-		rgmii_put_mdio(dev->rgmii_dev, dev->rgmii_port);
-	if (emac_has_feature(dev, EMAC_FTR_HAS_ZMII))
-		zmii_put_mdio(dev->zmii_dev, dev->zmii_port);
+	MDIO(put, dev);
 	mutex_unlock(&dev->mdio_lock);
-
 	return err == 0 ? r : err;
 }
 
-static void __emac_mdio_write(struct emac_instance *dev, u8 id, u8 reg,
-			      u16 val)
-{
+static inline void __emac_mdio_write(struct emac_instance *dev, u8 id, u8 reg, u16 val) {
 	struct emac_regs __iomem *p = dev->emacp;
-	u32 r = 0;
+	register u32 r = 0;
 	int n, err = -ETIMEDOUT;
 
 	mutex_lock(&dev->mdio_lock);
-
 	DBG2(dev, "mdio_write(%02x,%02x,%04x)" NL, id, reg, val);
-
-	/* Enable proper MDIO port */
-	if (emac_has_feature(dev, EMAC_FTR_HAS_ZMII))
-		zmii_get_mdio(dev->zmii_dev, dev->zmii_port);
-	if (emac_has_feature(dev, EMAC_FTR_HAS_RGMII))
-		rgmii_get_mdio(dev->rgmii_dev, dev->rgmii_port);
+	MDIO(get, dev);		/* Enable proper MDIO port */
 
 	/* Wait for management interface to be idle */
 	n = 20;
@@ -894,19 +793,13 @@
 	}
 
 	/* Issue write command */
-	if (emac_has_feature(dev, EMAC_FTR_EMAC4))
-		r = EMAC4_STACR_BASE(dev->opb_bus_freq);
-	else
-		r = EMAC_STACR_BASE(dev->opb_bus_freq);
-	if (emac_has_feature(dev, EMAC_FTR_STACR_OC_INVERT))
-		r |= EMAC_STACR_OC;
-	if (emac_has_feature(dev, EMAC_FTR_HAS_NEW_STACR))
-		r |= EMACX_STACR_STAC_WRITE;
-	else
-		r |= EMAC_STACR_STAC_WRITE;
-	r |= (reg & EMAC_STACR_PRA_MASK) |
-		((id & EMAC_STACR_PCDA_MASK) << EMAC_STACR_PCDA_SHIFT) |
-		(val << EMAC_STACR_PHYD_SHIFT);
+	if (likely(emac_has_feature(dev, EMAC_FTR_EMAC4))) r = EMAC4_STACR_BASE(dev->opb_bus_freq);
+	else r = EMAC_STACR_BASE(dev->opb_bus_freq);
+	if (likely(emac_has_feature(dev, EMAC_FTR_STACR_OC_INVERT))) r |= EMAC_STACR_OC;
+	if (likely(emac_has_feature(dev, EMAC_FTR_HAS_NEW_STACR))) r |= EMACX_STACR_STAC_WRITE;
+	else r |= EMAC_STACR_STAC_WRITE;
+	r |= (reg & EMAC_STACR_PRA_MASK) | ((id & EMAC_STACR_PCDA_MASK) 
+		<< EMAC_STACR_PCDA_SHIFT) |	(val << EMAC_STACR_PHYD_SHIFT);
 	out_be32(&p->stacr, r);
 
 	/* Wait for write to complete */
@@ -920,38 +813,24 @@
 	}
 	err = 0;
  bail:
-	if (emac_has_feature(dev, EMAC_FTR_HAS_RGMII))
-		rgmii_put_mdio(dev->rgmii_dev, dev->rgmii_port);
-	if (emac_has_feature(dev, EMAC_FTR_HAS_ZMII))
-		zmii_put_mdio(dev->zmii_dev, dev->zmii_port);
+	MDIO (put, dev);
 	mutex_unlock(&dev->mdio_lock);
 }
 
-static int emac_mdio_read(struct net_device *ndev, int id, int reg)
-{
+static int emac_mdio_read(struct net_device *ndev, int id, int reg) {
 	struct emac_instance *dev = netdev_priv(ndev);
-	int res;
-
-	res = __emac_mdio_read((dev->mdio_instance &&
-				dev->phy.gpcs_address != id) ?
-				dev->mdio_instance : dev,
-			       (u8) id, (u8) reg);
-	return res;
+	return __emac_mdio_read((dev->mdio_instance && dev->phy.gpcs_address != id) ?
+				dev->mdio_instance : dev, (u8) id, (u8) reg);
 }
 
-static void emac_mdio_write(struct net_device *ndev, int id, int reg, int val)
-{
+static void emac_mdio_write(struct net_device *ndev, int id, int reg, int val) {
 	struct emac_instance *dev = netdev_priv(ndev);
-
-	__emac_mdio_write((dev->mdio_instance &&
-			   dev->phy.gpcs_address != id) ?
-			   dev->mdio_instance : dev,
-			  (u8) id, (u8) reg, (u16) val);
+	__emac_mdio_write((dev->mdio_instance && dev->phy.gpcs_address != id) ?
+			   dev->mdio_instance : dev, (u8) id, (u8) reg, (u16) val);
 }
 
 /* Tx lock BH */
-static void __emac_set_multicast_list(struct emac_instance *dev)
-{
+static void __emac_set_multicast_list(struct emac_instance *dev) {
 	struct emac_regs __iomem *p = dev->emacp;
 	u32 rmr = emac_iff2rmr(dev->ndev);
 
@@ -976,64 +855,50 @@
 	 */
 	dev->mcast_pending = 0;
 	emac_rx_disable(dev);
-	if (rmr & EMAC_RMR_MAE)
-		emac_hash_mc(dev);
+	if (rmr & EMAC_RMR_MAE)	emac_hash_mc(dev);
 	out_be32(&p->rmr, rmr);
 	emac_rx_enable(dev);
 }
 
 /* Tx lock BH */
-static void emac_set_multicast_list(struct net_device *ndev)
-{
+static void emac_set_multicast_list(struct net_device *ndev) {
 	struct emac_instance *dev = netdev_priv(ndev);
 
 	DBG(dev, "multicast" NL);
-
 	BUG_ON(!netif_running(dev->ndev));
 
 	if (dev->no_mcast) {
 		dev->mcast_pending = 1;
 		return;
 	}
-
 	mutex_lock(&dev->link_lock);
 	__emac_set_multicast_list(dev);
 	mutex_unlock(&dev->link_lock);
 }
 
-static int emac_set_mac_address(struct net_device *ndev, void *sa)
-{
+static int emac_set_mac_address(struct net_device *ndev, void *sa) {
 	struct emac_instance *dev = netdev_priv(ndev);
 	struct sockaddr *addr = sa;
 	struct emac_regs __iomem *p = dev->emacp;
 
-	if (!is_valid_ether_addr(addr->sa_data))
-	       return -EADDRNOTAVAIL;
-
+	if (!is_valid_ether_addr(addr->sa_data)) return -EADDRNOTAVAIL;
 	mutex_lock(&dev->link_lock);
-
 	memcpy(ndev->dev_addr, addr->sa_data, ndev->addr_len);
-
 	emac_rx_disable(dev);
 	emac_tx_disable(dev);
 	out_be32(&p->iahr, (ndev->dev_addr[0] << 8) | ndev->dev_addr[1]);
 	out_be32(&p->ialr, (ndev->dev_addr[2] << 24) |
-		(ndev->dev_addr[3] << 16) | (ndev->dev_addr[4] << 8) |
-		ndev->dev_addr[5]);
+		(ndev->dev_addr[3] << 16) | (ndev->dev_addr[4] << 8) | ndev->dev_addr[5]);
 	emac_tx_enable(dev);
 	emac_rx_enable(dev);
-
 	mutex_unlock(&dev->link_lock);
-
 	return 0;
 }
 
-static int emac_resize_rx_ring(struct emac_instance *dev, int new_mtu)
-{
+static int emac_resize_rx_ring(struct emac_instance *dev, int new_mtu) {
 	int rx_sync_size = emac_rx_sync_size(new_mtu);
 	int rx_skb_size = emac_rx_skb_size(new_mtu);
-	int i, ret = 0;
-	int mr1_jumbo_bit_change = 0;
+	int i, ret = 0, mr1_jumbo_bit_change = 0;
 
 	mutex_lock(&dev->link_lock);
 	emac_netif_stop(dev);
@@ -1048,20 +913,18 @@
 
 	/* Make a first pass over RX ring and mark BDs ready, dropping
 	 * non-processed packets on the way. We need this as a separate pass
-	 * to simplify error recovery in the case of allocation failure later.
-	 */
+	 * to simplify error recovery in the case of allocation failure later */
 	for (i = 0; i < NUM_RX_BUFF; ++i) {
-		if (dev->rx_desc[i].ctrl & MAL_RX_CTRL_FIRST)
-			++dev->estats.rx_dropped_resize;
-
+		if (dev->rx_desc[i].ctrl & MAL_RX_CTRL_FIRST) ++dev->estats.rx_dropped_resize;
 		dev->rx_desc[i].data_len = 0;
-		dev->rx_desc[i].ctrl = MAL_RX_CTRL_EMPTY |
-		    (i == (NUM_RX_BUFF - 1) ? MAL_RX_CTRL_WRAP : 0);
+		dev->rx_desc[i].ctrl = MAL_RX_CTRL_EMPTY | MAL_RX_CTRL_INTR |
+			(i == (NUM_RX_BUFF - 1) ? MAL_RX_CTRL_WRAP : 0);  //ECO
 	}
 
 	/* Reallocate RX ring only if bigger skb buffers are required */
-	if (rx_skb_size <= dev->rx_skb_size)
-		goto skip;
+	DBG(dev, "New rx_skb_size = %d" NL, rx_skb_size);
+	DBG(dev, "Current rx_skb_size = %d" NL, dev->rx_skb_size);
+	if (rx_skb_size <= dev->rx_skb_size) goto skip;
 
 	/* Second pass, allocate new skbs */
 	for (i = 0; i < NUM_RX_BUFF; ++i) {
@@ -1076,18 +939,15 @@
 
 		skb_reserve(skb, EMAC_RX_SKB_HEADROOM + 2);
 		dev->rx_desc[i].data_ptr =
-		    dma_map_single(&dev->ofdev->dev, skb->data - 2, rx_sync_size,
-				   DMA_FROM_DEVICE) + 2;
+		    dma_map_single(&dev->ofdev->dev, skb->data - 2, rx_sync_size, DMA_FROM_DEVICE) + 2;
 		dev->rx_skb[i] = skb;
 	}
  skip:
 	/* Check if we need to change "Jumbo" bit in MR1 */
 	if (emac_has_feature(dev, EMAC_APM821XX_REQ_JUMBO_FRAME_SIZE)) {
-		mr1_jumbo_bit_change = (new_mtu > ETH_DATA_LEN) ||
-				(dev->ndev->mtu > ETH_DATA_LEN);
+		mr1_jumbo_bit_change = (new_mtu > ETH_DATA_LEN) || (dev->ndev->mtu > ETH_DATA_LEN);
 	} else {
-		mr1_jumbo_bit_change = (new_mtu > ETH_DATA_LEN) ^
-				(dev->ndev->mtu > ETH_DATA_LEN);
+		mr1_jumbo_bit_change = (new_mtu > ETH_DATA_LEN) ^ (dev->ndev->mtu > ETH_DATA_LEN);
 	}
 
 	if (mr1_jumbo_bit_change) {
@@ -1112,53 +972,65 @@
 }
 
 /* Process ctx, rtnl_lock semaphore */
-static int emac_change_mtu(struct net_device *ndev, int new_mtu)
-{
+static int emac_change_mtu(struct net_device *ndev, int new_mtu) {
 	struct emac_instance *dev = netdev_priv(ndev);
 	int ret = 0;
 
-	if (new_mtu < EMAC_MIN_MTU || new_mtu > dev->max_mtu)
-		return -EINVAL;
-
+	if (new_mtu < EMAC_MIN_MTU || new_mtu > dev->max_mtu) return -EINVAL;
 	DBG(dev, "change_mtu(%d)" NL, new_mtu);
-
 	if (netif_running(ndev)) {
 		/* Check if we really need to reinitialize RX ring */
 		if (emac_rx_skb_size(ndev->mtu) != emac_rx_skb_size(new_mtu))
 			ret = emac_resize_rx_ring(dev, new_mtu);
 	}
-
 	if (!ret) {
+#if defined(CONFIG_IBM_EMAC_TAH) && defined(EMAC_HW_TSO)  //ECO
+		//if (emac_has_feature(dev, EMAC_FTR_HAS_TAH)) {
+		struct tah_instance *tdev;
+		int i, adj_val = 0;
+		u32 ssr_def[TAH_NO_SSR];
+		switch (new_mtu) {
+			case 9000:	memcpy(ssr_def, (u32[])TAH_SS_DEFAULT_9K, sizeof ssr_def); break;
+			case 4080:	memcpy(ssr_def, (u32[])TAH_SS_DEFAULT_4K, sizeof ssr_def); break;
+			default:	memcpy(ssr_def, (u32[])TAH_SS_DEFAULT, sizeof ssr_def); break;
+		}
+		tdev = dev_get_drvdata(&dev->tah_dev->dev);
+		if (new_mtu > ssr_def[0]) {	/* add the current MTU if not 9000, 4080 or 1500 */
+			tah_set_ssr(dev->tah_dev, 0, new_mtu);
+			adj_val = 1;	/* update the adjustment var */
+		}
+		for (i = adj_val; i < TAH_NO_SSR; i++) {	/* don't allow values to exceed new MTU */
+			  if (ssr_def[i-adj_val] > new_mtu) tah_set_ssr(dev->tah_dev, i, new_mtu);					
+			  else tah_set_ssr(dev->tah_dev, i,	ssr_def[i-adj_val]);
+
+		}
+		//}
+#endif
 		ndev->mtu = new_mtu;
 		dev->rx_skb_size = emac_rx_skb_size(new_mtu);
 		dev->rx_sync_size = emac_rx_sync_size(new_mtu);
 	}
-
 	return ret;
 }
 
-static void emac_clean_tx_ring(struct emac_instance *dev)
-{
+static __always_inline void emac_clean_tx_ring(struct emac_instance *dev) {
 	int i;
 
 	for (i = 0; i < NUM_TX_BUFF; ++i) {
-		if (dev->tx_skb[i]) {
+		if (likely(dev->tx_skb[i])) {
 			dev_kfree_skb(dev->tx_skb[i]);
 			dev->tx_skb[i] = NULL;
-			if (dev->tx_desc[i].ctrl & MAL_TX_CTRL_READY)
-				++dev->estats.tx_dropped;
+			if (dev->tx_desc[i].ctrl & MAL_TX_CTRL_READY) ++dev->estats.tx_dropped;
 		}
-		dev->tx_desc[i].ctrl = 0;
-		dev->tx_desc[i].data_ptr = 0;
+		dev->tx_desc[i].ctrl = dev->tx_desc[i].data_ptr = 0;
 	}
 }
 
-static void emac_clean_rx_ring(struct emac_instance *dev)
-{
-	int i;
+static __always_inline void emac_clean_rx_ring(struct emac_instance *dev) {
+	register int i;
 
 	for (i = 0; i < NUM_RX_BUFF; ++i)
-		if (dev->rx_skb[i]) {
+		if (likely(dev->rx_skb[i])) {
 			dev->rx_desc[i].ctrl = 0;
 			dev_kfree_skb(dev->rx_skb[i]);
 			dev->rx_skb[i] = NULL;
@@ -1171,60 +1043,56 @@
 	}
 }
 
-static inline int emac_alloc_rx_skb(struct emac_instance *dev, int slot,
-				    gfp_t flags)
-{
+static inline int emac_alloc_rx_skb(struct emac_instance *dev, int slot, gfp_t flags) {
 	struct sk_buff *skb = alloc_skb(dev->rx_skb_size, flags);
-	if (unlikely(!skb))
-		return -ENOMEM;
+	if (unlikely(!skb))	return -ENOMEM;
 
 	dev->rx_skb[slot] = skb;
 	dev->rx_desc[slot].data_len = 0;
 
 	skb_reserve(skb, EMAC_RX_SKB_HEADROOM + 2);
 	dev->rx_desc[slot].data_ptr =
-	    dma_map_single(&dev->ofdev->dev, skb->data - 2, dev->rx_sync_size,
-			   DMA_FROM_DEVICE) + 2;
+	    dma_map_single(&dev->ofdev->dev, skb->data - 2, dev->rx_sync_size, DMA_FROM_DEVICE) + 2;
 	wmb();
-	dev->rx_desc[slot].ctrl = MAL_RX_CTRL_EMPTY |
-	    (slot == (NUM_RX_BUFF - 1) ? MAL_RX_CTRL_WRAP : 0);
+	dev->rx_desc[slot].ctrl = MAL_RX_CTRL_EMPTY | MAL_RX_CTRL_INTR |
+	    (slot == (NUM_RX_BUFF - 1) ? MAL_RX_CTRL_WRAP : 0);  //ECO
 
 	return 0;
 }
 
-static void emac_print_link_status(struct emac_instance *dev)
-{
+static void emac_print_link_status(struct emac_instance *dev) {
 	if (netif_carrier_ok(dev->ndev))
-		printk(KERN_INFO "%s: link is up, %d %s%s\n",
-		       dev->ndev->name, dev->phy.speed,
-		       dev->phy.duplex == DUPLEX_FULL ? "FDX" : "HDX",
-		       dev->phy.pause ? ", pause enabled" :
-		       dev->phy.asym_pause ? ", asymmetric pause enabled" : "");
-	else
-		printk(KERN_INFO "%s: link is down\n", dev->ndev->name);
+		printk(KERN_INFO "%s: link is up, %d %s%s\n", dev->ndev->name, dev->phy.speed,
+			dev->phy.duplex == DUPLEX_FULL ? "FDX" : "HDX",
+		    dev->phy.pause ? ", pause enabled" : dev->phy.asym_pause ? ", asymmetric pause enabled" : "");
+	else printk(KERN_INFO "%s: link is down\n", dev->ndev->name);
 }
 
-/* Process ctx, rtnl_lock semaphore */
-static int emac_open(struct net_device *ndev)
-{
+/* Called when the network interface is made active: Process ctx, rtnl_lock semaphore */
+static int emac_open(struct net_device *ndev) {
 	struct emac_instance *dev = netdev_priv(ndev);
 	int err, i;
 
 	DBG(dev, "open" NL);
 
-	/* Setup error IRQ handler */
-	err = request_irq(dev->emac_irq, emac_irq, 0, "EMAC", dev);
+	err = request_irq(dev->emac_irq, emac_irq, 0, "EMAC", dev); // Setup error IRQ handler
 	if (err) {
-		printk(KERN_ERR "%s: failed to request IRQ %d\n",
-		       ndev->name, dev->emac_irq);
+		printk(KERN_ERR "%s: failed to request IRQ %d\n", ndev->name, dev->emac_irq);
 		return err;
 	}
 
+	if (dev->wol_irq != NO_IRQ) { 	// Setup WOL IRQ handler
+		err = request_irq(dev->wol_irq, wol_irq, 0, "EMAC WOL", dev);
+		if (err) {
+			printk(KERN_ERR "%s: failed to request IRQ %d\n", ndev->name, dev->wol_irq);
+			return err;
+		}
+	}
+
 	/* Allocate RX ring */
 	for (i = 0; i < NUM_RX_BUFF; ++i)
-		if (emac_alloc_rx_skb(dev, i, GFP_KERNEL)) {
-			printk(KERN_ERR "%s: failed to allocate RX ring\n",
-			       ndev->name);
+		if (unlikely(emac_alloc_rx_skb(dev, i, GFP_KERNEL))) {
+			printk(KERN_ERR "%s: failed to allocate RX ring\n", ndev->name);
 			goto oom;
 		}
 
@@ -1235,8 +1103,7 @@
 	mutex_lock(&dev->link_lock);
 	dev->opened = 1;
 
-	/* Start PHY polling now.
-	 */
+	/* Start PHY polling now */
 	if (dev->phy.address >= 0) {
 		int link_poll_interval;
 		if (dev->phy.def->ops->poll_link(&dev->phy)) {
@@ -1259,6 +1126,7 @@
 	/* Required for Pause packet support in EMAC */
 	dev_mc_add_global(ndev, default_mcast_addr);
 
+	//local_irq_save(flags);	/* disable interrupts ECO */
 	emac_configure(dev);
 	mal_poll_add(dev->mal, &dev->commac);
 	mal_enable_tx_channel(dev->mal, dev->mal_tx_chan);
@@ -1266,6 +1134,8 @@
 	mal_enable_rx_channel(dev->mal, dev->mal_rx_chan);
 	emac_tx_enable(dev);
 	emac_rx_enable(dev);
+	//local_irq_restore(flags);
+
 	emac_netif_start(dev);
 
 	mutex_unlock(&dev->link_lock);
@@ -1274,55 +1144,42 @@
  oom:
 	emac_clean_rx_ring(dev);
 	free_irq(dev->emac_irq, dev);
+	if (dev->wol_irq != NO_IRQ) free_irq(dev->wol_irq, dev);
 
 	return -ENOMEM;
 }
 
 /* BHs disabled */
 #if 0
-static int emac_link_differs(struct emac_instance *dev)
-{
+static int emac_link_differs(struct emac_instance *dev) {
 	u32 r = in_be32(&dev->emacp->mr1);
 
 	int duplex = r & EMAC_MR1_FDE ? DUPLEX_FULL : DUPLEX_HALF;
 	int speed, pause, asym_pause;
 
-	if (r & EMAC_MR1_MF_1000)
-		speed = SPEED_1000;
-	else if (r & EMAC_MR1_MF_100)
-		speed = SPEED_100;
-	else
-		speed = SPEED_10;
+	if (r & EMAC_MR1_MF_1000) speed = SPEED_1000;
+	else if (r & EMAC_MR1_MF_100) speed = SPEED_100;
+	else speed = SPEED_10;
 
 	switch (r & (EMAC_MR1_EIFC | EMAC_MR1_APP)) {
-	case (EMAC_MR1_EIFC | EMAC_MR1_APP):
-		pause = 1;
-		asym_pause = 0;
-		break;
-	case EMAC_MR1_APP:
-		pause = 0;
-		asym_pause = 1;
-		break;
-	default:
-		pause = asym_pause = 0;
+	case (EMAC_MR1_EIFC | EMAC_MR1_APP):	pause = 1; asym_pause = 0; break;
+	case EMAC_MR1_APP:			pause = 0; asym_pause = 1; break;
+	default:				pause = asym_pause = 0;
 	}
 	return speed != dev->phy.speed || duplex != dev->phy.duplex ||
 	    pause != dev->phy.pause || asym_pause != dev->phy.asym_pause;
 }
 #endif
 
-static void emac_link_timer(struct work_struct *work)
-{
+static void emac_link_timer(struct work_struct *work) {
 	struct emac_instance *dev =
-		container_of(to_delayed_work(work),
-			     struct emac_instance, link_work);
+		container_of(to_delayed_work(work), struct emac_instance, link_work);
 	int link_poll_interval;
 
 	mutex_lock(&dev->link_lock);
 	DBG2(dev, "link timer" NL);
 
-	if (!dev->opened)
-		goto bail;
+	if (!dev->opened) goto bail;
 
 	if (dev->phy.def->ops->poll_link(&dev->phy)) {
 		if (!netif_carrier_ok(dev->ndev)) {
@@ -1352,8 +1209,7 @@
 	mutex_unlock(&dev->link_lock);
 }
 
-static void emac_force_link_update(struct emac_instance *dev)
-{
+static void emac_force_link_update(struct emac_instance *dev) {
 	netif_carrier_off(dev->ndev);
 	smp_rmb();
 	if (dev->link_polling) {
@@ -1363,9 +1219,8 @@
 	}
 }
 
-/* Process ctx, rtnl_lock semaphore */
-static int emac_close(struct net_device *ndev)
-{
+/* Called when the network interface is disabled: Process ctx, rtnl_lock semaphore */
+static int emac_close(struct net_device *ndev) {
 	struct emac_instance *dev = netdev_priv(ndev);
 
 	DBG(dev, "close" NL);
@@ -1391,35 +1246,54 @@
 	free_irq(dev->emac_irq, dev);
 
 	netif_carrier_off(ndev);
+	if (dev->wol_irq != NO_IRQ)	free_irq(dev->wol_irq, dev);
 
 	return 0;
 }
 
-static inline u16 emac_tx_csum(struct emac_instance *dev,
-			       struct sk_buff *skb)
-{
-	if (emac_has_feature(dev, EMAC_FTR_HAS_TAH) &&
-		(skb->ip_summed == CHECKSUM_PARTIAL)) {
+static inline u16 emac_tx_csum(struct emac_instance *dev, struct sk_buff *skb) {
+	if (skb->ip_summed == CHECKSUM_PARTIAL) {
 		++dev->stats.tx_packets_csum;
+
+#if defined(CONFIG_IBM_EMAC_TAH) && defined(EMAC_HW_TSO)  //ECO
+#define SKB_GSO_TYPE(skb)	(skb_shinfo(skb)->gso_type)
+		// Only support TSO (TCP segmentation offload) for TCP
+		if (likely(skb_is_gso(skb)) && likely(SKB_GSO_TYPE(skb) & SKB_GSO_TCPV4)) {
+			//|| (SKB_GSO_TYPE(skb) & SKB_GSO_TCPV6)) 
+			//return EMAC_TX_CTRL_TAH_SSR(0);
+			register u32 seg_size, i;
+			//struct tah_instance *tah_dev;
+			//static int first = 0;
+
+			//if (likely(skb->protocol == cpu_to_be16(ETH_P_IP)))	is_tcp = (ip_hdr(skb)->protocol == IPPROTO_TCP);
+			//else if (skb->protocol == cpu_to_be16(ETH_P_IPV6))	is_tcp = (ipv6_hdr(skb)->nexthdr == IPPROTO_TCP);
+			seg_size = skb->len + tcp_hdrlen(skb) + skb_network_header_len(skb);  
+			//tah_dev = dev_get_drvdata(&dev->tah_dev->dev);	// Get the best suitable MTU
+			for (i = 0; i < TAH_NO_SSR; i++) if (dev->ssr[i] <= seg_size) break;
+			//if (first++ & 0x40) printk(KERN_INFO "SSR: index %d, value:%d, segment size:%d, TCP_HDR:%d, NW_HDR:%d\n", 
+			//	i, dev->ssr[i], seg_size, tcp_hdrlen(skb), skb_network_header_len(skb));		
+			/*if (i == TAH_NO_SSR) {
+				printk(KERN_WARNING "No suitable TAH_SSRx for segmentation size %d\n", seg_size);
+				return EMAC_TX_CTRL_TAH_CSUM;  // Avoid using TSO feature in this case
+			}*/
+			return EMAC_TX_CTRL_TAH_SSR(i);
+		}
+#endif
 		return EMAC_TX_CTRL_TAH_CSUM;
 	}
 	return 0;
 }
 
-static inline int emac_xmit_finish(struct emac_instance *dev, int len)
-{
-	struct emac_regs __iomem *p = dev->emacp;
+static inline int emac_xmit_finish(struct emac_instance *dev, int len) {
 	struct net_device *ndev = dev->ndev;
 
 	/* Send the packet out. If the if makes a significant perf
-	 * difference, then we can store the TMR0 value in "dev"
-	 * instead
-	 */
-	if (emac_has_feature(dev, EMAC_FTR_EMAC4))
-		out_be32(&p->tmr0, EMAC4_TMR0_XMIT);
-	else
-		out_be32(&p->tmr0, EMAC_TMR0_XMIT);
-
+	 * difference, then we can store the TMR0 value in "dev" instead */
+#ifdef CONFIG_IBM_EMAC_EMAC4	
+	out_be32(dev->tmr0, EMAC4_TMR0_XMIT);
+#else
+	out_be32(dev->tmr0, EMAC_TMR0_XMIT);
+#endif
 	if (unlikely(++dev->tx_cnt == NUM_TX_BUFF)) {
 		netif_stop_queue(ndev);
 		DBG2(dev, "stopped TX queue" NL);
@@ -1433,48 +1307,45 @@
 }
 
 /* Tx lock BH */
-static int emac_start_xmit(struct sk_buff *skb, struct net_device *ndev)
-{
+static int emac_start_xmit(struct sk_buff *skb, struct net_device *ndev) {
 	struct emac_instance *dev = netdev_priv(ndev);
 	unsigned int len = skb->len;
-	int slot;
+	register int slot = dev->tx_slot++;
 
 	u16 ctrl = EMAC_TX_CTRL_GFCS | EMAC_TX_CTRL_GP | MAL_TX_CTRL_READY |
-	    MAL_TX_CTRL_LAST | emac_tx_csum(dev, skb);
+	    MAL_TX_CTRL_LAST | emac_tx_csum(dev, skb) | MAL_TX_CTRL_INTR;
+#ifdef CONFIG_IBM_EMAC_MASK_CEXT
+	if (atomic_read(&dev->mask_cext_enable))
+		if (atomic_read(&dev->idle_mode)) {
+		    emac_exit_idlemode(dev);
+		    atomic_set(&dev->idle_mode, 0);
+		}
+#endif
 
-	slot = dev->tx_slot++;
 	if (dev->tx_slot == NUM_TX_BUFF) {
 		dev->tx_slot = 0;
 		ctrl |= MAL_TX_CTRL_WRAP;
 	}
-
 	DBG2(dev, "xmit(%u) %d" NL, len, slot);
-
 	dev->tx_skb[slot] = skb;
-	dev->tx_desc[slot].data_ptr = dma_map_single(&dev->ofdev->dev,
-						     skb->data, len,
-						     DMA_TO_DEVICE);
+	// EMAC_DMA_ALIGN(len)?  (ECO)
+	dev->tx_desc[slot].data_ptr = dma_map_single(&dev->ofdev->dev, skb->data, len, DMA_TO_DEVICE);
 	dev->tx_desc[slot].data_len = (u16) len;
 	wmb();
 	dev->tx_desc[slot].ctrl = ctrl;
-
 	return emac_xmit_finish(dev, len);
 }
 
 static inline int emac_xmit_split(struct emac_instance *dev, int slot,
-				  u32 pd, int len, int last, u16 base_ctrl)
-{
+				  u32 pd, int len, int last, u16 base_ctrl) {
 	while (1) {
-		u16 ctrl = base_ctrl;
+		u16 ctrl = base_ctrl | MAL_TX_CTRL_INTR;
 		int chunk = min(len, MAL_MAX_TX_SIZE);
 		len -= chunk;
 
-		slot = (slot + 1) % NUM_TX_BUFF;
-
-		if (last && !len)
-			ctrl |= MAL_TX_CTRL_LAST;
-		if (slot == NUM_TX_BUFF - 1)
-			ctrl |= MAL_TX_CTRL_WRAP;
+		slot = NXT_TX_SLOT(slot);
+		if (last && !len) ctrl |= MAL_TX_CTRL_LAST;
+		if (slot == NUM_TX_BUFF - 1) ctrl |= MAL_TX_CTRL_WRAP;
 
 		dev->tx_skb[slot] = NULL;
 		dev->tx_desc[slot].data_ptr = pd;
@@ -1482,39 +1353,40 @@
 		dev->tx_desc[slot].ctrl = ctrl;
 		++dev->tx_cnt;
 
-		if (!len)
-			break;
-
+		if (!len) break;
 		pd += chunk;
 	}
 	return slot;
 }
 
 /* Tx lock BH disabled (SG version for TAH equipped EMACs) */
-static int emac_start_xmit_sg(struct sk_buff *skb, struct net_device *ndev)
-{
+/* Transmit the packet using specified transmit queue */
+static int emac_start_xmit_sg(struct sk_buff *skb, struct net_device *ndev) {
 	struct emac_instance *dev = netdev_priv(ndev);
 	int nr_frags = skb_shinfo(skb)->nr_frags;
-	int len = skb->len, chunk;
-	int slot, i;
+	int len = skb->len, chunk, slot, i;
 	u16 ctrl;
 	u32 pd;
 
 	/* This is common "fast" path */
-	if (likely(!nr_frags && len <= MAL_MAX_TX_SIZE))
-		return emac_start_xmit(skb, ndev);
+	if (likely(!nr_frags && len <= MAL_MAX_TX_SIZE)) return emac_start_xmit(skb, ndev);
+
+#ifdef CONFIG_IBM_NEW_EMAC_MASK_CEXT
+	if (atomic_read(&dev->mask_cext_enable))
+		if (atomic_read(&dev->idle_mode)) {
+		    emac_exit_idlemode(dev);
+		    atomic_set(&dev->idle_mode, 0);
+		}
+#endif
 
 	len -= skb->data_len;
 
-	/* Note, this is only an *estimation*, we can still run out of empty
-	 * slots because of the additional fragmentation into
-	 * MAL_MAX_TX_SIZE-sized chunks
-	 */
+	/* Note, this is only an *estimation*, we can still run out of empty slots because
+	 * of the additional fragmentation into MAL_MAX_TX_SIZE-sized chunks */
 	if (unlikely(dev->tx_cnt + nr_frags + mal_tx_chunks(len) > NUM_TX_BUFF))
 		goto stop_queue;
 
-	ctrl = EMAC_TX_CTRL_GFCS | EMAC_TX_CTRL_GP | MAL_TX_CTRL_READY |
-	    emac_tx_csum(dev, skb);
+	ctrl = EMAC_TX_CTRL_GFCS| EMAC_TX_CTRL_GP| MAL_TX_CTRL_READY| MAL_TX_CTRL_INTR| emac_tx_csum(dev, skb);
 	slot = dev->tx_slot;
 
 	/* skb data */
@@ -1525,21 +1397,14 @@
 	dev->tx_desc[slot].data_len = (u16) chunk;
 	len -= chunk;
 	if (unlikely(len))
-		slot = emac_xmit_split(dev, slot, pd + chunk, len, !nr_frags,
-				       ctrl);
+		slot = emac_xmit_split(dev, slot, pd + chunk, len, !nr_frags, ctrl);
 	/* skb fragments */
 	for (i = 0; i < nr_frags; ++i) {
 		struct skb_frag_struct *frag = &skb_shinfo(skb)->frags[i];
 		len = skb_frag_size(frag);
-
-		if (unlikely(dev->tx_cnt + mal_tx_chunks(len) >= NUM_TX_BUFF))
-			goto undo_frame;
-
-		pd = skb_frag_dma_map(&dev->ofdev->dev, frag, 0, len,
-				      DMA_TO_DEVICE);
-
-		slot = emac_xmit_split(dev, slot, pd, len, i == nr_frags - 1,
-				       ctrl);
+		if (unlikely(dev->tx_cnt + mal_tx_chunks(len) >= NUM_TX_BUFF)) goto undo_frame;
+		pd = skb_frag_dma_map(&dev->ofdev->dev, frag, 0, len, DMA_TO_DEVICE);
+		slot = emac_xmit_split(dev, slot, pd, len, i == nr_frags - 1, ctrl);
 	}
 
 	DBG2(dev, "xmit_sg(%u) %d - %d" NL, skb->len, dev->tx_slot, slot);
@@ -1548,23 +1413,19 @@
 	dev->tx_skb[slot] = skb;
 
 	/* Send the packet out */
-	if (dev->tx_slot == NUM_TX_BUFF - 1)
-		ctrl |= MAL_TX_CTRL_WRAP;
+	if (unlikely(dev->tx_slot == NUM_TX_BUFF - 1)) ctrl |= MAL_TX_CTRL_WRAP;
 	wmb();
 	dev->tx_desc[dev->tx_slot].ctrl = ctrl;
-	dev->tx_slot = (slot + 1) % NUM_TX_BUFF;
+	dev->tx_slot = NXT_TX_SLOT(slot);
 
 	return emac_xmit_finish(dev, skb->len);
 
  undo_frame:
-	/* Well, too bad. Our previous estimation was overly optimistic.
-	 * Undo everything.
-	 */
+	/* Well, too bad. Our previous estimation was overly optimistic. Undo everything */
 	while (slot != dev->tx_slot) {
-		dev->tx_desc[slot].ctrl = 0;
+		dev->tx_desc[slot].ctrl = 0 | (slot == (NUM_TX_BUFF - 1) ? MAL_TX_CTRL_WRAP : 0);
 		--dev->tx_cnt;
-		if (--slot < 0)
-			slot = NUM_TX_BUFF - 1;
+		if (--slot < 0)	slot = NUM_TX_BUFF - 1;
 	}
 	++dev->estats.tx_undo;
 
@@ -1575,126 +1436,120 @@
 }
 
 /* Tx lock BHs */
-static void emac_parse_tx_error(struct emac_instance *dev, u16 ctrl)
-{
+static void emac_parse_tx_error(struct emac_instance *dev, u16 ctrl) {
 	struct emac_error_stats *st = &dev->estats;
 
 	DBG(dev, "BD TX error %04x" NL, ctrl);
-
 	++st->tx_bd_errors;
-	if (ctrl & EMAC_TX_ST_BFCS)
-		++st->tx_bd_bad_fcs;
-	if (ctrl & EMAC_TX_ST_LCS)
-		++st->tx_bd_carrier_loss;
-	if (ctrl & EMAC_TX_ST_ED)
-		++st->tx_bd_excessive_deferral;
-	if (ctrl & EMAC_TX_ST_EC)
-		++st->tx_bd_excessive_collisions;
-	if (ctrl & EMAC_TX_ST_LC)
-		++st->tx_bd_late_collision;
-	if (ctrl & EMAC_TX_ST_MC)
-		++st->tx_bd_multple_collisions;
-	if (ctrl & EMAC_TX_ST_SC)
-		++st->tx_bd_single_collision;
-	if (ctrl & EMAC_TX_ST_UR)
-		++st->tx_bd_underrun;
-	if (ctrl & EMAC_TX_ST_SQE)
-		++st->tx_bd_sqe;
+	if (ctrl & EMAC_TX_ST_BFCS)	++st->tx_bd_bad_fcs;
+	if (ctrl & EMAC_TX_ST_LCS)	++st->tx_bd_carrier_loss;
+	if (ctrl & EMAC_TX_ST_ED)	++st->tx_bd_excessive_deferral;
+	if (ctrl & EMAC_TX_ST_EC)	++st->tx_bd_excessive_collisions;
+	if (ctrl & EMAC_TX_ST_LC)	++st->tx_bd_late_collision;
+	if (ctrl & EMAC_TX_ST_MC)	++st->tx_bd_multple_collisions;
+	if (ctrl & EMAC_TX_ST_SC)	++st->tx_bd_single_collision;
+	if (ctrl & EMAC_TX_ST_UR)	++st->tx_bd_underrun;
+	if (ctrl & EMAC_TX_ST_SQE)	++st->tx_bd_sqe;
 }
 
-static void emac_poll_tx(void *param)
-{
+static void emac_poll_tx(void *param) {
 	struct emac_instance *dev = param;
 	u32 bad_mask;
 
 	DBG2(dev, "poll_tx, %d %d" NL, dev->tx_cnt, dev->ack_slot);
 
-	if (emac_has_feature(dev, EMAC_FTR_HAS_TAH))
-		bad_mask = EMAC_IS_BAD_TX_TAH;
-	else
-		bad_mask = EMAC_IS_BAD_TX;
+	if (likely(emac_has_feature(dev, EMAC_FTR_HAS_TAH))) bad_mask = EMAC_IS_BAD_TX_TAH;
+	else bad_mask = EMAC_IS_BAD_TX;
 
 	netif_tx_lock_bh(dev->ndev);
 	if (dev->tx_cnt) {
-		u16 ctrl;
-		int slot = dev->ack_slot, n = 0;
+		register u16 ctrl;
+		register int slot = dev->ack_slot, n = 0;
 	again:
 		ctrl = dev->tx_desc[slot].ctrl;
 		if (!(ctrl & MAL_TX_CTRL_READY)) {
 			struct sk_buff *skb = dev->tx_skb[slot];
 			++n;
 
-			if (skb) {
+			if (likely(skb)) {
 				dev_kfree_skb(skb);
 				dev->tx_skb[slot] = NULL;
 			}
-			slot = (slot + 1) % NUM_TX_BUFF;
+			slot = NXT_TX_SLOT(slot);
+			if (unlikely(ctrl & bad_mask)) emac_parse_tx_error(dev, ctrl);
 
-			if (unlikely(ctrl & bad_mask))
-				emac_parse_tx_error(dev, ctrl);
+			if (--dev->tx_cnt) goto again;
+#ifdef CONFIG_IBM_NEW_EMAC_MASK_CEXT
+			else {
+				DBG(dev, "Testing for idle... " NL);
+				if (atomic_read(&dev->mask_cext_enable)) {
+					if (!atomic_read(&dev->idle_mode)) {
+						DBG(dev, "Entering idle mode" NL);
+						emac_start_idlemode(dev);
+						atomic_set(&dev->idle_mode, 1);
+					} else DBG(dev, "Already In Idle Mode" NL);
+				}
+			}
+#endif
+		} 
 
-			if (--dev->tx_cnt)
-				goto again;
-		}
 		if (n) {
 			dev->ack_slot = slot;
-			if (netif_queue_stopped(dev->ndev) &&
-			    dev->tx_cnt < EMAC_TX_WAKEUP_THRESH)
+			if (netif_queue_stopped(dev->ndev) && dev->tx_cnt < EMAC_TX_WAKEUP_THRESH)
 				netif_wake_queue(dev->ndev);
-
 			DBG2(dev, "tx %d pkts" NL, n);
 		}
 	}
+#ifdef CONFIG_IBM_EMAC_MASK_CEXT
+	else {
+		DBG(dev, "Testing for idle... " NL);
+		if (atomic_read(&dev->mask_cext_enable)) {
+			if (!atomic_read(&dev->idle_mode)) {
+			      DBG(dev, "Entering idle mode" NL);
+			      emac_start_idlemode(dev);
+			      atomic_set(&dev->idle_mode, 1);
+			} else DBG(dev, "Already In Idle Mode" NL);
+		}
+	}
+#endif
 	netif_tx_unlock_bh(dev->ndev);
 }
+/*
+#define EMAC_RECYCLE_RX_SKB(dev, slot, len, skbdata) \
+	if (len) dma_map_single(&dev->ofdev->dev, skbdata-2, EMAC_DMA_ALIGN(len+2), DMA_FROM_DEVICE);\
+	dev->rx_desc[slot].data_len = 0;\
+	wmb();\
+	dev->rx_desc[slot].ctrl = MAL_RX_CTRL_EMPTY | MAL_RX_CTRL_INTR |(slot == (NUM_RX_BUFF-1) ? MAL_RX_CTRL_WRAP:0);
+*/
 
-static inline void emac_recycle_rx_skb(struct emac_instance *dev, int slot,
-				       int len)
-{
-	struct sk_buff *skb = dev->rx_skb[slot];
+static __always_inline void emac_recycle_rx_skb(struct emac_instance *dev, int slot, int len, unsigned char* skbdata) {
+	//struct sk_buff *skb = dev->rx_skb[slot];
 
 	DBG2(dev, "recycle %d %d" NL, slot, len);
-
 	if (len)
-		dma_map_single(&dev->ofdev->dev, skb->data - 2,
-			       EMAC_DMA_ALIGN(len + 2), DMA_FROM_DEVICE);
-
+		dma_map_single(&dev->ofdev->dev, skbdata - 2, EMAC_DMA_ALIGN(len + 2), DMA_FROM_DEVICE);
 	dev->rx_desc[slot].data_len = 0;
 	wmb();
-	dev->rx_desc[slot].ctrl = MAL_RX_CTRL_EMPTY |
-	    (slot == (NUM_RX_BUFF - 1) ? MAL_RX_CTRL_WRAP : 0);
+	dev->rx_desc[slot].ctrl = MAL_RX_CTRL_EMPTY| MAL_RX_CTRL_INTR| (slot == (NUM_RX_BUFF-1) ? MAL_RX_CTRL_WRAP : 0);
 }
 
-static void emac_parse_rx_error(struct emac_instance *dev, u16 ctrl)
-{
+static void emac_parse_rx_error(struct emac_instance *dev, u16 ctrl) {
 	struct emac_error_stats *st = &dev->estats;
 
 	DBG(dev, "BD RX error %04x" NL, ctrl);
-
 	++st->rx_bd_errors;
-	if (ctrl & EMAC_RX_ST_OE)
-		++st->rx_bd_overrun;
-	if (ctrl & EMAC_RX_ST_BP)
-		++st->rx_bd_bad_packet;
-	if (ctrl & EMAC_RX_ST_RP)
-		++st->rx_bd_runt_packet;
-	if (ctrl & EMAC_RX_ST_SE)
-		++st->rx_bd_short_event;
-	if (ctrl & EMAC_RX_ST_AE)
-		++st->rx_bd_alignment_error;
-	if (ctrl & EMAC_RX_ST_BFCS)
-		++st->rx_bd_bad_fcs;
-	if (ctrl & EMAC_RX_ST_PTL)
-		++st->rx_bd_packet_too_long;
-	if (ctrl & EMAC_RX_ST_ORE)
-		++st->rx_bd_out_of_range;
-	if (ctrl & EMAC_RX_ST_IRE)
-		++st->rx_bd_in_range;
-}
-
-static inline void emac_rx_csum(struct emac_instance *dev,
-				struct sk_buff *skb, u16 ctrl)
-{
+	if (ctrl & EMAC_RX_ST_OE)	++st->rx_bd_overrun;
+	if (ctrl & EMAC_RX_ST_BP)	++st->rx_bd_bad_packet;
+	if (ctrl & EMAC_RX_ST_RP)	++st->rx_bd_runt_packet;
+	if (ctrl & EMAC_RX_ST_SE)	++st->rx_bd_short_event;
+	if (ctrl & EMAC_RX_ST_AE)	++st->rx_bd_alignment_error;
+	if (ctrl & EMAC_RX_ST_BFCS)	++st->rx_bd_bad_fcs;
+	if (ctrl & EMAC_RX_ST_PTL)	++st->rx_bd_packet_too_long;
+	if (ctrl & EMAC_RX_ST_ORE)	++st->rx_bd_out_of_range;
+	if (ctrl & EMAC_RX_ST_IRE)	++st->rx_bd_in_range;
+}
+
+static inline void emac_rx_csum(struct emac_instance *dev, struct sk_buff *skb, u16 ctrl) {
 #ifdef CONFIG_IBM_EMAC_TAH
 	if (!ctrl && dev->tah_dev) {
 		skb->ip_summed = CHECKSUM_UNNECESSARY;
@@ -1703,92 +1558,94 @@
 #endif
 }
 
-static inline int emac_rx_sg_append(struct emac_instance *dev, int slot)
-{
+/* ECO: local version of skb_put for performance reasons */
+static __always_inline unsigned char *skb_putl(struct sk_buff *skb, unsigned int len) {
+	unsigned char *tmp = skb_tail_pointer(skb);
+	SKB_LINEAR_ASSERT(skb);
+	skb->tail += len;
+	skb->len  += len;
+	return tmp;
+}
+
+static __always_inline int emac_rx_sg_append(struct emac_instance *dev, int slot, int len, unsigned char *data) {
 	if (likely(dev->rx_sg_skb != NULL)) {
-		int len = dev->rx_desc[slot].data_len;
+		//int len = dev->rx_desc[slot].data_len;
 		int tot_len = dev->rx_sg_skb->len + len;
 
 		if (unlikely(tot_len + 2 > dev->rx_skb_size)) {
 			++dev->estats.rx_dropped_mtu;
 			dev_kfree_skb(dev->rx_sg_skb);
 			dev->rx_sg_skb = NULL;
-		} else {
-			memcpy(skb_tail_pointer(dev->rx_sg_skb),
-					 dev->rx_skb[slot]->data, len);
-			skb_put(dev->rx_sg_skb, len);
-			emac_recycle_rx_skb(dev, slot, len);
+		} else {  //ECO
+			//if(unlikely((dev->rx_sg_skb->tail + len) > dev->rx_sg_skb->end)) goto out;
+			memcpy(skb_tail_pointer(dev->rx_sg_skb), data, len);	// dev->rx_skb[slot]->data
+			skb_putl(dev->rx_sg_skb, len);
+			emac_recycle_rx_skb(dev, slot, len, data);	//dev->rx_skb[slot]->data
 			return 0;
 		}
 	}
-	emac_recycle_rx_skb(dev, slot, 0);
+	emac_recycle_rx_skb(dev, slot, 0, dev->rx_skb[slot]->data);
 	return -1;
 }
 
 /* NAPI poll context */
-static int emac_poll_rx(void *param, int budget)
-{
-	struct emac_instance *dev = param;
-	int slot = dev->rx_slot, received = 0;
+static int emac_poll_rx(void *param, int budget) {
+	register struct emac_instance *dev = param;
+	register int slot = dev->rx_slot, received = 0;
 
 	DBG2(dev, "poll_rx(%d)" NL, budget);
 
  again:
 	while (budget > 0) {
-		int len;
+		register int len;
 		struct sk_buff *skb;
-		u16 ctrl = dev->rx_desc[slot].ctrl;
+		register u16 ctrl = dev->rx_desc[slot].ctrl;
 
-		if (ctrl & MAL_RX_CTRL_EMPTY)
-			break;
+		if (unlikely(ctrl & MAL_RX_CTRL_EMPTY)) break;
 
 		skb = dev->rx_skb[slot];
 		mb();
 		len = dev->rx_desc[slot].data_len;
 
-		if (unlikely(!MAL_IS_SINGLE_RX(ctrl)))
-			goto sg;
+		if (unlikely(!MAL_IS_SINGLE_RX(ctrl))) goto sg;
 
 		ctrl &= EMAC_BAD_RX_MASK;
 		if (unlikely(ctrl && ctrl != EMAC_RX_TAH_BAD_CSUM)) {
 			emac_parse_rx_error(dev, ctrl);
 			++dev->estats.rx_dropped_error;
-			emac_recycle_rx_skb(dev, slot, 0);
+			emac_recycle_rx_skb(dev, slot, 0, skb->data);
 			len = 0;
 			goto next;
 		}
 
 		if (len < ETH_HLEN) {
 			++dev->estats.rx_dropped_stack;
-			emac_recycle_rx_skb(dev, slot, len);
+			emac_recycle_rx_skb(dev, slot, len, skb->data);
 			goto next;
 		}
 
 		if (len && len < EMAC_RX_COPY_THRESH) {
-			struct sk_buff *copy_skb =
-			    alloc_skb(len + EMAC_RX_SKB_HEADROOM + 2, GFP_ATOMIC);
-			if (unlikely(!copy_skb))
-				goto oom;
+			struct sk_buff *copy_skb = alloc_skb(len + EMAC_RX_SKB_HEADROOM + 2, GFP_ATOMIC);
+			if (unlikely(!copy_skb)) goto oom;
 
 			skb_reserve(copy_skb, EMAC_RX_SKB_HEADROOM + 2);
-			memcpy(copy_skb->data - 2, skb->data - 2, len + 2);
-			emac_recycle_rx_skb(dev, slot, len);
+			memcpy(copy_skb->data - 2, skb->data - 2, len + 2);  //is cacheable_memcpy
+			emac_recycle_rx_skb(dev, slot, len, skb->data);
 			skb = copy_skb;
-		} else if (unlikely(emac_alloc_rx_skb(dev, slot, GFP_ATOMIC)))
-			goto oom;
+		} else if (unlikely(emac_alloc_rx_skb(dev, slot, GFP_ATOMIC))) goto oom;
 
-		skb_put(skb, len);
+		skb_putl(skb, len); //ECO: local version of skb_put
 	push_packet:
+		//skb->dev = dev->ndev;		//ECO
 		skb->protocol = eth_type_trans(skb, dev->ndev);
 		emac_rx_csum(dev, skb, ctrl);
 
-		if (unlikely(netif_receive_skb(skb) == NET_RX_DROP))
-			++dev->estats.rx_dropped_stack;
+		if (unlikely(netif_receive_skb(skb) == NET_RX_DROP)) ++dev->estats.rx_dropped_stack;
 	next:
 		++dev->stats.rx_packets;
 	skip:
 		dev->stats.rx_bytes += len;
-		slot = (slot + 1) % NUM_RX_BUFF;
+		slot = NXT_RX_SLOT(slot);
 		--budget;
 		++received;
 		continue;
@@ -1798,32 +1655,28 @@
 			if (unlikely(emac_alloc_rx_skb(dev, slot, GFP_ATOMIC))) {
 				DBG(dev, "rx OOM %d" NL, slot);
 				++dev->estats.rx_dropped_oom;
-				emac_recycle_rx_skb(dev, slot, 0);
+				emac_recycle_rx_skb(dev, slot, 0, skb->data);
 			} else {
 				dev->rx_sg_skb = skb;
-				skb_put(skb, len);
+				skb_putl(skb, len);
 			}
-		} else if (!emac_rx_sg_append(dev, slot) &&
-			   (ctrl & MAL_RX_CTRL_LAST)) {
-
+		} else if (!emac_rx_sg_append(dev, slot, len, skb->data) && (ctrl & MAL_RX_CTRL_LAST)) {
 			skb = dev->rx_sg_skb;
 			dev->rx_sg_skb = NULL;
-
 			ctrl &= EMAC_BAD_RX_MASK;
 			if (unlikely(ctrl && ctrl != EMAC_RX_TAH_BAD_CSUM)) {
 				emac_parse_rx_error(dev, ctrl);
 				++dev->estats.rx_dropped_error;
 				dev_kfree_skb(skb);
 				len = 0;
-			} else
-				goto push_packet;
+			} else goto push_packet;
 		}
 		goto skip;
 	oom:
 		DBG(dev, "rx OOM %d" NL, slot);
 		/* Drop the packet and recycle skb */
 		++dev->estats.rx_dropped_oom;
-		emac_recycle_rx_skb(dev, slot, 0);
+		emac_recycle_rx_skb(dev, slot, 0, skb->data);
 		goto next;
 	}
 
@@ -1856,46 +1709,33 @@
 }
 
 /* NAPI poll context */
-static int emac_peek_rx(void *param)
-{
+static int emac_peek_rx(void *param) {
 	struct emac_instance *dev = param;
-
 	return !(dev->rx_desc[dev->rx_slot].ctrl & MAL_RX_CTRL_EMPTY);
 }
 
 /* NAPI poll context */
-static int emac_peek_rx_sg(void *param)
-{
+static int emac_peek_rx_sg(void *param) {
 	struct emac_instance *dev = param;
-
-	int slot = dev->rx_slot;
+	register int slot = dev->rx_slot;
 	while (1) {
-		u16 ctrl = dev->rx_desc[slot].ctrl;
-		if (ctrl & MAL_RX_CTRL_EMPTY)
-			return 0;
-		else if (ctrl & MAL_RX_CTRL_LAST)
-			return 1;
-
-		slot = (slot + 1) % NUM_RX_BUFF;
-
-		/* I'm just being paranoid here :) */
-		if (unlikely(slot == dev->rx_slot))
-			return 0;
+		register u16 ctrl = dev->rx_desc[slot].ctrl;
+		if (unlikely(ctrl & MAL_RX_CTRL_EMPTY)) return 0;
+		else if (unlikely(ctrl & MAL_RX_CTRL_LAST)) return 1;
+		slot = NXT_RX_SLOT(slot);
+		//if (unlikely(slot == dev->rx_slot))	return 0;		// Paranoid ?
 	}
 }
 
 /* Hard IRQ */
-static void emac_rxde(void *param)
-{
+static void emac_rxde(void *param) {
 	struct emac_instance *dev = param;
-
 	++dev->estats.rx_stopped;
 	emac_rx_disable_async(dev);
 }
 
 /* Hard IRQ */
-static irqreturn_t emac_irq(int irq, void *dev_instance)
-{
+static irqreturn_t emac_irq(int irq, void *dev_instance) {
 	struct emac_instance *dev = dev_instance;
 	struct emac_regs __iomem *p = dev->emacp;
 	struct emac_error_stats *st = &dev->estats;
@@ -1907,45 +1747,32 @@
 	out_be32(&p->isr, isr);
 
 	DBG(dev, "isr = %08x" NL, isr);
+	printk(KERN_ERR "%s: isr = %08x\n", __func__, isr);
 
-	if (isr & EMAC4_ISR_TXPE)
-		++st->tx_parity;
-	if (isr & EMAC4_ISR_RXPE)
-		++st->rx_parity;
-	if (isr & EMAC4_ISR_TXUE)
-		++st->tx_underrun;
-	if (isr & EMAC4_ISR_RXOE)
-		++st->rx_fifo_overrun;
-	if (isr & EMAC_ISR_OVR)
-		++st->rx_overrun;
-	if (isr & EMAC_ISR_BP)
-		++st->rx_bad_packet;
-	if (isr & EMAC_ISR_RP)
-		++st->rx_runt_packet;
-	if (isr & EMAC_ISR_SE)
-		++st->rx_short_event;
-	if (isr & EMAC_ISR_ALE)
-		++st->rx_alignment_error;
-	if (isr & EMAC_ISR_BFCS)
-		++st->rx_bad_fcs;
-	if (isr & EMAC_ISR_PTLE)
-		++st->rx_packet_too_long;
-	if (isr & EMAC_ISR_ORE)
-		++st->rx_out_of_range;
-	if (isr & EMAC_ISR_IRE)
-		++st->rx_in_range;
-	if (isr & EMAC_ISR_SQE)
-		++st->tx_sqe;
-	if (isr & EMAC_ISR_TE)
-		++st->tx_errors;
-
+	if (isr & EMAC4_ISR_TXPE)	++st->tx_parity;
+	if (isr & EMAC4_ISR_RXPE)	++st->rx_parity;
+	if (isr & EMAC4_ISR_TXUE)	++st->tx_underrun;
+	if (isr & EMAC4_ISR_RXOE)	++st->rx_fifo_overrun;
+	if (isr & EMAC_ISR_OVR)		++st->rx_overrun;
+	if (isr & EMAC_ISR_BP)		++st->rx_bad_packet;
+	if (isr & EMAC_ISR_RP)		++st->rx_runt_packet;
+	if (isr & EMAC_ISR_SE)		++st->rx_short_event;
+	if (isr & EMAC_ISR_ALE)		++st->rx_alignment_error;
+	if (isr & EMAC_ISR_BFCS)	++st->rx_bad_fcs;
+	if (isr & EMAC_ISR_PTLE)	++st->rx_packet_too_long;
+	if (isr & EMAC_ISR_ORE)		++st->rx_out_of_range;
+	if (isr & EMAC_ISR_IRE)		++st->rx_in_range;
+	if (isr & EMAC_ISR_SQE)		++st->tx_sqe;
+	if (isr & EMAC_ISR_TE)		++st->tx_errors;
 	spin_unlock(&dev->lock);
+	return IRQ_HANDLED;
+}
 
+static irqreturn_t wol_irq(int irq, void *dev_instance) {
 	return IRQ_HANDLED;
 }
 
-static struct net_device_stats *emac_stats(struct net_device *ndev)
-{
+static struct net_device_stats *emac_stats(struct net_device *ndev) {
 	struct emac_instance *dev = netdev_priv(ndev);
 	struct emac_stats *st = &dev->stats;
 	struct emac_error_stats *est = &dev->estats;
@@ -1960,39 +1787,24 @@
 	nst->rx_bytes = (unsigned long)st->rx_bytes;
 	nst->tx_packets = (unsigned long)st->tx_packets;
 	nst->tx_bytes = (unsigned long)st->tx_bytes;
-	nst->rx_dropped = (unsigned long)(est->rx_dropped_oom +
-					  est->rx_dropped_error +
-					  est->rx_dropped_resize +
-					  est->rx_dropped_mtu);
+	nst->rx_dropped = (unsigned long)(est->rx_dropped_oom + est->rx_dropped_error +
+		est->rx_dropped_resize + est->rx_dropped_mtu);
 	nst->tx_dropped = (unsigned long)est->tx_dropped;
 
 	nst->rx_errors = (unsigned long)est->rx_bd_errors;
-	nst->rx_fifo_errors = (unsigned long)(est->rx_bd_overrun +
-					      est->rx_fifo_overrun +
-					      est->rx_overrun);
-	nst->rx_frame_errors = (unsigned long)(est->rx_bd_alignment_error +
-					       est->rx_alignment_error);
-	nst->rx_crc_errors = (unsigned long)(est->rx_bd_bad_fcs +
-					     est->rx_bad_fcs);
-	nst->rx_length_errors = (unsigned long)(est->rx_bd_runt_packet +
-						est->rx_bd_short_event +
-						est->rx_bd_packet_too_long +
-						est->rx_bd_out_of_range +
-						est->rx_bd_in_range +
-						est->rx_runt_packet +
-						est->rx_short_event +
-						est->rx_packet_too_long +
-						est->rx_out_of_range +
-						est->rx_in_range);
+	nst->rx_fifo_errors = (unsigned long)(est->rx_bd_overrun + est->rx_fifo_overrun + est->rx_overrun);
+	nst->rx_frame_errors = (unsigned long)(est->rx_bd_alignment_error + est->rx_alignment_error);
+	nst->rx_crc_errors = (unsigned long)(est->rx_bd_bad_fcs + est->rx_bad_fcs);
+	nst->rx_length_errors = (unsigned long)(est->rx_bd_runt_packet + est->rx_bd_short_event +
+		est->rx_bd_packet_too_long + est->rx_bd_out_of_range + est->rx_bd_in_range +
+		est->rx_runt_packet + est->rx_short_event + est->rx_packet_too_long +
+		est->rx_out_of_range + est->rx_in_range);
 
 	nst->tx_errors = (unsigned long)(est->tx_bd_errors + est->tx_errors);
-	nst->tx_fifo_errors = (unsigned long)(est->tx_bd_underrun +
-					      est->tx_underrun);
+	nst->tx_fifo_errors = (unsigned long)(est->tx_bd_underrun + est->tx_underrun);
 	nst->tx_carrier_errors = (unsigned long)est->tx_bd_carrier_loss;
 	nst->collisions = (unsigned long)(est->tx_bd_excessive_deferral +
-					  est->tx_bd_excessive_collisions +
-					  est->tx_bd_late_collision +
-					  est->tx_bd_multple_collisions);
+		est->tx_bd_excessive_collisions + est->tx_bd_late_collision + est->tx_bd_multple_collisions);
 	spin_unlock_irqrestore(&dev->lock, flags);
 	return nst;
 }
@@ -2012,16 +1824,13 @@
 };
 
 /* Ethtool support */
-static int emac_ethtool_get_settings(struct net_device *ndev,
-				     struct ethtool_cmd *cmd)
-{
+static int emac_ethtool_get_settings(struct net_device *ndev, struct ethtool_cmd *cmd) {
 	struct emac_instance *dev = netdev_priv(ndev);
 
 	cmd->supported = dev->phy.features;
 	cmd->port = PORT_MII;
 	cmd->phy_address = dev->phy.address;
-	cmd->transceiver =
-	    dev->phy.address >= 0 ? XCVR_EXTERNAL : XCVR_INTERNAL;
+	cmd->transceiver = dev->phy.address >= 0 ? XCVR_EXTERNAL : XCVR_INTERNAL;
 
 	mutex_lock(&dev->link_lock);
 	cmd->advertising = dev->phy.advertising;
@@ -2033,9 +1842,7 @@
 	return 0;
 }
 
-static int emac_ethtool_set_settings(struct net_device *ndev,
-				     struct ethtool_cmd *cmd)
-{
+static int emac_ethtool_set_settings(struct net_device *ndev, struct ethtool_cmd *cmd) {
 	struct emac_instance *dev = netdev_priv(ndev);
 	u32 f = dev->phy.features;
 
@@ -2043,60 +1850,37 @@
 	    cmd->autoneg, cmd->speed, cmd->duplex, cmd->advertising);
 
 	/* Basic sanity checks */
-	if (dev->phy.address < 0)
-		return -EOPNOTSUPP;
-	if (cmd->autoneg != AUTONEG_ENABLE && cmd->autoneg != AUTONEG_DISABLE)
-		return -EINVAL;
-	if (cmd->autoneg == AUTONEG_ENABLE && cmd->advertising == 0)
-		return -EINVAL;
-	if (cmd->duplex != DUPLEX_HALF && cmd->duplex != DUPLEX_FULL)
-		return -EINVAL;
+	if (dev->phy.address < 0) return -EOPNOTSUPP;
+	if (cmd->autoneg != AUTONEG_ENABLE && cmd->autoneg != AUTONEG_DISABLE) return -EINVAL;
+	if (cmd->autoneg == AUTONEG_ENABLE && cmd->advertising == 0) return -EINVAL;
+	if (cmd->duplex != DUPLEX_HALF && cmd->duplex != DUPLEX_FULL) return -EINVAL;
 
 	if (cmd->autoneg == AUTONEG_DISABLE) {
 		switch (cmd->speed) {
-		case SPEED_10:
-			if (cmd->duplex == DUPLEX_HALF &&
-			    !(f & SUPPORTED_10baseT_Half))
-				return -EINVAL;
-			if (cmd->duplex == DUPLEX_FULL &&
-			    !(f & SUPPORTED_10baseT_Full))
-				return -EINVAL;
+		case SPEED_1000:
+			if (cmd->duplex == DUPLEX_HALF && !(f & SUPPORTED_1000baseT_Half)) return -EINVAL;
+			if (cmd->duplex == DUPLEX_FULL && !(f & SUPPORTED_1000baseT_Full)) return -EINVAL;
 			break;
 		case SPEED_100:
-			if (cmd->duplex == DUPLEX_HALF &&
-			    !(f & SUPPORTED_100baseT_Half))
-				return -EINVAL;
-			if (cmd->duplex == DUPLEX_FULL &&
-			    !(f & SUPPORTED_100baseT_Full))
-				return -EINVAL;
+			if (cmd->duplex == DUPLEX_HALF && !(f & SUPPORTED_100baseT_Half)) return -EINVAL;
+			if (cmd->duplex == DUPLEX_FULL && !(f & SUPPORTED_100baseT_Full)) return -EINVAL;
 			break;
-		case SPEED_1000:
-			if (cmd->duplex == DUPLEX_HALF &&
-			    !(f & SUPPORTED_1000baseT_Half))
-				return -EINVAL;
-			if (cmd->duplex == DUPLEX_FULL &&
-			    !(f & SUPPORTED_1000baseT_Full))
-				return -EINVAL;
+		case SPEED_10:
+			if (cmd->duplex == DUPLEX_HALF && !(f & SUPPORTED_10baseT_Half)) return -EINVAL;
+			if (cmd->duplex == DUPLEX_FULL && !(f & SUPPORTED_10baseT_Full)) return -EINVAL;
 			break;
-		default:
-			return -EINVAL;
+		default: return -EINVAL;
 		}
 
 		mutex_lock(&dev->link_lock);
-		dev->phy.def->ops->setup_forced(&dev->phy, cmd->speed,
-						cmd->duplex);
+		dev->phy.def->ops->setup_forced(&dev->phy, cmd->speed, cmd->duplex);
 		mutex_unlock(&dev->link_lock);
 
 	} else {
-		if (!(f & SUPPORTED_Autoneg))
-			return -EINVAL;
-
+		if (!(f & SUPPORTED_Autoneg)) return -EINVAL;
 		mutex_lock(&dev->link_lock);
-		dev->phy.def->ops->setup_aneg(&dev->phy,
-					      (cmd->advertising & f) |
-					      (dev->phy.advertising &
-					       (ADVERTISED_Pause |
-						ADVERTISED_Asym_Pause)));
+		dev->phy.def->ops->setup_aneg(&dev->phy, (cmd->advertising & f) | 
+			(dev->phy.advertising &	(ADVERTISED_Pause |	ADVERTISED_Asym_Pause)));
 		mutex_unlock(&dev->link_lock);
 	}
 	emac_force_link_update(dev);
@@ -2104,16 +1888,12 @@
 	return 0;
 }
 
-static void emac_ethtool_get_ringparam(struct net_device *ndev,
-				       struct ethtool_ringparam *rp)
-{
+static void emac_ethtool_get_ringparam(struct net_device *ndev, struct ethtool_ringparam *rp) {
 	rp->rx_max_pending = rp->rx_pending = NUM_RX_BUFF;
 	rp->tx_max_pending = rp->tx_pending = NUM_TX_BUFF;
 }
 
-static void emac_ethtool_get_pauseparam(struct net_device *ndev,
-					struct ethtool_pauseparam *pp)
-{
+static void emac_ethtool_get_pauseparam(struct net_device *ndev, struct ethtool_pauseparam *pp) {
 	struct emac_instance *dev = netdev_priv(ndev);
 
 	mutex_lock(&dev->link_lock);
@@ -2122,56 +1902,41 @@
 		pp->autoneg = 1;
 
 	if (dev->phy.duplex == DUPLEX_FULL) {
-		if (dev->phy.pause)
-			pp->rx_pause = pp->tx_pause = 1;
-		else if (dev->phy.asym_pause)
-			pp->tx_pause = 1;
+		if (dev->phy.pause)	pp->rx_pause = pp->tx_pause = 1;
+		else if (dev->phy.asym_pause) pp->tx_pause = 1;
 	}
 	mutex_unlock(&dev->link_lock);
 }
 
-static int emac_get_regs_len(struct emac_instance *dev)
-{
-		return sizeof(struct emac_ethtool_regs_subhdr) +
-			sizeof(struct emac_regs);
+static int emac_get_regs_len(struct emac_instance *dev) {
+		return sizeof(struct emac_ethtool_regs_subhdr) + sizeof(struct emac_regs);
 }
 
-static int emac_ethtool_get_regs_len(struct net_device *ndev)
-{
+static int emac_ethtool_get_regs_len(struct net_device *ndev) {
 	struct emac_instance *dev = netdev_priv(ndev);
 	int size;
 
 	size = sizeof(struct emac_ethtool_regs_hdr) +
 		emac_get_regs_len(dev) + mal_get_regs_len(dev->mal);
-	if (emac_has_feature(dev, EMAC_FTR_HAS_ZMII))
-		size += zmii_get_regs_len(dev->zmii_dev);
-	if (emac_has_feature(dev, EMAC_FTR_HAS_RGMII))
-		size += rgmii_get_regs_len(dev->rgmii_dev);
-	if (emac_has_feature(dev, EMAC_FTR_HAS_TAH))
-		size += tah_get_regs_len(dev->tah_dev);
-
+	if (likely(emac_has_feature(dev, EMAC_FTR_HAS_RGMII))) size += rgmii_get_regs_len(dev->rgmii_dev);
+	else if (emac_has_feature(dev, EMAC_FTR_HAS_ZMII)) size += zmii_get_regs_len(dev->zmii_dev);
+	if (likely(emac_has_feature(dev, EMAC_FTR_HAS_TAH))) size += tah_get_regs_len(dev->tah_dev);
 	return size;
 }
 
-static void *emac_dump_regs(struct emac_instance *dev, void *buf)
-{
+static void *emac_dump_regs(struct emac_instance *dev, void *buf) {
 	struct emac_ethtool_regs_subhdr *hdr = buf;
 
 	hdr->index = dev->cell_index;
-	if (emac_has_feature(dev, EMAC_FTR_EMAC4SYNC)) {
-		hdr->version = EMAC4SYNC_ETHTOOL_REGS_VER;
-	} else if (emac_has_feature(dev, EMAC_FTR_EMAC4)) {
-		hdr->version = EMAC4_ETHTOOL_REGS_VER;
-	} else {
-		hdr->version = EMAC_ETHTOOL_REGS_VER;
-	}
+	if (emac_has_feature(dev, EMAC_FTR_EMAC4SYNC))	hdr->version = EMAC4SYNC_ETHTOOL_REGS_VER;
+	else if (emac_has_feature(dev, EMAC_FTR_EMAC4)) hdr->version = EMAC4_ETHTOOL_REGS_VER;
+	else hdr->version = EMAC_ETHTOOL_REGS_VER;
+
 	memcpy_fromio(hdr + 1, dev->emacp, sizeof(struct emac_regs));
 	return (void *)(hdr + 1) + sizeof(struct emac_regs);
 }
 
-static void emac_ethtool_get_regs(struct net_device *ndev,
-				  struct ethtool_regs *regs, void *buf)
-{
+static void emac_ethtool_get_regs(struct net_device *ndev, struct ethtool_regs *regs, void *buf) {
 	struct emac_instance *dev = netdev_priv(ndev);
 	struct emac_ethtool_regs_hdr *hdr = buf;
 
@@ -2194,15 +1959,12 @@
 	}
 }
 
-static int emac_ethtool_nway_reset(struct net_device *ndev)
-{
+static int emac_ethtool_nway_reset(struct net_device *ndev) {
 	struct emac_instance *dev = netdev_priv(ndev);
 	int res = 0;
 
 	DBG(dev, "nway_reset" NL);
-
-	if (dev->phy.address < 0)
-		return -EOPNOTSUPP;
+	if (dev->phy.address < 0) return -EOPNOTSUPP;
 
 	mutex_lock(&dev->link_lock);
 	if (!dev->phy.autoneg) {
@@ -2217,25 +1979,17 @@
 	return res;
 }
 
-static int emac_ethtool_get_sset_count(struct net_device *ndev, int stringset)
-{
-	if (stringset == ETH_SS_STATS)
-		return EMAC_ETHTOOL_STATS_COUNT;
-	else
-		return -EINVAL;
+static int emac_ethtool_get_sset_count(struct net_device *ndev, int stringset) {
+	if (stringset == ETH_SS_STATS)	return EMAC_ETHTOOL_STATS_COUNT;
+	else return -EINVAL;
 }
 
-static void emac_ethtool_get_strings(struct net_device *ndev, u32 stringset,
-				     u8 * buf)
-{
-	if (stringset == ETH_SS_STATS)
-		memcpy(buf, &emac_stats_keys, sizeof(emac_stats_keys));
+static void emac_ethtool_get_strings(struct net_device *ndev, u32 stringset, u8 * buf) {
+	if (stringset == ETH_SS_STATS) memcpy(buf, &emac_stats_keys, sizeof(emac_stats_keys));
 }
 
 static void emac_ethtool_get_ethtool_stats(struct net_device *ndev,
-					   struct ethtool_stats *estats,
-					   u64 * tmp_stats)
-{
+					   struct ethtool_stats *estats, u64 * tmp_stats){
 	struct emac_instance *dev = netdev_priv(ndev);
 
 	memcpy(tmp_stats, &dev->stats, sizeof(dev->stats));
@@ -2243,9 +1997,7 @@
 	memcpy(tmp_stats, &dev->estats, sizeof(dev->estats));
 }
 
-static void emac_ethtool_get_drvinfo(struct net_device *ndev,
-				     struct ethtool_drvinfo *info)
-{
+static void emac_ethtool_get_drvinfo(struct net_device *ndev, struct ethtool_drvinfo *info) {
 	struct emac_instance *dev = netdev_priv(ndev);
 
 	strlcpy(info->driver, "ibm_emac", sizeof(info->driver));
@@ -2254,6 +2006,34 @@
 		 dev->cell_index, dev->ofdev->dev.of_node->full_name);
 }
 
+#ifdef CONFIG_IBM_EMAC_INTR_COALESCE
+static int emac_ethtool_get_coalesce(struct net_device *dev, struct ethtool_coalesce *ec) {
+	struct emac_instance *ei = netdev_priv(dev);
+    memset(ec, 0, sizeof(*ec));			/* clean up */
+
+	/* Update with current status */
+	ec->rx_coalesce_usecs       = ei->mal->coales_param[0].rx_time / ei->plb_bus_freq;
+	ec->rx_max_coalesced_frames = ei->mal->coales_param[0].rx_count;
+	ec->tx_coalesce_usecs       = ei->mal->coales_param[0].tx_time / ei->plb_bus_freq;
+	ec->tx_max_coalesced_frames = ei->mal->coales_param[0].tx_count;
+    return 0;
+}
+
+static int emac_ethtool_set_coalesce(struct net_device *dev, struct ethtool_coalesce *ec) {
+	struct emac_instance *ei = netdev_priv(dev);
+	int i;
+	
+	for (i = 0; i < 4; i++) {
+		ei->mal->coales_param[i].tx_count =	(ec->tx_max_coalesced_frames & COAL_FRAME_MASK);
+		ei->mal->coales_param[i].rx_count =	(ec->rx_max_coalesced_frames & COAL_FRAME_MASK);
+		ei->mal->coales_param[i].tx_time =	(ec->tx_coalesce_usecs * ei->plb_bus_freq);
+		ei->mal->coales_param[i].rx_time =	(ec->rx_coalesce_usecs * ei->plb_bus_freq);
+	}
+	mal_enable_coal(ei->mal);
+	return 0;
+}
+#endif
+
 static const struct ethtool_ops emac_ethtool_ops = {
 	.get_settings = emac_ethtool_get_settings,
 	.set_settings = emac_ethtool_set_settings,
@@ -2272,33 +2052,323 @@
 	.get_ethtool_stats = emac_ethtool_get_ethtool_stats,
 
 	.get_link = ethtool_op_get_link,
+
+#ifdef CONFIG_IBM_EMAC_INTR_COALESCE
+	.get_coalesce           = emac_ethtool_get_coalesce,
+	.set_coalesce           = emac_ethtool_set_coalesce,
+#endif
+};
+
+/* sysfs support for IBM NEW EMAC */
+#if defined(CONFIG_IBM_EMAC_SYSFS)
+
+#if defined(CONFIG_IBM_EMAC_INTR_COALESCE)
+/* Display interrupt coalesce parametters values */
+static ssize_t show_tx_count(struct device *dev, struct device_attribute *attr, char *buf) {
+	struct net_device *ndev = to_net_dev(dev);
+	struct emac_instance *dev_ins = netdev_priv(ndev);
+	return sprintf(buf, "%d\n", dev_ins->mal->coales_param[0].tx_count);
+}
+
+static ssize_t show_rx_count(struct device *dev, struct device_attribute *attr, char *buf) {
+	struct net_device *ndev = to_net_dev(dev);
+	struct emac_instance *dev_ins = netdev_priv(ndev);
+	return sprintf(buf, "%d\n", dev_ins->mal->coales_param[0].rx_count);
+}
+
+static ssize_t show_tx_time(struct device *dev, struct device_attribute *attr, char *buf) {
+	struct net_device *ndev = to_net_dev(dev);
+	struct emac_instance *dev_ins = netdev_priv(ndev);
+	return sprintf(buf, "%d\n", dev_ins->mal->coales_param[0].tx_time);
+}
+
+static ssize_t show_rx_time(struct device *dev, struct device_attribute *attr, char *buf) {
+	struct net_device *ndev = to_net_dev(dev);
+	struct emac_instance *dev_ins = netdev_priv(ndev);
+	return sprintf(buf, "%d\n", dev_ins->mal->coales_param[0].rx_time);
+}
+
+static int core_reset(struct emac_instance * dev_ins) {
+	mutex_lock(&dev_ins->link_lock);
+	emac_netif_stop(dev_ins);
+	emac_rx_disable(dev_ins);
+	mal_disable_rx_channel(dev_ins->mal, dev_ins->mal_rx_chan);
+	if (dev_ins->rx_sg_skb) {
+		++dev_ins->estats.rx_dropped_resize;
+		dev_kfree_skb(dev_ins->rx_sg_skb);
+		dev_ins->rx_sg_skb = NULL;
+	}
+	/* This is to prevent starting RX channel in emac_rx_enable() */
+	set_bit(MAL_COMMAC_RX_STOPPED, &dev_ins->commac.flags);
+	emac_full_tx_reset(dev_ins);	/* Restart RX */
+	clear_bit(MAL_COMMAC_RX_STOPPED, &dev_ins->commac.flags);
+	dev_ins->rx_slot = 0;	
+	mal_enable_rx_channel(dev_ins->mal, dev_ins->mal_rx_chan);
+	emac_rx_enable(dev_ins);
+	emac_netif_start(dev_ins);
+	mutex_unlock(&dev_ins->link_lock);
+	return 0;
+}
+
+/* Set interrupt coalesce parametters values */
+static ssize_t store_tx_count(struct device *dev, struct device_attribute *attr,
+	const char *buf, size_t count) {
+	struct net_device *ndev = to_net_dev(dev);
+	struct emac_instance *dev_ins = netdev_priv(ndev);
+	
+	long tmp = simple_strtol(buf, NULL, 10);
+ 	dev_ins->mal->coales_param[0].tx_count = tmp; /* Reconfigure MAL intr coalesce parameters */
+	mutex_lock(&dev_ins->link_lock);
+	mal_enable_coal(dev_ins->mal);
+	mutex_unlock(&dev_ins->link_lock);
+	/* FIXME: It seems that not reset the interface cause it hangs after short period of time */
+	if (netif_running(dev_ins->ndev)) core_reset(dev_ins);
+	return count;
+}
+static ssize_t store_rx_count(struct device *dev, struct device_attribute *attr,
+	const char *buf, size_t count) {
+	struct net_device *ndev = to_net_dev(dev);
+	struct emac_instance *dev_ins = netdev_priv(ndev);
+
+	long tmp = simple_strtol(buf, NULL, 10);
+ 	dev_ins->mal->coales_param[0].rx_count = tmp; /* Reconfigure MAL intr coalesce parameters */
+	mutex_lock(&dev_ins->link_lock);
+	mal_enable_coal(dev_ins->mal);
+	mutex_unlock(&dev_ins->link_lock);
+	/* FIXME: It seems that not reset the interface cause it hangs after short period of time */
+	if (netif_running(dev_ins->ndev)) core_reset(dev_ins);
+	return count;
+}
+
+static ssize_t store_tx_time(struct device *dev, struct device_attribute *attr,
+	const char *buf, size_t count) {
+	struct net_device *ndev = to_net_dev(dev);
+	struct emac_instance *dev_ins = netdev_priv(ndev);
+
+	long tmp = simple_strtol(buf, NULL, 10);
+	dev_ins->mal->coales_param[0].tx_time = tmp; /* Reconfigure MAL intr coalesce parameters */
+	mutex_lock(&dev_ins->link_lock);
+	mal_enable_coal(dev_ins->mal);
+	mutex_unlock(&dev_ins->link_lock);
+	/* FIXME: It seems that not reset the interface cause it hangs after short period of time */
+	if (netif_running(dev_ins->ndev)) core_reset(dev_ins);
+	return count;
+}
+
+static ssize_t store_rx_time(struct device *dev, struct device_attribute *attr,
+	const char *buf, size_t count) {
+	struct net_device *ndev = to_net_dev(dev);
+	struct emac_instance *dev_ins = netdev_priv(ndev);
+
+	long tmp = simple_strtol(buf, NULL, 10);
+	dev_ins->mal->coales_param[0].rx_time = tmp; /* Reconfigure MAL intr coalesce parameters */
+	mutex_lock(&dev_ins->link_lock);        
+	mal_enable_coal(dev_ins->mal);
+	mutex_unlock(&dev_ins->link_lock);
+	/* FIXME: It seems that not reset the interface cause it hangs after short period of time */
+	if (netif_running(dev_ins->ndev)) core_reset(dev_ins);
+	return count;
+}
+#endif
+
+#if defined(CONFIG_IBM_EMAC_MASK_CEXT)
+static ssize_t show_emi_fix_enable(struct device *dev, struct device_attribute *attr, char *buf) {
+	struct net_device *ndev = to_net_dev(dev);
+	struct emac_instance *dev_ins = netdev_priv(ndev);
+	return sprintf(buf, "%d\n", atomic_read(&dev_ins->mask_cext_enable));
+}
+
+static ssize_t store_emi_fix_enable(struct device *dev, struct device_attribute *attr,
+	const char *buf, size_t count) {
+	struct net_device *ndev = to_net_dev(dev);
+	struct emac_instance *dev_ins = netdev_priv(ndev);
+
+	long tmp = !!simple_strtol(buf, NULL, 10);
+	printk(KERN_INFO "%s EMAC EMI Fix\n", (tmp) ? "Enable" : "Disable");
+	atomic_set(&dev_ins->mask_cext_enable, tmp);	/* Exit idle mode before return */
+
+	if (atomic_read(&dev_ins->idle_mode)) {
+	   	emac_exit_idlemode(dev_ins);
+		atomic_set(&dev_ins->idle_mode, 0);
+	}
+	return count;
+}
+
+#endif
+
+#if defined(CONFIG_IBM_EMAC_TAH)
+static ssize_t show_tah_ssr0(struct device *dev, struct device_attribute *attr, char *buf) {
+	struct net_device *ndev = to_net_dev(dev);
+	struct emac_instance *dev_ins = netdev_priv(ndev);
+	if (emac_has_feature(dev_ins, EMAC_FTR_HAS_TAH))
+		return sprintf(buf, "%d\n", TAH_SSR_2_SS(tah_get_ssr(dev_ins->tah_dev, 0)) << 1);
+	return 0;
+}
+
+static ssize_t store_tah_ssr0(struct device *dev, struct device_attribute *attr,
+	 const char *buf, size_t count) {
+	struct net_device *ndev = to_net_dev(dev);
+	struct emac_instance *dev_ins = netdev_priv(ndev);
+
+	long tmp = simple_strtol(buf, NULL, 10);
+	if (emac_has_feature(dev_ins, EMAC_FTR_HAS_TAH)) tah_set_ssr(dev_ins->tah_dev, 0, tmp);	
+	return count;
+}
+
+static ssize_t show_tah_ssr1(struct device *dev, struct device_attribute *attr, char *buf) {
+	struct net_device *ndev = to_net_dev(dev);
+	struct emac_instance *dev_ins = netdev_priv(ndev);
+
+	if (emac_has_feature(dev_ins, EMAC_FTR_HAS_TAH))
+		return sprintf(buf, "%d\n", TAH_SSR_2_SS(tah_get_ssr(dev_ins->tah_dev, 1)) << 1);
+	return 0;
+}
+
+static ssize_t store_tah_ssr1(struct device *dev, struct device_attribute *attr,
+	const char *buf, size_t count) {
+	struct net_device *ndev = to_net_dev(dev);
+	struct emac_instance *dev_ins = netdev_priv(ndev);
+
+	long tmp = simple_strtol(buf, NULL, 10);
+	if (emac_has_feature(dev_ins, EMAC_FTR_HAS_TAH)) tah_set_ssr(dev_ins->tah_dev, 1, tmp);	
+	return count;
+}
+
+static ssize_t show_tah_ssr2(struct device *dev, struct device_attribute *attr, char *buf) {
+	struct net_device *ndev = to_net_dev(dev);
+	struct emac_instance *dev_ins = netdev_priv(ndev);
+
+	if (emac_has_feature(dev_ins, EMAC_FTR_HAS_TAH))
+		return sprintf(buf, "%d\n", TAH_SSR_2_SS(tah_get_ssr(dev_ins->tah_dev, 2)) << 1);
+	return 0;
+}
+
+static ssize_t store_tah_ssr2(struct device *dev, struct device_attribute *attr,
+	const char *buf, size_t count) {
+	struct net_device *ndev = to_net_dev(dev);
+	struct emac_instance *dev_ins = netdev_priv(ndev);
+
+	long tmp = simple_strtol(buf, NULL, 10);
+	if (emac_has_feature(dev_ins, EMAC_FTR_HAS_TAH)) tah_set_ssr(dev_ins->tah_dev, 2, tmp);	
+	return count;
+}
+
+static ssize_t show_tah_ssr3(struct device *dev, struct device_attribute *attr, char *buf) {
+	struct net_device *ndev = to_net_dev(dev);
+	struct emac_instance *dev_ins = netdev_priv(ndev);
+
+	if (emac_has_feature(dev_ins, EMAC_FTR_HAS_TAH))
+		return sprintf(buf, "%d\n", TAH_SSR_2_SS(tah_get_ssr(dev_ins->tah_dev, 3)) << 1);
+	return 0;
+}
+
+static ssize_t store_tah_ssr3(struct device *dev, struct device_attribute *attr,
+	const char *buf, size_t count) {
+	struct net_device *ndev = to_net_dev(dev);
+	struct emac_instance *dev_ins = netdev_priv(ndev);
+
+	long tmp = simple_strtol(buf, NULL, 10);
+	if (emac_has_feature(dev_ins, EMAC_FTR_HAS_TAH)) tah_set_ssr(dev_ins->tah_dev, 3, tmp);	
+	return count;
+}
+
+static ssize_t show_tah_ssr4(struct device *dev, struct device_attribute *attr, char *buf) {
+	struct net_device *ndev = to_net_dev(dev);
+	struct emac_instance *dev_ins = netdev_priv(ndev);
+
+	if (emac_has_feature(dev_ins, EMAC_FTR_HAS_TAH)) 
+		return sprintf(buf, "%d\n", TAH_SSR_2_SS(tah_get_ssr(dev_ins->tah_dev, 4)) << 1);
+	return 0;
+}
+
+static ssize_t store_tah_ssr4(struct device *dev, struct device_attribute *attr,
+	const char *buf, size_t count) {
+	struct net_device *ndev = to_net_dev(dev);
+	struct emac_instance *dev_ins = netdev_priv(ndev);
+
+	long tmp = simple_strtol(buf, NULL, 10);
+	if (emac_has_feature(dev_ins, EMAC_FTR_HAS_TAH)) tah_set_ssr(dev_ins->tah_dev, 4, tmp);	
+	return count;
+}
+
+static ssize_t show_tah_ssr5(struct device *dev, struct device_attribute *attr, char *buf) {
+	struct net_device *ndev = to_net_dev(dev);
+	struct emac_instance *dev_ins = netdev_priv(ndev);
+
+	if (emac_has_feature(dev_ins, EMAC_FTR_HAS_TAH))
+		return sprintf(buf, "%d\n", TAH_SSR_2_SS(tah_get_ssr(dev_ins->tah_dev, 5)) << 1);
+	return 0;
+}
+
+static ssize_t store_tah_ssr5(struct device *dev, struct device_attribute *attr,
+	const char *buf, size_t count) {
+	struct net_device *ndev = to_net_dev(dev);
+	struct emac_instance *dev_ins = netdev_priv(ndev);
+
+	long tmp = simple_strtol(buf, NULL, 10);
+	if (emac_has_feature(dev_ins, EMAC_FTR_HAS_TAH)) tah_set_ssr(dev_ins->tah_dev, 5, tmp);	
+	return count;
+}
+#endif
+
+#if defined(CONFIG_IBM_EMAC_INTR_COALESCE)
+static DEVICE_ATTR(coalesce_param_tx_count, S_IRUGO | S_IWUSR, show_tx_count, store_tx_count);
+static DEVICE_ATTR(coalesce_param_rx_count, S_IRUGO | S_IWUSR, show_rx_count, store_rx_count);
+static DEVICE_ATTR(coalesce_param_tx_time, S_IRUGO | S_IWUSR, show_tx_time, store_tx_time);
+static DEVICE_ATTR(coalesce_param_rx_time, S_IRUGO | S_IWUSR, show_rx_time, store_rx_time);
+#endif
+
+#if defined(CONFIG_IBM_EMAC_TAH)
+static DEVICE_ATTR(tah_ssr0, S_IRUGO | S_IWUSR, show_tah_ssr0, store_tah_ssr0);
+static DEVICE_ATTR(tah_ssr1, S_IRUGO | S_IWUSR, show_tah_ssr1, store_tah_ssr1);
+static DEVICE_ATTR(tah_ssr2, S_IRUGO | S_IWUSR, show_tah_ssr2, store_tah_ssr2);
+static DEVICE_ATTR(tah_ssr3, S_IRUGO | S_IWUSR, show_tah_ssr3, store_tah_ssr3);
+static DEVICE_ATTR(tah_ssr4, S_IRUGO | S_IWUSR, show_tah_ssr4, store_tah_ssr4);
+static DEVICE_ATTR(tah_ssr5, S_IRUGO | S_IWUSR, show_tah_ssr5, store_tah_ssr5);
+#endif
+
+#if defined(CONFIG_APM821xx) && defined(CONFIG_IBM_EMAC_MASK_CEXT)
+static DEVICE_ATTR(emi_fix_enable, S_IRUGO | S_IWUSR, show_emi_fix_enable, store_emi_fix_enable);
+#endif
+
+static struct attribute *ibm_newemac_attr[] = {
+#if defined(CONFIG_IBM_EMAC_INTR_COALESCE)
+	&dev_attr_coalesce_param_tx_count.attr,	&dev_attr_coalesce_param_rx_count.attr,
+	&dev_attr_coalesce_param_tx_time.attr,	&dev_attr_coalesce_param_rx_time.attr,
+#endif
+
+#if defined(CONFIG_IBM_EMAC_TAH)
+	&dev_attr_tah_ssr0.attr, &dev_attr_tah_ssr1.attr, &dev_attr_tah_ssr2.attr,
+	&dev_attr_tah_ssr3.attr, &dev_attr_tah_ssr4.attr, &dev_attr_tah_ssr5.attr,
+#endif
+
+#if defined(CONFIG_APM821xx) && defined(CONFIG_IBM_EMAC_MASK_CEXT)
+	&dev_attr_emi_fix_enable.attr,
+#endif
+	NULL
 };
 
-static int emac_ioctl(struct net_device *ndev, struct ifreq *rq, int cmd)
-{
+static const struct attribute_group ibm_newemac_attr_group = {
+	.attrs = ibm_newemac_attr,
+};
+
+#endif
+
+/* IOCTL support for the interface */
+static int emac_ioctl(struct net_device *ndev, struct ifreq *rq, int cmd) {
 	struct emac_instance *dev = netdev_priv(ndev);
 	struct mii_ioctl_data *data = if_mii(rq);
 
 	DBG(dev, "ioctl %08x" NL, cmd);
-
-	if (dev->phy.address < 0)
-		return -EOPNOTSUPP;
+	if (dev->phy.address < 0) return -EOPNOTSUPP;
 
 	switch (cmd) {
-	case SIOCGMIIPHY:
-		data->phy_id = dev->phy.address;
-		/* Fall through */
-	case SIOCGMIIREG:
-		data->val_out = emac_mdio_read(ndev, dev->phy.address,
-					       data->reg_num);
+	case SIOCGMIIPHY:	data->phy_id = dev->phy.address;	/* Fall through */
+	case SIOCGMIIREG:	data->val_out = emac_mdio_read(ndev, dev->phy.address, data->reg_num);
 		return 0;
-
-	case SIOCSMIIREG:
-		emac_mdio_write(ndev, dev->phy.address, data->reg_num,
-				data->val_in);
+	case SIOCSMIIREG:	emac_mdio_write(ndev, dev->phy.address, data->reg_num, data->val_in);
 		return 0;
-	default:
-		return -EOPNOTSUPP;
+	default:			return -EOPNOTSUPP;
 	}
 }
 
@@ -2317,9 +2387,7 @@
 #define	EMAC_DEP_PREV_IDX	5
 #define	EMAC_DEP_COUNT		6
 
-static int emac_check_deps(struct emac_instance *dev,
-			   struct emac_depentry *deps)
-{
+static int emac_check_deps(struct emac_instance *dev, struct emac_depentry *deps) {
 	int i, there = 0;
 	struct device_node *np;
 
@@ -2337,27 +2405,19 @@
 				there++;
 				continue;
 			}
-			if (deps[i].node == NULL)
-				deps[i].node = of_node_get(np);
+			if (deps[i].node == NULL) deps[i].node = of_node_get(np);
 		}
-		if (deps[i].node == NULL)
-			deps[i].node = of_find_node_by_phandle(deps[i].phandle);
-		if (deps[i].node == NULL)
-			continue;
-		if (deps[i].ofdev == NULL)
-			deps[i].ofdev = of_find_device_by_node(deps[i].node);
-		if (deps[i].ofdev == NULL)
-			continue;
-		if (deps[i].drvdata == NULL)
-			deps[i].drvdata = platform_get_drvdata(deps[i].ofdev);
-		if (deps[i].drvdata != NULL)
-			there++;
+		if (deps[i].node == NULL) 	deps[i].node = of_find_node_by_phandle(deps[i].phandle);
+		if (deps[i].node == NULL) 	continue;
+		if (deps[i].ofdev == NULL)	deps[i].ofdev = of_find_device_by_node(deps[i].node);
+		if (deps[i].ofdev == NULL)	continue;
+		if (deps[i].drvdata == NULL) deps[i].drvdata = platform_get_drvdata(deps[i].ofdev);
+		if (deps[i].drvdata != NULL) there++;
 	}
-	return there == EMAC_DEP_COUNT;
+	return (there == EMAC_DEP_COUNT);
 }
 
-static void emac_put_deps(struct emac_instance *dev)
-{
+static void emac_put_deps(struct emac_instance *dev) {
 	of_dev_put(dev->mal_dev);
 	of_dev_put(dev->zmii_dev);
 	of_dev_put(dev->rgmii_dev);
@@ -2365,12 +2425,9 @@
 	of_dev_put(dev->tah_dev);
 }
 
-static int emac_of_bus_notify(struct notifier_block *nb, unsigned long action,
-			      void *data)
-{
+static int emac_of_bus_notify(struct notifier_block *nb, unsigned long action, void *data) {
 	/* We are only intereted in device addition */
-	if (action == BUS_NOTIFY_BOUND_DRIVER)
-		wake_up_all(&emac_probe_wait);
+	if (action == BUS_NOTIFY_BOUND_DRIVER) wake_up_all(&emac_probe_wait);
 	return 0;
 }
 
@@ -2378,8 +2435,7 @@
 	.notifier_call = emac_of_bus_notify
 };
 
-static int emac_wait_deps(struct emac_instance *dev)
-{
+static int emac_wait_deps(struct emac_instance *dev) {
 	struct emac_depentry deps[EMAC_DEP_COUNT];
 	int i, err;
 
@@ -2388,22 +2444,16 @@
 	deps[EMAC_DEP_MAL_IDX].phandle = dev->mal_ph;
 	deps[EMAC_DEP_ZMII_IDX].phandle = dev->zmii_ph;
 	deps[EMAC_DEP_RGMII_IDX].phandle = dev->rgmii_ph;
-	if (dev->tah_ph)
-		deps[EMAC_DEP_TAH_IDX].phandle = dev->tah_ph;
-	if (dev->mdio_ph)
-		deps[EMAC_DEP_MDIO_IDX].phandle = dev->mdio_ph;
-	if (dev->blist && dev->blist > emac_boot_list)
-		deps[EMAC_DEP_PREV_IDX].phandle = 0xffffffffu;
+	if (dev->tah_ph)	deps[EMAC_DEP_TAH_IDX].phandle = dev->tah_ph;
+	if (dev->mdio_ph)	deps[EMAC_DEP_MDIO_IDX].phandle = dev->mdio_ph;
+	if (dev->blist && dev->blist > emac_boot_list) deps[EMAC_DEP_PREV_IDX].phandle = 0xffffffffu;
 	bus_register_notifier(&platform_bus_type, &emac_of_bus_notifier);
-	wait_event_timeout(emac_probe_wait,
-			   emac_check_deps(dev, deps),
-			   EMAC_PROBE_DEP_TIMEOUT);
+	wait_event_timeout(emac_probe_wait, emac_check_deps(dev, deps), EMAC_PROBE_DEP_TIMEOUT);
 	bus_unregister_notifier(&platform_bus_type, &emac_of_bus_notifier);
 	err = emac_check_deps(dev, deps) ? 0 : -ENODEV;
 	for (i = 0; i < EMAC_DEP_COUNT; i++) {
 		of_node_put(deps[i].node);
-		if (err)
-			of_dev_put(deps[i].ofdev);
+		if (err) of_dev_put(deps[i].ofdev);
 	}
 	if (err == 0) {
 		dev->mal_dev = deps[EMAC_DEP_MAL_IDX].ofdev;
@@ -2416,23 +2466,246 @@
 	return err;
 }
 
-static int emac_read_uint_prop(struct device_node *np, const char *name,
-			       u32 *val, int fatal)
-{
+static int emac_read_prop(struct device_node *np, const char *name, u32 *val, int fatal) {
 	int len;
 	const u32 *prop = of_get_property(np, name, &len);
 	if (prop == NULL || len < sizeof(u32)) {
-		if (fatal)
-			printk(KERN_ERR "%s: missing %s property\n",
-			       np->full_name, name);
+		if (fatal) printk(KERN_ERR "%s: missing %s property\n", np->full_name, name);
 		return -ENODEV;
 	}
 	*val = *prop;
 	return 0;
 }
 
-static int emac_init_phy(struct emac_instance *dev)
-{
+static void emac_adjust_link(struct net_device *ndev) {
+	struct emac_instance *dev = netdev_priv(ndev);
+	struct phy_device *phy = dev->phy_dev;
+
+	dev->phy.autoneg = phy->autoneg;
+	dev->phy.speed = phy->speed;
+	dev->phy.duplex = phy->duplex;
+	dev->phy.pause = phy->pause;
+	dev->phy.asym_pause = phy->asym_pause;
+	dev->phy.advertising = phy->advertising;
+}
+
+static int emac_mii_bus_read(struct mii_bus *bus, int addr, int regnum) {
+	return emac_mdio_read(bus->priv, addr, regnum);
+}
+
+static int emac_mii_bus_write(struct mii_bus *bus, int addr, int regnum, u16 val) {
+	emac_mdio_write(bus->priv, addr, regnum, val);
+	return 0;
+}
+
+static int emac_mii_bus_reset(struct mii_bus *bus) {
+	struct emac_instance *dev = netdev_priv(bus->priv);
+	int err = emac_reset(dev);
+	if (err) return err;
+	/* Meraki MX60(W)'s uboot will disable the switch and
+	 * a bus reset won't do anything. */
+	emac_mii_reset_phy(&dev->phy);
+	return 0;
+}
+
+static int emac_mdio_setup_aneg(struct mii_phy *phy, u32 advertise) {
+	struct net_device *ndev = phy->dev;
+	struct emac_instance *dev = netdev_priv(ndev);
+
+	dev->phy.autoneg = AUTONEG_ENABLE;
+	dev->phy.speed = SPEED_1000;
+	dev->phy.duplex = DUPLEX_FULL;
+	dev->phy.advertising = advertise;
+	phy->autoneg = AUTONEG_ENABLE;
+	phy->speed = dev->phy.speed;
+	phy->duplex = dev->phy.duplex;
+	phy->advertising = advertise;
+	return phy_start_aneg(dev->phy_dev);
+}
+
+static int emac_mdio_setup_forced(struct mii_phy *phy, int speed, int fd) {
+	struct net_device *ndev = phy->dev;
+	struct emac_instance *dev = netdev_priv(ndev);
+
+	dev->phy.autoneg =  AUTONEG_DISABLE;
+	dev->phy.speed = speed;
+	dev->phy.duplex = fd;
+	phy->autoneg = AUTONEG_DISABLE;
+	phy->speed = speed;
+	phy->duplex = fd;
+	return phy_start_aneg(dev->phy_dev);
+}
+
+static int emac_mdio_poll_link(struct mii_phy *phy) {
+	struct net_device *ndev = phy->dev;
+	struct emac_instance *dev = netdev_priv(ndev);
+	int res= phy_read_status(dev->phy_dev);
+	if (res) {
+		dev_err(&dev->ofdev->dev, "link update failed (%d).", res);
+		return ethtool_op_get_link(ndev);
+	}
+
+	return dev->phy_dev->link;
+}
+
+static int emac_mdio_read_link(struct mii_phy *phy) {
+	struct net_device *ndev = phy->dev;
+	struct emac_instance *dev = netdev_priv(ndev);
+	int res = phy_read_status(dev->phy_dev);
+	if (res) return res;
+
+	dev->phy.speed = phy->speed;
+	dev->phy.duplex = phy->duplex;
+	dev->phy.pause = phy->pause;
+	dev->phy.asym_pause = phy->asym_pause;
+	return 0;
+}
+
+static int emac_mdio_init_phy(struct mii_phy *phy) {
+	struct net_device *ndev = phy->dev;
+	struct emac_instance *dev = netdev_priv(ndev);
+
+	phy_start(dev->phy_dev);
+	dev->phy.autoneg = phy->autoneg;
+	dev->phy.speed = phy->speed;
+	dev->phy.duplex = phy->duplex;
+	dev->phy.advertising = phy->advertising;
+	dev->phy.pause = phy->pause;
+	dev->phy.asym_pause = phy->asym_pause;
+
+	return phy_init_hw(dev->phy_dev);
+}
+
+static const struct mii_phy_ops emac_dt_mdio_phy_ops = {
+	.init		= emac_mdio_init_phy,
+	.setup_aneg	= emac_mdio_setup_aneg,
+	.setup_forced	= emac_mdio_setup_forced,
+	.poll_link	= emac_mdio_poll_link,
+	.read_link	= emac_mdio_read_link,
+};
+
+static int emac_dt_mdio_probe(struct emac_instance *dev) {
+	struct device_node *mii_np;
+	int res;
+
+	mii_np = of_get_child_by_name(dev->ofdev->dev.of_node, "mdio");
+	if (!mii_np) {
+		dev_err(&dev->ofdev->dev, "no mdio definition found.");
+		return -ENODEV;
+	}
+
+	if (!of_device_is_available(mii_np)) {
+		res = 1;
+		goto put_node;
+	}
+
+	dev->mii_bus = devm_mdiobus_alloc(&dev->ofdev->dev);
+	if (!dev->mii_bus) {
+		res = -ENOMEM;
+		goto put_node;
+	}
+
+	dev->mii_bus->priv = dev->ndev;
+	dev->mii_bus->parent = dev->ndev->dev.parent;
+	dev->mii_bus->name = "emac_mdio";
+	dev->mii_bus->read = &emac_mii_bus_read;
+	dev->mii_bus->write = &emac_mii_bus_write;
+	dev->mii_bus->reset = &emac_mii_bus_reset;
+	snprintf(dev->mii_bus->id, MII_BUS_ID_SIZE, "%s", dev->ofdev->name);
+	res = of_mdiobus_register(dev->mii_bus, mii_np);
+	if (res) dev_err(&dev->ofdev->dev, "cannot register MDIO bus %s (%d)", dev->mii_bus->name, res);
+
+ put_node:
+	of_node_put(mii_np);
+	return res;
+}
+
+static int emac_dt_phy_connect(struct emac_instance *dev, struct device_node *phy_handle) {
+	dev->phy.def = devm_kzalloc(&dev->ofdev->dev, sizeof(*dev->phy.def), GFP_KERNEL);
+	if (!dev->phy.def) return -ENOMEM;
+
+	dev->phy_dev = of_phy_connect(dev->ndev, phy_handle, &emac_adjust_link, 0, dev->phy_mode);
+	if (!dev->phy_dev) {
+		dev_err(&dev->ofdev->dev, "failed to connect to PHY.\n");
+		return -ENODEV;
+	}
+
+	dev->phy.def->phy_id = dev->phy_dev->drv->phy_id;
+	dev->phy.def->phy_id_mask = dev->phy_dev->drv->phy_id_mask;
+	dev->phy.def->name = dev->phy_dev->drv->name;
+	dev->phy.def->ops = &emac_dt_mdio_phy_ops;
+	dev->phy.features = dev->phy_dev->supported;
+	dev->phy.address = dev->phy_dev->mdio.addr;
+	dev->phy.mode = dev->phy_dev->interface;
+	return 0;
+}
+
+static int emac_dt_phy_probe(struct emac_instance *dev) {
+	int res = 1;
+	struct device_node *np = dev->ofdev->dev.of_node;
+	struct device_node *phy_handle = of_parse_phandle(np, "phy-handle", 0);
+
+	if (phy_handle) {
+		res = emac_dt_mdio_probe(dev);
+		if (!res) {
+			res = emac_dt_phy_connect(dev, phy_handle);
+			if (res) mdiobus_unregister(dev->mii_bus);
+		}
+	}
+
+	of_node_put(phy_handle);
+	return res;
+}
+
+/*
+static int emac_dt_phy_probe(struct emac_instance *dev) {
+	int res = 1;
+	struct device_node *np = dev->ofdev->dev.of_node;
+	struct device_node *phy_handle = of_parse_phandle(np, "phy-handle", 0);
+	u32 phy_flags = 0;
+	int res = of_property_read_u32(phy_handle, "phy-flags", &phy_flags);
+	if (res < 0 && res != -EINVAL) return res;
+
+	dev->phy.def = devm_kzalloc(&dev->ofdev->dev, sizeof(*dev->phy.def), GFP_KERNEL);
+	if (!dev->phy.def) return -ENOMEM;
+
+	dev->phy_dev = of_phy_connect(dev->ndev, phy_handle, &emac_adjust_link, phy_flags,
+				      PHY_INTERFACE_MODE_RGMII);
+	if (!dev->phy_dev) {
+		dev_err(&dev->ofdev->dev, "failed to connect to PHY.\n");
+		return -ENODEV;
+	}
+
+	dev->phy.def->phy_id = dev->phy_dev->drv->phy_id;
+	dev->phy.def->phy_id_mask = dev->phy_dev->drv->phy_id_mask;
+	dev->phy.def->name = dev->phy_dev->drv->name;
+	dev->phy.def->ops = &emac_dt_mdio_phy_ops;
+	dev->phy.features = dev->phy_dev->supported;
+	dev->phy.address = dev->phy_dev->mdio.addr;
+	dev->phy.mode = dev->phy_dev->interface;
+	return 0;
+}
+
+static int emac_probe_dt_phy(struct emac_instance *dev) {
+	struct device_node *np = dev->ofdev->dev.of_node;
+	int res = 0;
+
+	struct device_node *phy_handle = of_parse_phandle(np, "phy-handle", 0);
+	if (phy_handle) {
+		res = emac_dt_mdio_probe(dev);
+		if (!res) {
+			res = emac_dt_phy_probe(dev, phy_handle);
+			if (!res) res = 1;
+			else mdiobus_unregister(dev->mii_bus);
+		}
+	}
+
+	of_node_put(phy_handle);
+	// if no phy device was specified in the device tree, then we fallback to the old emac_phy.c probe code for compatibility reasons
+	return res;
+}
+*/
+static int emac_init_phy(struct emac_instance *dev) {
 	struct device_node *np = dev->ofdev->dev.of_node;
 	struct net_device *ndev = dev->ndev;
 	u32 phy_map, adv;
@@ -2447,17 +2720,12 @@
 	if (dev->phy_address == 0xffffffff && dev->phy_map == 0xffffffff) {
 		emac_reset(dev);
 
-		/* PHY-less configuration.
-		 * XXX I probably should move these settings to the dev tree
-		 */
+		/* PHY-less configuration. Probably should move these settings to the dev tree */
 		dev->phy.address = -1;
 		dev->phy.features = SUPPORTED_MII;
-		if (emac_phy_supports_gige(dev->phy_mode))
-			dev->phy.features |= SUPPORTED_1000baseT_Full;
-		else
-			dev->phy.features |= SUPPORTED_100baseT_Full;
+		if (emac_phy_supports_gige(dev->phy_mode)) dev->phy.features |= SUPPORTED_1000baseT_Full;
+		else dev->phy.features |= SUPPORTED_100baseT_Full;
 		dev->phy.pause = 1;
-
 		return 0;
 	}
 
@@ -2486,23 +2754,27 @@
 	 * This is needed mostly for 440GX
 	 */
 	if (emac_phy_gpcs(dev->phy.mode)) {
-		/* XXX
-		 * Make GPCS PHY address equal to EMAC index.
-		 * We probably should take into account busy_phy_map
-		 * and/or phy_map here.
-		 *
-		 * Note that the busy_phy_map is currently global
-		 * while it should probably be per-ASIC...
-		 */
+		/* Make GPCS PHY address equal to EMAC index.
+		 * We probably should take into account busy_phy_map and/or phy_map here.
+		 * Note that the busy_phy_map is currently global while it should probably be per-ASIC */
 		dev->phy.gpcs_address = dev->gpcs_address;
-		if (dev->phy.gpcs_address == 0xffffffff)
-			dev->phy.address = dev->cell_index;
+		if (dev->phy.gpcs_address == 0xffffffff) dev->phy.address = dev->cell_index;
 	}
 
 	emac_configure(dev);
 
-	if (dev->phy_address != 0xffffffff)
-		phy_map = ~(1 << dev->phy_address);
+	if (emac_has_feature(dev, EMAC_FTR_HAS_RGMII)) {
+		int res = emac_dt_phy_probe(dev);
+		if (res != 1) {
+			mutex_unlock(&emac_phy_map_lock);
+			if (res == 0) goto init_phy;	
+			dev_err(&dev->ofdev->dev, "failed to attach dt phy (%d).\n", res);
+			return res;
+		}
+		// else = No phy-handle property configured. Continue with the existing phy probe and setup code
+	}
+
+	if (dev->phy_address != 0xffffffff)	phy_map = ~(1 << dev->phy_address);
 
 	for (i = 0; i < 0x20; phy_map >>= 1, ++i)
 		if (!(phy_map & 1)) {
@@ -2511,10 +2783,8 @@
 
 			/* Quick check if there is a PHY at the address */
 			r = emac_mdio_read(dev->ndev, i, MII_BMCR);
-			if (r == 0xffff || r < 0)
-				continue;
-			if (!emac_mii_phy_probe(&dev->phy, i))
-				break;
+			if (r == 0xffff || r < 0) continue;
+			if (!emac_mii_phy_probe(&dev->phy, i)) break;
 		}
 
 	/* Enable external clock source */
@@ -2528,6 +2798,7 @@
 		return -ENXIO;
 	}
 
+ init_phy:
 	/* Init PHY */
 	if (dev->phy.def->ops->init)
 		dev->phy.def->ops->init(&dev->phy);
@@ -2551,15 +2822,12 @@
 		if (f & SUPPORTED_1000baseT_Full) {
 			speed = SPEED_1000;
 			fd = DUPLEX_FULL;
-		} else if (f & SUPPORTED_1000baseT_Half)
-			speed = SPEED_1000;
+		} else if (f & SUPPORTED_1000baseT_Half) speed = SPEED_1000;
 		else if (f & SUPPORTED_100baseT_Full) {
 			speed = SPEED_100;
 			fd = DUPLEX_FULL;
-		} else if (f & SUPPORTED_100baseT_Half)
-			speed = SPEED_100;
-		else if (f & SUPPORTED_10baseT_Full)
-			fd = DUPLEX_FULL;
+		} else if (f & SUPPORTED_100baseT_Half)	speed = SPEED_100;
+		else if (f & SUPPORTED_10baseT_Full) fd = DUPLEX_FULL;
 
 		/* Force link parameters */
 		dev->phy.def->ops->setup_forced(&dev->phy, speed, fd);
@@ -2567,94 +2835,68 @@
 	return 0;
 }
 
-static int emac_init_config(struct emac_instance *dev)
-{
+static int emac_init_config(struct emac_instance *dev) {
 	struct device_node *np = dev->ofdev->dev.of_node;
 	const void *p;
 
 	/* Read config from device-tree */
-	if (emac_read_uint_prop(np, "mal-device", &dev->mal_ph, 1))
-		return -ENXIO;
-	if (emac_read_uint_prop(np, "mal-tx-channel", &dev->mal_tx_chan, 1))
-		return -ENXIO;
-	if (emac_read_uint_prop(np, "mal-rx-channel", &dev->mal_rx_chan, 1))
-		return -ENXIO;
-	if (emac_read_uint_prop(np, "cell-index", &dev->cell_index, 1))
-		return -ENXIO;
-	if (emac_read_uint_prop(np, "max-frame-size", &dev->max_mtu, 0))
-		dev->max_mtu = 1500;
-	if (emac_read_uint_prop(np, "rx-fifo-size", &dev->rx_fifo_size, 0))
-		dev->rx_fifo_size = 2048;
-	if (emac_read_uint_prop(np, "tx-fifo-size", &dev->tx_fifo_size, 0))
-		dev->tx_fifo_size = 2048;
-	if (emac_read_uint_prop(np, "rx-fifo-size-gige", &dev->rx_fifo_size_gige, 0))
-		dev->rx_fifo_size_gige = dev->rx_fifo_size;
-	if (emac_read_uint_prop(np, "tx-fifo-size-gige", &dev->tx_fifo_size_gige, 0))
-		dev->tx_fifo_size_gige = dev->tx_fifo_size;
-	if (emac_read_uint_prop(np, "phy-address", &dev->phy_address, 0))
-		dev->phy_address = 0xffffffff;
-	if (emac_read_uint_prop(np, "phy-map", &dev->phy_map, 0))
-		dev->phy_map = 0xffffffff;
-	if (emac_read_uint_prop(np, "gpcs-address", &dev->gpcs_address, 0))
-		dev->gpcs_address = 0xffffffff;
-	if (emac_read_uint_prop(np->parent, "clock-frequency", &dev->opb_bus_freq, 1))
-		return -ENXIO;
-	if (emac_read_uint_prop(np, "tah-device", &dev->tah_ph, 0))
-		dev->tah_ph = 0;
-	if (emac_read_uint_prop(np, "tah-channel", &dev->tah_port, 0))
-		dev->tah_port = 0;
-	if (emac_read_uint_prop(np, "mdio-device", &dev->mdio_ph, 0))
-		dev->mdio_ph = 0;
-	if (emac_read_uint_prop(np, "zmii-device", &dev->zmii_ph, 0))
-		dev->zmii_ph = 0;
-	if (emac_read_uint_prop(np, "zmii-channel", &dev->zmii_port, 0))
-		dev->zmii_port = 0xffffffff;
-	if (emac_read_uint_prop(np, "rgmii-device", &dev->rgmii_ph, 0))
-		dev->rgmii_ph = 0;
-	if (emac_read_uint_prop(np, "rgmii-channel", &dev->rgmii_port, 0))
-		dev->rgmii_port = 0xffffffff;
-	if (emac_read_uint_prop(np, "fifo-entry-size", &dev->fifo_entry_size, 0))
-		dev->fifo_entry_size = 16;
-	if (emac_read_uint_prop(np, "mal-burst-size", &dev->mal_burst_size, 0))
-		dev->mal_burst_size = 256;
+	if (emac_read_prop(np, "mal-device", &dev->mal_ph, 1))	return -ENXIO;
+	if (emac_read_prop(np, "mal-tx-channel", &dev->mal_tx_chan, 1)) return -ENXIO;
+	if (emac_read_prop(np, "mal-rx-channel", &dev->mal_rx_chan, 1)) return -ENXIO;
+	if (emac_read_prop(np, "cell-index", &dev->cell_index, 1))	return -ENXIO;
+	if (emac_read_prop(np, "max-frame-size", &dev->max_mtu, 0)) dev->max_mtu = ETH_DATA_LEN;
+	if (emac_read_prop(np, "rx-fifo-size", &dev->rx_fifo_size, 0))	dev->rx_fifo_size = 2048;
+	if (emac_read_prop(np, "tx-fifo-size", &dev->tx_fifo_size, 0))	dev->tx_fifo_size = 2048;
+	if (emac_read_prop(np, "rx-fifo-size-gige", &dev->rx_fifo_size_gige, 0)) dev->rx_fifo_size_gige = dev->rx_fifo_size;
+	if (emac_read_prop(np, "tx-fifo-size-gige", &dev->tx_fifo_size_gige, 0)) dev->tx_fifo_size_gige = dev->tx_fifo_size;
+	if (emac_read_prop(np, "phy-address", &dev->phy_address, 0)) dev->phy_address = 0xffffffff;
+	if (emac_read_prop(np, "phy-map", &dev->phy_map, 0)) dev->phy_map = 0xffffffff;
+	if (emac_read_prop(np, "gpcs-address", &dev->gpcs_address, 0)) dev->gpcs_address = 0xffffffff;
+	if (emac_read_prop(np->parent, "clock-frequency", &dev->opb_bus_freq, 1)) return -ENXIO;
+#ifdef CONFIG_IBM_EMAC_INTR_COALESCE
+	if (emac_read_prop(np->parent->parent, "clock-frequency", &dev->plb_bus_freq, 1)) return -ENXIO;
+	dev->plb_bus_freq /= 1000000;		/* save as MHz */
+#endif
+	if (emac_read_prop(np, "tah-device", &dev->tah_ph, 0)) dev->tah_ph = 0;
+	if (emac_read_prop(np, "tah-channel", &dev->tah_port, 0)) dev->tah_port = 0;
+	if (emac_read_prop(np, "mdio-device", &dev->mdio_ph, 0)) dev->mdio_ph = 0;
+	if (emac_read_prop(np, "zmii-device", &dev->zmii_ph, 0)) dev->zmii_ph = 0;
+	if (emac_read_prop(np, "zmii-channel", &dev->zmii_port, 0))	dev->zmii_port = 0xffffffff;
+	if (emac_read_prop(np, "rgmii-device", &dev->rgmii_ph, 0)) dev->rgmii_ph = 0;
+	if (emac_read_prop(np, "rgmii-channel", &dev->rgmii_port, 0)) dev->rgmii_port = 0xffffffff;
+	if (emac_read_prop(np, "fifo-entry-size", &dev->fifo_entry_size, 0)) dev->fifo_entry_size = 16;
+	if (emac_read_prop(np, "mal-burst-size", &dev->mal_burst_size, 0))	dev->mal_burst_size = 256;
 
 	/* PHY mode needs some decoding */
-	dev->phy_mode = of_get_phy_mode(np);
-	if (dev->phy_mode < 0)
-		dev->phy_mode = PHY_MODE_NA;
+	dev->phy_mode = of_get_phy_mode(np);	/* Decode PHY-mode */
+	if (dev->phy_mode < 0) dev->phy_mode = PHY_MODE_NA;
 
 	/* Check EMAC version */
 	if (of_device_is_compatible(np, "ibm,emac4sync")) {
 		dev->features |= (EMAC_FTR_EMAC4 | EMAC_FTR_EMAC4SYNC);
-		if (of_device_is_compatible(np, "ibm,emac-460ex") ||
-		    of_device_is_compatible(np, "ibm,emac-460gt"))
+		if (of_device_is_compatible(np, "ibm,emac-460ex") || of_device_is_compatible(np, "ibm,emac-460gt"))
 			dev->features |= EMAC_FTR_460EX_PHY_CLK_FIX;
-		if (of_device_is_compatible(np, "ibm,emac-405ex") ||
-		    of_device_is_compatible(np, "ibm,emac-405exr"))
+		if (of_device_is_compatible(np, "ibm,emac-405ex") || of_device_is_compatible(np, "ibm,emac-405exr"))
 			dev->features |= EMAC_FTR_440EP_PHY_CLK_FIX;
-		if (of_device_is_compatible(np, "ibm,emac-apm821xx")) {
+		if (of_device_is_compatible(np, "ibm,emac-apm821xx"))
 			dev->features |= (EMAC_APM821XX_REQ_JUMBO_FRAME_SIZE |
-					  EMAC_FTR_APM821XX_NO_HALF_DUPLEX |
-					  EMAC_FTR_460EX_PHY_CLK_FIX);
-		}
+				EMAC_FTR_APM821XX_NO_HALF_DUPLEX | EMAC_FTR_APM821XX_PHY_CLK_FIX);
+
 	} else if (of_device_is_compatible(np, "ibm,emac4")) {
 		dev->features |= EMAC_FTR_EMAC4;
 		if (of_device_is_compatible(np, "ibm,emac-440gx"))
 			dev->features |= EMAC_FTR_440GX_PHY_CLK_FIX;
 	} else {
-		if (of_device_is_compatible(np, "ibm,emac-440ep") ||
-		    of_device_is_compatible(np, "ibm,emac-440gr"))
+		if (of_device_is_compatible(np, "ibm,emac-440ep") || of_device_is_compatible(np, "ibm,emac-440gr"))
 			dev->features |= EMAC_FTR_440EP_PHY_CLK_FIX;
 		if (of_device_is_compatible(np, "ibm,emac-405ez")) {
 #ifdef CONFIG_IBM_EMAC_NO_FLOW_CTRL
 			dev->features |= EMAC_FTR_NO_FLOW_CONTROL_40x;
 #else
-			printk(KERN_ERR "%s: Flow control not disabled!\n",
-					np->full_name);
+			printk(KERN_ERR "%s: Flow control not disabled!\n", np->full_name);
 			return -ENXIO;
 #endif
 		}
-
 	}
 
 	/* Fixup some feature bits based on the device tree */
@@ -2665,16 +2907,14 @@
 
 	/* CAB lacks the appropriate properties */
 	if (of_device_is_compatible(np, "ibm,emac-axon"))
-		dev->features |= EMAC_FTR_HAS_NEW_STACR |
-			EMAC_FTR_STACR_OC_INVERT;
+		dev->features |= EMAC_FTR_HAS_NEW_STACR | EMAC_FTR_STACR_OC_INVERT;
 
 	/* Enable TAH/ZMII/RGMII features as found */
 	if (dev->tah_ph != 0) {
 #ifdef CONFIG_IBM_EMAC_TAH
 		dev->features |= EMAC_FTR_HAS_TAH;
 #else
-		printk(KERN_ERR "%s: TAH support not enabled !\n",
-		       np->full_name);
+		printk(KERN_ERR "%s: TAH support not enabled !\n", np->full_name);
 		return -ENXIO;
 #endif
 	}
@@ -2683,8 +2923,7 @@
 #ifdef CONFIG_IBM_EMAC_ZMII
 		dev->features |= EMAC_FTR_HAS_ZMII;
 #else
-		printk(KERN_ERR "%s: ZMII support not enabled !\n",
-		       np->full_name);
+		printk(KERN_ERR "%s: ZMII support not enabled !\n", np->full_name);
 		return -ENXIO;
 #endif
 	}
@@ -2693,8 +2932,7 @@
 #ifdef CONFIG_IBM_EMAC_RGMII
 		dev->features |= EMAC_FTR_HAS_RGMII;
 #else
-		printk(KERN_ERR "%s: RGMII support not enabled !\n",
-		       np->full_name);
+		printk(KERN_ERR "%s: RGMII support not enabled !\n", np->full_name);
 		return -ENXIO;
 #endif
 	}
@@ -2702,8 +2940,7 @@
 	/* Read MAC-address */
 	p = of_get_property(np, "local-mac-address", NULL);
 	if (p == NULL) {
-		printk(KERN_ERR "%s: Can't find local-mac-address property\n",
-		       np->full_name);
+		printk(KERN_ERR "%s: Can't find local-mac-address property\n", np->full_name);
 		return -ENXIO;
 	}
 	memcpy(dev->ndev->dev_addr, p, ETH_ALEN);
@@ -2716,6 +2953,9 @@
 		dev->xaht_slots_shift = EMAC4_XAHT_SLOTS_SHIFT;
 		dev->xaht_width_shift = EMAC4_XAHT_WIDTH_SHIFT;
 	}
+	/* This should never happen */
+	if (WARN_ON(EMAC_XAHT_REGS(dev) > EMAC_XAHT_MAX_REGS))
+		return -ENXIO;
 
 	DBG(dev, "features     : 0x%08x / 0x%08x\n", dev->features, EMAC_FTRS_POSSIBLE);
 	DBG(dev, "tx_fifo_size : %d (%d gige)\n", dev->tx_fifo_size, dev->tx_fifo_size_gige);
@@ -2725,7 +2965,9 @@
 
 	return 0;
 }
-
+#ifdef CONFIG_NET_POLL_CONTROLLER
+static void emac_netpoll(struct net_device *dev){}
+#endif
 static const struct net_device_ops emac_netdev_ops = {
 	.ndo_open		= emac_open,
 	.ndo_stop		= emac_close,
@@ -2734,9 +2976,12 @@
 	.ndo_do_ioctl		= emac_ioctl,
 	.ndo_tx_timeout		= emac_tx_timeout,
 	.ndo_validate_addr	= eth_validate_addr,
-	.ndo_set_mac_address	= emac_set_mac_address,
+	.ndo_set_mac_address= emac_set_mac_address,
 	.ndo_start_xmit		= emac_start_xmit,
 	.ndo_change_mtu		= eth_change_mtu,
+#ifdef CONFIG_NET_POLL_CONTROLLER
+	.ndo_poll_controller= emac_netpoll,
+#endif
 };
 
 static const struct net_device_ops emac_gige_netdev_ops = {
@@ -2747,36 +2992,34 @@
 	.ndo_do_ioctl		= emac_ioctl,
 	.ndo_tx_timeout		= emac_tx_timeout,
 	.ndo_validate_addr	= eth_validate_addr,
-	.ndo_set_mac_address	= emac_set_mac_address,
+	.ndo_set_mac_address= emac_set_mac_address,
 	.ndo_start_xmit		= emac_start_xmit_sg,
 	.ndo_change_mtu		= emac_change_mtu,
+#ifdef CONFIG_NET_POLL_CONTROLLER
+	.ndo_poll_controller= emac_netpoll,
+#endif
 };
 
-static int emac_probe(struct platform_device *ofdev)
-{
+static int emac_probe(struct platform_device *ofdev) {
 	struct net_device *ndev;
 	struct emac_instance *dev;
 	struct device_node *np = ofdev->dev.of_node;
 	struct device_node **blist = NULL;
 	int err, i;
 
-	/* Skip unused/unwired EMACS.  We leave the check for an unused
-	 * property here for now, but new flat device trees should set a
-	 * status property to "disabled" instead.
-	 */
+	/* Skip unused/unwired EMACS.  We leave the check for an unused property here for now, 
+	 * but new flat device trees should set a status property to "disabled" instead. */
 	if (of_get_property(np, "unused", NULL) || !of_device_is_available(np))
 		return -ENODEV;
 
 	/* Find ourselves in the bootlist if we are there */
 	for (i = 0; i < EMAC_BOOT_LIST_SIZE; i++)
-		if (emac_boot_list[i] == np)
-			blist = &emac_boot_list[i];
+		if (emac_boot_list[i] == np) blist = &emac_boot_list[i];
 
 	/* Allocate our net_device structure */
 	err = -ENOMEM;
 	ndev = alloc_etherdev(sizeof(struct emac_instance));
-	if (!ndev)
-		goto err_gone;
+	if (!ndev) goto err_gone;
 
 	dev = netdev_priv(ndev);
 	dev->ndev = ndev;
@@ -2792,8 +3035,7 @@
 
 	/* Init various config data based on device-tree */
 	err = emac_init_config(dev);
-	if (err != 0)
-		goto err_free;
+	if (err != 0) goto err_free;
 
 	/* Get interrupts. EMAC irq is mandatory, WOL irq is optional */
 	dev->emac_irq = irq_of_parse_and_map(np, 0);
@@ -2806,16 +3048,13 @@
 
 	/* Map EMAC regs */
 	if (of_address_to_resource(np, 0, &dev->rsrc_regs)) {
-		printk(KERN_ERR "%s: Can't get registers address\n",
-		       np->full_name);
+		printk(KERN_ERR "%s: Can't get registers address\n", np->full_name);
 		goto err_irq_unmap;
 	}
 	// TODO : request_mem_region
-	dev->emacp = ioremap(dev->rsrc_regs.start,
-			     resource_size(&dev->rsrc_regs));
+	dev->emacp = ioremap(dev->rsrc_regs.start, resource_size(&dev->rsrc_regs));
 	if (dev->emacp == NULL) {
-		printk(KERN_ERR "%s: Can't map device registers!\n",
-		       np->full_name);
+		printk(KERN_ERR "%s: Can't map device registers!\n", np->full_name);
 		err = -ENOMEM;
 		goto err_irq_unmap;
 	}
@@ -2823,15 +3062,12 @@
 	/* Wait for dependent devices */
 	err = emac_wait_deps(dev);
 	if (err) {
-		printk(KERN_ERR
-		       "%s: Timeout waiting for dependent devices\n",
-		       np->full_name);
+		printk(KERN_ERR "%s: Timeout waiting for dependent devices\n", np->full_name);
 		/*  display more info about what's missing ? */
 		goto err_reg_unmap;
 	}
 	dev->mal = platform_get_drvdata(dev->mal_dev);
-	if (dev->mdio_dev != NULL)
-		dev->mdio_instance = platform_get_drvdata(dev->mdio_dev);
+	if (dev->mdio_dev != NULL) dev->mdio_instance = platform_get_drvdata(dev->mdio_dev);
 
 	/* Register with MAL */
 	dev->commac.ops = &emac_commac_ops;
@@ -2861,7 +3097,9 @@
 	memset(dev->rx_desc, 0, NUM_RX_BUFF * sizeof(struct mal_descriptor));
 	memset(dev->tx_skb, 0, NUM_TX_BUFF * sizeof(struct sk_buff *));
 	memset(dev->rx_skb, 0, NUM_RX_BUFF * sizeof(struct sk_buff *));
-
+#ifdef CONFIG_IBM_EMAC_MASK_CEXT
+	atomic_set(&dev->mask_cext_enable, 0);		/* By default: DISABLE EMI fix */
+#endif
 	/* Attach to ZMII, if needed */
 	if (emac_has_feature(dev, EMAC_FTR_HAS_ZMII) &&
 	    (err = zmii_attach(dev->zmii_dev, dev->zmii_port, &dev->phy_mode)) != 0)
@@ -2886,48 +3124,46 @@
 	INIT_DELAYED_WORK(&dev->link_work, emac_link_timer);
 
 	/* Some SoCs like APM821xx does not support Half Duplex mode. */
-	if (emac_has_feature(dev, EMAC_FTR_APM821XX_NO_HALF_DUPLEX)) {
-		dev->phy_feat_exc = (SUPPORTED_1000baseT_Half |
-				     SUPPORTED_100baseT_Half |
-				     SUPPORTED_10baseT_Half);
-	}
+	if (emac_has_feature(dev, EMAC_FTR_APM821XX_NO_HALF_DUPLEX))
+		dev->phy_feat_exc = (SUPPORTED_1000baseT_Half| SUPPORTED_100baseT_Half| SUPPORTED_10baseT_Half);
 
 	/* Find PHY if any */
 	err = emac_init_phy(dev);
-	if (err != 0)
-		goto err_detach_tah;
+	if (err != 0) goto err_detach_tah;
 
 	if (dev->tah_dev) {
-		ndev->hw_features = NETIF_F_IP_CSUM | NETIF_F_SG;
+		struct tah_instance *tah_dev = dev_get_drvdata(&dev->tah_dev->dev);
+		ndev->hw_features = NETIF_F_IP_CSUM | NETIF_F_SG  
+#if defined(CONFIG_IBM_EMAC_TAH) && defined(EMAC_HW_TSO)  //ECO
+		| NETIF_F_TSO;
+		dev->ssr = &tah_dev->ssr[0];	// cache in emac for performance reasons
+#else
+		;
+#endif
 		ndev->features |= ndev->hw_features | NETIF_F_RXCSUM;
 	}
 	ndev->watchdog_timeo = 5 * HZ;
 	if (emac_phy_supports_gige(dev->phy_mode)) {
 		ndev->netdev_ops = &emac_gige_netdev_ops;
 		dev->commac.ops = &emac_commac_sg_ops;
-	} else
-		ndev->netdev_ops = &emac_netdev_ops;
+	} else ndev->netdev_ops = &emac_netdev_ops;
 	ndev->ethtool_ops = &emac_ethtool_ops;
 
 	netif_carrier_off(ndev);
 
 	err = register_netdev(ndev);
 	if (err) {
-		printk(KERN_ERR "%s: failed to register net device (%d)!\n",
-		       np->full_name, err);
+		printk(KERN_ERR "%s: failed to register net device (%d)!\n", np->full_name, err);
 		goto err_detach_tah;
 	}
 
-	/* Set our drvdata last as we don't want them visible until we are
-	 * fully initialized
-	 */
+	/* Set our drvdata last as we don't want them visible until we are fully initialized */
 	wmb();
 	platform_set_drvdata(ofdev, dev);
 
 	/* There's a new kid in town ! Let's tell everybody */
 	wake_up_all(&emac_probe_wait);
 
-
 	printk(KERN_INFO "%s: EMAC-%d %s, MAC %pM\n",
 	       ndev->name, dev->cell_index, np->full_name, ndev->dev_addr);
 
@@ -2935,25 +3171,31 @@
 		printk(KERN_NOTICE "%s: in SGMII mode\n", ndev->name);
 
 	if (dev->phy.address >= 0)
-		printk("%s: found %s PHY (0x%02x)\n", ndev->name,
-		       dev->phy.def->name, dev->phy.address);
+		printk("%s: found %s PHY (0x%02x)\n", ndev->name, dev->phy.def->name, dev->phy.address);
 
-	emac_dbg_register(dev);
+	/* performance optimization: cache time crtical register addresses */
+	dev->mr0 = &dev->emacp->mr0; //ECO
+	dev->tmr0 = &dev->emacp->tmr0;
 
-	/* Life is good */
-	return 0;
+	emac_dbg_register(dev);
 
-	/* I have a bad feeling about this ... */
+#if defined(CONFIG_IBM_EMAC_SYSFS)
+	/* Register sys fs hooks */
+	err = sysfs_create_group(&dev->ndev->dev.kobj, &ibm_newemac_attr_group);
+	if (err) {
+		printk("WARN: %s: failed to create sys interfaces for EMAC-%d %s\n",
+		ndev->name, dev->cell_index, np->full_name);
+		goto err_sysfs;
+	}
+#endif
+	return 0;		/* Life is good */
 
  err_detach_tah:
-	if (emac_has_feature(dev, EMAC_FTR_HAS_TAH))
-		tah_detach(dev->tah_dev, dev->tah_port);
+	if (emac_has_feature(dev, EMAC_FTR_HAS_TAH)) tah_detach(dev->tah_dev, dev->tah_port);
  err_detach_rgmii:
-	if (emac_has_feature(dev, EMAC_FTR_HAS_RGMII))
-		rgmii_detach(dev->rgmii_dev, dev->rgmii_port);
+	if (emac_has_feature(dev, EMAC_FTR_HAS_RGMII)) rgmii_detach(dev->rgmii_dev, dev->rgmii_port);
  err_detach_zmii:
-	if (emac_has_feature(dev, EMAC_FTR_HAS_ZMII))
-		zmii_detach(dev->zmii_dev, dev->zmii_port);
+	if (emac_has_feature(dev, EMAC_FTR_HAS_ZMII)) zmii_detach(dev->zmii_dev, dev->zmii_port);
  err_unreg_commac:
 	mal_unregister_commac(dev->mal, &dev->commac);
  err_rel_deps:
@@ -2961,41 +3203,39 @@
  err_reg_unmap:
 	iounmap(dev->emacp);
  err_irq_unmap:
-	if (dev->wol_irq)
-		irq_dispose_mapping(dev->wol_irq);
-	if (dev->emac_irq)
-		irq_dispose_mapping(dev->emac_irq);
+	if (dev->wol_irq)	irq_dispose_mapping(dev->wol_irq);
+	if (dev->emac_irq)	irq_dispose_mapping(dev->emac_irq);
  err_free:
 	free_netdev(ndev);
  err_gone:
 	/* if we were on the bootlist, remove us as we won't show up and
-	 * wake up all waiters to notify them in case they were waiting
-	 * on us
-	 */
+	 * wake up all waiters to notify them in case they were waiting on us */
 	if (blist) {
 		*blist = NULL;
 		wake_up_all(&emac_probe_wait);
 	}
+#if defined(CONFIG_IBM_EMAC_SYSFS)
+ err_sysfs:
+#endif
 	return err;
 }
 
-static int emac_remove(struct platform_device *ofdev)
-{
+static int emac_remove(struct platform_device *ofdev) {
 	struct emac_instance *dev = platform_get_drvdata(ofdev);
 
 	DBG(dev, "remove" NL);
 
+#if defined(CONFIG_IBM_EMAC_SYSFS)
+	sysfs_remove_group(&dev->ndev->dev.kobj, &ibm_newemac_attr_group);
+#endif
 	unregister_netdev(dev->ndev);
-
 	cancel_work_sync(&dev->reset_work);
+	if (emac_has_feature(dev, EMAC_FTR_HAS_TAH))	tah_detach(dev->tah_dev, dev->tah_port);
+	if (emac_has_feature(dev, EMAC_FTR_HAS_RGMII))	rgmii_detach(dev->rgmii_dev, dev->rgmii_port);
+	if (emac_has_feature(dev, EMAC_FTR_HAS_ZMII))	zmii_detach(dev->zmii_dev, dev->zmii_port);
 
-	if (emac_has_feature(dev, EMAC_FTR_HAS_TAH))
-		tah_detach(dev->tah_dev, dev->tah_port);
-	if (emac_has_feature(dev, EMAC_FTR_HAS_RGMII))
-		rgmii_detach(dev->rgmii_dev, dev->rgmii_port);
-	if (emac_has_feature(dev, EMAC_FTR_HAS_ZMII))
-		zmii_detach(dev->zmii_dev, dev->zmii_port);
-
+	if (dev->phy_dev) phy_disconnect(dev->phy_dev);
+	if (dev->mii_bus) mdiobus_unregister(dev->mii_bus);
 	busy_phy_map &= ~(1 << dev->phy.address);
 	DBG(dev, "busy_phy_map now %#x" NL, busy_phy_map);
 
@@ -3005,31 +3245,21 @@
 	emac_dbg_unregister(dev);
 	iounmap(dev->emacp);
 
-	if (dev->wol_irq)
-		irq_dispose_mapping(dev->wol_irq);
-	if (dev->emac_irq)
-		irq_dispose_mapping(dev->emac_irq);
+	if (dev->wol_irq) 	irq_dispose_mapping(dev->wol_irq);
+	if (dev->emac_irq)	irq_dispose_mapping(dev->emac_irq);
 
 	free_netdev(dev->ndev);
-
 	return 0;
 }
 
 /* XXX Features in here should be replaced by properties... */
-static const struct of_device_id emac_match[] =
-{
-	{
-		.type		= "network",
-		.compatible	= "ibm,emac",
-	},
-	{
-		.type		= "network",
-		.compatible	= "ibm,emac4",
-	},
-	{
-		.type		= "network",
-		.compatible	= "ibm,emac4sync",
-	},
+static const struct of_device_id emac_match[] = {
+	{	.type		= "network",
+		.compatible	= "ibm,emac", },
+	{	.type		= "network",
+		.compatible	= "ibm,emac4", },
+	{	.type		= "network",
+		.compatible	= "ibm,emac4sync", },
 	{},
 };
 MODULE_DEVICE_TABLE(of, emac_match);
@@ -3043,8 +3273,7 @@
 	.remove = emac_remove,
 };
 
-static void __init emac_make_bootlist(void)
-{
+static void __init emac_make_bootlist(void) {
 	struct device_node *np = NULL;
 	int j, max, i = 0;
 	int cell_indices[EMAC_BOOT_LIST_SIZE];
@@ -3053,13 +3282,10 @@
 	while((np = of_find_all_nodes(np)) != NULL) {
 		const u32 *idx;
 
-		if (of_match_node(emac_match, np) == NULL)
-			continue;
-		if (of_get_property(np, "unused", NULL))
-			continue;
+		if (of_match_node(emac_match, np) == NULL) continue;
+		if (of_get_property(np, "unused", NULL)) continue;
 		idx = of_get_property(np, "cell-index", NULL);
-		if (idx == NULL)
-			continue;
+		if (idx == NULL) continue;
 		cell_indices[i] = *idx;
 		emac_boot_list[i++] = of_node_get(np);
 		if (i >= EMAC_BOOT_LIST_SIZE) {
@@ -3079,35 +3305,24 @@
 		}
 }
 
-static int __init emac_init(void)
-{
+static int __init emac_init(void) {
 	int rc;
 
 	printk(KERN_INFO DRV_DESC ", version " DRV_VERSION "\n");
-
-	/* Init debug stuff */
-	emac_init_debug();
-
-	/* Build EMAC boot list */
-	emac_make_bootlist();
+	emac_init_debug();			/* Init debug stuff */
+	emac_make_bootlist();		/* Build EMAC boot list */
 
 	/* Init submodules */
 	rc = mal_init();
-	if (rc)
-		goto err;
+	if (rc)	goto err;
 	rc = zmii_init();
-	if (rc)
-		goto err_mal;
+	if (rc)	goto err_mal;
 	rc = rgmii_init();
-	if (rc)
-		goto err_zmii;
+	if (rc)	goto err_zmii;
 	rc = tah_init();
-	if (rc)
-		goto err_rgmii;
+	if (rc)	goto err_rgmii;
 	rc = platform_driver_register(&emac_driver);
-	if (rc)
-		goto err_tah;
-
+	if (rc)	goto err_tah;
 	return 0;
 
  err_tah:
@@ -3122,12 +3337,10 @@
 	return rc;
 }
 
-static void __exit emac_exit(void)
-{
+static void __exit emac_exit(void) {
 	int i;
 
 	platform_driver_unregister(&emac_driver);
-
 	tah_exit();
 	rgmii_exit();
 	zmii_exit();
@@ -3135,8 +3348,7 @@
 	emac_fini_debug();
 
 	/* Destroy EMAC boot list */
-	for (i = 0; i < EMAC_BOOT_LIST_SIZE; i++)
-		of_node_put(emac_boot_list[i]);
+	for (i = 0; i < EMAC_BOOT_LIST_SIZE; i++) of_node_put(emac_boot_list[i]);
 }
 
 module_init(emac_init);
diff -Naur a/drivers/net/ethernet/ibm/emac/core.h b/drivers/net/ethernet/ibm/emac/core.h
--- a/drivers/net/ethernet/ibm/emac/core.h	2019-01-09 0116:16:45.000000000 +0000
+++ b/drivers/net/ethernet/ibm/emac/core.h	2019-02-16 13:50:23.589563000 +0000
@@ -46,13 +46,39 @@
 #include "tah.h"
 #include "debug.h"
 
-#define NUM_TX_BUFF			CONFIG_IBM_EMAC_TXB
-#define NUM_RX_BUFF			CONFIG_IBM_EMAC_RXB
+#define EMAC_HW_TSO
+
+/* MDIO macro's */
+#define CONCAT(x,y,z)		x ## y ## z
+#if defined(CONFIG_IBM_EMAC_RGMII)
+#define MDIO(op, dev)		CONCAT(rgmii_,op,_mdio)(dev->rgmii_dev, dev->rgmii_port)	
+#elif defined (CONFIG_IBM_EMAC_ZMII)
+#define MDIO(op, dev)		CONCAT(zmii_,op,_mdio)(dev->zmii_dev, dev->zmii_port)		
+#endif
+
+#define NUM_TX_BUFF		CONFIG_IBM_EMAC_TXB
+#define NUM_RX_BUFF		CONFIG_IBM_EMAC_RXB
+
+#ifdef CONFIG_IBM_EMAC_MASK_CEXT
+#define TX_FIFO_SYNC_USEC	20
+#endif
 
 /* Simple sanity check */
 #if NUM_TX_BUFF > 256 || NUM_RX_BUFF > 256
 #error Invalid number of buffer descriptors (greater than 256)
 #endif
+#define ISPOWEROF2(X)		((X & (X - 1)) == 0)
+
+#if ISPOWEROF2(NUM_TX_BUFF)
+#define NXT_TX_SLOT(slot)	(slot + 1) & ~NUM_TX_BUFF;
+#else
+#define NXT_TX_SLOT(slot)	(slot + 1) % NUM_TX_BUFF;
+#endif
+#if ISPOWEROF2(NUM_RX_BUFF)
+#define NXT_RX_SLOT(slot)	(slot + 1) & ~NUM_RX_BUFF;
+#else
+#define NXT_RX_SLOT(slot)	(slot + 1) % NUM_RX_BUFF;
+#endif
 
 #define EMAC_MIN_MTU			46
 
@@ -60,29 +86,23 @@
 #define EMAC_MTU_OVERHEAD		(6 * 2 + 2 + 4)
 
 /* RX BD size for the given MTU */
-static inline int emac_rx_size(int mtu)
-{
-	if (mtu > ETH_DATA_LEN)
-		return MAL_MAX_RX_SIZE;
-	else
-		return mal_rx_size(ETH_DATA_LEN + EMAC_MTU_OVERHEAD);
+static inline int emac_rx_size(int mtu) {
+	if (mtu > ETH_DATA_LEN)	return MAL_MAX_RX_SIZE;
+	else return mal_rx_size(ETH_DATA_LEN + EMAC_MTU_OVERHEAD);
 }
 
 #define EMAC_DMA_ALIGN(x)		ALIGN((x), dma_get_cache_alignment())
 
-#define EMAC_RX_SKB_HEADROOM		\
-	EMAC_DMA_ALIGN(CONFIG_IBM_EMAC_RX_SKB_HEADROOM)
+#define EMAC_RX_SKB_HEADROOM	EMAC_DMA_ALIGN(CONFIG_IBM_EMAC_RX_SKB_HEADROOM)
 
 /* Size of RX skb for the given MTU */
-static inline int emac_rx_skb_size(int mtu)
-{
+static inline int emac_rx_skb_size(int mtu) {
 	int size = max(mtu + EMAC_MTU_OVERHEAD, emac_rx_size(mtu));
 	return EMAC_DMA_ALIGN(size + 2) + EMAC_RX_SKB_HEADROOM;
 }
 
 /* RX DMA sync size */
-static inline int emac_rx_sync_size(int mtu)
-{
+static inline int emac_rx_sync_size(int mtu) {
 	return EMAC_DMA_ALIGN(emac_rx_size(mtu) + 2);
 }
 
@@ -162,8 +182,7 @@
 };
 
 #define EMAC_ETHTOOL_STATS_COUNT	((sizeof(struct emac_stats) + \
-					  sizeof(struct emac_error_stats)) \
-					 / sizeof(u64))
+	sizeof(struct emac_error_stats)) / sizeof(u64))
 
 struct emac_instance {
 	struct net_device		*ndev;
@@ -199,6 +218,10 @@
 	struct emac_instance		*mdio_instance;
 	struct mutex			mdio_lock;
 
+	/* Device-tree based phy configuration */
+	struct mii_bus			*mii_bus;
+	struct phy_device		*phy_dev;
+
 	/* ZMII infos if any */
 	u32				zmii_ph;
 	u32				zmii_port;
@@ -221,6 +244,11 @@
 	/* OPB bus frequency in Mhz */
 	u32				opb_bus_freq;
 
+#ifdef CONFIG_IBM_EMAC_INTR_COALESCE
+	/* PLB bus frequency in Mhz */
+	u32				plb_bus_freq;
+#endif
+
 	/* Cell index within an ASIC (for clk mgmnt) */
 	u32				cell_index;
 
@@ -242,8 +270,7 @@
 	u32				xaht_slots_shift;
 	u32				xaht_width_shift;
 
-	/* Descriptor management
-	 */
+	/* Descriptor management */
 	struct mal_descriptor		*tx_desc;
 	int				tx_cnt;
 	int				tx_slot;
@@ -258,117 +285,89 @@
 	struct sk_buff			*tx_skb[NUM_TX_BUFF];
 	struct sk_buff			*rx_skb[NUM_RX_BUFF];
 
-	/* Stats
-	 */
+	/* Stats */
 	struct emac_error_stats		estats;
 	struct net_device_stats		nstats;
 	struct emac_stats 		stats;
 
-	/* Misc
-	 */
+	/* Misc	 */
+#ifdef CONFIG_IBM_EMAC_MASK_CEXT
+	atomic_t			idle_mode;
+	atomic_t 			mask_cext_enable;
+#endif
 	int				reset_failed;
 	int				stop_timeout;	/* in us */
 	int				no_mcast;
 	int				mcast_pending;
 	int				opened;
+	u32 __iomem			*mr0;			/* Special ECO */
+	u32 __iomem			*tmr0;			/* Special ECO */
+#if defined(CONFIG_IBM_EMAC_TAH) && defined(EMAC_HW_TSO)  //ECO
+	u32				*ssr;			/* Special ECO */
+#endif
 	struct work_struct		reset_work;
 	spinlock_t			lock;
 };
 
-/*
- * Features of various EMAC implementations
- */
+/* Features of various EMAC implementations */
 
-/*
- * No flow control on 40x according to the original driver
- */
+/* No flow control on 40x according to the original driver*/
 #define EMAC_FTR_NO_FLOW_CONTROL_40x	0x00000001
-/*
- * Cell is an EMAC4
- */
+/* Cell is an EMAC4 */
 #define EMAC_FTR_EMAC4			0x00000002
-/*
- * For the 440SPe, AMCC inexplicably changed the polarity of
- * the "operation complete" bit in the MII control register.
- */
+/* For the 440SPe, AMCC inexplicably changed the polarity of
+ * the "operation complete" bit in the MII control register */
 #define EMAC_FTR_STACR_OC_INVERT	0x00000004
-/*
- * Set if we have a TAH.
- */
+/* Set if we have a TAH.*/
 #define EMAC_FTR_HAS_TAH		0x00000008
-/*
- * Set if we have a ZMII.
- */
+/* Set if we have a ZMII.*/
 #define EMAC_FTR_HAS_ZMII		0x00000010
-/*
- * Set if we have a RGMII.
- */
+/* Set if we have a RGMII.*/
 #define EMAC_FTR_HAS_RGMII		0x00000020
-/*
- * Set if we have new type STACR with STAOPC
- */
+/* Set if we have new type STACR with STAOPC */
 #define EMAC_FTR_HAS_NEW_STACR		0x00000040
-/*
- * Set if we need phy clock workaround for 440gx
- */
+/* Set if we need phy clock workaround for 440gx */
 #define EMAC_FTR_440GX_PHY_CLK_FIX	0x00000080
-/*
- * Set if we need phy clock workaround for 440ep or 440gr
- */
+/* Set if we need phy clock workaround for 440ep or 440gr */
 #define EMAC_FTR_440EP_PHY_CLK_FIX	0x00000100
-/*
- * The 405EX and 460EX contain the EMAC4SYNC core
- */
+/* The 405EX and 460EX contain the EMAC4SYNC core */
 #define EMAC_FTR_EMAC4SYNC		0x00000200
-/*
- * Set if we need phy clock workaround for 460ex or 460gt
- */
+/* Set if we need phy clock workaround for 460ex or 460gt */
 #define EMAC_FTR_460EX_PHY_CLK_FIX	0x00000400
-/*
- * APM821xx requires Jumbo frame size set explicitly
- */
-#define EMAC_APM821XX_REQ_JUMBO_FRAME_SIZE	0x00000800
-/*
- * APM821xx does not support Half Duplex mode
- */
-#define EMAC_FTR_APM821XX_NO_HALF_DUPLEX	0x00001000
+/* APM821xx requires Jumbo frame size set explicitly */
+#define EMAC_APM821XX_REQ_JUMBO_FRAME_SIZE 0x00000800
+/* APM821xx does not support Half Duplex mode */
+#define EMAC_FTR_APM821XX_NO_HALF_DUPLEX 0x00001000
+#define EMAC_FTR_APM821XX_PHY_CLK_FIX	0x000002000
 
 /* Right now, we don't quite handle the always/possible masks on the
  * most optimal way as we don't have a way to say something like
- * always EMAC4. Patches welcome.
- */
+ * always EMAC4. Patches welcome. */
 enum {
 	EMAC_FTRS_ALWAYS	= 0,
-
 	EMAC_FTRS_POSSIBLE	=
 #ifdef CONFIG_IBM_EMAC_EMAC4
-	    EMAC_FTR_EMAC4	| EMAC_FTR_EMAC4SYNC	|
-	    EMAC_FTR_HAS_NEW_STACR	|
-	    EMAC_FTR_STACR_OC_INVERT | EMAC_FTR_440GX_PHY_CLK_FIX |
+	EMAC_FTR_EMAC4 | EMAC_FTR_EMAC4SYNC | EMAC_FTR_HAS_NEW_STACR |
+	EMAC_FTR_STACR_OC_INVERT | EMAC_FTR_440GX_PHY_CLK_FIX |
 #endif
 #ifdef CONFIG_IBM_EMAC_TAH
-	    EMAC_FTR_HAS_TAH	|
+	EMAC_FTR_HAS_TAH |
 #endif
 #ifdef CONFIG_IBM_EMAC_ZMII
-	    EMAC_FTR_HAS_ZMII	|
+	EMAC_FTR_HAS_ZMII |
 #endif
 #ifdef CONFIG_IBM_EMAC_RGMII
-	    EMAC_FTR_HAS_RGMII	|
+	EMAC_FTR_HAS_RGMII |
 #endif
 #ifdef CONFIG_IBM_EMAC_NO_FLOW_CTRL
-	    EMAC_FTR_NO_FLOW_CONTROL_40x |
+	EMAC_FTR_NO_FLOW_CONTROL_40x |
 #endif
-	EMAC_FTR_460EX_PHY_CLK_FIX |
-	EMAC_FTR_440EP_PHY_CLK_FIX |
-	EMAC_APM821XX_REQ_JUMBO_FRAME_SIZE |
-	EMAC_FTR_APM821XX_NO_HALF_DUPLEX,
+	EMAC_FTR_460EX_PHY_CLK_FIX | EMAC_FTR_440EP_PHY_CLK_FIX |
+	EMAC_APM821XX_REQ_JUMBO_FRAME_SIZE | EMAC_FTR_APM821XX_NO_HALF_DUPLEX,
 };
 
-static inline int emac_has_feature(struct emac_instance *dev,
-				   unsigned long feature)
-{
-	return (EMAC_FTRS_ALWAYS & feature) ||
-	       (EMAC_FTRS_POSSIBLE & dev->features & feature);
+static inline int emac_has_feature(struct emac_instance *dev, unsigned long feature) {
+	return (EMAC_FTRS_ALWAYS & feature) || (EMAC_FTRS_POSSIBLE & dev->features & feature);
 }
 
 /*
@@ -387,53 +386,38 @@
 
 #define	EMAC4SYNC_XAHT_SLOTS_SHIFT	8
 #define	EMAC4SYNC_XAHT_WIDTH_SHIFT	5
+/* The largest span between slots and widths above is 3 */
+#define	EMAC_XAHT_MAX_REGS		    (1 << 3)
 
-#define	EMAC_XAHT_SLOTS(dev)         	(1 << (dev)->xaht_slots_shift)
-#define	EMAC_XAHT_WIDTH(dev)         	(1 << (dev)->xaht_width_shift)
-#define	EMAC_XAHT_REGS(dev)          	(1 << ((dev)->xaht_slots_shift - \
-					       (dev)->xaht_width_shift))
-
-#define	EMAC_XAHT_CRC_TO_SLOT(dev, crc)			\
-	((EMAC_XAHT_SLOTS(dev) - 1) -			\
-	 ((crc) >> ((sizeof (u32) * BITS_PER_BYTE) -	\
-		    (dev)->xaht_slots_shift)))
+#define	EMAC_XAHT_SLOTS(dev)        (1 << (dev)->xaht_slots_shift)
+#define	EMAC_XAHT_WIDTH(dev)        (1 << (dev)->xaht_width_shift)
+#define	EMAC_XAHT_REGS(dev)         (1 << ((dev)->xaht_slots_shift - (dev)->xaht_width_shift))
 
-#define	EMAC_XAHT_SLOT_TO_REG(dev, slot)		\
-	((slot) >> (dev)->xaht_width_shift)
+#define	EMAC_XAHT_CRC_TO_SLOT(dev, crc)		((EMAC_XAHT_SLOTS(dev) - 1) - \
+	((crc) >> ((sizeof (u32) * BITS_PER_BYTE) -	(dev)->xaht_slots_shift)))
 
-#define	EMAC_XAHT_SLOT_TO_MASK(dev, slot)		\
-	((u32)(1 << (EMAC_XAHT_WIDTH(dev) - 1)) >>	\
+#define	EMAC_XAHT_SLOT_TO_REG(dev, slot)	((slot) >> (dev)->xaht_width_shift)
+
+#define	EMAC_XAHT_SLOT_TO_MASK(dev, slot)	((u32)(1 << (EMAC_XAHT_WIDTH(dev) - 1)) >>	\
 	 ((slot) & (u32)(EMAC_XAHT_WIDTH(dev) - 1)))
 
-static inline u32 *emac_xaht_base(struct emac_instance *dev)
-{
+static inline u32 *emac_xaht_base(struct emac_instance *dev) {
 	struct emac_regs __iomem *p = dev->emacp;
-	int offset;
 
-	/* The first IAHT entry always is the base of the block of
-	 * IAHT and GAHT registers.
-	 */
-	if (emac_has_feature(dev, EMAC_FTR_EMAC4SYNC))
-		offset = offsetof(struct emac_regs, u1.emac4sync.iaht1);
+	/* The first IAHT entry always is the base of the block of IAHT and GAHT registers */
+	if (likely(emac_has_feature(dev, EMAC_FTR_EMAC4SYNC)))
+		return (u32 *)((ptrdiff_t)p + offsetof(struct emac_regs, u1.emac4sync.iaht1));
 	else
-		offset = offsetof(struct emac_regs, u0.emac4.iaht1);
-
-	return (u32 *)((ptrdiff_t)p + offset);
+		return (u32 *)((ptrdiff_t)p + offsetof(struct emac_regs, u0.emac4.iaht1));
 }
 
-static inline u32 *emac_gaht_base(struct emac_instance *dev)
-{
-	/* GAHT registers always come after an identical number of
-	 * IAHT registers.
-	 */
+static inline u32 *emac_gaht_base(struct emac_instance *dev) {
+	/* GAHT registers always come after an identical number of IAHT registers */
 	return emac_xaht_base(dev) + EMAC_XAHT_REGS(dev);
 }
 
-static inline u32 *emac_iaht_base(struct emac_instance *dev)
-{
-	/* IAHT registers always come before an identical number of
-	 * GAHT registers.
-	 */
+static inline u32 *emac_iaht_base(struct emac_instance *dev) {
+	/* IAHT registers always come before an identical number of GAHT registers */
 	return emac_xaht_base(dev);
 }
 
diff -Naur a/drivers/net/ethernet/ibm/emac/debug.c b/drivers/net/ethernet/ibm/emac/debug.c
--- a/drivers/net/ethernet/ibm/emac/debug.c	2019-01-09 16:16:45.000000000 +0000
+++ b/drivers/net/ethernet/ibm/emac/debug.c	2018-10-22 14:57:34.812585000 +0000
@@ -28,13 +28,10 @@
 
 static DEFINE_SPINLOCK(emac_dbg_lock);
 
-static void emac_desc_dump(struct emac_instance *p)
-{
+static void emac_desc_dump(struct emac_instance *p){
 	int i;
-	printk("** EMAC %s TX BDs **\n"
-	       " tx_cnt = %d tx_slot = %d ack_slot = %d\n",
-	       p->ofdev->dev.of_node->full_name,
-	       p->tx_cnt, p->tx_slot, p->ack_slot);
+	printk("** EMAC %s TX BDs **\n tx_cnt = %d tx_slot = %d ack_slot = %d\n",
+	       p->ofdev->dev.of_node->full_name, p->tx_cnt, p->tx_slot, p->ack_slot);
 	for (i = 0; i < NUM_TX_BUFF / 2; ++i)
 		printk
 		    ("bd[%2d] 0x%08x %c 0x%04x %4u - bd[%2d] 0x%08x %c 0x%04x %4u\n",
@@ -64,8 +61,7 @@
 		     p->rx_desc[NUM_RX_BUFF / 2 + i].data_len);
 }
 
-static void emac_mac_dump(struct emac_instance *dev)
-{
+static void emac_mac_dump(struct emac_instance *dev) {
 	struct emac_regs __iomem *p = dev->emacp;
 	const int xaht_regs = EMAC_XAHT_REGS(dev);
 	u32 *gaht_base = emac_gaht_base(dev);
@@ -77,21 +73,15 @@
 	       "MR0 = 0x%08x MR1 = 0x%08x TMR0 = 0x%08x TMR1 = 0x%08x\n"
 	       "RMR = 0x%08x ISR = 0x%08x ISER = 0x%08x\n"
 	       "IAR = %04x%08x VTPID = 0x%04x VTCI = 0x%04x\n",
-	       dev->ofdev->dev.of_node->full_name,
-	       in_be32(&p->mr0), in_be32(&p->mr1),
+	       dev->ofdev->dev.of_node->full_name, in_be32(&p->mr0), in_be32(&p->mr1),
 	       in_be32(&p->tmr0), in_be32(&p->tmr1),
 	       in_be32(&p->rmr), in_be32(&p->isr), in_be32(&p->iser),
-	       in_be32(&p->iahr), in_be32(&p->ialr), in_be32(&p->vtpid),
-	       in_be32(&p->vtci)
-	       );
+	       in_be32(&p->iahr), in_be32(&p->ialr), in_be32(&p->vtpid), in_be32(&p->vtci));
 
 	if (emac4sync)
-		printk("MAR = %04x%08x MMAR = %04x%08x\n",
-		       in_be32(&p->u0.emac4sync.mahr),
-		       in_be32(&p->u0.emac4sync.malr),
-		       in_be32(&p->u0.emac4sync.mmahr),
-		       in_be32(&p->u0.emac4sync.mmalr)
-		       );
+		printk("MAR = %04x%08x MMAR = %04x%08x\n", in_be32(&p->u0.emac4sync.mahr),
+		       in_be32(&p->u0.emac4sync.malr), in_be32(&p->u0.emac4sync.mmahr),
+		       in_be32(&p->u0.emac4sync.mmalr));
 
 	for (n = 0; n < xaht_regs; n++)
 		printk("IAHT%02d = 0x%08x\n", n + 1, in_be32(iaht_base + n));
@@ -107,22 +97,14 @@
 	       in_be32(&p->octx), in_be32(&p->ocrx)
 	       );
 
-	if (!emac4sync) {
-		printk("IPCR = 0x%08x\n",
-		       in_be32(&p->u1.emac4.ipcr)
-		       );
-	} else {
-		printk("REVID = 0x%08x TPC = 0x%08x\n",
-		       in_be32(&p->u1.emac4sync.revid),
-		       in_be32(&p->u1.emac4sync.tpc)
-		       );
-	}
+	if (!emac4sync) printk("IPCR = 0x%08x\n", in_be32(&p->u1.emac4.ipcr));
+	else printk("REVID = 0x%08x TPC = 0x%08x\n", in_be32(&p->u1.emac4sync.revid),
+			in_be32(&p->u1.emac4sync.tpc));
 
 	emac_desc_dump(dev);
 }
 
-static void emac_mal_dump(struct mal_instance *mal)
-{
+static void emac_mal_dump(struct mal_instance *mal) {
 	int i;
 
 	printk("** MAL %s Registers **\n"
@@ -140,21 +122,18 @@
 
 	printk("TX|");
 	for (i = 0; i < mal->num_tx_chans; ++i) {
-		if (i && !(i % 4))
-			printk("\n   ");
+		if (i && !(i % 4)) printk("\n   ");
 		printk("CTP%d = 0x%08x ", i, get_mal_dcrn(mal, MAL_TXCTPR(i)));
 	}
 	printk("\nRX|");
 	for (i = 0; i < mal->num_rx_chans; ++i) {
-		if (i && !(i % 4))
-			printk("\n   ");
+		if (i && !(i % 4)) printk("\n   ");
 		printk("CTP%d = 0x%08x ", i, get_mal_dcrn(mal, MAL_RXCTPR(i)));
 	}
 	printk("\n   ");
 	for (i = 0; i < mal->num_rx_chans; ++i) {
 		u32 r = get_mal_dcrn(mal, MAL_RCBS(i));
-		if (i && !(i % 3))
-			printk("\n   ");
+		if (i && !(i % 3)) printk("\n   ");
 		printk("RCBS%d = 0x%08x (%d) ", i, r, r * 16);
 	}
 	printk("\n");
@@ -163,8 +142,7 @@
 static struct emac_instance *__emacs[4];
 static struct mal_instance *__mals[1];
 
-void emac_dbg_register(struct emac_instance *dev)
-{
+void emac_dbg_register(struct emac_instance *dev) {
 	unsigned long flags;
 	int i;
 
@@ -177,8 +155,7 @@
 	spin_unlock_irqrestore(&emac_dbg_lock, flags);
 }
 
-void emac_dbg_unregister(struct emac_instance *dev)
-{
+void emac_dbg_unregister(struct emac_instance *dev) {
 	unsigned long flags;
 	int i;
 
@@ -191,8 +168,7 @@
 	spin_unlock_irqrestore(&emac_dbg_lock, flags);
 }
 
-void mal_dbg_register(struct mal_instance *mal)
-{
+void mal_dbg_register(struct mal_instance *mal) {
 	unsigned long flags;
 	int i;
 
@@ -205,8 +181,7 @@
 	spin_unlock_irqrestore(&emac_dbg_lock, flags);
 }
 
-void mal_dbg_unregister(struct mal_instance *mal)
-{
+void mal_dbg_unregister(struct mal_instance *mal) {
 	unsigned long flags;
 	int i;
 
@@ -219,27 +194,23 @@
 	spin_unlock_irqrestore(&emac_dbg_lock, flags);
 }
 
-void emac_dbg_dump_all(void)
-{
+void emac_dbg_dump_all(void) {
 	unsigned int i;
 	unsigned long flags;
 
 	spin_lock_irqsave(&emac_dbg_lock, flags);
 
 	for (i = 0; i < ARRAY_SIZE(__mals); ++i)
-		if (__mals[i])
-			emac_mal_dump(__mals[i]);
+		if (__mals[i])	emac_mal_dump(__mals[i]);
 
 	for (i = 0; i < ARRAY_SIZE(__emacs); ++i)
-		if (__emacs[i])
-			emac_mac_dump(__emacs[i]);
+		if (__emacs[i])	emac_mac_dump(__emacs[i]);
 
 	spin_unlock_irqrestore(&emac_dbg_lock, flags);
 }
 
 #if defined(CONFIG_MAGIC_SYSRQ)
-static void emac_sysrq_handler(int key)
-{
+static void emac_sysrq_handler(int key) {
 	emac_dbg_dump_all();
 }
 
@@ -249,22 +220,18 @@
 	.action_msg = "Show EMAC(s) status",
 };
 
-int __init emac_init_debug(void)
-{
+int __init emac_init_debug(void) {
 	return register_sysrq_key('c', &emac_sysrq_op);
 }
 
-void __exit emac_fini_debug(void)
-{
+void __exit emac_fini_debug(void) {
 	unregister_sysrq_key('c', &emac_sysrq_op);
 }
 
 #else
-int __init emac_init_debug(void)
-{
+int __init emac_init_debug(void) {
 	return 0;
 }
-void __exit emac_fini_debug(void)
-{
+void __exit emac_fini_debug(void) {
 }
 #endif				/* CONFIG_MAGIC_SYSRQ */
diff -Naur a/drivers/net/ethernet/ibm/emac/emac.h b/drivers/net/ethernet/ibm/emac/emac.h
--- a/drivers/net/ethernet/ibm/emac/emac.h	2019-01-09 16:16:45.000000000 +0000
+++ b/drivers/net/ethernet/ibm/emac/emac.h	2019-02-16 13:50:41.814384000 +0000
@@ -104,18 +104,16 @@
 	} u1;
 };
 
-/*
- * PHY mode settings (EMAC <-> ZMII/RGMII bridge <-> PHY)
- */
-#define PHY_MODE_NA	PHY_INTERFACE_MODE_NA
-#define PHY_MODE_MII	PHY_INTERFACE_MODE_MII
-#define PHY_MODE_RMII	PHY_INTERFACE_MODE_RMII
-#define PHY_MODE_SMII	PHY_INTERFACE_MODE_SMII
-#define PHY_MODE_RGMII	PHY_INTERFACE_MODE_RGMII
-#define PHY_MODE_TBI	PHY_INTERFACE_MODE_TBI
-#define PHY_MODE_GMII	PHY_INTERFACE_MODE_GMII
-#define PHY_MODE_RTBI	PHY_INTERFACE_MODE_RTBI
-#define PHY_MODE_SGMII	PHY_INTERFACE_MODE_SGMII
+/* PHY mode settings (EMAC <-> ZMII/RGMII bridge <-> PHY) */
+#define PHY_MODE_NA			PHY_INTERFACE_MODE_NA
+#define PHY_MODE_MII			PHY_INTERFACE_MODE_MII
+#define PHY_MODE_RMII			PHY_INTERFACE_MODE_RMII
+#define PHY_MODE_SMII			PHY_INTERFACE_MODE_SMII
+#define PHY_MODE_RGMII			PHY_INTERFACE_MODE_RGMII
+#define PHY_MODE_TBI			PHY_INTERFACE_MODE_TBI
+#define PHY_MODE_GMII			PHY_INTERFACE_MODE_GMII
+#define PHY_MODE_RTBI			PHY_INTERFACE_MODE_RTBI
+#define PHY_MODE_SGMII			PHY_INTERFACE_MODE_SGMII
 
 /* EMACx_MR0 */
 #define EMAC_MR0_RXI			0x80000000
@@ -137,23 +135,25 @@
 #define EMAC_MR1_MF_10			0x00000000
 #define EMAC_MR1_MF_100			0x00400000
 #define EMAC_MR1_MF_1000		0x00800000
-#define EMAC_MR1_MF_1000GPCS		0x00c00000
-#define EMAC_MR1_MF_IPPA(id)		(((id) & 0x1f) << 6)
+#define EMAC_MR1_MF_1000GPCS	0x00c00000
+#define EMAC_MR1_MF_IPPA(id)	(((id) & 0x1f) << 6)
 
 #define EMAC_MR1_RFS_4K			0x00300000
 #define EMAC_MR1_RFS_16K		0x00000000
 #define EMAC_MR1_TFS_2K			0x00080000
 #define EMAC_MR1_TR0_MULT		0x00008000
 #define EMAC_MR1_JPSM			0x00000000
-#define EMAC_MR1_MWSW_001		0x00000000
+#define EMAC_MR1_MWSW_001		0x00001000			// ECO was 0x00000000
 #define EMAC_MR1_BASE(opb)		(EMAC_MR1_TFS_2K | EMAC_MR1_TR0_MULT)
 
 
 #define EMAC4_MR1_RFS_2K		0x00100000
 #define EMAC4_MR1_RFS_4K		0x00180000
+#define EMAC4_MR1_RFS_8K		0x00200000
 #define EMAC4_MR1_RFS_16K		0x00280000
-#define EMAC4_MR1_TFS_2K       		0x00020000
+#define EMAC4_MR1_TFS_2K		0x00020000
 #define EMAC4_MR1_TFS_4K		0x00030000
+#define EMAC4_MR1_TFS_8K		0x00040000
 #define EMAC4_MR1_TFS_16K		0x00050000
 #define EMAC4_MR1_TR			0x00008000
 #define EMAC4_MR1_MWSW_001		0x00001000
@@ -164,33 +164,30 @@
 #define EMAC4_MR1_OBCI_83		0x00000010
 #define EMAC4_MR1_OBCI_100		0x00000018
 #define EMAC4_MR1_OBCI_100P		0x00000020
-#define EMAC4_MR1_OBCI(freq)		((freq) <= 50  ? EMAC4_MR1_OBCI_50 : \
-					 (freq) <= 66  ? EMAC4_MR1_OBCI_66 : \
-					 (freq) <= 83  ? EMAC4_MR1_OBCI_83 : \
-					 (freq) <= 100 ? EMAC4_MR1_OBCI_100 : \
-						EMAC4_MR1_OBCI_100P)
+#define EMAC4_MR1_OBCI(freq)	((freq) <= 50  ? EMAC4_MR1_OBCI_50 : \
+	(freq) <= 66  ? EMAC4_MR1_OBCI_66 : (freq) <= 83  ? EMAC4_MR1_OBCI_83 : \
+	(freq) <= 100 ? EMAC4_MR1_OBCI_100 : EMAC4_MR1_OBCI_100P)
 
 /* EMACx_TMR0 */
 #define EMAC_TMR0_GNP			0x80000000
 #define EMAC_TMR0_DEFAULT		0x00000000
-#define EMAC4_TMR0_TFAE_2_32		0x00000001
-#define EMAC4_TMR0_TFAE_4_64		0x00000002
-#define EMAC4_TMR0_TFAE_8_128		0x00000003
-#define EMAC4_TMR0_TFAE_16_256		0x00000004
-#define EMAC4_TMR0_TFAE_32_512		0x00000005
-#define EMAC4_TMR0_TFAE_64_1024		0x00000006
-#define EMAC4_TMR0_TFAE_128_2048	0x00000007
+#define EMAC4_TMR0_TFAE_2_32	0x00000001
+#define EMAC4_TMR0_TFAE_4_64	0x00000002
+#define EMAC4_TMR0_TFAE_8_128	0x00000003
+#define EMAC4_TMR0_TFAE_16_256	0x00000004
+#define EMAC4_TMR0_TFAE_32_512	0x00000005
+#define EMAC4_TMR0_TFAE_64_1024	0x00000006
+#define EMAC4_TMR0_TFAE_128_2048 0x00000007
 #define EMAC4_TMR0_DEFAULT		EMAC4_TMR0_TFAE_2_32
 #define EMAC_TMR0_XMIT			(EMAC_TMR0_GNP | EMAC_TMR0_DEFAULT)
 #define EMAC4_TMR0_XMIT			(EMAC_TMR0_GNP | EMAC4_TMR0_DEFAULT)
 
 /* EMACx_TMR1 */
-
 #define EMAC_TMR1(l,h)			(((l) << 27) | (((h) & 0xff) << 16))
 #define EMAC4_TMR1(l,h)			(((l) << 27) | (((h) & 0x3ff) << 14))
 
 /* EMACx_RMR */
-#define EMAC_RMR_SP			0x80000000
+#define EMAC_RMR_SP				0x80000000
 #define EMAC_RMR_SFCS			0x40000000
 #define EMAC_RMR_RRP			0x20000000
 #define EMAC_RMR_RFP			0x10000000
@@ -206,14 +203,14 @@
 #define EMAC_RMR_BASE			0x00000000
 #define EMAC4_RMR_RFAF_2_32		0x00000001
 #define EMAC4_RMR_RFAF_4_64		0x00000002
-#define EMAC4_RMR_RFAF_8_128		0x00000003
-#define EMAC4_RMR_RFAF_16_256		0x00000004
-#define EMAC4_RMR_RFAF_32_512		0x00000005
-#define EMAC4_RMR_RFAF_64_1024		0x00000006
-#define EMAC4_RMR_RFAF_128_2048		0x00000007
+#define EMAC4_RMR_RFAF_8_128	0x00000003
+#define EMAC4_RMR_RFAF_16_256	0x00000004
+#define EMAC4_RMR_RFAF_32_512	0x00000005
+#define EMAC4_RMR_RFAF_64_1024	0x00000006
+#define EMAC4_RMR_RFAF_128_2048	0x00000007
 #define EMAC4_RMR_BASE			EMAC4_RMR_RFAF_128_2048
-#define EMAC4_RMR_MJS_MASK              0x0001fff8
-#define EMAC4_RMR_MJS(s)                (((s) << 3) & EMAC4_RMR_MJS_MASK)
+#define EMAC4_RMR_MJS_MASK		0x0001fff8
+#define EMAC4_RMR_MJS(s)        (((s) << 3) & EMAC4_RMR_MJS_MASK)
 
 /* EMACx_ISR & EMACx_ISER */
 #define EMAC4_ISR_TXPE			0x20000000
@@ -221,53 +218,52 @@
 #define EMAC4_ISR_TXUE			0x08000000
 #define EMAC4_ISR_RXOE			0x04000000
 #define EMAC_ISR_OVR			0x02000000
-#define EMAC_ISR_PP			0x01000000
-#define EMAC_ISR_BP			0x00800000
-#define EMAC_ISR_RP			0x00400000
-#define EMAC_ISR_SE			0x00200000
+#define EMAC_ISR_PP				0x01000000
+#define EMAC_ISR_BP				0x00800000
+#define EMAC_ISR_RP				0x00400000
+#define EMAC_ISR_SE				0x00200000
 #define EMAC_ISR_ALE			0x00100000
 #define EMAC_ISR_BFCS			0x00080000
 #define EMAC_ISR_PTLE			0x00040000
 #define EMAC_ISR_ORE			0x00020000
 #define EMAC_ISR_IRE			0x00010000
 #define EMAC_ISR_SQE			0x00000080
-#define EMAC_ISR_TE			0x00000040
+#define EMAC_ISR_TE				0x00000040
 #define EMAC_ISR_MOS			0x00000002
 #define EMAC_ISR_MOF			0x00000001
 
 /* EMACx_STACR */
-#define EMAC_STACR_PHYD_MASK		0xffff
-#define EMAC_STACR_PHYD_SHIFT		16
+#define EMAC_STACR_PHYD_MASK	0xffff
+#define EMAC_STACR_PHYD_SHIFT	16
 #define EMAC_STACR_OC			0x00008000
 #define EMAC_STACR_PHYE			0x00004000
-#define EMAC_STACR_STAC_MASK		0x00003000
-#define EMAC_STACR_STAC_READ		0x00001000
-#define EMAC_STACR_STAC_WRITE		0x00002000
-#define EMAC_STACR_OPBC_MASK		0x00000C00
+#define EMAC_STACR_STAC_MASK	0x00003000
+#define EMAC_STACR_STAC_READ	0x00001000
+#define EMAC_STACR_STAC_WRITE	0x00002000
+#define EMAC_STACR_OPBC_MASK	0x00000C00
 #define EMAC_STACR_OPBC_50		0x00000000
 #define EMAC_STACR_OPBC_66		0x00000400
 #define EMAC_STACR_OPBC_83		0x00000800
 #define EMAC_STACR_OPBC_100		0x00000C00
-#define EMAC_STACR_OPBC(freq)		((freq) <= 50 ? EMAC_STACR_OPBC_50 : \
-					 (freq) <= 66 ? EMAC_STACR_OPBC_66 : \
-					 (freq) <= 83 ? EMAC_STACR_OPBC_83 : EMAC_STACR_OPBC_100)
+#define EMAC_STACR_OPBC(freq)	((freq) <= 50 ? EMAC_STACR_OPBC_50 : (freq) <= 66 ? \
+	EMAC_STACR_OPBC_66 : (freq) <= 83 ? EMAC_STACR_OPBC_83 : EMAC_STACR_OPBC_100)
 #define EMAC_STACR_BASE(opb)		EMAC_STACR_OPBC(opb)
-#define EMAC4_STACR_BASE(opb)		0x00000000
-#define EMAC_STACR_PCDA_MASK		0x1f
-#define EMAC_STACR_PCDA_SHIFT		5
+#define EMAC4_STACR_BASE(opb)	0x00000000
+#define EMAC_STACR_PCDA_MASK	0x1f
+#define EMAC_STACR_PCDA_SHIFT	5
 #define EMAC_STACR_PRA_MASK		0x1f
-#define EMACX_STACR_STAC_MASK		0x00003800
-#define EMACX_STACR_STAC_READ		0x00001000
-#define EMACX_STACR_STAC_WRITE		0x00000800
-#define EMACX_STACR_STAC_IND_ADDR	0x00002000
-#define EMACX_STACR_STAC_IND_READ	0x00003800
-#define EMACX_STACR_STAC_IND_READINC	0x00003000
+#define EMACX_STACR_STAC_MASK	0x00003800
+#define EMACX_STACR_STAC_READ	0x00001000
+#define EMACX_STACR_STAC_WRITE	0x00000800
+#define EMACX_STACR_STAC_IND_ADDR 0x00002000
+#define EMACX_STACR_STAC_IND_READ 0x00003800
+#define EMACX_STACR_STAC_IND_READINC 0x00003000
 #define EMACX_STACR_STAC_IND_WRITE	0x00002800
 
 
 /* EMACx_TRTR */
-#define EMAC_TRTR_SHIFT_EMAC4		24
-#define EMAC_TRTR_SHIFT		27
+#define EMAC_TRTR_SHIFT_EMAC4	24
+#define EMAC_TRTR_SHIFT			27
 
 /* EMAC specific TX descriptor control fields (write access) */
 #define EMAC_TX_CTRL_GFCS		0x0200
@@ -276,7 +272,14 @@
 #define EMAC_TX_CTRL_RSA		0x0040
 #define EMAC_TX_CTRL_IVT		0x0020
 #define EMAC_TX_CTRL_RVT		0x0010
-#define EMAC_TX_CTRL_TAH_CSUM		0x000e
+#define EMAC_TX_CTRL_TAH_SSR0	0x0002
+#define EMAC_TX_CTRL_TAH_SSR1	0x0004
+#define EMAC_TX_CTRL_TAH_SSR2	0x0006
+#define EMAC_TX_CTRL_TAH_SSR3	0x0008
+#define EMAC_TX_CTRL_TAH_SSR4	0x000a
+#define EMAC_TX_CTRL_TAH_SSR5	0x000c
+#define EMAC_TX_CTRL_TAH_SSR(i) (((i) + 1) << 1)
+#define EMAC_TX_CTRL_TAH_CSUM	0x000e		//HW Chksum but no TCP segmentation offload
 
 /* EMAC specific TX descriptor status fields (read access) */
 #define EMAC_TX_ST_BFCS			0x0200
@@ -289,10 +292,9 @@
 #define EMAC_TX_ST_UR			0x0002
 #define EMAC_TX_ST_SQE			0x0001
 #define EMAC_IS_BAD_TX			(EMAC_TX_ST_LCS | EMAC_TX_ST_ED | \
-					 EMAC_TX_ST_EC | EMAC_TX_ST_LC | \
-					 EMAC_TX_ST_MC | EMAC_TX_ST_UR)
+	EMAC_TX_ST_EC | EMAC_TX_ST_LC | EMAC_TX_ST_MC | EMAC_TX_ST_UR)
 #define EMAC_IS_BAD_TX_TAH		(EMAC_TX_ST_LCS | EMAC_TX_ST_ED | \
-					 EMAC_TX_ST_EC | EMAC_TX_ST_LC)
+	EMAC_TX_ST_EC | EMAC_TX_ST_LC)
 
 /* EMAC specific RX descriptor status fields (read access) */
 #define EMAC_RX_ST_OE			0x0200
@@ -305,10 +307,9 @@
 #define EMAC_RX_ST_PTL			0x0004
 #define EMAC_RX_ST_ORE			0x0002
 #define EMAC_RX_ST_IRE			0x0001
-#define EMAC_RX_TAH_BAD_CSUM		0x0003
+#define EMAC_RX_TAH_BAD_CSUM	0x0003
 #define EMAC_BAD_RX_MASK		(EMAC_RX_ST_OE | EMAC_RX_ST_BP | \
-					 EMAC_RX_ST_RP | EMAC_RX_ST_SE | \
-					 EMAC_RX_ST_AE | EMAC_RX_ST_BFCS | \
-					 EMAC_RX_ST_PTL | EMAC_RX_ST_ORE | \
-					 EMAC_RX_ST_IRE )
+	EMAC_RX_ST_RP | EMAC_RX_ST_SE | EMAC_RX_ST_AE | EMAC_RX_ST_BFCS | \
+	EMAC_RX_ST_PTL | EMAC_RX_ST_ORE | EMAC_RX_ST_IRE )
+
 #endif /* __IBM_NEWEMAC_H */
diff -Naur a/drivers/net/ethernet/ibm/emac/mal.c b/drivers/net/ethernet/ibm/emac/mal.c
--- a/drivers/net/ethernet/ibm/emac/mal.c.orig	2019-01-09 16:16:45.000000000 +0000
+++ b/drivers/net/ethernet/ibm/emac/mal.c	2019-02-16 18:36:30.981820000 +0000
@@ -30,314 +30,364 @@
 #include <linux/of_irq.h>
 
 #include "core.h"
+#include "mal.h"
 #include <asm/dcr-regs.h>
+#include <asm/ppc4xx_ocm.h>
 
 static int mal_count;
+#ifdef CONFIG_IBM_EMAC_INTR_COALESCE
+static char *tx_coal_irqname[] = {"TX0 COAL", "TX1 COAL", "TX2 COAL", "TX3 COAL",};
+static char *rx_coal_irqname[] = {"RX0 COAL", "RX1 COAL", "RX2 COAL", "RX3 COAL",};
+#endif
 
-int mal_register_commac(struct mal_instance *mal, struct mal_commac *commac)
-{
+int mal_register_commac(struct mal_instance *mal, struct mal_commac *commac) {
 	unsigned long flags;
 
 	spin_lock_irqsave(&mal->lock, flags);
 
-	MAL_DBG(mal, "reg(%08x, %08x)" NL,
-		commac->tx_chan_mask, commac->rx_chan_mask);
+	MAL_DBG(mal, "reg(%08x, %08x)" NL, commac->tx_chan_mask, commac->rx_chan_mask);
 
 	/* Don't let multiple commacs claim the same channel(s) */
-	if ((mal->tx_chan_mask & commac->tx_chan_mask) ||
-	    (mal->rx_chan_mask & commac->rx_chan_mask)) {
+	if ((mal->tx_chan_mask & commac->tx_chan_mask) || (mal->rx_chan_mask & commac->rx_chan_mask)) {
 		spin_unlock_irqrestore(&mal->lock, flags);
-		printk(KERN_WARNING "mal%d: COMMAC channels conflict!\n",
-		       mal->index);
+		printk(KERN_WARNING "mal%d: COMMAC channels conflict!\n", mal->index);
 		return -EBUSY;
 	}
 
-	if (list_empty(&mal->list))
-		napi_enable(&mal->napi);
+	if (list_empty(&mal->list))	napi_enable(&mal->napi);
 	mal->tx_chan_mask |= commac->tx_chan_mask;
 	mal->rx_chan_mask |= commac->rx_chan_mask;
 	list_add(&commac->list, &mal->list);
-
 	spin_unlock_irqrestore(&mal->lock, flags);
 
 	return 0;
 }
 
-void mal_unregister_commac(struct mal_instance	*mal,
-		struct mal_commac *commac)
-{
+void mal_unregister_commac(struct mal_instance	*mal, struct mal_commac *commac) {
 	unsigned long flags;
 
 	spin_lock_irqsave(&mal->lock, flags);
-
-	MAL_DBG(mal, "unreg(%08x, %08x)" NL,
-		commac->tx_chan_mask, commac->rx_chan_mask);
+	MAL_DBG(mal, "unreg(%08x, %08x)" NL, commac->tx_chan_mask, commac->rx_chan_mask);
 
 	mal->tx_chan_mask &= ~commac->tx_chan_mask;
 	mal->rx_chan_mask &= ~commac->rx_chan_mask;
 	list_del_init(&commac->list);
-	if (list_empty(&mal->list))
-		napi_disable(&mal->napi);
-
+	if (list_empty(&mal->list))	napi_disable(&mal->napi);
 	spin_unlock_irqrestore(&mal->lock, flags);
 }
 
-int mal_set_rcbs(struct mal_instance *mal, int channel, unsigned long size)
-{
-	BUG_ON(channel < 0 || channel >= mal->num_rx_chans ||
-	       size > MAL_MAX_RX_SIZE);
-
+int mal_set_rcbs(struct mal_instance *mal, int channel, unsigned long size) {
+	BUG_ON(channel < 0 || channel >= mal->num_rx_chans || size > MAL_MAX_RX_SIZE);
 	MAL_DBG(mal, "set_rbcs(%d, %lu)" NL, channel, size);
-
 	if (size & 0xf) {
-		printk(KERN_WARNING
-		       "mal%d: incorrect RX size %lu for the channel %d\n",
+		printk(KERN_WARNING "mal%d: incorrect RX size %lu for the channel %d\n",
 		       mal->index, size, channel);
 		return -EINVAL;
 	}
-
 	set_mal_dcrn(mal, MAL_RCBS(channel), size >> 4);
 	return 0;
 }
 
-int mal_tx_bd_offset(struct mal_instance *mal, int channel)
-{
+int mal_tx_bd_offset(struct mal_instance *mal, int channel) {
 	BUG_ON(channel < 0 || channel >= mal->num_tx_chans);
-
 	return channel * NUM_TX_BUFF;
 }
 
-int mal_rx_bd_offset(struct mal_instance *mal, int channel)
-{
+int mal_rx_bd_offset(struct mal_instance *mal, int channel) {
 	BUG_ON(channel < 0 || channel >= mal->num_rx_chans);
 	return mal->num_tx_chans * NUM_TX_BUFF + channel * NUM_RX_BUFF;
 }
 
-void mal_enable_tx_channel(struct mal_instance *mal, int channel)
-{
+void mal_enable_tx_channel(struct mal_instance *mal, int channel) {
 	unsigned long flags;
 
 	spin_lock_irqsave(&mal->lock, flags);
-
 	MAL_DBG(mal, "enable_tx(%d)" NL, channel);
-
-	set_mal_dcrn(mal, MAL_TXCASR,
-		     get_mal_dcrn(mal, MAL_TXCASR) | MAL_CHAN_MASK(channel));
-
+	set_mal_dcrn(mal, MAL_TXCASR, get_mal_dcrn(mal, MAL_TXCASR) | MAL_CHAN_MASK(channel));
 	spin_unlock_irqrestore(&mal->lock, flags);
 }
 
-void mal_disable_tx_channel(struct mal_instance *mal, int channel)
-{
+void mal_disable_tx_channel(struct mal_instance *mal, int channel) {
 	set_mal_dcrn(mal, MAL_TXCARR, MAL_CHAN_MASK(channel));
-
 	MAL_DBG(mal, "disable_tx(%d)" NL, channel);
 }
 
-void mal_enable_rx_channel(struct mal_instance *mal, int channel)
-{
+void mal_enable_rx_channel(struct mal_instance *mal, int channel) {
+	/* On some 4xx PPC's (e.g. 460EX/GT), the rx channel is a multiple of 8,
+	 * but enabling in MAL_RXCASR needs dividing by 8 value for the bitmask */
 	unsigned long flags;
-
-	/*
-	 * On some 4xx PPC's (e.g. 460EX/GT), the rx channel is a multiple
-	 * of 8, but enabling in MAL_RXCASR needs the divided by 8 value
-	 * for the bitmask
-	 */
-	if (!(channel % 8))
-		channel >>= 3;
+	if (!(channel % 8)) channel >>= 3;
 
 	spin_lock_irqsave(&mal->lock, flags);
-
 	MAL_DBG(mal, "enable_rx(%d)" NL, channel);
-
-	set_mal_dcrn(mal, MAL_RXCASR,
-		     get_mal_dcrn(mal, MAL_RXCASR) | MAL_CHAN_MASK(channel));
-
+	set_mal_dcrn(mal, MAL_RXCASR, get_mal_dcrn(mal, MAL_RXCASR) | MAL_CHAN_MASK(channel));
 	spin_unlock_irqrestore(&mal->lock, flags);
 }
 
-void mal_disable_rx_channel(struct mal_instance *mal, int channel)
-{
-	/*
-	 * On some 4xx PPC's (e.g. 460EX/GT), the rx channel is a multiple
-	 * of 8, but enabling in MAL_RXCASR needs the divided by 8 value
-	 * for the bitmask
-	 */
-	if (!(channel % 8))
-		channel >>= 3;
-
+void mal_disable_rx_channel(struct mal_instance *mal, int channel) {
+	/* On some 4xx PPC's (e.g. 460EX/GT), the rx channel is a multiple of 8,
+	 * but enabling in MAL_RXCASR needs dividing by 8 value for the bitmask */
+	if (!(channel % 8)) channel >>= 3;
 	set_mal_dcrn(mal, MAL_RXCARR, MAL_CHAN_MASK(channel));
-
 	MAL_DBG(mal, "disable_rx(%d)" NL, channel);
 }
 
-void mal_poll_add(struct mal_instance *mal, struct mal_commac *commac)
-{
+void mal_poll_add(struct mal_instance *mal, struct mal_commac *commac) {
 	unsigned long flags;
 
 	spin_lock_irqsave(&mal->lock, flags);
-
 	MAL_DBG(mal, "poll_add(%p)" NL, commac);
-
-	/* starts disabled */
-	set_bit(MAL_COMMAC_POLL_DISABLED, &commac->flags);
-
+	set_bit(MAL_COMMAC_POLL_DISABLED, &commac->flags);	/* starts disabled */
 	list_add_tail(&commac->poll_list, &mal->poll_list);
-
 	spin_unlock_irqrestore(&mal->lock, flags);
 }
 
-void mal_poll_del(struct mal_instance *mal, struct mal_commac *commac)
-{
+void mal_poll_del(struct mal_instance *mal, struct mal_commac *commac) {
 	unsigned long flags;
 
 	spin_lock_irqsave(&mal->lock, flags);
-
 	MAL_DBG(mal, "poll_del(%p)" NL, commac);
-
 	list_del(&commac->poll_list);
-
 	spin_unlock_irqrestore(&mal->lock, flags);
 }
 
 /* synchronized by mal_poll() */
-static inline void mal_enable_eob_irq(struct mal_instance *mal)
-{
+static inline void mal_enable_eob_irq(struct mal_instance *mal) {
 	MAL_DBG2(mal, "enable_irq" NL);
-
 	// XXX might want to cache MAL_CFG as the DCR read can be slooooow
 	set_mal_dcrn(mal, MAL_CFG, get_mal_dcrn(mal, MAL_CFG) | MAL_CFG_EOPIE);
 }
 
 /* synchronized by NAPI state */
-static inline void mal_disable_eob_irq(struct mal_instance *mal)
-{
+static inline void mal_disable_eob_irq(struct mal_instance *mal) {
 	// XXX might want to cache MAL_CFG as the DCR read can be slooooow
 	set_mal_dcrn(mal, MAL_CFG, get_mal_dcrn(mal, MAL_CFG) & ~MAL_CFG_EOPIE);
-
 	MAL_DBG2(mal, "disable_irq" NL);
 }
 
-static irqreturn_t mal_serr(int irq, void *dev_instance)
-{
-	struct mal_instance *mal = dev_instance;
+#ifdef CONFIG_IBM_EMAC_INTR_COALESCE
+#if defined(CONFIG_460SX)
+/* Set Tx fram count */
+static inline void set_ic_txfthr(struct mal_instance *mal) {
+	int val = (mal->coales_param[0].tx_count) << SDR0_ICC_FTHR_SHIFT;
+	int reg = val | (1<<SDR0_ICC_FLUSH);  // Flush bit 1 enables counter
+
+	SDR_WRITE(DCRN_SDR0_ICCRTX0, reg);	/* set counter */
+	SDR_WRITE(DCRN_SDR0_ICCRTX0, val);	/* enable counter */
+	SDR_WRITE(DCRN_SDR0_ICCRTX1, reg);	/* set counter */
+	SDR_WRITE(DCRN_SDR0_ICCRTX1, val);	/* enable counter */
+	SDR_WRITE(DCRN_SDR0_ICCRTX2, reg);	/* set counter */
+	SDR_WRITE(DCRN_SDR0_ICCRTX2, val);	/* enable counter */
+	SDR_WRITE(DCRN_SDR0_ICCRTX3, reg);	/* set counter */
+	SDR_WRITE(DCRN_SDR0_ICCRTX3, val);	/* enable counter */
+	mal->enet_coales_iccrtx = reg;
+}
+/* Set Rx fram count */
+static inline void set_ic_rxfthr(struct mal_instance *mal) {
+	int val = (mal->coales_param[0].rx_count) << SDR0_ICC_FTHR_SHIFT;
+	int reg = val | (1<<SDR0_ICC_FLUSH);  // Flush bit 1 enables counter
+
+	SDR_WRITE(DCRN_SDR0_ICCRRX0, reg);	/* set counter */
+	SDR_WRITE(DCRN_SDR0_ICCRRX0, val);/* enable counter */
+	SDR_WRITE(DCRN_SDR0_ICCRRX1, reg);	/* set counter */
+	SDR_WRITE(DCRN_SDR0_ICCRRX1, val);/* enable counter */
+	SDR_WRITE(DCRN_SDR0_ICCRRX2, reg);	/* set counter */
+	SDR_WRITE(DCRN_SDR0_ICCRRX2, val);/* enable counter */
+	SDR_WRITE(DCRN_SDR0_ICCRRX3, reg);	/* set counter */
+	SDR_WRITE(DCRN_SDR0_ICCRRX3, val);/* enable counter */
+	mal->enet_coales_iccrrx = reg;
+}
+#endif
 
-	u32 esr = get_mal_dcrn(mal, MAL_ESR);
+#define TX_COAL_CNT (CONFIG_IBM_EMAC_TX_COAL_COUNT & COAL_FRAME_MASK)
+#define RX_COAL_CNT (CONFIG_IBM_EMAC_RX_COAL_COUNT & COAL_FRAME_MASK)
+
+inline void mal_enable_coal(struct mal_instance *mal) {
+#if defined(CONFIG_405EX)
+	/* Clear the counters */
+	mtdcri(SDR0, DCRN_SDR0_ICCRTX, SDR0_ICC_FLUSH0 | SDR0_ICC_FLUSH1);
+	mtdcri(SDR0, DCRN_SDR0_ICCRRX, SDR0_ICC_FLUSH0 | SDR0_ICC_FLUSH1);
+
+	/* Set Tx/Rx Timer values */
+	mtdcri(SDR0, DCRN_SDR0_ICCTRTX0, CONFIG_IBM_EMAC_TX_COAL_TIMER);
+	mtdcri(SDR0, DCRN_SDR0_ICCTRTX1, CONFIG_IBM_EMAC_TX_COAL_TIMER);
+	mtdcri(SDR0, DCRN_SDR0_ICCTRRX0, CONFIG_IBM_EMAC_RX_COAL_TIMER);
+	mtdcri(SDR0, DCRN_SDR0_ICCTRRX1, CONFIG_IBM_EMAC_RX_COAL_TIMER);
+
+	/* Enable the Tx/Rx Coalescing interrupt */
+	mtdcri(SDR0, DCRN_SDR0_ICCRTX, (TX_COAL_CNT<<SDR0_ICC_FTHR0_SHIFT)|(TX_COAL_CNT<<SDR0_ICC_FTHR1_SHIFT));
+	mtdcri(SDR0, DCRN_SDR0_ICCRRX, (RX_COAL_CNT<<SDR0_ICC_FTHR0_SHIFT)|(RX_COAL_CNT<<SDR0_ICC_FTHR1_SHIFT));
+#elif defined(CONFIG_APM821xx)
+	/* Clear the counters */
+	//val = SDR0_ICC_FLUSH;
+	mtdcri(SDR0, DCRN_SDR0_ICCRTX0, SDR0_ICC_FLUSH);	//val
+	mtdcri(SDR0, DCRN_SDR0_ICCRRX0, SDR0_ICC_FLUSH);	//val
+
+	/* Set Tx/Rx Timer values, with SYSFS the user can change those */
+#if defined(CONFIG_IBM_EMAC_SYSFS)
+	mtdcri(SDR0, DCRN_SDR0_ICCTRTX0,  mal->coales_param[0].tx_time);
+	mtdcri(SDR0, DCRN_SDR0_ICCTRRX0,  mal->coales_param[0].rx_time);
+	/* Enable the Tx/Rx Coalescing interrupt */	
+	mtdcri(SDR0, DCRN_SDR0_ICCRTX0, (mal->coales_param[0].tx_count & COAL_FRAME_MASK)<<SDR0_ICC_FTHR_SHIFT);
+	mtdcri(SDR0, DCRN_SDR0_ICCRRX0, (mal->coales_param[0].rx_count & COAL_FRAME_MASK)<<SDR0_ICC_FTHR_SHIFT);
+#else
+	mtdcri(SDR0, DCRN_SDR0_ICCTRTX0,  CONFIG_IBM_EMAC_TX_COAL_TIMER);
+	mtdcri(SDR0, DCRN_SDR0_ICCTRRX0,  CONFIG_IBM_EMAC_RX_COAL_TIMER);
+
+	/* Enable the Tx/Rx Coalescing interrupt */	
+	mtdcri(SDR0, DCRN_SDR0_ICCRTX0, TX_COAL_CNT << SDR0_ICC_FTHR_SHIFT);
+	mtdcri(SDR0, DCRN_SDR0_ICCRRX0, RX_COAL_CNT << SDR0_ICC_FTHR_SHIFT);
+#endif
+#elif (defined(CONFIG_460EX) || defined(CONFIG_460GT)) && !defined(CONFIG_APM821xx)
+	mtdcri(SDR0, DCRN_SDR0_ICCRTX0, SDR0_ICC_FLUSH);	/* Clear the counters */
+	mtdcri(SDR0, DCRN_SDR0_ICCRTX1, SDR0_ICC_FLUSH);
+	mtdcri(SDR0, DCRN_SDR0_ICCRRX0, SDR0_ICC_FLUSH);
+	mtdcri(SDR0, DCRN_SDR0_ICCRRX1, SDR0_ICC_FLUSH);
+#if defined(CONFIG_460GT)
+	mtdcri(SDR0, DCRN_SDR0_ICCRTX2, SDR0_ICC_FLUSH);
+	mtdcri(SDR0, DCRN_SDR0_ICCRTX3, SDR0_ICC_FLUSH);
+	mtdcri(SDR0, DCRN_SDR0_ICCRRX2, SDR0_ICC_FLUSH);
+	mtdcri(SDR0, DCRN_SDR0_ICCRRX3, SDR0_ICC_FLUSH);
+#endif
+
+	/* Set Tx/Rx Timer values */
+	mtdcri(SDR0, DCRN_SDR0_ICCTRTX0, CONFIG_IBM_EMAC_TX_COAL_TIMER);
+	mtdcri(SDR0, DCRN_SDR0_ICCTRTX1, CONFIG_IBM_EMAC_TX_COAL_TIMER);
+	mtdcri(SDR0, DCRN_SDR0_ICCTRRX0, CONFIG_IBM_EMAC_RX_COAL_TIMER);
+	mtdcri(SDR0, DCRN_SDR0_ICCTRRX1, CONFIG_IBM_EMAC_RX_COAL_TIMER);
+
+#if defined(CONFIG_460GT)
+	mtdcri(SDR0, DCRN_SDR0_ICCTRTX2, CONFIG_IBM_EMAC_TX_COAL_TIMER);
+	mtdcri(SDR0, DCRN_SDR0_ICCTRTX3, CONFIG_IBM_EMAC_TX_COAL_TIMER);
+	mtdcri(SDR0, DCRN_SDR0_ICCTRRX2, CONFIG_IBM_EMAC_RX_COAL_TIMER);
+	mtdcri(SDR0, DCRN_SDR0_ICCTRRX3, CONFIG_IBM_EMAC_RX_COAL_TIMER);
+#endif
 
-	/* Clear the error status register */
-	set_mal_dcrn(mal, MAL_ESR, esr);
+	/* Enable the Tx/Rx Coalescing interrupt */
+	mtdcri(SDR0, DCRN_SDR0_ICCRTX0, TX_COAL_CNT << SDR0_ICC_FTHR_SHIFT);
+	mtdcri(SDR0, DCRN_SDR0_ICCRTX1, TX_COAL_CNT << SDR0_ICC_FTHR_SHIFT);
+#if defined(CONFIG_460GT)
+	mtdcri(SDR0, DCRN_SDR0_ICCRTX2, TX_COAL_CNT << SDR0_ICC_FTHR_SHIFT);
+	mtdcri(SDR0, DCRN_SDR0_ICCRTX3, TX_COAL_CNT << SDR0_ICC_FTHR_SHIFT);
+#endif
+
+	mtdcri(SDR0, DCRN_SDR0_ICCRRX0, RX_COAL_CNT << SDR0_ICC_FTHR_SHIFT);
+	mtdcri(SDR0, DCRN_SDR0_ICCRRX1, RX_COAL_CNT << SDR0_ICC_FTHR_SHIFT);
+#if defined(CONFIG_460GT)
+	mtdcri(SDR0, DCRN_SDR0_ICCRRX2, RX_COAL_CNT << SDR0_ICC_FTHR_SHIFT);
+	mtdcri(SDR0, DCRN_SDR0_ICCRRX3, RX_COAL_CNT << SDR0_ICC_FTHR_SHIFT);
+#endif
+
+#elif defined(CONFIG_460SX)
+	mtdcri(SDR0, DCRN_SDR0_ICCTRTX0, mal->coales_param[0].tx_time);
+	mtdcri(SDR0, DCRN_SDR0_ICCTRTX1, mal->coales_param[1].tx_time);
+	mtdcri(SDR0, DCRN_SDR0_ICCTRTX2, mal->coales_param[2].tx_time);
+	mtdcri(SDR0, DCRN_SDR0_ICCTRTX3, mal->coales_param[3].tx_time);
+
+	mtdcri(SDR0, DCRN_SDR0_ICCTRRX0, mal->coales_param[0].rx_time);
+	mtdcri(SDR0, DCRN_SDR0_ICCTRRX1, mal->coales_param[1].rx_time);
+	mtdcri(SDR0, DCRN_SDR0_ICCTRRX2, mal->coales_param[2].rx_time);
+	mtdcri(SDR0, DCRN_SDR0_ICCTRRX3, mal->coales_param[3].rx_time);
+
+	set_ic_rxfthr(mal);
+	set_ic_txfthr(mal);
+#endif
+	printk(KERN_INFO "MAL: Interrupt Coalescing TxCnt:%d RxCnt:%d TxTimer:%d RxTimer:%d\n",
+		mal->coales_param[0].tx_count, mal->coales_param[0].rx_count,
+		mal->coales_param[0].tx_time, mal->coales_param[0].rx_time);
+}
+#endif
+
+static irqreturn_t mal_serr(int irq, void *dev_instance) {
+	struct mal_instance *mal = dev_instance;
+	u32 esr = get_mal_dcrn(mal, MAL_ESR);
 
+	set_mal_dcrn(mal, MAL_ESR, esr);		/* Clear the error status register */
 	MAL_DBG(mal, "SERR %08x" NL, esr);
 
 	if (esr & MAL_ESR_EVB) {
-		if (esr & MAL_ESR_DE) {
-			/* We ignore Descriptor error,
-			 * TXDE or RXDE interrupt will be generated anyway.
-			 */
-			return IRQ_HANDLED;
-		}
-
+		/* Ignore Descriptor error, TXDE or RXDE interrupt will be generated anyway */
+		if (esr & MAL_ESR_DE) return IRQ_HANDLED;
+		/* PLB error, buggy hardware or incorrect physical address in BD (i.e. bug) */
 		if (esr & MAL_ESR_PEIN) {
-			/* PLB error, it's probably buggy hardware or
-			 * incorrect physical address in BD (i.e. bug)
-			 */
 			if (net_ratelimit())
-				printk(KERN_ERR
-				       "mal%d: system error, "
-				       "PLB (ESR = 0x%08x)\n",
-				       mal->index, esr);
+				printk(KERN_ERR "mal%d: system error, PLB (ESR = 0x%08x)\n", mal->index, esr);
 			return IRQ_HANDLED;
 		}
 
-		/* OPB error, it's probably buggy hardware or incorrect
-		 * EBC setup
-		 */
+		/* OPB error, it's probably buggy hardware or incorrect EBC setup */
 		if (net_ratelimit())
-			printk(KERN_ERR
-			       "mal%d: system error, OPB (ESR = 0x%08x)\n",
-			       mal->index, esr);
+			printk(KERN_ERR "mal%d: system error, OPB (ESR = 0x%08x)\n", mal->index, esr);
 	}
 	return IRQ_HANDLED;
 }
 
-static inline void mal_schedule_poll(struct mal_instance *mal)
-{
+static inline void mal_schedule_poll(struct mal_instance *mal) {
 	if (likely(napi_schedule_prep(&mal->napi))) {
 		MAL_DBG2(mal, "schedule_poll" NL);
 		spin_lock(&mal->lock);
 		mal_disable_eob_irq(mal);
 		spin_unlock(&mal->lock);
 		__napi_schedule(&mal->napi);
-	} else
-		MAL_DBG2(mal, "already in poll" NL);
+	} else MAL_DBG2(mal, "already in poll" NL);
 }
 
-static irqreturn_t mal_txeob(int irq, void *dev_instance)
-{
+static irqreturn_t mal_txeob(int irq, void *dev_instance) {
 	struct mal_instance *mal = dev_instance;
 
 	u32 r = get_mal_dcrn(mal, MAL_TXEOBISR);
-
 	MAL_DBG2(mal, "txeob %08x" NL, r);
-
 	mal_schedule_poll(mal);
 	set_mal_dcrn(mal, MAL_TXEOBISR, r);
 
 #ifdef CONFIG_PPC_DCR_NATIVE
 	if (mal_has_feature(mal, MAL_FTR_CLEAR_ICINTSTAT))
-		mtdcri(SDR0, DCRN_SDR_ICINTSTAT,
-				(mfdcri(SDR0, DCRN_SDR_ICINTSTAT) | ICINTSTAT_ICTX));
+		mtdcri(SDR0, DCRN_SDR_ICINTSTAT, (mfdcri(SDR0, DCRN_SDR_ICINTSTAT) | ICINTSTAT_ICTX));
 #endif
-
 	return IRQ_HANDLED;
 }
 
-static irqreturn_t mal_rxeob(int irq, void *dev_instance)
-{
+static irqreturn_t mal_rxeob(int irq, void *dev_instance) {
 	struct mal_instance *mal = dev_instance;
 
 	u32 r = get_mal_dcrn(mal, MAL_RXEOBISR);
-
 	MAL_DBG2(mal, "rxeob %08x" NL, r);
-
 	mal_schedule_poll(mal);
 	set_mal_dcrn(mal, MAL_RXEOBISR, r);
 
 #ifdef CONFIG_PPC_DCR_NATIVE
 	if (mal_has_feature(mal, MAL_FTR_CLEAR_ICINTSTAT))
-		mtdcri(SDR0, DCRN_SDR_ICINTSTAT,
-				(mfdcri(SDR0, DCRN_SDR_ICINTSTAT) | ICINTSTAT_ICRX));
+		mtdcri(SDR0, DCRN_SDR_ICINTSTAT, (mfdcri(SDR0, DCRN_SDR_ICINTSTAT) | ICINTSTAT_ICRX));
 #endif
 
 	return IRQ_HANDLED;
 }
 
-static irqreturn_t mal_txde(int irq, void *dev_instance)
-{
+#ifdef CONFIG_IBM_EMAC_INTR_COALESCE
+static irqreturn_t mal_coal(int irq, void *dev_instance) {
+	struct mal_instance *mal = dev_instance;
+	mal_schedule_poll(mal);
+	return IRQ_HANDLED;
+}
+#endif
+
+static irqreturn_t mal_txde(int irq, void *dev_instance) {
 	struct mal_instance *mal = dev_instance;
 
 	u32 deir = get_mal_dcrn(mal, MAL_TXDEIR);
 	set_mal_dcrn(mal, MAL_TXDEIR, deir);
-
 	MAL_DBG(mal, "txde %08x" NL, deir);
-
 	if (net_ratelimit())
-		printk(KERN_ERR
-		       "mal%d: TX descriptor error (TXDEIR = 0x%08x)\n",
-		       mal->index, deir);
-
+		printk(KERN_ERR "mal%d: TX descriptor error (TXDEIR = 0x%08x)\n", mal->index, deir);
 	return IRQ_HANDLED;
 }
 
-static irqreturn_t mal_rxde(int irq, void *dev_instance)
-{
+static irqreturn_t mal_rxde(int irq, void *dev_instance) {
 	struct mal_instance *mal = dev_instance;
 	struct list_head *l;
 
 	u32 deir = get_mal_dcrn(mal, MAL_RXDEIR);
-
 	MAL_DBG(mal, "rxde %08x" NL, deir);
-
 	list_for_each(l, &mal->list) {
 		struct mal_commac *mc = list_entry(l, struct mal_commac, list);
 		if (deir & mc->rx_chan_mask) {
@@ -345,44 +395,33 @@
 			mc->ops->rxde(mc->dev);
 		}
 	}
-
 	mal_schedule_poll(mal);
 	set_mal_dcrn(mal, MAL_RXDEIR, deir);
-
 	return IRQ_HANDLED;
 }
 
-static irqreturn_t mal_int(int irq, void *dev_instance)
-{
+static irqreturn_t mal_int(int irq, void *dev_instance) {
 	struct mal_instance *mal = dev_instance;
 	u32 esr = get_mal_dcrn(mal, MAL_ESR);
 
 	if (esr & MAL_ESR_EVB) {
-		/* descriptor error */
-		if (esr & MAL_ESR_DE) {
-			if (esr & MAL_ESR_CIDT)
-				return mal_rxde(irq, dev_instance);
-			else
-				return mal_txde(irq, dev_instance);
-		} else { /* SERR */
-			return mal_serr(irq, dev_instance);
-		}
+		if (esr & MAL_ESR_DE) {			/* descriptor error */
+			if (esr & MAL_ESR_CIDT)	return mal_rxde(irq, dev_instance);
+			else	return mal_txde(irq, dev_instance);
+		} else return mal_serr(irq, dev_instance);	/* SERR */
 	}
 	return IRQ_HANDLED;
 }
 
-void mal_poll_disable(struct mal_instance *mal, struct mal_commac *commac)
-{
+void mal_poll_disable(struct mal_instance *mal, struct mal_commac *commac) {
 	/* Spinlock-type semantics: only one caller disable poll at a time */
-	while (test_and_set_bit(MAL_COMMAC_POLL_DISABLED, &commac->flags))
-		msleep(1);
+	while (test_and_set_bit(MAL_COMMAC_POLL_DISABLED, &commac->flags)) msleep(1);
 
 	/* Synchronize with the MAL NAPI poller */
 	napi_synchronize(&mal->napi);
 }
 
-void mal_poll_enable(struct mal_instance *mal, struct mal_commac *commac)
-{
+void mal_poll_enable(struct mal_instance *mal, struct mal_commac *commac) {
 	smp_wmb();
 	clear_bit(MAL_COMMAC_POLL_DISABLED, &commac->flags);
 
@@ -394,8 +433,7 @@
 	napi_schedule(&mal->napi);
 }
 
-static int mal_poll(struct napi_struct *napi, int budget)
-{
+static int mal_poll(struct napi_struct *napi, int budget) {
 	struct mal_instance *mal = container_of(napi, struct mal_instance, napi);
 	struct list_head *l;
 	int received = 0;
@@ -405,45 +443,48 @@
 
 	/* Process TX skbs */
 	list_for_each(l, &mal->poll_list) {
-		struct mal_commac *mc =
-			list_entry(l, struct mal_commac, poll_list);
+		struct mal_commac *mc =	list_entry(l, struct mal_commac, poll_list);
 		mc->ops->poll_tx(mc->dev);
 	}
 
 	/* Process RX skbs.
-	 *
-	 * We _might_ need something more smart here to enforce polling
-	 * fairness.
-	 */
+	 * We _might_ need something more smart here to enforce polling fairness. */
 	list_for_each(l, &mal->poll_list) {
-		struct mal_commac *mc =
-			list_entry(l, struct mal_commac, poll_list);
-		int n;
+		struct mal_commac *mc =	list_entry(l, struct mal_commac, poll_list);
+		register int n;
 		if (unlikely(test_bit(MAL_COMMAC_POLL_DISABLED, &mc->flags)))
 			continue;
 		n = mc->ops->poll_rx(mc->dev, budget);
+        	//n = mc->ops->poll_rx(mc->dev, budget - received);
 		if (n) {
 			received += n;
 			budget -= n;
-			if (budget <= 0)
-				goto more_work; // XXX What if this is the last one ?
+			if (budget <= 0) goto more_work; // XXX What if this is the last one ?
+            		//if (received >= budget) return budget;
 		}
 	}
 
-	/* We need to disable IRQs to protect from RXDE IRQ here */
-	spin_lock_irqsave(&mal->lock, flags);
-	__napi_complete(napi);
-	mal_enable_eob_irq(mal);
+	///* old code
+	spin_lock_irqsave(&mal->lock, flags); // We need to disable IRQs to protect from RXDE IRQ here
+	__napi_complete(napi);  // There are no packets left
+	mal_enable_eob_irq(mal);  // Re-enable hypervisor interrupts. 
 	spin_unlock_irqrestore(&mal->lock, flags);
+	//*/
+
+    	/* Remove __napi_complete
+	if (napi_complete_done(napi, received)) {
+		spin_lock_irqsave(&mal->lock, flags);  // We need to disable IRQs to protect from RXDE IRQ here
+		mal_enable_eob_irq(mal);
+		spin_unlock_irqrestore(&mal->lock, flags);
+	}
+    	*/
 
 	/* Check for "rotting" packet(s) */
 	list_for_each(l, &mal->poll_list) {
-		struct mal_commac *mc =
-			list_entry(l, struct mal_commac, poll_list);
+		struct mal_commac *mc =	list_entry(l, struct mal_commac, poll_list);
 		if (unlikely(test_bit(MAL_COMMAC_POLL_DISABLED, &mc->flags)))
 			continue;
-		if (unlikely(mc->ops->peek_rx(mc->dev) ||
-			     test_bit(MAL_COMMAC_RX_STOPPED, &mc->flags))) {
+		if (unlikely(mc->ops->peek_rx(mc->dev) || test_bit(MAL_COMMAC_RX_STOPPED, &mc->flags))) {
 			MAL_DBG2(mal, "rotting packet" NL);
 			if (!napi_reschedule(napi))
 				goto more_work;
@@ -460,12 +501,10 @@
 	return received;
 }
 
-static void mal_reset(struct mal_instance *mal)
-{
+static void mal_reset(struct mal_instance *mal) {
 	int n = 10;
 
 	MAL_DBG(mal, "reset" NL);
-
 	set_mal_dcrn(mal, MAL_CFG, MAL_CFG_SR);
 
 	/* Wait for reset to complete (1 system clock) */
@@ -476,10 +515,8 @@
 		printk(KERN_ERR "mal%d: reset timeout\n", mal->index);
 }
 
-int mal_get_regs_len(struct mal_instance *mal)
-{
-	return sizeof(struct emac_ethtool_regs_subhdr) +
-	    sizeof(struct mal_regs);
+int mal_get_regs_len(struct mal_instance *mal) {
+	return sizeof(struct emac_ethtool_regs_subhdr) + sizeof(struct mal_regs);
 }
 
 void *mal_dump_regs(struct mal_instance *mal, void *buf)
@@ -516,16 +553,20 @@
 	return regs + 1;
 }
 
-static int mal_probe(struct platform_device *ofdev)
-{
+static int mal_probe(struct platform_device *ofdev) {
 	struct mal_instance *mal;
-	int err = 0, i, bd_size;
-	int index = mal_count++;
+	int err = 0, i, bd_size, index = mal_count++;
 	unsigned int dcr_base;
 	const u32 *prop;
+	const char *str_prop;
 	u32 cfg;
 	unsigned long irqflags;
 	irq_handler_t hdlr_serr, hdlr_txde, hdlr_rxde;
+	struct device *dp = &ofdev->dev;
+	struct device_node *np = dp->of_node;
+#ifdef CONFIG_IBM_EMAC_INTR_COALESCE
+	int num_phys_chans, coal_intr_index;
+#endif
 
 	mal = kzalloc(sizeof(struct mal_instance), GFP_KERNEL);
 	if (!mal)
@@ -533,85 +574,112 @@
 
 	mal->index = index;
 	mal->ofdev = ofdev;
-	mal->version = of_device_is_compatible(ofdev->dev.of_node, "ibm,mcmal2") ? 2 : 1;
+	mal->version = of_device_is_compatible(np, "ibm,mcmal2") ? 2 : 1;
 
 	MAL_DBG(mal, "probe" NL);
 
-	prop = of_get_property(ofdev->dev.of_node, "num-tx-chans", NULL);
+	str_prop = of_get_property(np, "descriptor-memory", NULL);
+	if (str_prop && (!strcmp(str_prop,"ocm") || !strcmp(str_prop,"OCM")))
+		mal->desc_memory = MAL_DESC_MEM_OCM;
+
+	prop = of_get_property(np, "num-tx-chans", NULL);
 	if (prop == NULL) {
-		printk(KERN_ERR
-		       "mal%d: can't find MAL num-tx-chans property!\n",
-		       index);
+		printk(KERN_ERR "mal%d: can't find MAL num-tx-chans property!\n", index);
 		err = -ENODEV;
 		goto fail;
 	}
 	mal->num_tx_chans = prop[0];
 
-	prop = of_get_property(ofdev->dev.of_node, "num-rx-chans", NULL);
+	prop = of_get_property(np, "num-rx-chans", NULL);
 	if (prop == NULL) {
-		printk(KERN_ERR
-		       "mal%d: can't find MAL num-rx-chans property!\n",
-		       index);
+		printk(KERN_ERR "mal%d: can't find MAL num-rx-chans property!\n", index);
 		err = -ENODEV;
 		goto fail;
 	}
 	mal->num_rx_chans = prop[0];
 
-	dcr_base = dcr_resource_start(ofdev->dev.of_node, 0);
+	dcr_base = dcr_resource_start(np, 0);
 	if (dcr_base == 0) {
-		printk(KERN_ERR
-		       "mal%d: can't find DCR resource!\n", index);
+		printk(KERN_ERR "mal%d: can't find DCR resource!\n", index);
 		err = -ENODEV;
 		goto fail;
 	}
-	mal->dcr_host = dcr_map(ofdev->dev.of_node, dcr_base, 0x100);
+	mal->dcr_host = dcr_map(np, dcr_base, 0x100);
 	if (!DCR_MAP_OK(mal->dcr_host)) {
-		printk(KERN_ERR
-		       "mal%d: failed to map DCRs !\n", index);
+		printk(KERN_ERR "mal%d: failed to map DCRs !\n", index);
 		err = -ENODEV;
 		goto fail;
 	}
 
-	if (of_device_is_compatible(ofdev->dev.of_node, "ibm,mcmal-405ez")) {
-#if defined(CONFIG_IBM_EMAC_MAL_CLR_ICINTSTAT) && \
-		defined(CONFIG_IBM_EMAC_MAL_COMMON_ERR)
-		mal->features |= (MAL_FTR_CLEAR_ICINTSTAT |
-				MAL_FTR_COMMON_ERR_INT);
+	if (of_device_is_compatible(np, "ibm,mcmal-405ez")) {
+#if defined(CONFIG_IBM_EMAC_MAL_CLR_ICINTSTAT) && defined(CONFIG_IBM_EMAC_MAL_COMMON_ERR)
+		mal->features |= (MAL_FTR_CLEAR_ICINTSTAT | MAL_FTR_COMMON_ERR_INT);
 #else
-		printk(KERN_ERR "%s: Support for 405EZ not enabled!\n",
-				ofdev->dev.of_node->full_name);
+		printk(KERN_ERR "%s: Support for 405EZ not enabled!\n",	np->full_name);
 		err = -ENODEV;
 		goto fail;
 #endif
 	}
 
-	mal->txeob_irq = irq_of_parse_and_map(ofdev->dev.of_node, 0);
-	mal->rxeob_irq = irq_of_parse_and_map(ofdev->dev.of_node, 1);
-	mal->serr_irq = irq_of_parse_and_map(ofdev->dev.of_node, 2);
+	mal->txeob_irq = irq_of_parse_and_map(np, 0);
+	mal->rxeob_irq = irq_of_parse_and_map(np, 1);
+	mal->serr_irq  = irq_of_parse_and_map(np, 2);
 
-	if (mal_has_feature(mal, MAL_FTR_COMMON_ERR_INT)) {
+	if (mal_has_feature(mal, MAL_FTR_COMMON_ERR_INT))
 		mal->txde_irq = mal->rxde_irq = mal->serr_irq;
-	} else {
-		mal->txde_irq = irq_of_parse_and_map(ofdev->dev.of_node, 3);
-		mal->rxde_irq = irq_of_parse_and_map(ofdev->dev.of_node, 4);
+	else {
+		mal->txde_irq = irq_of_parse_and_map(np, 3);
+		mal->rxde_irq = irq_of_parse_and_map(np, 4);
 	}
 
-	if (!mal->txeob_irq || !mal->rxeob_irq || !mal->serr_irq ||
-	    !mal->txde_irq  || !mal->rxde_irq) {
-		printk(KERN_ERR
-		       "mal%d: failed to map interrupts !\n", index);
+	if (!mal->txeob_irq|| !mal->rxeob_irq|| !mal->serr_irq|| !mal->txde_irq|| !mal->rxde_irq) {
+		printk(KERN_ERR "mal%d: failed to map interrupts !\n", index);
 		err = -ENODEV;
 		goto fail_unmap;
 	}
 
+#ifdef CONFIG_IBM_EMAC_INTR_COALESCE
+	/* Number of Tx channels is equal to Physical channels */
+	/* Rx channels include Virtual channels so use Tx channels */
+	BUG_ON(mal->num_tx_chans > MAL_MAX_PHYS_CHANNELS);
+	num_phys_chans = mal->num_tx_chans;
+	/* Older revs in 460EX and 460GT have coalesce bug in h/w */
+#if (defined(CONFIG_460EX) || defined(CONFIG_460GT)) && !defined(CONFIG_APM821xx)
+	{	unsigned int pvr = mfspr(SPRN_PVR);
+		unsigned short min = PVR_MIN(pvr);
+		if (min < 4) {
+			printk(KERN_INFO "PVR %x Intr Coal disabled: H/W bug\n", pvr);
+			mal->coalesce_disabled = 1;
+		}
+	}
+#else
+	mal->coalesce_disabled = 0;
+#endif
+	coal_intr_index = 5;
+	/* If device tree doesn't Interrupt coal IRQ, fall back to EOB IRQ */
+	for (i = 0; (i < num_phys_chans) && (mal->coalesce_disabled == 0) ; i++) {
+		mal->txcoal_irq[i] = irq_of_parse_and_map(np, coal_intr_index++);
+		if (mal->txcoal_irq[i] == NO_IRQ) {
+			printk(KERN_INFO "MAL: No device tree IRQ for TxCoal%d  - disabling coalescing\n", i);
+			mal->coalesce_disabled = 1;
+		}
+	}
+	for (i = 0; (i < num_phys_chans) && (mal->coalesce_disabled == 0); i++) {
+		mal->rxcoal_irq[i] = irq_of_parse_and_map(np, coal_intr_index++);
+		if (mal->rxcoal_irq[i] == NO_IRQ) {
+			printk(KERN_INFO "MAL: No device tree IRQ for RxCoal%d  - disabling coalescing\n", i);
+			mal->coalesce_disabled = 1;
+		}
+	}
+#endif
+
 	INIT_LIST_HEAD(&mal->poll_list);
 	INIT_LIST_HEAD(&mal->list);
 	spin_lock_init(&mal->lock);
 
 	init_dummy_netdev(&mal->dummy_dev);
 
-	netif_napi_add(&mal->dummy_dev, &mal->napi, mal_poll,
-		       CONFIG_IBM_EMAC_POLL_WEIGHT);
+	netif_napi_add(&mal->dummy_dev, &mal->napi, mal_poll, CONFIG_IBM_EMAC_POLL_WEIGHT);
 
 	/* Load power-on reset defaults */
 	mal_reset(mal);
@@ -620,10 +688,8 @@
 	cfg = (mal->version == 2) ? MAL2_CFG_DEFAULT : MAL1_CFG_DEFAULT;
 	cfg |= MAL_CFG_PLBB | MAL_CFG_OPBBL | MAL_CFG_LEA;
 
-	/* Current Axon is not happy with priority being non-0, it can
-	 * deadlock, fix it up here
-	 */
-	if (of_device_is_compatible(ofdev->dev.of_node, "ibm,mcmal-axon"))
+	/* Current Axon is not happy with priority being non-0, it can deadlock, fix it up here */
+	if (of_device_is_compatible(np, "ibm,mcmal-axon"))
 		cfg &= ~(MAL2_CFG_RPP_10 | MAL2_CFG_WPP_10);
 
 	/* Apply configuration */
@@ -633,25 +699,42 @@
 	BUG_ON(mal->num_tx_chans <= 0 || mal->num_tx_chans > 32);
 	BUG_ON(mal->num_rx_chans <= 0 || mal->num_rx_chans > 32);
 
-	bd_size = sizeof(struct mal_descriptor) *
-		(NUM_TX_BUFF * mal->num_tx_chans +
+	bd_size = sizeof(struct mal_descriptor) * (NUM_TX_BUFF * mal->num_tx_chans +
 		 NUM_RX_BUFF * mal->num_rx_chans);
-	mal->bd_virt = dma_zalloc_coherent(&ofdev->dev, bd_size, &mal->bd_dma,
-					   GFP_KERNEL);
+/* ECO */
+	if (mal->desc_memory == MAL_DESC_MEM_OCM) {
+		mal->bd_virt = ppc4xx_ocm_alloc(&mal->bd_phys, bd_size, 4, PPC4XX_OCM_NON_CACHED, "mal_descriptors");
+		mal->bd_dma  = (u32)mal->bd_phys;
+	}
+
 	if (mal->bd_virt == NULL) {
+		// Allocate BD on SDRAM in case !MAL_DESC_MEM_OCM or failed OCM alloc
+		if (mal->desc_memory == MAL_DESC_MEM_OCM){
+			printk(KERN_INFO "mal%d: failed OCM alloc, descriptor-memory = SDRAM\n", index);
+			mal->desc_memory = MAL_DESC_MEM_SDRAM;
+		}
+		mal->bd_virt = dma_alloc_coherent(dp, bd_size, &mal->bd_dma, GFP_KERNEL |__GFP_ZERO);
+	}
+	if (mal->bd_virt == NULL) {
+		printk(KERN_ERR "mal%d: out of memory allocating RX/TX descriptors!\n", index);
 		err = -ENOMEM;
 		goto fail_unmap;
 	}
 
-	for (i = 0; i < mal->num_tx_chans; ++i)
-		set_mal_dcrn(mal, MAL_TXCTPR(i), mal->bd_dma +
-			     sizeof(struct mal_descriptor) *
+	//memset(mal->bd_virt, 0, bd_size);
+	for (i = 0; i < mal->num_tx_chans; ++i) {
+		if (mal->desc_memory == MAL_DESC_MEM_OCM)
+			set_mal_dcrn(mal, MAL_TXBADDR, (mal->bd_phys >> 32));
+		set_mal_dcrn(mal, MAL_TXCTPR(i), mal->bd_dma + sizeof(struct mal_descriptor) *
 			     mal_tx_bd_offset(mal, i));
+	}
 
-	for (i = 0; i < mal->num_rx_chans; ++i)
-		set_mal_dcrn(mal, MAL_RXCTPR(i), mal->bd_dma +
-			     sizeof(struct mal_descriptor) *
+	for (i = 0; i < mal->num_rx_chans; ++i) {
+		if (mal->desc_memory == MAL_DESC_MEM_OCM)
+			set_mal_dcrn(mal, MAL_RXBADDR, (u32)(mal->bd_phys >> 32));
+		set_mal_dcrn(mal, MAL_RXCTPR(i), mal->bd_dma + sizeof(struct mal_descriptor) *
 			     mal_rx_bd_offset(mal, i));
+	}
 
 	if (mal_has_feature(mal, MAL_FTR_COMMON_ERR_INT)) {
 		irqflags = IRQF_SHARED;
@@ -664,72 +747,118 @@
 	}
 
 	err = request_irq(mal->serr_irq, hdlr_serr, irqflags, "MAL SERR", mal);
-	if (err)
-		goto fail2;
+	if (err) goto fail2;
 	err = request_irq(mal->txde_irq, hdlr_txde, irqflags, "MAL TX DE", mal);
-	if (err)
-		goto fail3;
-	err = request_irq(mal->txeob_irq, mal_txeob, 0, "MAL TX EOB", mal);
-	if (err)
-		goto fail4;
+	if (err) goto fail3;
+
 	err = request_irq(mal->rxde_irq, hdlr_rxde, irqflags, "MAL RX DE", mal);
-	if (err)
-		goto fail5;
-	err = request_irq(mal->rxeob_irq, mal_rxeob, 0, "MAL RX EOB", mal);
-	if (err)
-		goto fail6;
+	if (err) goto fail4;
+
+#ifdef CONFIG_IBM_EMAC_INTR_COALESCE
+	for (i = 0; (i < num_phys_chans) && (!mal->coalesce_disabled); i++) {
+		err = request_irq(mal->txcoal_irq[i], mal_coal, 0, tx_coal_irqname[i], mal);
+		if (err) {
+			printk(KERN_INFO "MAL: TxCoal%d ReqIRQ failed - disabling coalescing\n", i);
+			mal->txcoal_irq[i] = NO_IRQ;
+			mal->coalesce_disabled = 1;
+			break;
+		}
+	}
+	for (i = 0; (i < num_phys_chans) && (!mal->coalesce_disabled); i++) {
+		err = request_irq(mal->rxcoal_irq[i], mal_coal, 0, rx_coal_irqname[i], mal);
+		if (err) {
+			printk(KERN_INFO "MAL: RxCoal%d ReqIRQ failed - disabling coalescing\n", i);
+			mal->rxcoal_irq[i] = NO_IRQ;
+			mal->coalesce_disabled = 1;
+			break;
+		}
+	}
+
+	if (mal->coalesce_disabled) {	/* Fall back to EOB IRQ if coalesce not supported */
+		for (i = 0; i < num_phys_chans; i++) { 	// Clean up any IRQs allocated for Coalescing
+			if (mal->txcoal_irq[i] != NO_IRQ) free_irq(mal->txcoal_irq[i], mal);
+			if (mal->rxcoal_irq[i] != NO_IRQ) free_irq(mal->rxcoal_irq[i], mal);
+		}
+#endif
+		err = request_irq(mal->txeob_irq, mal_txeob, 0, "MAL TX EOB", mal);
+		if (err) goto fail5;
+		err = request_irq(mal->rxeob_irq, mal_rxeob, 0, "MAL RX EOB", mal);
+		if (err) {
+			mal->rxeob_irq = NO_IRQ;
+			goto fail6;
+		}
+#ifdef CONFIG_IBM_EMAC_INTR_COALESCE
+	}
+#endif
 
 	/* Enable all MAL SERR interrupt sources */
 	set_mal_dcrn(mal, MAL_IER, MAL_IER_EVENTS);
 
+#ifdef CONFIG_IBM_EMAC_INTR_COALESCE
+	if (!mal->coalesce_disabled) {
+		for (i = 0; i < 4; i++) {
+			mal->coales_param[i].tx_count = CONFIG_IBM_EMAC_TX_COAL_COUNT & COAL_FRAME_MASK;
+			mal->coales_param[i].rx_count = CONFIG_IBM_EMAC_RX_COAL_COUNT & COAL_FRAME_MASK;
+			mal->coales_param[i].tx_time  = CONFIG_IBM_EMAC_TX_COAL_TIMER;
+			mal->coales_param[i].rx_time  = CONFIG_IBM_EMAC_RX_COAL_TIMER;
+		}
+		mal_enable_coal(mal);
+	}
+#endif
+
 	/* Enable EOB interrupt */
 	mal_enable_eob_irq(mal);
 
-	printk(KERN_INFO
-	       "MAL v%d %s, %d TX channels, %d RX channels\n",
-	       mal->version, ofdev->dev.of_node->full_name,
-	       mal->num_tx_chans, mal->num_rx_chans);
+	printk(KERN_INFO "MAL v%d %s, %d TX channels, %d RX channels\n",
+	       mal->version, np->full_name, mal->num_tx_chans, mal->num_rx_chans);
 
 	/* Advertise this instance to the rest of the world */
 	wmb();
 	platform_set_drvdata(ofdev, mal);
-
 	mal_dbg_register(mal);
-
 	return 0;
 
  fail6:
-	free_irq(mal->rxde_irq, mal);
- fail5:
 	free_irq(mal->txeob_irq, mal);
+ fail5:
+	free_irq(mal->rxde_irq, mal);
  fail4:
 	free_irq(mal->txde_irq, mal);
  fail3:
 	free_irq(mal->serr_irq, mal);
  fail2:
-	dma_free_coherent(&ofdev->dev, bd_size, mal->bd_virt, mal->bd_dma);
+	dma_free_coherent(dp, bd_size, mal->bd_virt, mal->bd_dma);
+
+#ifdef CONFIG_IBM_EMAC_INTR_COALESCE
+	if (!mal->coalesce_disabled) {
+		for (i = 0; i < num_phys_chans; i++) {
+			if (mal->txcoal_irq[i] != NO_IRQ) free_irq(mal->txcoal_irq[i], mal);
+			if (mal->rxcoal_irq[i] != NO_IRQ) free_irq(mal->rxcoal_irq[i], mal);
+		}
+	}
+#endif
+	if (mal->desc_memory == MAL_DESC_MEM_OCM) ppc4xx_ocm_free(mal->bd_virt);
+	else dma_free_coherent(&ofdev->dev, bd_size, mal->bd_virt, mal->bd_dma);
  fail_unmap:
 	dcr_unmap(mal->dcr_host, 0x100);
  fail:
 	kfree(mal);
-
 	return err;
 }
 
-static int mal_remove(struct platform_device *ofdev)
-{
+static int mal_remove(struct platform_device *ofdev) {
 	struct mal_instance *mal = platform_get_drvdata(ofdev);
+#ifdef CONFIG_IBM_EMAC_INTR_COALESCE
+	int i, num_phys_chans;
+#endif
 
 	MAL_DBG(mal, "remove" NL);
 
 	/* Synchronize with scheduled polling */
 	napi_disable(&mal->napi);
 
-	if (!list_empty(&mal->list))
-		/* This is *very* bad */
-		WARN(1, KERN_EMERG
-		       "mal%d: commac list is not empty on remove!\n",
-		       mal->index);
+	if (!list_empty(&mal->list)) /* This is *very* bad */
+		WARN(1, KERN_EMERG "mal%d: commac list is not empty on remove!\n", mal->index);
 
 	free_irq(mal->serr_irq, mal);
 	free_irq(mal->txde_irq, mal);
@@ -737,37 +866,34 @@
 	free_irq(mal->rxde_irq, mal);
 	free_irq(mal->rxeob_irq, mal);
 
+#ifdef CONFIG_IBM_EMAC_INTR_COALESCE
+	num_phys_chans = mal->num_tx_chans;
+	if (!mal->coalesce_disabled) {
+		for (i = 0; i < num_phys_chans; i++) {
+			if (mal->txcoal_irq[i]) free_irq(mal->txcoal_irq[i], mal);
+			if (mal->rxcoal_irq[i]) free_irq(mal->rxcoal_irq[i], mal);
+		}
+	}
+#endif
 	mal_reset(mal);
-
 	mal_dbg_unregister(mal);
 
-	dma_free_coherent(&ofdev->dev,
-			  sizeof(struct mal_descriptor) *
-			  (NUM_TX_BUFF * mal->num_tx_chans +
-			   NUM_RX_BUFF * mal->num_rx_chans), mal->bd_virt,
-			  mal->bd_dma);
+	if (mal->desc_memory == MAL_DESC_MEM_OCM)
+		ppc4xx_ocm_free(mal->bd_virt);
+	else dma_free_coherent(&ofdev->dev, sizeof(struct mal_descriptor) *
+		(NUM_TX_BUFF * mal->num_tx_chans + NUM_RX_BUFF * mal->num_rx_chans), 
+		mal->bd_virt, mal->bd_dma);
 	kfree(mal);
-
 	return 0;
 }
 
-static const struct of_device_id mal_platform_match[] =
-{
-	{
-		.compatible	= "ibm,mcmal",
-	},
-	{
-		.compatible	= "ibm,mcmal2",
-	},
-	/* Backward compat */
-	{
-		.type		= "mcmal-dma",
-		.compatible	= "ibm,mcmal",
-	},
-	{
-		.type		= "mcmal-dma",
-		.compatible	= "ibm,mcmal2",
-	},
+static const struct of_device_id mal_platform_match[] = {
+	{	.compatible	= "ibm,mcmal",	},
+	{	.compatible	= "ibm,mcmal2",	},
+	{	.type		= "mcmal-dma",			/* Backward compat */
+		.compatible	= "ibm,mcmal",	},
+	{	.type		= "mcmal-dma",
+		.compatible	= "ibm,mcmal2",	},
 	{},
 };
 
@@ -780,12 +906,10 @@
 	.remove = mal_remove,
 };
 
-int __init mal_init(void)
-{
+int __init mal_init(void) {
 	return platform_driver_register(&mal_of_driver);
 }
 
-void mal_exit(void)
-{
+void mal_exit(void) {
 	platform_driver_unregister(&mal_of_driver);
 }
diff -Naur a/drivers/net/ethernet/ibm/emac/mal.h b/drivers/net/ethernet/ibm/emac/mal.h
--- a/drivers/net/ethernet/ibm/emac/mal.h	2019-01-09 16:16:45.000000000 +0000
+++ b/drivers/net/ethernet/ibm/emac/mal.h	2019-02-16 13:53:50.966853000 +0000
@@ -39,104 +39,101 @@
  */
 
 /* MALx DCR registers */
-#define	MAL_CFG			0x00
-#define	  MAL_CFG_SR		0x80000000
-#define   MAL_CFG_PLBB		0x00004000
-#define   MAL_CFG_OPBBL		0x00000080
-#define   MAL_CFG_EOPIE		0x00000004
-#define   MAL_CFG_LEA		0x00000002
-#define   MAL_CFG_SD		0x00000001
+#define	MAL_CFG 		0x00
+#define	MAL_CFG_SR  		0x80000000
+#define MAL_CFG_PLBB		0x00004000
+#define MAL_CFG_OPBBL		0x00000080
+#define MAL_CFG_EOPIE		0x00000004
+#define MAL_CFG_LEA	    	0x00000002
+#define MAL_CFG_SD	    	0x00000001
 
 /* MAL V1 CFG bits */
-#define   MAL1_CFG_PLBP_MASK	0x00c00000
-#define   MAL1_CFG_PLBP_10	0x00800000
-#define   MAL1_CFG_GA		0x00200000
-#define   MAL1_CFG_OA		0x00100000
-#define   MAL1_CFG_PLBLE	0x00080000
-#define   MAL1_CFG_PLBT_MASK	0x00078000
-#define   MAL1_CFG_DEFAULT	(MAL1_CFG_PLBP_10 | MAL1_CFG_PLBT_MASK)
+#define MAL1_CFG_PLBP_MASK	0x00c00000
+#define MAL1_CFG_PLBP_10	0x00800000
+#define MAL1_CFG_GA	    	0x00200000
+#define MAL1_CFG_OA	    	0x00100000
+#define MAL1_CFG_PLBLE  	0x00080000
+#define MAL1_CFG_PLBT_MASK	0x00078000
+#define MAL1_CFG_DEFAULT	(MAL1_CFG_PLBP_10 | MAL1_CFG_PLBT_MASK)
 
 /* MAL V2 CFG bits */
-#define   MAL2_CFG_RPP_MASK	0x00c00000
-#define   MAL2_CFG_RPP_10	0x00800000
-#define   MAL2_CFG_RMBS_MASK	0x00300000
-#define   MAL2_CFG_WPP_MASK	0x000c0000
-#define   MAL2_CFG_WPP_10	0x00080000
-#define   MAL2_CFG_WMBS_MASK	0x00030000
-#define   MAL2_CFG_PLBLE	0x00008000
-#define   MAL2_CFG_DEFAULT	(MAL2_CFG_RMBS_MASK | MAL2_CFG_WMBS_MASK | \
+#define MAL2_CFG_RPP_MASK	0x00c00000
+#define MAL2_CFG_RPP_10	    0x00800000
+#define MAL2_CFG_RMBS_MASK	0x00300000
+#define MAL2_CFG_WPP_MASK	0x000c0000
+#define MAL2_CFG_WPP_10	    0x00080000
+#define MAL2_CFG_WMBS_MASK	0x00030000
+#define MAL2_CFG_PLBLE	    0x00008000
+#define MAL2_CFG_DEFAULT	(MAL2_CFG_RMBS_MASK | MAL2_CFG_WMBS_MASK | \
 				 MAL2_CFG_RPP_10 | MAL2_CFG_WPP_10)
 
-#define MAL_ESR			0x01
-#define   MAL_ESR_EVB		0x80000000
-#define   MAL_ESR_CIDT		0x40000000
-#define   MAL_ESR_CID_MASK	0x3e000000
-#define   MAL_ESR_CID_SHIFT	25
-#define   MAL_ESR_DE		0x00100000
-#define   MAL_ESR_OTE		0x00040000
-#define   MAL_ESR_OSE		0x00020000
-#define   MAL_ESR_PEIN		0x00010000
-#define   MAL_ESR_DEI		0x00000010
-#define   MAL_ESR_OTEI		0x00000004
-#define   MAL_ESR_OSEI		0x00000002
-#define   MAL_ESR_PBEI		0x00000001
+#define MAL_ESR			    0x01
+#define MAL_ESR_EVB	    	0x80000000
+#define MAL_ESR_CIDT		0x40000000
+#define MAL_ESR_CID_MASK	0x3e000000
+#define MAL_ESR_CID_SHIFT	25
+#define MAL_ESR_DE	    	0x00100000
+#define MAL_ESR_OTE	    	0x00040000
+#define MAL_ESR_OSE	    	0x00020000
+#define MAL_ESR_PEIN		0x00010000
+#define MAL_ESR_DEI	    	0x00000010
+#define MAL_ESR_OTEI		0x00000004
+#define MAL_ESR_OSEI		0x00000002
+#define MAL_ESR_PBEI		0x00000001
 
 /* MAL V1 ESR bits */
 #define   MAL1_ESR_ONE		0x00080000
 #define   MAL1_ESR_ONEI		0x00000008
 
 /* MAL V2 ESR bits */
-#define   MAL2_ESR_PTE		0x00800000
-#define   MAL2_ESR_PRE		0x00400000
-#define   MAL2_ESR_PWE		0x00200000
-#define   MAL2_ESR_PTEI		0x00000080
-#define   MAL2_ESR_PREI		0x00000040
-#define   MAL2_ESR_PWEI		0x00000020
-
+#define MAL2_ESR_PTE		0x00800000
+#define MAL2_ESR_PRE		0x00400000
+#define MAL2_ESR_PWE		0x00200000
+#define MAL2_ESR_PTEI		0x00000080
+#define MAL2_ESR_PREI		0x00000040
+#define MAL2_ESR_PWEI		0x00000020
 
 #define MAL_IER			0x02
 /* MAL IER bits */
-#define   MAL_IER_DE		0x00000010
-#define   MAL_IER_OTE		0x00000004
-#define   MAL_IER_OE		0x00000002
-#define   MAL_IER_PE		0x00000001
+#define MAL_IER_DE		0x00000010
+#define MAL_IER_OTE		0x00000004
+#define MAL_IER_OE		0x00000002
+#define MAL_IER_PE		0x00000001
 
 /* PLB read/write/timeout errors */
-#define   MAL_IER_PTE		0x00000080
-#define   MAL_IER_PRE		0x00000040
-#define   MAL_IER_PWE		0x00000020
-
-#define   MAL_IER_SOC_EVENTS	(MAL_IER_PTE | MAL_IER_PRE | MAL_IER_PWE)
-#define   MAL_IER_EVENTS	(MAL_IER_SOC_EVENTS | MAL_IER_DE | \
-				 MAL_IER_OTE | MAL_IER_OE | MAL_IER_PE)
+#define MAL_IER_PTE		0x00000080
+#define MAL_IER_PRE		0x00000040
+#define MAL_IER_PWE		0x00000020
+
+#define MAL_IER_SOC_EVENTS	(MAL_IER_PTE | MAL_IER_PRE | MAL_IER_PWE)
+#define MAL_IER_EVENTS	    	(MAL_IER_SOC_EVENTS | MAL_IER_DE | MAL_IER_OTE | MAL_IER_OE | MAL_IER_PE)
 
 #define MAL_TXCASR		0x04
 #define MAL_TXCARR		0x05
 #define MAL_TXEOBISR		0x06
 #define MAL_TXDEIR		0x07
+#define MAL_TXBADDR		0x09
 #define MAL_RXCASR		0x10
 #define MAL_RXCARR		0x11
 #define MAL_RXEOBISR		0x12
 #define MAL_RXDEIR		0x13
+#define MAL_RXBADDR		0x15
 #define MAL_TXCTPR(n)		((n) + 0x20)
 #define MAL_RXCTPR(n)		((n) + 0x40)
 #define MAL_RCBS(n)		((n) + 0x60)
 
 /* In reality MAL can handle TX buffers up to 4095 bytes long,
- * but this isn't a good round number :) 		 --ebs
- */
+ * but this isn't a good round number :) --ebs */
 #define MAL_MAX_TX_SIZE		4080
 #define MAL_MAX_RX_SIZE		4080
 
-static inline int mal_rx_size(int len)
-{
+static inline int mal_rx_size(int len) {
 	len = (len + 0xf) & ~0xf;
 	return len > MAL_MAX_RX_SIZE ? MAL_MAX_RX_SIZE : len;
 }
 
-static inline int mal_tx_chunks(int len)
-{
-	return (len + MAL_MAX_TX_SIZE - 1) / MAL_MAX_TX_SIZE;
+static inline int mal_tx_chunks(int len) {
+    return DIV_ROUND_UP(len, MAL_MAX_TX_SIZE);
 }
 
 #define MAL_CHAN_MASK(n)	(0x80000000 >> (n))
@@ -155,7 +152,13 @@
 #define MAL_RX_CTRL_CM		0x2000
 #define MAL_RX_CTRL_LAST	0x1000
 #define MAL_RX_CTRL_FIRST	0x0800
+/* Optimize OR operations */
+#ifdef CONFIG_IBM_EMAC_INTR_COALESCE
 #define MAL_RX_CTRL_INTR	0x0400
+#else
+#define MAL_RX_CTRL_INTR	0x0
+#endif
+
 #define MAL_RX_CTRL_SINGLE	(MAL_RX_CTRL_LAST | MAL_RX_CTRL_FIRST)
 #define MAL_IS_SINGLE_RX(ctrl)	(((ctrl) & MAL_RX_CTRL_SINGLE) == MAL_RX_CTRL_SINGLE)
 
@@ -165,17 +168,83 @@
 #define MAL_TX_CTRL_LAST	0x1000
 #define MAL_TX_CTRL_INTR	0x0400
 
+#define MAL_DESC_MEM_SDRAM	0x0
+#define MAL_DESC_MEM_OCM	0x1
+
+#if defined(CONFIG_405EX)
+#define DCRN_SDR0_ICCRTX	0x430B /* Int coal Tx control register */
+#define DCRN_SDR0_ICCRRX	0x430C /* Int coal Rx control register */
+#define SDR0_ICC_FTHR0_SHIFT 23
+#define SDR0_ICC_FLUSH0		22
+#define SDR0_ICC_FLUWI0		21
+#define SDR0_ICC_FTHR1_SHIFT 12
+#define SDR0_ICC_FLUSH1		11
+#define SDR0_ICC_FLUWI1		10
+#define DCRN_SDR0_ICCTRTX0	0x430D /* Int coal Tx0 count threshold */
+#define DCRN_SDR0_ICCTRTX1	0x430E /* Int coal Tx1 count threshold */
+#define DCRN_SDR0_ICCTRRX0	0x430F /* Int coal Rx0 count threshold */
+#define DCRN_SDR0_ICCTRRX1	0x4310 /* Int coal Rx1 count threshold */
+#define DCRN_SDR0_ICTSRTX0	0x4307 /* Int coal Tx0 timer status*/
+#define DCRN_SDR0_ICTSRTX1	0x4308 /* Int coal Tx1 timer status*/
+#define DCRN_SDR0_ICTSRRX0	0x4309 /* Int coal Rx0 timer status*/
+#define DCRN_SDR0_ICTSRRX1	0x430A /* Int coal Rx1 timer status*/
+
+#elif defined(CONFIG_APM821xx)
+#define DCRN_SDR0_ICCRTX0	0x4410 /* Int coal Tx0 control register */
+#define DCRN_SDR0_ICCRRX0	0x4414 /* Int coal Rx0 control register */
+#define SDR0_ICC_FTHR_SHIFT	23
+#define SDR0_ICC_FLUSH		22
+#define SDR0_ICC_FLUWI		21
+#define DCRN_SDR0_ICCTRTX0	0x4418 /* Int coal Tx0 count threshold */
+#define DCRN_SDR0_ICCTRRX0	0x441C /* Int coal Rx0 count threshold */
+#define DCRN_SDR0_ICTSRTX0	0x4420 /* Int coal Tx0 timer status*/
+#define DCRN_SDR0_ICTSRRX0	0x4424 /* Int coal Rx0 timer status*/
+#define SDR0_PERCLK			0x4201
+
+#elif defined(CONFIG_460EX) || defined(CONFIG_460GT) || defined(CONFIG_460SX)
+#define DCRN_SDR0_ICCRTX0	0x4410 /* Int coal Tx0 control register */
+#define DCRN_SDR0_ICCRTX1	0x4411 /* Int coal Tx1 control register */
+#define DCRN_SDR0_ICCRTX2	0x4412 /* Int coal Tx2 control register */
+#define DCRN_SDR0_ICCRTX3	0x4413 /* Int coal Tx3 control register */
+#define DCRN_SDR0_ICCRRX0	0x4414 /* Int coal Rx0 control register */
+#define DCRN_SDR0_ICCRRX1	0x4415 /* Int coal Rx1 control register */
+#define DCRN_SDR0_ICCRRX2	0x4416 /* Int coal Rx2 control register */
+#define DCRN_SDR0_ICCRRX3	0x4417 /* Int coal Rx3 control register */
+#define SDR0_ICC_FTHR_SHIFT	23
+#define SDR0_ICC_FLUSH		22
+#define SDR0_ICC_FLUWI		21
+#define DCRN_SDR0_ICCTRTX0	0x4418 /* Int coal Tx0 count threshold */
+#define DCRN_SDR0_ICCTRTX1	0x4419 /* Int coal Tx1 count threshold */
+#define DCRN_SDR0_ICCTRTX2	0x441A /* Int coal Tx2 count threshold */
+#define DCRN_SDR0_ICCTRTX3	0x441B /* Int coal Tx3 count threshold */
+#define DCRN_SDR0_ICCTRRX0	0x441C /* Int coal Rx0 count threshold */
+#define DCRN_SDR0_ICCTRRX1	0x441D /* Int coal Rx1 count threshold */
+#define DCRN_SDR0_ICCTRRX2	0x441E /* Int coal Rx2 count threshold */
+#define DCRN_SDR0_ICCTRRX3	0x441F /* Int coal Rx3 count threshold */
+#define DCRN_SDR0_ICTSRTX0	0x4420 /* Int coal Tx0 timer status*/
+#define DCRN_SDR0_ICTSRTX1	0x4421 /* Int coal Tx1 timer status*/
+#define DCRN_SDR0_ICTSRTX2	0x4422 /* Int coal Tx2 timer status*/
+#define DCRN_SDR0_ICTSRTX3	0x4423 /* Int coal Tx3 timer status*/
+#define DCRN_SDR0_ICTSRRX0	0x4424 /* Int coal Rx0 timer status*/
+#define DCRN_SDR0_ICTSRRX1	0x4425 /* Int coal Rx1 timer status*/
+#define DCRN_SDR0_ICTSRRX2	0x4426 /* Int coal Rx2 timer status*/
+#define DCRN_SDR0_ICTSRRX3	0x4427 /* Int coal Rx3 timer status*/
+#endif
+
+#define COAL_FRAME_MASK		0x1FF
+#define MAL_MAX_PHYS_CHANNELS	4
+
 struct mal_commac_ops {
-	void	(*poll_tx) (void *dev);
+	void (*poll_tx) (void *dev);
 	int	(*poll_rx) (void *dev, int budget);
 	int	(*peek_rx) (void *dev);
-	void	(*rxde) (void *dev);
+	void (*rxde) (void *dev);
 };
 
 struct mal_commac {
-	struct mal_commac_ops	*ops;
-	void			*dev;
-	struct list_head	poll_list;
+	struct mal_commac_ops *ops;
+	void		*dev;
+	struct list_head poll_list;
 	long       		flags;
 #define MAL_COMMAC_RX_STOPPED		0
 #define MAL_COMMAC_POLL_DISABLED	1
@@ -184,18 +253,45 @@
 	struct list_head	list;
 };
 
+#ifdef CONFIG_IBM_EMAC_INTR_COALESCE
+struct mal_coales_param { /* Configuration parameters for the coalescing function */
+	int         tx_count;
+	int         tx_time;
+	int         rx_count;
+	int         rx_time;
+};
+#endif
+
 struct mal_instance {
 	int			version;
-	dcr_host_t		dcr_host;
-
+	dcr_host_t	dcr_host;
+	int			desc_memory;	/* SDRAM or OCM */
 	int			num_tx_chans;	/* Number of TX channels */
 	int			num_rx_chans;	/* Number of RX channels */
-	int 			txeob_irq;	/* TX End Of Buffer IRQ  */
-	int 			rxeob_irq;	/* RX End Of Buffer IRQ  */
+	int 		txeob_irq;	/* TX End Of Buffer IRQ  */
+	int 		rxeob_irq;	/* RX End Of Buffer IRQ  */
 	int			txde_irq;	/* TX Descriptor Error IRQ */
 	int			rxde_irq;	/* RX Descriptor Error IRQ */
 	int			serr_irq;	/* MAL System Error IRQ    */
 
+#if defined(CONFIG_IBM_EMAC_INTR_COALESCE)
+	int			txcoal0_irq;	/* COAL */
+	int			txcoal1_irq;	/* COAL */
+	int			txcoal2_irq;	/* COAL */
+	int			txcoal3_irq;	/* COAL */
+	int			rxcoal0_irq;	/* COAL */
+	int			rxcoal1_irq;	/* COAL */
+	int			rxcoal2_irq;	/* COAL */
+	int			rxcoal3_irq;	/* COAL */
+
+	struct mal_coales_param coales_param[4];
+	/* add copy of iccrtx and iccrrx registers to bypass the bug on the 440EPX pass1 
+	 * where these registers are write only */
+	u32     	enet_coales_iccrtx;
+	u32     	enet_coales_iccrrx;
+	struct timer_list mal_coal_timer;
+#endif
+
 	struct list_head	poll_list;
 	struct napi_struct	napi;
 
@@ -203,73 +299,66 @@
 	u32			tx_chan_mask;
 	u32			rx_chan_mask;
 
-	dma_addr_t		bd_dma;
+	dma_addr_t	bd_dma;
+	phys_addr_t	bd_phys;
 	struct mal_descriptor	*bd_virt;
 
 	struct platform_device	*ofdev;
 	int			index;
-	spinlock_t		lock;
+	spinlock_t	lock;
 
 	struct net_device	dummy_dev;
 
 	unsigned int features;
+#ifdef CONFIG_IBM_EMAC_INTR_COALESCE
+	int			txcoal_irq[MAL_MAX_PHYS_CHANNELS];	/* MAL TxCoalesce Error IRQ    */
+	int			rxcoal_irq[MAL_MAX_PHYS_CHANNELS];	/* MAL RxCoalesce IRQ    */
+	int			coalesce_disabled;	/* Coalesce disable flag    */
+#endif
 };
 
-static inline u32 get_mal_dcrn(struct mal_instance *mal, int reg)
-{
+static inline u32 get_mal_dcrn(struct mal_instance *mal, int reg) {
 	return dcr_read(mal->dcr_host, reg);
 }
 
-static inline void set_mal_dcrn(struct mal_instance *mal, int reg, u32 val)
-{
+static inline void set_mal_dcrn(struct mal_instance *mal, int reg, u32 val){
 	dcr_write(mal->dcr_host, reg, val);
 }
 
 /* Features of various MAL implementations */
 
 /* Set if you have interrupt coalescing and you have to clear the SDR
- * register for TXEOB and RXEOB interrupts to work
- */
+ * register for TXEOB and RXEOB interrupts to work */
 #define MAL_FTR_CLEAR_ICINTSTAT	0x00000001
 
-/* Set if your MAL has SERR, TXDE, and RXDE OR'd into a single UIC
- * interrupt
- */
+/* Set if your MAL has SERR, TXDE, and RXDE OR'd into a single UIC interrupt */
 #define MAL_FTR_COMMON_ERR_INT	0x00000002
 
 enum {
 	MAL_FTRS_ALWAYS = 0,
-
 	MAL_FTRS_POSSIBLE =
 #ifdef CONFIG_IBM_EMAC_MAL_CLR_ICINTSTAT
-		MAL_FTR_CLEAR_ICINTSTAT |
+	MAL_FTR_CLEAR_ICINTSTAT |
 #endif
 #ifdef CONFIG_IBM_EMAC_MAL_COMMON_ERR
-		MAL_FTR_COMMON_ERR_INT |
+	MAL_FTR_COMMON_ERR_INT |
 #endif
-		0,
+	0,
 };
 
-static inline int mal_has_feature(struct mal_instance *dev,
-		unsigned long feature)
-{
-	return (MAL_FTRS_ALWAYS & feature) ||
-		(MAL_FTRS_POSSIBLE & dev->features & feature);
+static inline int mal_has_feature(struct mal_instance *dev, unsigned long feature) {
+	return (MAL_FTRS_ALWAYS & feature) || (MAL_FTRS_POSSIBLE & dev->features & feature);
 }
 
 /* Register MAL devices */
 int mal_init(void);
 void mal_exit(void);
 
-int mal_register_commac(struct mal_instance *mal,
-			struct mal_commac *commac);
-void mal_unregister_commac(struct mal_instance *mal,
-			   struct mal_commac *commac);
+int mal_register_commac(struct mal_instance *mal, struct mal_commac *commac);
+void mal_unregister_commac(struct mal_instance *mal, struct mal_commac *commac);
 int mal_set_rcbs(struct mal_instance *mal, int channel, unsigned long size);
 
-/* Returns BD ring offset for a particular channel
-   (in 'struct mal_descriptor' elements)
-*/
+/* Returns BD ring offset for a particular channel (in 'struct mal_descriptor' elements)*/
 int mal_tx_bd_offset(struct mal_instance *mal, int channel);
 int mal_rx_bd_offset(struct mal_instance *mal, int channel);
 
@@ -280,6 +369,9 @@
 
 void mal_poll_disable(struct mal_instance *mal, struct mal_commac *commac);
 void mal_poll_enable(struct mal_instance *mal, struct mal_commac *commac);
+#ifdef CONFIG_IBM_EMAC_INTR_COALESCE
+void mal_enable_coal(struct mal_instance *mal);
+#endif
 
 /* Add/remove EMAC to/from MAL polling list */
 void mal_poll_add(struct mal_instance *mal, struct mal_commac *commac);
@@ -289,7 +381,6 @@
 struct mal_regs {
 	u32 tx_count;
 	u32 rx_count;
-
 	u32 cfg;
 	u32 esr;
 	u32 ier;
diff -Naur a/drivers/net/ethernet/ibm/emac/phy.c b/drivers/net/ethernet/ibm/emac/phy.c
--- a/drivers/net/ethernet/ibm/emac/phy.c	2019-01-09 16:16:45.000000000 +0000
+++ b/drivers/net/ethernet/ibm/emac/phy.c	2019-02-16 13:59:47.594123000 +0000
@@ -24,6 +24,8 @@
 #include <linux/mii.h>
 #include <linux/ethtool.h>
 #include <linux/delay.h>
+#include <linux/brcmphy.h>
+#include <linux/mii.h>
 
 #include "emac.h"
 #include "phy.h"
@@ -31,66 +33,53 @@
 #define phy_read _phy_read
 #define phy_write _phy_write
 
-static inline int _phy_read(struct mii_phy *phy, int reg)
-{
+static inline int _phy_read(struct mii_phy *phy, int reg) {
 	return phy->mdio_read(phy->dev, phy->address, reg);
 }
 
-static inline void _phy_write(struct mii_phy *phy, int reg, int val)
-{
+static inline void _phy_write(struct mii_phy *phy, int reg, int val) {
 	phy->mdio_write(phy->dev, phy->address, reg, val);
 }
 
-static inline int gpcs_phy_read(struct mii_phy *phy, int reg)
-{
+static inline int gpcs_phy_read(struct mii_phy *phy, int reg) {
 	return phy->mdio_read(phy->dev, phy->gpcs_address, reg);
 }
 
-static inline void gpcs_phy_write(struct mii_phy *phy, int reg, int val)
-{
+static inline void gpcs_phy_write(struct mii_phy *phy, int reg, int val) {
 	phy->mdio_write(phy->dev, phy->gpcs_address, reg, val);
 }
 
-int emac_mii_reset_phy(struct mii_phy *phy)
-{
-	int val;
-	int limit = 10000;
+int emac_mii_reset_phy(struct mii_phy *phy) {
+	int val, limit = 10000;
 
-	val = phy_read(phy, MII_BMCR);
+	val = phy_read(phy, MII_BMCR) | BMCR_RESET;
 	val &= ~(BMCR_ISOLATE | BMCR_ANENABLE);
-	val |= BMCR_RESET;
 	phy_write(phy, MII_BMCR, val);
 
 	udelay(300);
 
 	while (--limit) {
 		val = phy_read(phy, MII_BMCR);
-		if (val >= 0 && (val & BMCR_RESET) == 0)
-			break;
+		if (val >= 0 && (val & BMCR_RESET) == 0) break;
 		udelay(10);
 	}
 	if ((val & BMCR_ISOLATE) && limit > 0)
 		phy_write(phy, MII_BMCR, val & ~BMCR_ISOLATE);
-
 	return limit <= 0;
 }
 
-int emac_mii_reset_gpcs(struct mii_phy *phy)
-{
-	int val;
-	int limit = 10000;
+int emac_mii_reset_gpcs(struct mii_phy *phy) {
+	int val, limit = 10000;
 
-	val = gpcs_phy_read(phy, MII_BMCR);
+	val = gpcs_phy_read(phy, MII_BMCR) | BMCR_RESET;
 	val &= ~(BMCR_ISOLATE | BMCR_ANENABLE);
-	val |= BMCR_RESET;
 	gpcs_phy_write(phy, MII_BMCR, val);
 
 	udelay(300);
 
 	while (--limit) {
 		val = gpcs_phy_read(phy, MII_BMCR);
-		if (val >= 0 && (val & BMCR_RESET) == 0)
-			break;
+		if (val >= 0 && (val & BMCR_RESET) == 0) break;
 		udelay(10);
 	}
 	if ((val & BMCR_ISOLATE) && limit > 0)
@@ -106,8 +95,7 @@
 	return limit <= 0;
 }
 
-static int genmii_setup_aneg(struct mii_phy *phy, u32 advertise)
-{
+static int genmii_setup_aneg(struct mii_phy *phy, u32 advertise) {
 	int ctl, adv;
 
 	phy->autoneg = AUTONEG_ENABLE;
@@ -117,8 +105,7 @@
 	phy->advertising = advertise;
 
 	ctl = phy_read(phy, MII_BMCR);
-	if (ctl < 0)
-		return ctl;
+	if (ctl < 0) return ctl;
 	ctl &= ~(BMCR_FULLDPLX | BMCR_SPEED100 | BMCR_SPEED1000 | BMCR_ANENABLE);
 
 	/* First clear the PHY */
@@ -126,47 +113,32 @@
 
 	/* Setup standard advertise */
 	adv = phy_read(phy, MII_ADVERTISE);
-	if (adv < 0)
-		return adv;
-	adv &= ~(ADVERTISE_ALL | ADVERTISE_100BASE4 | ADVERTISE_PAUSE_CAP |
-		 ADVERTISE_PAUSE_ASYM);
-	if (advertise & ADVERTISED_10baseT_Half)
-		adv |= ADVERTISE_10HALF;
-	if (advertise & ADVERTISED_10baseT_Full)
-		adv |= ADVERTISE_10FULL;
-	if (advertise & ADVERTISED_100baseT_Half)
-		adv |= ADVERTISE_100HALF;
-	if (advertise & ADVERTISED_100baseT_Full)
-		adv |= ADVERTISE_100FULL;
-	if (advertise & ADVERTISED_Pause)
-		adv |= ADVERTISE_PAUSE_CAP;
-	if (advertise & ADVERTISED_Asym_Pause)
-		adv |= ADVERTISE_PAUSE_ASYM;
+	if (adv < 0) return adv;
+	adv &= ~(ADVERTISE_ALL | ADVERTISE_100BASE4 | ADVERTISE_PAUSE_CAP | ADVERTISE_PAUSE_ASYM);
+	if (advertise & ADVERTISED_10baseT_Half)	adv |= ADVERTISE_10HALF;
+	if (advertise & ADVERTISED_10baseT_Full)	adv |= ADVERTISE_10FULL;
+	if (advertise & ADVERTISED_100baseT_Half)	adv |= ADVERTISE_100HALF;
+	if (advertise & ADVERTISED_100baseT_Full)	adv |= ADVERTISE_100FULL;
+	if (advertise & ADVERTISED_Pause)			adv |= ADVERTISE_PAUSE_CAP;
+	if (advertise & ADVERTISED_Asym_Pause)		adv |= ADVERTISE_PAUSE_ASYM;
 	phy_write(phy, MII_ADVERTISE, adv);
 
-	if (phy->features &
-	    (SUPPORTED_1000baseT_Full | SUPPORTED_1000baseT_Half)) {
+	if (phy->features & (SUPPORTED_1000baseT_Full | SUPPORTED_1000baseT_Half)) {
 		adv = phy_read(phy, MII_CTRL1000);
-		if (adv < 0)
-			return adv;
+		if (adv < 0) return adv;
 		adv &= ~(ADVERTISE_1000FULL | ADVERTISE_1000HALF);
-		if (advertise & ADVERTISED_1000baseT_Full)
-			adv |= ADVERTISE_1000FULL;
-		if (advertise & ADVERTISED_1000baseT_Half)
-			adv |= ADVERTISE_1000HALF;
+		if (advertise & ADVERTISED_1000baseT_Full)	adv |= ADVERTISE_1000FULL;
+		if (advertise & ADVERTISED_1000baseT_Half)	adv |= ADVERTISE_1000HALF;
 		phy_write(phy, MII_CTRL1000, adv);
 	}
 
 	/* Start/Restart aneg */
-	ctl = phy_read(phy, MII_BMCR);
-	ctl |= (BMCR_ANENABLE | BMCR_ANRESTART);
+	ctl = phy_read(phy, MII_BMCR) | BMCR_ANENABLE | BMCR_ANRESTART;
 	phy_write(phy, MII_BMCR, ctl);
-
 	return 0;
 }
 
-static int genmii_setup_forced(struct mii_phy *phy, int speed, int fd)
-{
+static int genmii_setup_forced(struct mii_phy *phy, int speed, int fd) {
 	int ctl;
 
 	phy->autoneg = AUTONEG_DISABLE;
@@ -175,8 +147,7 @@
 	phy->pause = phy->asym_pause = 0;
 
 	ctl = phy_read(phy, MII_BMCR);
-	if (ctl < 0)
-		return ctl;
+	if (ctl < 0) return ctl;
 	ctl &= ~(BMCR_FULLDPLX | BMCR_SPEED100 | BMCR_SPEED1000 | BMCR_ANENABLE);
 
 	/* First clear the PHY */
@@ -184,54 +155,38 @@
 
 	/* Select speed & duplex */
 	switch (speed) {
-	case SPEED_10:
-		break;
-	case SPEED_100:
-		ctl |= BMCR_SPEED100;
-		break;
-	case SPEED_1000:
-		ctl |= BMCR_SPEED1000;
-		break;
-	default:
-		return -EINVAL;
+		case SPEED_1000:	ctl |= BMCR_SPEED1000; break;
+		case SPEED_100:		ctl |= BMCR_SPEED100; break;
+		case SPEED_10:		break;
+		default:			return -EINVAL;
 	}
-	if (fd == DUPLEX_FULL)
-		ctl |= BMCR_FULLDPLX;
+	if (fd == DUPLEX_FULL) ctl |= BMCR_FULLDPLX;
 	phy_write(phy, MII_BMCR, ctl);
-
 	return 0;
 }
 
-static int genmii_poll_link(struct mii_phy *phy)
-{
+static int genmii_poll_link(struct mii_phy *phy) {
 	int status;
 
 	/* Clear latched value with dummy read */
 	phy_read(phy, MII_BMSR);
 	status = phy_read(phy, MII_BMSR);
-	if (status < 0 || (status & BMSR_LSTATUS) == 0)
-		return 0;
-	if (phy->autoneg == AUTONEG_ENABLE && !(status & BMSR_ANEGCOMPLETE))
-		return 0;
+	if (status < 0 || (status & BMSR_LSTATUS) == 0)	return 0;
+	if (phy->autoneg == AUTONEG_ENABLE && !(status & BMSR_ANEGCOMPLETE)) return 0;
 	return 1;
 }
 
-static int genmii_read_link(struct mii_phy *phy)
-{
+static int genmii_read_link(struct mii_phy *phy) {
 	if (phy->autoneg == AUTONEG_ENABLE) {
 		int glpa = 0;
 		int lpa = phy_read(phy, MII_LPA) & phy_read(phy, MII_ADVERTISE);
-		if (lpa < 0)
-			return lpa;
+		if (lpa < 0) return lpa;
 
 		if (phy->features &
 		    (SUPPORTED_1000baseT_Full | SUPPORTED_1000baseT_Half)) {
 			int adv = phy_read(phy, MII_CTRL1000);
 			glpa = phy_read(phy, MII_STAT1000);
-
-			if (glpa < 0 || adv < 0)
-				return adv;
-
+			if (glpa < 0 || adv < 0) return adv;
 			glpa &= adv << 2;
 		}
 
@@ -241,14 +196,11 @@
 
 		if (glpa & (LPA_1000FULL | LPA_1000HALF)) {
 			phy->speed = SPEED_1000;
-			if (glpa & LPA_1000FULL)
-				phy->duplex = DUPLEX_FULL;
+			if (glpa & LPA_1000FULL) phy->duplex = DUPLEX_FULL;
 		} else if (lpa & (LPA_100FULL | LPA_100HALF)) {
 			phy->speed = SPEED_100;
-			if (lpa & LPA_100FULL)
-				phy->duplex = DUPLEX_FULL;
-		} else if (lpa & LPA_10FULL)
-			phy->duplex = DUPLEX_FULL;
+			if (lpa & LPA_100FULL) phy->duplex = DUPLEX_FULL;
+		} else if (lpa & LPA_10FULL) phy->duplex = DUPLEX_FULL;
 
 		if (phy->duplex == DUPLEX_FULL) {
 			phy->pause = lpa & LPA_PAUSE_CAP ? 1 : 0;
@@ -256,19 +208,13 @@
 		}
 	} else {
 		int bmcr = phy_read(phy, MII_BMCR);
-		if (bmcr < 0)
-			return bmcr;
-
-		if (bmcr & BMCR_FULLDPLX)
-			phy->duplex = DUPLEX_FULL;
-		else
-			phy->duplex = DUPLEX_HALF;
-		if (bmcr & BMCR_SPEED1000)
-			phy->speed = SPEED_1000;
-		else if (bmcr & BMCR_SPEED100)
-			phy->speed = SPEED_100;
-		else
-			phy->speed = SPEED_10;
+		if (bmcr < 0) return bmcr;
+		if (bmcr & BMCR_FULLDPLX) phy->duplex = DUPLEX_FULL;
+		else phy->duplex = DUPLEX_HALF;
+
+		if (bmcr & BMCR_SPEED1000) phy->speed = SPEED_1000;
+		else if (bmcr & BMCR_SPEED100) phy->speed = SPEED_100;
+		else phy->speed = SPEED_10;
 
 		phy->pause = phy->asym_pause = 0;
 	}
@@ -276,7 +222,7 @@
 }
 
 /* Generic implementation for most 10/100/1000 PHYs */
-static struct mii_phy_ops generic_phy_ops = {
+static const struct mii_phy_ops generic_phy_ops = {
 	.setup_aneg	= genmii_setup_aneg,
 	.setup_forced	= genmii_setup_forced,
 	.poll_link	= genmii_poll_link,
@@ -294,53 +240,39 @@
 #define MII_CIS8201_10BTCSR	0x16
 #define  TENBTCSR_ECHO_DISABLE	0x2000
 #define MII_CIS8201_EPCR	0x17
-#define  EPCR_MODE_MASK		0x3000
-#define  EPCR_GMII_MODE		0x0000
-#define  EPCR_RGMII_MODE	0x1000
-#define  EPCR_TBI_MODE		0x2000
-#define  EPCR_RTBI_MODE		0x3000
+#define EPCR_MODE_MASK		0x3000
+#define EPCR_GMII_MODE		0x0000
+#define EPCR_RGMII_MODE	0x1000
+#define EPCR_TBI_MODE		0x2000
+#define EPCR_RTBI_MODE		0x3000
 #define MII_CIS8201_ACSR	0x1c
 #define  ACSR_PIN_PRIO_SELECT	0x0004
 
-static int cis8201_init(struct mii_phy *phy)
-{
-	int epcr;
-
-	epcr = phy_read(phy, MII_CIS8201_EPCR);
-	if (epcr < 0)
-		return epcr;
+static int cis8201_init(struct mii_phy *phy) {
+	int epcr = phy_read(phy, MII_CIS8201_EPCR);
 
+	if (epcr < 0) return epcr;
 	epcr &= ~EPCR_MODE_MASK;
-
 	switch (phy->mode) {
-	case PHY_MODE_TBI:
-		epcr |= EPCR_TBI_MODE;
-		break;
-	case PHY_MODE_RTBI:
-		epcr |= EPCR_RTBI_MODE;
-		break;
-	case PHY_MODE_GMII:
-		epcr |= EPCR_GMII_MODE;
-		break;
-	case PHY_MODE_RGMII:
-	default:
-		epcr |= EPCR_RGMII_MODE;
+		case PHY_INTERFACE_MODE_TBI:	epcr |= EPCR_TBI_MODE; break;
+		case PHY_INTERFACE_MODE_RTBI:	epcr |= EPCR_RTBI_MODE;	break;
+		case PHY_INTERFACE_MODE_GMII:	epcr |= EPCR_GMII_MODE;	break;
+		case PHY_INTERFACE_MODE_RGMII:
+		default:			epcr |= EPCR_RGMII_MODE;
 	}
 
 	phy_write(phy, MII_CIS8201_EPCR, epcr);
 
 	/* MII regs override strap pins */
-	phy_write(phy, MII_CIS8201_ACSR,
-		  phy_read(phy, MII_CIS8201_ACSR) | ACSR_PIN_PRIO_SELECT);
+	phy_write(phy, MII_CIS8201_ACSR, phy_read(phy, MII_CIS8201_ACSR) | ACSR_PIN_PRIO_SELECT);
 
 	/* Disable TX_EN -> CRS echo mode, otherwise 10/HDX doesn't work */
 	phy_write(phy, MII_CIS8201_10BTCSR,
-		  phy_read(phy, MII_CIS8201_10BTCSR) | TENBTCSR_ECHO_DISABLE);
-
+		phy_read(phy, MII_CIS8201_10BTCSR) | TENBTCSR_ECHO_DISABLE);
 	return 0;
 }
 
-static struct mii_phy_ops cis8201_phy_ops = {
+static const struct mii_phy_ops cis8201_phy_ops = {
 	.init		= cis8201_init,
 	.setup_aneg	= genmii_setup_aneg,
 	.setup_forced	= genmii_setup_forced,
@@ -356,15 +288,44 @@
 };
 
 static struct mii_phy_def bcm5248_phy_def = {
-
 	.phy_id		= 0x0143bc00,
 	.phy_id_mask	= 0x0ffffff0,
 	.name		= "BCM5248 10/100 SMII Ethernet",
 	.ops		= &generic_phy_ops
 };
+#ifdef CONFIG_APOLLO3G
+static int bcm54610_init(struct mii_phy *phy) {
+	int reg;
+	phy_write(phy, MII_NCONFIG, 0x2C00);	/* find out in what mode we are */
+	reg = phy_read(phy, MII_NCONFIG);
+	phy_write(phy, MII_NCONFIG, 0xAC8C);
+	phy_write(phy, MII_NCONFIG, 0x2C00);
+	//printk(KERN_INFO "%s: 0x%04x -> 0x%04x\n", __FUNCTION__, reg, phy_read(phy, MII_NCONFIG));
+
+	/* the RGMII interface is not half-duplex capable */
+	reg = phy_read(phy, MII_ADVERTISE);		// Autonegotiation advertisement register
+	phy_write(phy, MII_ADVERTISE, reg & ~(ADVERTISE_100HALF | ADVERTISE_10HALF)); //0x00a0	
+	reg = phy_read(phy, MII_CTRL1000);
+	phy_write(phy, MII_CTRL1000, reg & ~ADVERTISE_1000HALF); // 0x0100)
+	return 0;
+}
 
-static int m88e1111_init(struct mii_phy *phy)
-{
+static struct mii_phy_ops bcm54610_phy_ops = {
+	.init			= bcm54610_init,
+	.setup_aneg		= genmii_setup_aneg,
+	.setup_forced	= genmii_setup_forced,
+	.poll_link		= genmii_poll_link,
+	.read_link		= genmii_read_link
+};
+
+static struct mii_phy_def bcm54610_phy_def = {
+	.phy_id			= 0x0143BD63,
+	.phy_id_mask	= 0xffffffff,
+	.name			= "BCM54610 Gigabit Ethernet",
+	.ops			= &bcm54610_phy_ops
+};
+#endif
+static int m88e1111_init(struct mii_phy *phy) {
 	pr_debug("%s: Marvell 88E1111 Ethernet\n", __func__);
 	phy_write(phy, 0x14, 0x0ce3);
 	phy_write(phy, 0x18, 0x4101);
@@ -372,25 +333,18 @@
 	phy_write(phy, 0x04, 0x01e1);
 	phy_write(phy, 0x00, 0x9140);
 	phy_write(phy, 0x00, 0x1140);
-
 	return  0;
 }
 
-static int m88e1112_init(struct mii_phy *phy)
-{
-	/*
-	 * Marvell 88E1112 PHY needs to have the SGMII MAC
-	 * interace (page 2) properly configured to
-	 * communicate with the 460EX/GT GPCS interface.
-	 */
+static int m88e1112_init(struct mii_phy *phy) {
+	/* Marvell 88E1112 PHY needs to have the SGMII MAC interace (page 2) properly 
+	 * configured to communicate with the 460EX/GT GPCS interface */
 
 	u16 reg_short;
-
 	pr_debug("%s: Marvell 88E1112 Ethernet\n", __func__);
 
 	/* Set access to Page 2 */
 	phy_write(phy, 0x16, 0x0002);
-
 	phy_write(phy, 0x00, 0x0040); /* 1Gbps */
 	reg_short = (u16)(phy_read(phy, 0x1a));
 	reg_short |= 0x8000; /* bypass Auto-Negotiation */
@@ -403,8 +357,7 @@
 	return  0;
 }
 
-static int et1011c_init(struct mii_phy *phy)
-{
+static int et1011c_init(struct mii_phy *phy) {
 	u16 reg_short;
 
 	reg_short = (u16)(phy_read(phy, 0x16));
@@ -420,7 +373,7 @@
 	return 0;
 }
 
-static struct mii_phy_ops et1011c_phy_ops = {
+static const struct mii_phy_ops et1011c_phy_ops = {
 	.init		= et1011c_init,
 	.setup_aneg	= genmii_setup_aneg,
 	.setup_forced	= genmii_setup_forced,
@@ -435,11 +388,7 @@
 	.ops		= &et1011c_phy_ops
 };
 
-
-
-
-
-static struct mii_phy_ops m88e1111_phy_ops = {
+static const struct mii_phy_ops m88e1111_phy_ops = {
 	.init		= m88e1111_init,
 	.setup_aneg	= genmii_setup_aneg,
 	.setup_forced	= genmii_setup_forced,
@@ -448,14 +397,13 @@
 };
 
 static struct mii_phy_def m88e1111_phy_def = {
-
 	.phy_id		= 0x01410CC0,
 	.phy_id_mask	= 0x0ffffff0,
 	.name		= "Marvell 88E1111 Ethernet",
 	.ops		= &m88e1111_phy_ops,
 };
 
-static struct mii_phy_ops m88e1112_phy_ops = {
+static const struct mii_phy_ops m88e1112_phy_ops = {
 	.init		= m88e1112_init,
 	.setup_aneg	= genmii_setup_aneg,
 	.setup_forced	= genmii_setup_forced,
@@ -470,8 +418,7 @@
 	.ops		= &m88e1112_phy_ops,
 };
 
-static int ar8035_init(struct mii_phy *phy)
-{
+static int ar8035_init(struct mii_phy *phy){
 	phy_write(phy, 0x1d, 0x5); /* Address debug register 5 */
 	phy_write(phy, 0x1e, 0x2d47); /* Value copied from u-boot */
 	phy_write(phy, 0x1d, 0xb);    /* Address hib ctrl */
@@ -480,7 +427,7 @@
 	return 0;
 }
 
-static struct mii_phy_ops ar8035_phy_ops = {
+static const struct mii_phy_ops ar8035_phy_ops = {
 	.init		= ar8035_init,
 	.setup_aneg	= genmii_setup_aneg,
 	.setup_forced	= genmii_setup_forced,
@@ -499,6 +446,9 @@
 	&et1011c_phy_def,
 	&cis8201_phy_def,
 	&bcm5248_phy_def,
+#ifdef CONFIG_APOLLO3G
+	&bcm54610_phy_def,
+#endif
 	&m88e1111_phy_def,
 	&m88e1112_phy_def,
 	&ar8035_phy_def,
@@ -506,8 +456,7 @@
 	NULL
 };
 
-int emac_mii_phy_probe(struct mii_phy *phy, int address)
-{
+int emac_mii_phy_probe(struct mii_phy *phy, int address) {
 	struct mii_phy_def *def;
 	int i;
 	u32 id;
@@ -520,17 +469,14 @@
 	phy->pause = phy->asym_pause = 0;
 
 	/* Take PHY out of isolate mode and reset it. */
-	if (emac_mii_reset_phy(phy))
-		return -ENODEV;
+	if (emac_mii_reset_phy(phy)) return -ENODEV;
 
 	/* Read ID and find matching entry */
 	id = (phy_read(phy, MII_PHYSID1) << 16) | phy_read(phy, MII_PHYSID2);
 	for (i = 0; (def = mii_phy_table[i]) != NULL; i++)
-		if ((id & def->phy_id_mask) == def->phy_id)
-			break;
+		if ((id & def->phy_id_mask) == def->phy_id)	break;
 	/* Should never be NULL (we have a generic entry), but... */
-	if (!def)
-		return -ENODEV;
+	if (!def) return -ENODEV;
 
 	phy->def = def;
 
@@ -538,29 +484,25 @@
 	phy->features = def->features;
 	if (!phy->features) {
 		u16 bmsr = phy_read(phy, MII_BMSR);
-		if (bmsr & BMSR_ANEGCAPABLE)
-			phy->features |= SUPPORTED_Autoneg;
-		if (bmsr & BMSR_10HALF)
-			phy->features |= SUPPORTED_10baseT_Half;
-		if (bmsr & BMSR_10FULL)
-			phy->features |= SUPPORTED_10baseT_Full;
-		if (bmsr & BMSR_100HALF)
-			phy->features |= SUPPORTED_100baseT_Half;
-		if (bmsr & BMSR_100FULL)
-			phy->features |= SUPPORTED_100baseT_Full;
+		if (bmsr & BMSR_ANEGCAPABLE)	phy->features |= SUPPORTED_Autoneg;
+		if (bmsr & BMSR_10HALF)			phy->features |= SUPPORTED_10baseT_Half;
+		if (bmsr & BMSR_10FULL)			phy->features |= SUPPORTED_10baseT_Full;
+		if (bmsr & BMSR_100HALF)		phy->features |= SUPPORTED_100baseT_Half;
+		if (bmsr & BMSR_100FULL)		phy->features |= SUPPORTED_100baseT_Full;
 		if (bmsr & BMSR_ESTATEN) {
 			u16 esr = phy_read(phy, MII_ESTATUS);
-			if (esr & ESTATUS_1000_TFULL)
-				phy->features |= SUPPORTED_1000baseT_Full;
-			if (esr & ESTATUS_1000_THALF)
-				phy->features |= SUPPORTED_1000baseT_Half;
+			if (esr & ESTATUS_1000_TFULL)	phy->features |= SUPPORTED_1000baseT_Full;
+			if (esr & ESTATUS_1000_THALF)	phy->features |= SUPPORTED_1000baseT_Half;
 		}
 		phy->features |= SUPPORTED_MII;
 	}
 
+#if (defined CONFIG_APM821xx)  /* RGMII does not support half-duplex */
+	phy->features &= ~(SUPPORTED_1000baseT_Half | SUPPORTED_100baseT_Half | SUPPORTED_10baseT_Half);
+#endif
+
 	/* Setup default advertising */
 	phy->advertising = phy->features;
-
 	return 0;
 }
 
diff -Naur a/drivers/net/ethernet/ibm/emac/phy.h b/drivers/net/ethernet/ibm/emac/phy.h
--- a/drivers/net/ethernet/ibm/emac/phy.h	2019-01-09 16:16:45.000000000 +0000
+++ b/drivers/net/ethernet/ibm/emac/phy.h	2018-10-22 14:57:34.842585000 +0000
@@ -23,6 +23,8 @@
  * flexible than mii.c
  */
 
+#include <linux/brcmphy.h>
+ 
 #ifndef __IBM_NEWEMAC_PHY_H
 #define __IBM_NEWEMAC_PHY_H
 
@@ -40,10 +42,9 @@
 
 /* Structure used to statically define an mii/gii based PHY */
 struct mii_phy_def {
-	u32 phy_id;		/* Concatenated ID1 << 16 | ID2 */
+	u32 phy_id;			/* Concatenated ID1 << 16 | ID2 */
 	u32 phy_id_mask;	/* Significant bits */
-	u32 features;		/* Ethtool SUPPORTED_* defines or
-				   0 for autodetect */
+	u32 features;		/* Ethtool SUPPORTED_* defines or 0 for autodetect */
 	int magic_aneg;		/* Autoneg does all speed test for us */
 	const char *name;
 	const struct mii_phy_ops *ops;
@@ -53,18 +54,14 @@
 struct mii_phy {
 	struct mii_phy_def *def;
 	u32 advertising;	/* Ethtool ADVERTISED_* defines */
-	u32 features;		/* Copied from mii_phy_def.features
-				   or determined automaticaly */
+	u32 features;		/* Copied from mii_phy_def.features or determined automaticaly */
 	int address;		/* PHY address */
-	int mode;		/* PHY mode */
+	int mode;			/* PHY mode */
 	int gpcs_address;	/* GPCS PHY address */
 
-	/* 1: autoneg enabled, 0: disabled */
-	int autoneg;
+	int autoneg;		/* 1: autoneg enabled, 0: disabled */
 
-	/* forced speed & duplex (no autoneg)
-	 * partner speed & duplex & pause (autoneg)
-	 */
+	/* forced speed & duplex (no autoneg) partner speed & duplex & pause (autoneg) */
 	int speed;
 	int duplex;
 	int pause;
@@ -73,13 +70,11 @@
 	/* Provided by host chip */
 	struct net_device *dev;
 	int (*mdio_read) (struct net_device * dev, int addr, int reg);
-	void (*mdio_write) (struct net_device * dev, int addr, int reg,
-			    int val);
+	void (*mdio_write) (struct net_device * dev, int addr, int reg, int val);
 };
 
 /* Pass in a struct mii_phy with dev, mdio_read and mdio_write
- * filled, the remaining fields will be filled on return
- */
+ * filled, the remaining fields will be filled on return */
 int emac_mii_phy_probe(struct mii_phy *phy, int address);
 int emac_mii_reset_phy(struct mii_phy *phy);
 int emac_mii_reset_gpcs(struct mii_phy *phy);
diff -Naur a/drivers/net/ethernet/ibm/emac/rgmii.c b/drivers/net/ethernet/ibm/emac/rgmii.c
--- a/drivers/net/ethernet/ibm/emac/rgmii.c	2019-01-09 16:16:45.000000000 +0000
+++ b/drivers/net/ethernet/ibm/emac/rgmii.c	2017-07-06 17:09:08.100796200 +0000
@@ -50,190 +50,131 @@
 #define RGMII_SSR_1000(idx)	(0x4 << ((idx) * 8))
 
 /* RGMII bridge supports only GMII/TBI and RGMII/RTBI PHYs */
-static inline int rgmii_valid_mode(int phy_mode)
-{
-	return  phy_mode == PHY_MODE_GMII ||
-		phy_mode == PHY_MODE_MII ||
-		phy_mode == PHY_MODE_RGMII ||
-		phy_mode == PHY_MODE_TBI ||
-		phy_mode == PHY_MODE_RTBI;
+static inline int rgmii_valid_mode(int phy_mode) {
+	return  phy_mode == PHY_MODE_GMII || phy_mode == PHY_MODE_MII ||
+		phy_mode == PHY_MODE_RGMII || phy_mode == PHY_MODE_TBI || phy_mode == PHY_MODE_RTBI;
 }
 
-static inline const char *rgmii_mode_name(int mode)
-{
+static inline const char *rgmii_mode_name(int mode) {
 	switch (mode) {
-	case PHY_MODE_RGMII:
-		return "RGMII";
-	case PHY_MODE_TBI:
-		return "TBI";
-	case PHY_MODE_GMII:
-		return "GMII";
-	case PHY_MODE_MII:
-		return "MII";
-	case PHY_MODE_RTBI:
-		return "RTBI";
-	default:
-		BUG();
+		case PHY_MODE_RGMII:	return "RGMII";
+		case PHY_MODE_TBI:	return "TBI";
+		case PHY_MODE_GMII:	return "GMII";
+		case PHY_MODE_MII:	return "MII";
+		case PHY_MODE_RTBI:	return "RTBI";
+		default:		BUG();
 	}
 }
 
-static inline u32 rgmii_mode_mask(int mode, int input)
-{
+static inline u32 rgmii_mode_mask(int mode, int input) {
 	switch (mode) {
-	case PHY_MODE_RGMII:
-		return RGMII_FER_RGMII(input);
-	case PHY_MODE_TBI:
-		return RGMII_FER_TBI(input);
-	case PHY_MODE_GMII:
-		return RGMII_FER_GMII(input);
-	case PHY_MODE_MII:
-		return RGMII_FER_MII(input);
-	case PHY_MODE_RTBI:
-		return RGMII_FER_RTBI(input);
-	default:
-		BUG();
+		case PHY_MODE_RGMII:	return RGMII_FER_RGMII(input);
+		case PHY_MODE_TBI:	return RGMII_FER_TBI(input);
+		case PHY_MODE_GMII:	return RGMII_FER_GMII(input);
+		case PHY_MODE_MII:	return RGMII_FER_MII(input);
+		case PHY_MODE_RTBI:	return RGMII_FER_RTBI(input);
+		default:		BUG();
 	}
 }
 
-int rgmii_attach(struct platform_device *ofdev, int input, int mode)
-{
+int rgmii_attach(struct platform_device *ofdev, int input, int mode) {
 	struct rgmii_instance *dev = platform_get_drvdata(ofdev);
 	struct rgmii_regs __iomem *p = dev->base;
 
 	RGMII_DBG(dev, "attach(%d)" NL, input);
-
 	/* Check if we need to attach to a RGMII */
 	if (input < 0 || !rgmii_valid_mode(mode)) {
-		printk(KERN_ERR "%s: unsupported settings !\n",
-		       ofdev->dev.of_node->full_name);
+		printk(KERN_ERR "%s: unsupported settings !\n", ofdev->dev.of_node->full_name);
 		return -ENODEV;
 	}
-
 	mutex_lock(&dev->lock);
-
 	/* Enable this input */
 	out_be32(&p->fer, in_be32(&p->fer) | rgmii_mode_mask(mode, input));
-
 	printk(KERN_NOTICE "%s: input %d in %s mode\n",
 	       ofdev->dev.of_node->full_name, input, rgmii_mode_name(mode));
-
 	++dev->users;
-
 	mutex_unlock(&dev->lock);
-
 	return 0;
 }
 
-void rgmii_set_speed(struct platform_device *ofdev, int input, int speed)
-{
+void rgmii_set_speed(struct platform_device *ofdev, int input, int speed) {
 	struct rgmii_instance *dev = platform_get_drvdata(ofdev);
 	struct rgmii_regs __iomem *p = dev->base;
 	u32 ssr;
-
 	mutex_lock(&dev->lock);
-
 	ssr = in_be32(&p->ssr) & ~RGMII_SSR_MASK(input);
-
 	RGMII_DBG(dev, "speed(%d, %d)" NL, input, speed);
-
-	if (speed == SPEED_1000)
-		ssr |= RGMII_SSR_1000(input);
-	else if (speed == SPEED_100)
-		ssr |= RGMII_SSR_100(input);
-	else if (speed == SPEED_10)
-		ssr |= RGMII_SSR_10(input);
-
+	if (speed == SPEED_1000) 	ssr |= RGMII_SSR_1000(input);
+	else if (speed == SPEED_100) 	ssr |= RGMII_SSR_100(input);
+	else if (speed == SPEED_10) 	ssr |= RGMII_SSR_10(input);
 	out_be32(&p->ssr, ssr);
-
 	mutex_unlock(&dev->lock);
 }
 
-void rgmii_get_mdio(struct platform_device *ofdev, int input)
-{
+void rgmii_get_mdio(struct platform_device *ofdev, int input) {
 	struct rgmii_instance *dev = platform_get_drvdata(ofdev);
 	struct rgmii_regs __iomem *p = dev->base;
 	u32 fer;
 
 	RGMII_DBG2(dev, "get_mdio(%d)" NL, input);
-
-	if (!(dev->flags & EMAC_RGMII_FLAG_HAS_MDIO))
-		return;
-
+	if (!(dev->flags & EMAC_RGMII_FLAG_HAS_MDIO)) return;
 	mutex_lock(&dev->lock);
-
-	fer = in_be32(&p->fer);
-	fer |= 0x00080000u >> input;
+	fer = in_be32(&p->fer) | (0x00080000u >> input);
 	out_be32(&p->fer, fer);
 	(void)in_be32(&p->fer);
-
 	DBG2(dev, " fer = 0x%08x\n", fer);
 }
 
-void rgmii_put_mdio(struct platform_device *ofdev, int input)
-{
+void rgmii_put_mdio(struct platform_device *ofdev, int input) {
 	struct rgmii_instance *dev = platform_get_drvdata(ofdev);
 	struct rgmii_regs __iomem *p = dev->base;
 	u32 fer;
 
 	RGMII_DBG2(dev, "put_mdio(%d)" NL, input);
 
-	if (!(dev->flags & EMAC_RGMII_FLAG_HAS_MDIO))
-		return;
+	if (!(dev->flags & EMAC_RGMII_FLAG_HAS_MDIO)) return;
 
-	fer = in_be32(&p->fer);
-	fer &= ~(0x00080000u >> input);
+	fer = in_be32(&p->fer) & ~(0x00080000u >> input);
 	out_be32(&p->fer, fer);
 	(void)in_be32(&p->fer);
 
 	DBG2(dev, " fer = 0x%08x\n", fer);
-
 	mutex_unlock(&dev->lock);
 }
 
-void rgmii_detach(struct platform_device *ofdev, int input)
-{
+void rgmii_detach(struct platform_device *ofdev, int input) {
 	struct rgmii_instance *dev = platform_get_drvdata(ofdev);
 	struct rgmii_regs __iomem *p;
 
 	BUG_ON(!dev || dev->users == 0);
 	p = dev->base;
-
 	mutex_lock(&dev->lock);
-
 	RGMII_DBG(dev, "detach(%d)" NL, input);
-
 	/* Disable this input */
 	out_be32(&p->fer, in_be32(&p->fer) & ~RGMII_FER_MASK(input));
-
 	--dev->users;
-
 	mutex_unlock(&dev->lock);
 }
 
-int rgmii_get_regs_len(struct platform_device *ofdev)
-{
-	return sizeof(struct emac_ethtool_regs_subhdr) +
-		sizeof(struct rgmii_regs);
+int rgmii_get_regs_len(struct platform_device *ofdev) {
+	return sizeof(struct emac_ethtool_regs_subhdr) + sizeof(struct rgmii_regs);
 }
 
-void *rgmii_dump_regs(struct platform_device *ofdev, void *buf)
-{
+void *rgmii_dump_regs(struct platform_device *ofdev, void *buf) {
 	struct rgmii_instance *dev = platform_get_drvdata(ofdev);
 	struct emac_ethtool_regs_subhdr *hdr = buf;
 	struct rgmii_regs *regs = (struct rgmii_regs *)(hdr + 1);
 
 	hdr->version = 0;
-	hdr->index = 0; /* for now, are there chips with more than one
-			 * rgmii ? if yes, then we'll add a cell_index
-			 * like we do for emac
-			 */
+	hdr->index = 0; 
+	/* for now, are there chips with more than one rgmii ? if yes, then we'll add a cell_index
+	 * like we do for emac */
 	memcpy_fromio(regs, dev->base, sizeof(struct rgmii_regs));
 	return regs + 1;
 }
 
 
-static int rgmii_probe(struct platform_device *ofdev)
-{
+static int rgmii_probe(struct platform_device *ofdev) {
 	struct device_node *np = ofdev->dev.of_node;
 	struct rgmii_instance *dev;
 	struct resource regs;
@@ -241,50 +182,38 @@
 
 	rc = -ENOMEM;
 	dev = kzalloc(sizeof(struct rgmii_instance), GFP_KERNEL);
-	if (dev == NULL)
-		goto err_gone;
-
+	if (dev == NULL) goto err_gone;
 	mutex_init(&dev->lock);
 	dev->ofdev = ofdev;
 
 	rc = -ENXIO;
 	if (of_address_to_resource(np, 0, &regs)) {
-		printk(KERN_ERR "%s: Can't get registers address\n",
-		       np->full_name);
+		printk(KERN_ERR "%s: Can't get registers address\n", np->full_name);
 		goto err_free;
 	}
 
 	rc = -ENOMEM;
-	dev->base = (struct rgmii_regs __iomem *)ioremap(regs.start,
-						 sizeof(struct rgmii_regs));
+	dev->base = (struct rgmii_regs __iomem *)ioremap(regs.start, sizeof(struct rgmii_regs));
 	if (dev->base == NULL) {
-		printk(KERN_ERR "%s: Can't map device registers!\n",
-		       np->full_name);
+		printk(KERN_ERR "%s: Can't map device registers!\n", np->full_name);
 		goto err_free;
 	}
 
 	/* Check for RGMII flags */
-	if (of_get_property(ofdev->dev.of_node, "has-mdio", NULL))
-		dev->flags |= EMAC_RGMII_FLAG_HAS_MDIO;
+	if (of_get_property(np, "has-mdio", NULL)) dev->flags |= EMAC_RGMII_FLAG_HAS_MDIO;
 
 	/* CAB lacks the right properties, fix this up */
-	if (of_device_is_compatible(ofdev->dev.of_node, "ibm,rgmii-axon"))
-		dev->flags |= EMAC_RGMII_FLAG_HAS_MDIO;
-
-	DBG2(dev, " Boot FER = 0x%08x, SSR = 0x%08x\n",
-	     in_be32(&dev->base->fer), in_be32(&dev->base->ssr));
+	if (of_device_is_compatible(np, "ibm,rgmii-axon")) dev->flags |= EMAC_RGMII_FLAG_HAS_MDIO;
+	DBG2(dev, " Boot FER = 0x%08x, SSR = 0x%08x\n", in_be32(&dev->base->fer), in_be32(&dev->base->ssr));
 
 	/* Disable all inputs by default */
 	out_be32(&dev->base->fer, 0);
 
-	printk(KERN_INFO
-	       "RGMII %s initialized with%s MDIO support\n",
-	       ofdev->dev.of_node->full_name,
-	       (dev->flags & EMAC_RGMII_FLAG_HAS_MDIO) ? "" : "out");
+	printk(KERN_INFO "RGMII %s initialized with%s MDIO support\n", np->full_name,
+		(dev->flags & EMAC_RGMII_FLAG_HAS_MDIO) ? "" : "out");
 
 	wmb();
 	platform_set_drvdata(ofdev, dev);
-
 	return 0;
 
  err_free:
@@ -293,26 +222,18 @@
 	return rc;
 }
 
-static int rgmii_remove(struct platform_device *ofdev)
-{
+static int rgmii_remove(struct platform_device *ofdev) {
 	struct rgmii_instance *dev = platform_get_drvdata(ofdev);
 
 	WARN_ON(dev->users != 0);
-
 	iounmap(dev->base);
 	kfree(dev);
-
 	return 0;
 }
 
-static const struct of_device_id rgmii_match[] =
-{
-	{
-		.compatible	= "ibm,rgmii",
-	},
-	{
-		.type		= "emac-rgmii",
-	},
+static const struct of_device_id rgmii_match[] = {
+	{	.compatible	= "ibm,rgmii",  },
+	{	.type		= "emac-rgmii",	},
 	{},
 };
 
@@ -325,12 +246,10 @@
 	.remove = rgmii_remove,
 };
 
-int __init rgmii_init(void)
-{
+int __init rgmii_init(void) {
 	return platform_driver_register(&rgmii_driver);
 }
 
-void rgmii_exit(void)
-{
+void rgmii_exit(void) {
 	platform_driver_unregister(&rgmii_driver);
 }
diff -Naur a/drivers/net/ethernet/ibm/emac/rgmii.h b/drivers/net/ethernet/ibm/emac/rgmii.h
--- a/drivers/net/ethernet/ibm/emac/rgmii.h	2019-01-09 16:16:45.000000000  +0000
+++ b/drivers/net/ethernet/ibm/emac/rgmii.h	2017-06-25 20:27:27.380080900 +0000
@@ -77,6 +77,6 @@
 # define rgmii_set_speed(x,y,z)	do { } while(0)
 # define rgmii_get_regs_len(x)	0
 # define rgmii_dump_regs(x,buf)	(buf)
-#endif				/* !CONFIG_IBM_EMAC_RGMII */
+#endif	/* !CONFIG_IBM_EMAC_RGMII */
 
-#endif /* __IBM_NEWEMAC_RGMII_H */
+#endif	/* __IBM_NEWEMAC_RGMII_H */
diff -Naur a/drivers/net/ethernet/ibm/emac/tah.c b/drivers/net/ethernet/ibm/emac/tah.c
--- a/drivers/net/ethernet/ibm/emac/tah.c	2019-01-09 16:16:45.000000000 +0000
+++ b/drivers/net/ethernet/ibm/emac/tah.c	2017-07-06 06:29:01.466070285 +0000
@@ -24,72 +24,115 @@
 #include "emac.h"
 #include "core.h"
 
-int tah_attach(struct platform_device *ofdev, int channel)
-{
+int tah_attach(struct platform_device *ofdev, int channel) {
 	struct tah_instance *dev = platform_get_drvdata(ofdev);
 
 	mutex_lock(&dev->lock);
 	/* Reset has been done at probe() time... nothing else to do for now */
 	++dev->users;
 	mutex_unlock(&dev->lock);
-
 	return 0;
 }
 
-void tah_detach(struct platform_device *ofdev, int channel)
-{
+void tah_detach(struct platform_device *ofdev, int channel) {
 	struct tah_instance *dev = platform_get_drvdata(ofdev);
-
 	mutex_lock(&dev->lock);
 	--dev->users;
 	mutex_unlock(&dev->lock);
 }
 
-void tah_reset(struct platform_device *ofdev)
-{
+void tah_reset(struct platform_device *ofdev) {
 	struct tah_instance *dev = platform_get_drvdata(ofdev);
 	struct tah_regs __iomem *p = dev->base;
 	int n;
+	u32 ssr_tmp[] = TAH_SS_DEFAULT;
 
 	/* Reset TAH */
 	out_be32(&p->mr, TAH_MR_SR);
 	n = 100;
-	while ((in_be32(&p->mr) & TAH_MR_SR) && n)
-		--n;
+	while ((in_be32(&p->mr) & TAH_MR_SR) && n) --n;
 
 	if (unlikely(!n))
-		printk(KERN_ERR "%s: reset timeout\n",
-			ofdev->dev.of_node->full_name);
+		printk(KERN_ERR "%s: reset timeout\n", ofdev->dev.of_node->full_name);
+
+	/* 10KB TAH TX FIFO accommodates the max MTU of 9000 */ // ECO
+	out_be32(&p->mr, TAH_MR_CVR | TAH_MR_ST_768 | TAH_MR_TFS_10KB | TAH_MR_DTFP | TAH_MR_DIG);
+	//out_be32(&p->mr, TAH_MR_CVR | TAH_MR_ST_256 | TAH_MR_TFS_10KB | TAH_MR_DTFP | TAH_MR_DIG);
 
-	/* 10KB TAH TX FIFO accommodates the max MTU of 9000 */
-	out_be32(&p->mr,
-		 TAH_MR_CVR | TAH_MR_ST_768 | TAH_MR_TFS_10KB | TAH_MR_DTFP |
-		 TAH_MR_DIG);
+	/* Re-initialize SSRx values */ // (ECO)
+	//for (n=0; n < TAH_NO_SSR; n++) dev->ssr_order[n] = n;
+    for (n = 0; n < TAH_NO_SSR; n++) tah_set_ssr(ofdev, n, ssr_tmp[n]);
 }
 
-int tah_get_regs_len(struct platform_device *ofdev)
-{
-	return sizeof(struct emac_ethtool_regs_subhdr) +
-		sizeof(struct tah_regs);
+int tah_get_regs_len(struct platform_device *ofdev) {
+	return sizeof(struct emac_ethtool_regs_subhdr) + sizeof(struct tah_regs);
 }
 
-void *tah_dump_regs(struct platform_device *ofdev, void *buf)
-{
+void *tah_dump_regs(struct platform_device *ofdev, void *buf) {
 	struct tah_instance *dev = platform_get_drvdata(ofdev);
 	struct emac_ethtool_regs_subhdr *hdr = buf;
 	struct tah_regs *regs = (struct tah_regs *)(hdr + 1);
 
 	hdr->version = 0;
-	hdr->index = 0; /* for now, are there chips with more than one
-			 * zmii ? if yes, then we'll add a cell_index
-			 * like we do for emac
-			 */
+	hdr->index = 0; 
+	/* for now, are there chips with more than one zmii ? if yes, then we'll add a cell_index
+	 * like we do for emac */
 	memcpy_fromio(regs, dev->base, sizeof(struct tah_regs));
 	return regs + 1;
 }
 
-static int tah_probe(struct platform_device *ofdev)
-{
+void tah_set_ssr(struct platform_device *ofdev, int index, int seg_size) {
+	struct tah_instance *dev = dev_get_drvdata(&ofdev->dev);
+	struct tah_regs __iomem *p = dev->base;
+	//u32 ssr_tmp[TAH_NO_SSR];
+	//int i, j = 0;
+
+	if ((index < 0) || (index > 5)) return;
+	mutex_lock(&dev->lock);
+	/// TAH segment size reg defines the number of half words */
+	out_be32(&p->ssr0 + index, SS_2_TAH_SSR(seg_size >> 1));
+
+	dev->ssr[index] = seg_size & 0x3ffe;
+/*
+	// Sort the TAH_SSRx values and store the index in ssr_order array in high-to-low order
+	for (i=0; i < TAH_NO_SSR; i++) {
+		ssr_tmp[i] = dev->ssr[i];	
+		dev->ssr_order[i] = i;
+	}
+	for (i =0; i < (TAH_NO_SSR-1); i++)			// Simple bubble short
+		for (j = i+1; j < TAH_NO_SSR; j++)
+			if (ssr_tmp[i] < ssr_tmp[j]) {
+				swap(ssr_tmp[i], ssr_tmp[j]);
+				swap(dev->ssr_order[i], dev->ssr_order[j]);
+			}
+#if 0
+	printk(KERN_DEBUG "%s: Setting TAH_SSR%d[SS] to %d\n", ofdev->dev.of_node->full_name, index, 
+			TAH_SSR_2_SS(in_be32(&p->ssr0+index)));
+	printk("SSRx array: ");
+	for (i = 0; i < TAH_NO_SSR; i++) printk("%d ", ssr_tmp[i]);
+    printk("\n");
+
+	printk("SSRx order: ");
+	for (i = 0; i < TAH_NO_SSR; i++) printk("%d ", dev->ssr_order[i]);
+	printk("\n");
+#endif
+*/
+	mutex_unlock(&dev->lock);
+}
+
+u32 tah_get_ssr(struct platform_device *ofdev, int index) {
+	struct tah_instance *dev = dev_get_drvdata(&ofdev->dev);
+	struct tah_regs __iomem *p = dev->base;
+	u32 ret = 0;
+	
+	if ((index < 0) || (index > 5)) return 0;
+    mutex_lock(&dev->lock);
+	ret = (in_be32(&p->ssr0 + index));
+	mutex_unlock(&dev->lock);
+	return ret;
+}
+
+static int tah_probe(struct platform_device *ofdev) {
 	struct device_node *np = ofdev->dev.of_node;
 	struct tah_instance *dev;
 	struct resource regs;
@@ -97,37 +140,28 @@
 
 	rc = -ENOMEM;
 	dev = kzalloc(sizeof(struct tah_instance), GFP_KERNEL);
-	if (dev == NULL)
-		goto err_gone;
-
+	if (dev == NULL) goto err_gone;
 	mutex_init(&dev->lock);
 	dev->ofdev = ofdev;
 
 	rc = -ENXIO;
 	if (of_address_to_resource(np, 0, &regs)) {
-		printk(KERN_ERR "%s: Can't get registers address\n",
-		       np->full_name);
+		printk(KERN_ERR "%s: Can't get registers address\n", np->full_name);
 		goto err_free;
 	}
 
 	rc = -ENOMEM;
-	dev->base = (struct tah_regs __iomem *)ioremap(regs.start,
-					       sizeof(struct tah_regs));
+	dev->base = (struct tah_regs __iomem *)ioremap(regs.start, sizeof(struct tah_regs));
 	if (dev->base == NULL) {
-		printk(KERN_ERR "%s: Can't map device registers!\n",
-		       np->full_name);
+		printk(KERN_ERR "%s: Can't map device registers!\n", np->full_name);
 		goto err_free;
 	}
 
 	platform_set_drvdata(ofdev, dev);
-
 	/* Initialize TAH and enable IPv4 checksum verification, no TSO yet */
 	tah_reset(ofdev);
-
-	printk(KERN_INFO
-	       "TAH %s initialized\n", ofdev->dev.of_node->full_name);
+	printk(KERN_INFO "TAH %s initialized\n", ofdev->dev.of_node->full_name);
 	wmb();
-
 	return 0;
 
  err_free:
@@ -136,27 +170,18 @@
 	return rc;
 }
 
-static int tah_remove(struct platform_device *ofdev)
-{
+static int tah_remove(struct platform_device *ofdev) {
 	struct tah_instance *dev = platform_get_drvdata(ofdev);
-
+	//platform_set_drvdata(ofdev, NULL);	//ECO
 	WARN_ON(dev->users != 0);
-
 	iounmap(dev->base);
 	kfree(dev);
-
 	return 0;
 }
 
-static const struct of_device_id tah_match[] =
-{
-	{
-		.compatible	= "ibm,tah",
-	},
-	/* For backward compat with old DT */
-	{
-		.type		= "tah",
-	},
+static const struct of_device_id tah_match[] = {
+	{	.compatible	= "ibm,tah", },
+	{	.type		= "tah", },			/* For backward compat with old DT */
 	{},
 };
 
@@ -169,12 +194,10 @@
 	.remove = tah_remove,
 };
 
-int __init tah_init(void)
-{
+int __init tah_init(void) {
 	return platform_driver_register(&tah_driver);
 }
 
-void tah_exit(void)
-{
+void tah_exit(void) {
 	platform_driver_unregister(&tah_driver);
 }
diff -Naur a/drivers/net/ethernet/ibm/emac/tah.h b/drivers/net/ethernet/ibm/emac/tah.h
--- a/drivers/net/ethernet/ibm/emac/tah.h	2019-01-09 16:16:45.000000000 +0000
+++ b/drivers/net/ethernet/ibm/emac/tah.h	2017-07-07 08:37:22.765108480 +0000
@@ -38,20 +38,24 @@
 
 
 /* TAH device */
-struct tah_instance {
-	struct tah_regs __iomem		*base;
+/* Default MTU values for common networks. Note that the first value may not correct as 
+ * we will use the device's current MTU for SSR0 */
+#define TAH_SS_DEFAULT_9K	{9000, 4080, 1500, 1006, 576, 68}
+#define TAH_SS_DEFAULT_4K	{4080, 1500, 1400, 1006, 576, 68}
+#define TAH_SS_DEFAULT		{1500, 1400, 1280, 1006, 576, 68}
 
-	/* Only one EMAC whacks us at a time */
-	struct mutex			lock;
+#define TAH_NO_SSR	6
+struct tah_instance {
+	struct tah_regs __iomem	*base;
 
-	/* number of EMACs using this TAH */
-	int				users;
+	u32 			ssr[TAH_NO_SSR];	// Current setting for TAHx_SSRx
+	//u32 			ssr_order[TAH_NO_SSR];	// Indexes of ordered TAH_x_SSRx values, high to low
 
-	/* OF device instance */
-	struct platform_device		*ofdev;
+	struct mutex		lock;	// Only one EMAC whacks us at a time
+	int			users;	// number of EMACs using this TAH
+	struct platform_device	*ofdev;	// OF device instance
 };
 
-
 /* TAH engine */
 #define TAH_MR_CVR		0x80000000
 #define TAH_MR_SR		0x40000000
@@ -69,6 +73,8 @@
 #define TAH_MR_TFS_10KB		0x00a00000
 #define TAH_MR_DTFP		0x00100000
 #define TAH_MR_DIG		0x00080000
+#define TAH_SSR_2_SS(val)	(((val) >> 17) & 0x1fff)
+#define SS_2_TAH_SSR(s)		(((s) & 0x1fff) << 17) 		// s is number of half words
 
 #ifdef CONFIG_IBM_EMAC_TAH
 
@@ -79,6 +85,8 @@
 void tah_reset(struct platform_device *ofdev);
 int tah_get_regs_len(struct platform_device *ofdev);
 void *tah_dump_regs(struct platform_device *ofdev, void *buf);
+void tah_set_ssr(struct platform_device *ofdev, int index, int seg_size);
+u32 tah_get_ssr(struct platform_device *ofdev, int index);
 
 #else
 
@@ -90,6 +98,6 @@
 # define tah_get_regs_len(x)	0
 # define tah_dump_regs(x,buf)	(buf)
 
-#endif				/* !CONFIG_IBM_EMAC_TAH */
+#endif	/* !CONFIG_IBM_EMAC_TAH */
 
 #endif /* __IBM_NEWEMAC_TAH_H */
